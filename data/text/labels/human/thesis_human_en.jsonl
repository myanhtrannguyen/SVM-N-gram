{"ID": "00010001", "file_name": "Design and develop website for travel social network", "content": "Along with the process of globalization and the development of information technology, the internet in the world and Vietnam has almost been covered. The participation of individuals on the internet is increasingly active and the need to share information and connect with friends is an essential need to promote the birth and development of social networks.", "label": "human"}
{"ID": "00010002", "file_name": "Design and develop website for travel social network", "content": "Currently, social networks are developing extremely brilliantly, and the num ber of people accessing and registering members in social networks is increasing.", "label": "human"}
{"ID": "00010003", "file_name": "Design and develop website for travel social network", "content": "Typically, some social networking websites are Facebook or Twitter. Even so, user demand is still very high and specificity is even more necessary.", "label": "human"}
{"ID": "00010004", "file_name": "Design and develop website for travel social network", "content": "After the COVID pandemic is over, domestic tourism activities have witnessed a boom, represented by the strong growth of visitors over the months. According to the Vietnam National Administration of Tourism, in May and June 2022, the number of domestic tourists reached 12 million and 12.2 million respectively. This is the highest number of domestic visitors in a month in Vietnam in recent years. As a result, the number of domestic tourists in the first 6 months of 2022 reached 60.8 million (nearly 1.4 times higher than the same period in 2019), of which about 8.3 million guests stayed. Total revenue from tourists is estimated at 265,000 billion VND.", "label": "human"}
{"ID": "00010005", "file_name": "Design and develop website for travel social network", "content": "According to Digital’s statistics, as of June 2021, the number of Internet usersin Vietnam is nearly 70 million, an increase of 0.8% in the period 2020-2021 (ac counting for more than 70% of the population); The number of social network users in Vietnam is nearly 76 million, an increase of nearly 10 million people within a year (equivalent to 73.7% of the population). Every day, Vietnamese users spend up to 7 hours participating in Internet-related activities.", "label": "human"}
{"ID": "00010006", "file_name": "Design and develop website for travel social network", "content": "If Reddit is a website specializing in updating social news, LinkedIn is a place to connect employers and candidates, then I aim to build a social networking sitespecializing in sharing photos or videos about tourist attractions, and user experi ences. That’s why I chose the topic \"Design and develop a website for travel social network\" for my graduation thesis, and I named this social network Vifrin.", "label": "human"}
{"ID": "00010007", "file_name": "Design and develop website for travel social network", "content": "The goal of the project is to build a social network to create a centralized en vironment with an intuitive interface that is easy to use, as well as can simplifyplaces, and share their experiences after interesting trips. The system also allows users to search for places of interest to get useful information about that place, as well as featured hotels in that location. In addition, the system can be easily further developed on mobile platforms (Android and IOS).", "label": "human"}
{"ID": "00010008", "file_name": "Design and develop website for travel social network", "content": "Social networking site aims to create a friendly, reliable environment, making it easy for users to find useful information about the place they want to go. Users can rate the place through comments, all comments are real-time, helping the rating of the place to be updated as quickly as possible. What’s more, tourist destinations also suggest featured hotels, making it easier for users to choose accommodation when starting a trip. Users can follow other users when they share an experience, enter reviews, to express their feelings about that experience. The system is suitable for many different audiences of many ages, as long as that person needs to travel.", "label": "human"}
{"ID": "00010009", "file_name": "Design and develop website for travel social network", "content": "To meet the goals of the solution, the system needs to have good performance and easily integrate many different technologies. Vifrin is a web product, built on the client-server model, which divides the application into two components. The server is a place to provide APIs that clients can use to interact with data. The advantages of this model are reflected in centralization, security, scalability, and accessibility. The server side will use the Java Spring Boot Framework designedaccording to the microservices architecture, with many outstanding features compared to mono service, increasing the ability to test, maintain, and scale the appli cation. The client-side will use the ReactJS library to create the user interface, use redux, and redux-saga to manage the global state, increase the scale when addingnew features to the system, easier to test execution. After the application develop ment process, I completed the web version with all the features. The application has been deployed on Microsoft Azure servers. When developing and deploying, I use docker to help install the environment and run the project faster and moreprofessionally.For the rest of this graduation thesis, it will be presented in the following se quence:", "label": "human"}
{"ID": "00010010", "file_name": "Design and develop website for travel social network", "content": "Chapter 2 Survey: In this chapter, I would like to show some reviews about other methods and some main functions of this software.", "label": "human"}
{"ID": "00010011", "file_name": "Design and develop website for travel social network", "content": "Chapter 3 Methodology: This chapter covers system design, structural modeling, behavior modeling, overview architecture design, class design, database design, and user interface design.", "label": "human"}
{"ID": "00010012", "file_name": "Design and develop website for travel social network", "content": "Chapter 4 System analysis and design: After researching user demand as well as doing some surveys, I started to design and implement the system.", "label": "human"}
{"ID": "00010013", "file_name": "Design and develop website for travel social network", "content": "Chapter 5 System deployment and evaluation: This chapter talks about test re sults and actual implementation status Chapter 6 Solution and contribution: The main content of this chapter will be about proceeding to build the system and describing the results achieved.", "label": "human"}
{"ID": "00010014", "file_name": "Design and develop website for travel social network", "content": "Chapter 7 Conclusion: The final chapter presents the points that have worked and failed in the project, summarizes the development results, and analyzes new directions that allow improvement and upgrading of the system.2.1 Status survey The tourism industry has a very large role, and the demand for users is high.", "label": "human"}
{"ID": "00010015", "file_name": "Design and develop website for travel social network", "content": "Although the number of social networks in Vietnam is very high, there is still nospecialized social networking site for tourism. We can know Facebook as the high est shared social network in the world, we can create groups for people to exchange, but this social network doesn’t suggest prominent places. In addition, the amount of information on Facebook is very large and diverse. Therefore, it is difficult for users to find information about the tourist destination they want to find. There are also sites like TripAdvisor or Traveloka, which are quite famous travel review sites, but mainly focus on hotel room rentals and travel amenities, not on sharing the feeling of users. Therefore, Vifrin was born to create a social networking site focused on sharing experiences through trips, recommending outstanding places, or highly rated hotels in that place to help users make the right decisions, and get great experiences when making a trip.", "label": "human"}
{"ID": "00010016", "file_name": "Design and develop website for travel social network", "content": "From the analysis of the above applications and platforms, I can draw the agents and functions according to the agent required in my system:", "label": "human"}
{"ID": "00010017", "file_name": "Design and develop website for travel social network", "content": "Admin As a user who logs in to the system with an administrator role, he has full control over the system Overview of functions: Functions serve 3 agents.", "label": "human"}
{"ID": "00010018", "file_name": "Design and develop website for travel social network", "content": "User: when registering an account, the default permission is a user with func tions such as login, logout, manage posts, rate, comment, update profile, and search.", "label": "human"}
{"ID": "00010019", "file_name": "Design and develop website for travel social network", "content": "Admin: view, delete user accounts, manage destinations, hotels, view statistics about the total number of users, posts of the system.Figure 2.1: General usecasea, Detailed use case diagram for \"Post module\" Figure 2.2: Post module Create a post: Users can share feelings, photos, videos about a place through posts Get lists post: Users get list personal posts or other user’s post Edit a post: Users can edit personal posts Delete a post: Users can delete personal posts Aggregate feeds: Users can see the posts they are interested in by following other users or system can suggest posts.Figure 2.3: Comment module Comment a post: Users can comment on post Comment a destination: Users can comment on destination c, Detailed use case diagram for \"Like module\" Figure 2.4: Like module Like a post: Users can like post Unlike a post: Users can unlike post•Unlike a post: Users can unlike comment d, Detailed use case diagram for \"Rate module\" Figure 2.5: Rate module Rate a destination: Users can rate destination from 1 star to 5 star e, Detailed use case diagram for \"Search module\" Figure 2.6: Search module Search hotels: Users can search hotels with keyword on the system Search destinations: Users can search destinations Search users: Users can search other usersFigure 2.7: Destination module Get detail of a destination: Users can get information of destination: name, description, media, rating, comment.", "label": "human"}
{"ID": "00010020", "file_name": "Design and develop website for travel social network", "content": "Main scenario (success)ON Actors Actions 1Guest Chooses login function 2System Display login form interface 3Guest Enter login information, press the login button 4System Check validity of information 5System Announces successful registration and redirects to the home page Extensions None Alternative scenario ON Actors Actions 1System If input information is not valid, the system report an error asking the user to re-enter itTable 2.4: Description of use case \"Create a post\" Use case Create a post Code UC03 Actor User Description An user post with photos, videos, and can add locations Pre-condition An user has logged into the system.", "label": "human"}
{"ID": "00010021", "file_name": "Design and develop website for travel social network", "content": "Main scenario (success)ON Actors Actions 1User Click the \"Create post\" button, and the 2System Display create post form interface 3User Enters the content of the post, uploads files, add destination and then click \"Post\" button.", "label": "human"}
{"ID": "00010022", "file_name": "Design and develop website for travel social network", "content": "Use case Comment a post Code UC04 Actor User Description An user comments on created post Pre-condition An user has logged into the system.", "label": "human"}
{"ID": "00010023", "file_name": "Design and develop website for travel social network", "content": "Main scenario (success)ON Actors Actions 1User Click on the text box \"Enter comments...\" 2System Display create post form interface 3User Enters the content of the post, uploads files, add destination and then click \"Post\" button.", "label": "human"}
{"ID": "00010024", "file_name": "Design and develop website for travel social network", "content": "Extensions None Alternative scenario ON Actors Actions 1System If the request fails, the system notifies the user.Table 2.6: Description of use case \"Search\" Use case Search Code UC05 Actor User Description An user search destination, hotel or other user Pre-condition An user has logged into the system.", "label": "human"}
{"ID": "00010025", "file_name": "Design and develop website for travel social network", "content": "Post-condition An user successfully searched for the necessary information Main scenario (success)ON Actors Actions 1User Click on the search input 2System Focus input 3User Enter keyword to search 4System Show part of recent search results 5User Click on the search results 6System Redirect to detail page Extensions None Alternative scenario ON Actors Actions 1User Click \"Show all result\".", "label": "human"}
{"ID": "00010026", "file_name": "Design and develop website for travel social network", "content": "Post-condition An user successfully rated for the destination Main scenario (success)ON Actors Actions 1User User go to detail destination page, and select rating input box 2System Focus input 3User Enter a comment and select a review score, then click post button 4System Show comment at the top of list comments Extensions NoneTable 2.8: Description of use case \"Explore destinations\" Use case Explore destinations Code UC05 Actor User Description An user can see suggested destinations.", "label": "human"}
{"ID": "00010027", "file_name": "Design and develop website for travel social network", "content": "The system will work on any Web browser User-friendly interface, easy to use Fast data retrieval, good data storage capacity Quick and convenient search High security Easy to expand to add new featuresIn this chapter, I present about the technologies used in the project, the reasons for their use, their advantages and disadvantages.", "label": "human"}
{"ID": "00010028", "file_name": "Design and develop website for travel social network", "content": "Java Spring BootJava Spring Framework (Spring Framework) is a popular, open source, the enterprise level framework for creating standalone, production-grade applications that run on the Java Virtual Machine (JVM)  Java Spring Boot (Spring Boot) is a tool that makes developing the web application and microservices with Spring Framework faster and easier through three core capabilities:", "label": "human"}
{"ID": "00010029", "file_name": "Design and develop website for travel social network", "content": "Spring Framework offers a dependency injection feature that lets objects define their dependencies that the Spring container later injects into them. This enablesdevelopers to create modular applications consisting of loosely coupled compo nents that are ideal for microservices and distributed network applications.", "label": "human"}
{"ID": "00010030", "file_name": "Design and develop website for travel social network", "content": "Spring Framework also offers built-in support for typical tasks that an application needs to perform, such as data binding, type conversion, validation, excep tion handling, resource and event management, internationalization, and more. Itintegrates with various Java EE technologies such as RMI (Remote Method Invo cation), AMQP (Advanced Message Queuing Protocol), Java Web Services, andothers. In sum, Spring Framework provides developers with all the tools and fea tures they need to create loosely coupled, cross-platform Java EE applications that run in any environment.Redis is an open-source key-value database. Data in a key-value database has two parts: the key and the value. Because Redis can accept keys in a wide range of formats, operations can be executed on the server and reduce the client’s workload.", "label": "human"}
{"ID": "00010031", "file_name": "Design and develop website for travel social network", "content": "Redis has excellent read-write performance, fast IO read-write speed from memory, and supports read-write frequencies of more than 100k + per second.", "label": "human"}
{"ID": "00010032", "file_name": "Design and develop website for travel social network", "content": "Redis supports data persistence, AOF and RDBRedis supports master-slave replication. The host will automatically synchro nize the data to the slave, allowing read-write separation.", "label": "human"}
{"ID": "00010033", "file_name": "Design and develop website for travel social network", "content": "Master-slave synchronization, data synchronization will be delayed. If the host goes down and some data is not synchronized to the slave before the shutdown, the data will be inconsistent.", "label": "human"}
{"ID": "00010034", "file_name": "Design and develop website for travel social network", "content": "It is difficult to support on capacity expansion. When the cluster capac ity reaches the upper limit, the on capacity expansion will become very complex. When the system goes on, enough space must be ensured, which causes a great waste of resources.Figure 3.3: Cloudinary (Source: Internet).", "label": "human"}
{"ID": "00010035", "file_name": "Design and develop website for travel social network", "content": "Cloudinary is an end-to-end image- and video management solution for web sites and mobile apps, covering everything from image and video uploads, storage,manipulations, and optimizations to delivery. With Cloudinary, we can easily up load images and videos to the cloud and automate smart manipulations of those media without installing any other software. Cloudinary then seamlessly deliversyour media through a fast content delivery network (CDN), optimized with the in dustry’s best practices. Additionally, Cloudinary offers comprehensive APIs andadministration capabilities, which you can easily integrate with your web and mo bile apps. Cloudinary has only one limitation, that is we only have 25 GB of storage for the free version.", "label": "human"}
{"ID": "00010036", "file_name": "Design and develop website for travel social network", "content": "PostgreSQL PostgreSQL is an open-source relational database management system ( DBMS ) developed by a worldwide team of volunteers.  PostgreSQL is not controlled by any corporation or other private entity and the source code is available free of charge. PostgreSQL outperforms MongoDB in almost all performance test cases.", "label": "human"}
{"ID": "00010037", "file_name": "Design and develop website for travel social network", "content": "PostgreSQL source code is freely available under an open source license. This allows you the freedom to use, modify, and implement it as per your business needs.", "label": "human"}
{"ID": "00010038", "file_name": "Design and develop website for travel social network", "content": "PostgreSQL supports geographic objects so it can be used as a geospatial data store for location-based services and geographic information systems.", "label": "human"}
{"ID": "00010039", "file_name": "Design and develop website for travel social network", "content": "Postgres is not owned by one organization. So, it has had trouble getting its name out there despite being fully featured and comparable to other DBMS systems Changes made for speed improvement require more work than MySQL as PostgreSQL focuses on compatibility Many open source apps support MySQL, but may not support PostgreSQL On performance metrics, it is slower than MySQL.", "label": "human"}
{"ID": "00010040", "file_name": "Design and develop website for travel social network", "content": "Apache Kafka is a distributed publish-subscribe messaging system that receives data from disparate source systems and makes the data available to target systemsin real-time. Kafka is written in Scala and Java and is often associated with real time event stream processing for big data.", "label": "human"}
{"ID": "00010041", "file_name": "Design and develop website for travel social network", "content": "There are many benefits when using kafka Kafka is highly scalable. Kafka is a distributed system, which can be scaled quickly and easily without incurring any downtime. Apache Kafka can handle many terabytes of data without incurring much at all in the way of overhead.", "label": "human"}
{"ID": "00010042", "file_name": "Design and develop website for travel social network", "content": "Kafka is highly reliable. Kafka replicates data and can support multiple subscribers. Additionally, it automatically balances consumers in the event of failure. That means that it’s more reliable than similar messaging services avail able.", "label": "human"}
{"ID": "00010043", "file_name": "Design and develop website for travel social network", "content": "Kafka offers high performance. Kafka delivers high throughput for both pub lishings and subscribing, utilizing disk structures that are capable of offering constant levels of performance, even when dealing with many terabytes of stored messages.", "label": "human"}
{"ID": "00010044", "file_name": "Design and develop website for travel social network", "content": "Docker is a virtual machine, but unlike virtual machines that create a completelyseparate operating system. Docker allows the applications to use the Linux ker nel of the same machine on which it is installed. By using this benefit, it can make the applications ready to ship to other machines running the same Linux OS withsomewhat different configurations. Through Docker DevOps, developers can eas ily pack all parts of an application like libraries and other dependencies and ship it out as a single package.", "label": "human"}
{"ID": "00010045", "file_name": "Design and develop website for travel social network", "content": "ReactFigure 3.7: React (Source: Internet)library. It works best to build user interfaces by combining sections of code (com ponents) into full websites. Originally built by Facebook, Meta and the open-source community now maintain it. One of the good things about React is that you can useit as much or as little as you want! For example, we can build your entire site in Re act or just use one single React component on one page. There are many other famous FE libraries or frameworks such as Vuejs, AngularJs. So why would we choose React instead of Vue.js, or vice versa? The big bonus to React is that it’s maintained by Meta – a tech giant. Such strong support from a main player in the tech world provides React the stability and long-term support that most librariesjust don’t have. This gives developers the confidence that React won’t be depre cated in the near future, and developments will continue to improve it. Besides,React is better than Angular due to its virtual DOM implementation and render ing optimizations. Migrating between React’s versions is quite easy, too; you don’t need to install updates one by one, as in the case of Angular. Finally, with React, developers have myriads of existing solutions they can use 3.2.2 Redux saga Figure 3.8: Redux saga (Source: Internet).", "label": "human"}
{"ID": "00010046", "file_name": "Design and develop website for travel social network", "content": "Redux Saga is a middleware library used to allow a Redux  store to inter act with resources outside of itself asynchronously. This includes making HTTPrequests to external services, accessing browser storage, and executing I/O operations. These operations are also known as side effects. Redux Saga helps to orga nize these side effects in a way that is easier to manage.", "label": "human"}
{"ID": "00010047", "file_name": "Design and develop website for travel social network", "content": "Antd is a collection of React components built according to the design standards of the Ant UED Team. Similar to the Material Design standard, Ant provides most of the common components in modern web applications, like Layout, Button, Icon, DatePicket, and more. . . Besides that, Ant also has its interesting components, like the LocaleProvider that allows you to change the language across the application.", "label": "human"}
{"ID": "00010048", "file_name": "Design and develop website for travel social network", "content": "Ant currently has over 51k stars on Github. Ant Design for React can be considered as a collection of most React libraries. It meets most of your project’s requirements without you having to install any additional libraries.", "label": "human"}
{"ID": "00010049", "file_name": "Design and develop website for travel social network", "content": "Antd is a FE-friendly library of pre-provided components that make it easy forprogrammers to customize without spending much time and effort while still en suring quality.4.1 Architecture design 4.1.1 Software architecture selection Figure 4.1: Overall architecture of the systemThe figure above depicts the architecture of the system that will include fron tend and backend. The frontend has 2 parts, an admin page and a user page which use ReactJs to build UI/UX components and interact with the backend through Rest APIs. The global state in ReactJS is managed by the redux-saga, which makes components easier to test, and the application architecture is cleaner. Components are injected only when used, resulting in better performance. I have developed a tool to make code faster, and easier to interact with API. This will be explained in more detail in chapter 4. The backend uses a microservice system , divided into 11 services. Each service is implemented separately, to ensure that they canwork independently of each other. They are all connected to the database as Post greSQL, each service will be attached to manipulate a table in the database. Allrequests from the front end using restful API will be handled by the backend gate way service. Gateway service is supported by java spring boot in configuring whicheach other by listening to Kafka queues. That means those services will subscribeto a queue to listen to and handle events sent by other services. In addition, the sys tem uses Redis to store cache queries. To create an environment for development and deploy, I used docker and docker-compose to manage the config and version of environment.", "label": "human"}
{"ID": "00010050", "file_name": "Design and develop website for travel social network", "content": "Auth Service : implement the registration, login API User Service : update user information, follow other users Post Service : add, edit, delete, view, save postsComment Service : take care of APIs related to adding, editing, deleting com ments Like Service : like the post or like the comment Destination Service : responsible for tourist destination functions Hotel Service : responsible for hotel functions Feed Service : aggregate feeds for users Media Service : interact with CDN to save media Search Service : responsible for the function of returning search results Chat Service : manage chats between users Docker : run services like database, Kafka and deploy service into containers Cloudinary : storage of multimedia files (photos, videos) Redis : save information on cache, serve to save some important information and retrieve information quicklyKafka : assume the role of communication between services, handle asyn chronous events.", "label": "human"}
{"ID": "00010051", "file_name": "Design and develop website for travel social network", "content": "With both admin and user sites, I use ReactJS to build screens. I use redux saga to handle asynchronous logic. This layer also handles the business logic, we won’t handle too much logic in screens/components(views). The structure of the front-end is designed with folders and functions as shown:4.1.2 Overall design Figure 4.3: Package diagram of post service The packages of service will have the same structure as a post-service (abovefigure). Post-service will use 2 packages (i) com.vifrin.common : where the system’s shared data types are stored (eg entity, response structure definition, sys tem’s shared constant functions ...). These data types are not divided into each service, but centralized management in one place will have certain benefits. Forexample, when we change a field in another database, the definition of the entity changes/calls the result of this service from service if the management is dis tributed in each service, then just change the classes in the package. in this package, (ii)com.virgin.feign : used to call API from 1 service from another service, must finish calling, get results, then the program will continue to run. This is differentevent, there is no need to wait for the result of the action of firing the event on Kafka. Next, we will clarify the function of the sub-packages in each service.", "label": "human"}
{"ID": "00010052", "file_name": "Design and develop website for travel social network", "content": "client: define API to call between services. For example, we can using @GetMapping(\"/users\"), an anotation imported by org.springframework.cloud.// open feign.FeignClient to call API of user service from another service.", "label": "human"}
{"ID": "00010053", "file_name": "Design and develop website for travel social network", "content": "config: contain common config of web (page size of list, default page num ber,..), redis, operator with data base( create, read, update, delete).", "label": "human"}
{"ID": "00010054", "file_name": "Design and develop website for travel social network", "content": "util: common utils( operations with redis,..) dto: This only contain data, not business logic. In this system, when we get result from DB, data will tranfer to store in DTO.", "label": "human"}
{"ID": "00010055", "file_name": "Design and develop website for travel social network", "content": "payload: define payload of request which sent from client side type: common type of system( action type, notification type,...) entity: define field property and relationship between them in database + com.vifrin.post:", "label": "human"}
{"ID": "00010056", "file_name": "Design and develop website for travel social network", "content": "config: custom sercurity config, for example check token before handle re quest message: define message to send to kafka mapper: convert results when query from database to dto exception: contains error configurations that will be returned to the user when the program encounters an errorservice: define the functions for the business logic, using the help of the repos itoryFigure 4.4: Detail package diagram of post serviceThe main feature of this design is dependency injection. This is a very famous technique in software design. Spring Boot is built on top of the Spring Framework, it uses XML and annotation to create stand-alone, production-grade Spring based applications more easily. Dependency Injection is evident in the architectureof spring boots. As shown in the figure, class Sercurity Config is similar to a mid dleware, used to check the requirements of the request. Class Sercurity Configextends from WebSecurityConfigurerAdapter, which is supported by spring frame work. All requests must pass the check of this class before going to the next handler.", "label": "human"}
{"ID": "00010057", "file_name": "Design and develop website for travel social network", "content": "This class injects filters: CustomAuthorizationFilter (for decode token in header of request). I will take another example. Class Post Repository is injected into class Post Service . Of course, we can inject it with other repositories. All repositories extend from class JpaRepository , which supports writing very concise queries.", "label": "human"}
{"ID": "00010058", "file_name": "Design and develop website for travel social network", "content": "User interface designThe system interface is designed with a 16: 9 ratio, 1920x1080 resolution. Ap plication support screen size for laptops, tablets, and mobile. The layout includes a header, and content components arranged as shown below.The header will include a logo, search box, and navigation bar ( home, explore, profile ). The colors will be mixed according to the main color tone to increase the consistency of the system. The table below will present the uniform information of the interface.", "label": "human"}
{"ID": "00010059", "file_name": "Design and develop website for travel social network", "content": "Each comment can have multiple photos. Posts and comments can be liked. The system has many destinations, each destination can have many hotels. Users can rate that destination through review scores or comments. The administrator is theperson who manages the normal users, the destination, and the hotels of that desti nation.", "label": "human"}
{"ID": "00010060", "file_name": "Design and develop website for travel social network", "content": "Database design The social network system uses a relational database (SQL) with the advantages mentioned in the previous section. Database using PostgreSQL technology.Description of the tables in the database Users Store information about users participating in the system, including name, username, avatar url,..", "label": "human"}
{"ID": "00010061", "file_name": "Design and develop website for travel social network", "content": "Post Store posts that user shares Comment Store comments of destination, post Media Store information of media such as url, width, height,...Store destinations information Hotel Store hotels information c, Detail database design + Users Table 4.2: User table ON Field name Field type Primary keyForeign key Description 1 id longxUser code 2 username nchar(100) Username 3 password nchar(100) Password 4 avatar_url nchar(500) Avatar url 5 is_enabled boolean Account status 6 last_login DateTime Last time login 7 role nchar(100) Account role 8 created_at DateTime Created time 9 updated_at DateTime Updated time + Profile Table 4.3: Profile table ON Field name Field type Primary keyForeign key Description 1 user_id longxUser code 2 email nchar(100) Email 3 phone_number nchar(100) Phone number 4 bio nchar(100) Biography 5 full_name nchar(100) Full name 6 gender nchar(100) Gender 7 date_of_birth DateTime Date of birth 8 country nchar(100) Country + DestinationON Field name Field type Primary keyForeign key Description 1 id longxDestination code 2 name text Destination name 3 description text Description 4 average_score float Average score 5 longitude float Longitude 6 latitude float Latitude 7 check_in_count int Check in count 8 created_at DateTime Created time 9 updated_at DateTime Updated time + HotelON Field name Field type Primary keyForeign key Description 1 id longxDestination code 2 name text Destination name 3 description text Description 4 average_score float Average score 5 longitude float Longitude 6 latitude float Latitude 7 address text Latitude 8 price float Price 9 sales_price float Sales price 10 phone text Phone number 11 has_air_conditioner boolean Hotel has air conditioner or not12 has_bathroom boolean Hotel has bath room or not13 has_elevator boolean Hotel has eleva tor or not14 has_parking boolean Hotel has park ing or not 15 has_restaurant boolean Hotel has restaurant or not16 has_swimming_pool boolean Hotel has swim ming pool or not 17 has_wifi boolean Hotel has wifi or not 18 created_at DateTime Created time 19 updated_at DateTime Updated time 20 destination_id long Destination code + PostON Field name Field type Primary keyForeign key Description 1 id longxPost code 2 user_id longxCreator code 3 activity_id longxActivity code 4 destination_id longxDestination code 5 content text Content of post 6 config float Config: public or private + Media Table 4.7: Media table ON Field name Field type Primary keyForeign key Description 1 id long Media code 2 url nchar(500) Media url 3 mime nchar(500) Mime of media 4 name nchar(500) Name 5 width float Width 6 height float Height 7 size float Size 8 created_at DateTime Created time 9 updated_at DateTime Updated time 10 post_id longxPost code 11 user_id longxUser code 12 comment_id longxComment code 13 destination_id longxDestination code + CommentON Field name Field type Primary keyForeign key Description 1 id long Media code 2 content text Media url 3 star int Name 4 created_at DateTime Created time 5 updated_at DateTime Updated time 6 post_id longxPost code 7 user_id longxUser code 8 destination_id longxDestination code + Likes Table 4.9: Likes table ON Field name Field type Primary keyForeign key Description 1 id long Media code 2 type text Media url 3 created_at DateTime Created time 4 post_id longxPost code 5 user_id longxUser code + Activity Table 4.10: Activity table ON Field name Field type Primary keyForeign key Description 1 activity_id long Activity code 2 likes_count text Number of likes3 comments_count DateTime Number of com ments 4 post_count longxNumber of posts5 followers_count longxNumber of fol lowers + FollowON Field name Field type Primary keyForeign key Description 1 following_id long User following code 2 follower_count long User follower code 3 created_at DateTime Created time5.1 Application Building 5.1.1 Libraries and Tools Purpose Tools URL Version IDE Visual studio code  1.69IDE Intellij IDEA Com munity Edition 2022.1.2 APIs testing Postman  v9.25.2Package Man agerNPM  8.1.0Database man agerpgAdmin  4.0.0 Redux Flow MonitorRedux Dev Tools Chrome Extensions Store 4.25.0Browser Debug ging ToolChrome Dev Tools  v9.25.2 Table 5.1: List of libraries and tools used 5.1.2 AchievementAfter the research and implementation process, I have developed a tourism so cial network system that can be easily deployed to put into practice. The packaged product includes backend and frontend source code, and a docker-compose file to easily package services into containers on the server environment.Figure 5.1: Home page Figure 5.2: Search on headerFigure 5.4: Personal profile page5.2 Testing 5.2.1 Testing scenariosThe table 5.2 shows some testing scenarios for some of the most important features of the application:Register1. Input user infor mation ( username, password, retypepassword,...)1. If the input is correct, navigate to lo gin page.", "label": "human"}
{"ID": "00010062", "file_name": "Design and develop website for travel social network", "content": "Click the “Log in”button2. If the input is incorrect, an error mes sage will appear, request the user to try again.", "label": "human"}
{"ID": "00010063", "file_name": "Design and develop website for travel social network", "content": "Create post and updatefeeds1. Upload image, en ter content and select destination1. If the input is correct, notify success and update list post of user. The system will update the feeds of the users, who follow current user.", "label": "human"}
{"ID": "00010064", "file_name": "Design and develop website for travel social network", "content": "Delete post1. Hover on createdpost, select delete1. If click \"Yes\", notify success and up date list posts of user. If click \"No\", nothing happen 2. An popup confirm appear, click \"Yes\" or No\"2. If error, notify error.", "label": "human"}
{"ID": "00010065", "file_name": "Design and develop website for travel social network", "content": "Search desti nations, users or hotels1. Click search input in nav bar1. An dropdown component appear, show recent search results 2. Enter keywordChange language1. Click user drop down on right navbar.1. Switch website language 2. Select \"Change language\" button.", "label": "human"}
{"ID": "00010066", "file_name": "Design and develop website for travel social network", "content": "The system will be deployed according to the client-server model. Because the product is being tested, I do not have clear statistics on the number of users, the number of hits, or the server’s load capacity. I use the Microsoft Azure server with configs as shown:", "label": "human"}
{"ID": "00010067", "file_name": "Design and develop website for travel social network", "content": "Property Value Operating System Linux 20.04 RAM 16GB CPU core 4 cores Environment Docker, maven Table 5.4: Server deployment configuration6.1 Build micro-service system with java spring boot 6.1.1 ProblemMonolithic architecture is considered to be a traditional way of building appli cations. A monolithic application is built as a single and indivisible unit. Usually, such a solution comprises a client-side user interface, a server side-application, and a database. It is unified and all the functions are managed and served in one place.", "label": "human"}
{"ID": "00010068", "file_name": "Design and develop website for travel social network", "content": "Understanding: When a monolithic application scales up, it becomes toocomplicated to understand. Also, a complex system of code within one ap plication is hard to manage.", "label": "human"}
{"ID": "00010069", "file_name": "Design and develop website for travel social network", "content": "Making changes: It is harder to implement changes in such a large and com plex application with highly tight coupling. Any code change affects the wholesystem so it has to be thoroughly coordinated. This makes the overall devel opment process much longer.", "label": "human"}
{"ID": "00010070", "file_name": "Design and develop website for travel social network", "content": "New technology barriers: It is extremely problematic to apply new technol ogy in a monolithic application because then the entire application has to be rewritten.", "label": "human"}
{"ID": "00010071", "file_name": "Design and develop website for travel social network", "content": "Solution overview Instead of using monolithic architecture, I use micro-service architecture. A micro-services architecture breaks application down into a collection of smaller independent units. These units carry out every application process as a separateservice. So all the services have their logic and database as well as perform spe cific functions. Within a micro-services architecture, the entire functionality is split up into independently deployable modules which communicate with each other through defined methods called APIs (Application Programming Interfaces). Each service covers its scope and can be updated, deployed, and scaled independently.", "label": "human"}
{"ID": "00010072", "file_name": "Design and develop website for travel social network", "content": "Independent components: All the services can be deployed and updatedservice has an impact only on a particular service and does not influence theentire application. Also, it is much easier to add new features to a micro service application than a monolithic one.", "label": "human"}
{"ID": "00010073", "file_name": "Design and develop website for travel social network", "content": "Easier understanding: All the services can be deployed and updated inde pendently, which gives more flexibility. Secondly, a bug in one micro-service has an impact only on a particular service and does not influence the entire application. Also, it is much easier to add new features to a micro-service application than a monolithic one.", "label": "human"}
{"ID": "00010074", "file_name": "Design and develop website for travel social network", "content": "Better scalability: Another advantage of the micro-services approach is thateach element can be scaled independently. So the entire process is more cost and time-effective than with monoliths when the whole application has to be scaled even if there is no need for it. In addition, every monolith has limits in terms of scalability, so the more users you acquire, the more problems you have with your monolith. Therefore, many companies, end up rebuilding their monolithic architectures.", "label": "human"}
{"ID": "00010075", "file_name": "Design and develop website for travel social network", "content": "Results and future development directions After research and implementation, I have built a micro-service system with theJava Spring Boot framework. Spring Boot makes it very easy to deploy micro services. Each micro-service system must have a gateway, which is a softwareapplication between a client and a set of back-end micro-services. I use cloud gateway, a package of maven that helps easily to create the configuration of the gateway.", "label": "human"}
{"ID": "00010076", "file_name": "Design and develop website for travel social network", "content": "CRUD is the basic operation that most applications will be implemented. In vifrinapplication, there are many operators with posts, comments, destinations, and ho tels,...This requires a tool that helps handle some of the s of code that software developers have to type. This tool can support data processing from API and put it into view to display to the front-end.", "label": "human"}
{"ID": "00010077", "file_name": "Design and develop website for travel social network", "content": "Solution overviewRedux-saga is a library that aims to make application side effects (i.e. asyn chronous things like data fetching). At this part, we can perform a function to call API using Axios, handle logic business, and dispatch results to the global state.", "label": "human"}
{"ID": "00010078", "file_name": "Design and develop website for travel social network", "content": "This separates the view and logic, so we can generate code according to a certainCRUD form. Javascript is a language of any type. Therefore, after we get the re turned result, we can put its value in a variable called ¨data¨. The initial idea is that we will create a web page that allows entering the necessary parameters, depending on the API headers, the parameters submitted, which is the action that will generate the corresponding code. The program will also automatically create the function name, and variable name based on the action name.", "label": "human"}
{"ID": "00010079", "file_name": "Design and develop website for travel social network", "content": "Results and future development directionsAfter developing and deploying, I get a website application deployed on vercel  a platform for front-end frameworks and static sites, built to integrate with headless content, commerce, or database. After entering the necessary information, we get the code from dispatching an action to saving the data to the global state for the view to use. Below is the interface of the website:This tool can develop into a scripting language commands file (.sh) or even become an extension of IDE visual studio code.", "label": "human"}
{"ID": "00010080", "file_name": "Design and develop website for travel social network", "content": "Problem Performance is an issue that any large application has to deal with. React is a component-based library. As the application expands, the larger the number of components, the heavier the amount of data stored in the global state. Besides, if we are including large third-party libraries. We need to keep an eye on the code we are including in our bundle so that we don’t accidentally make it so large that ourapp takes a long time to load. Hence we need a mechanism to only load the neces sary stuff when the user needs it. This helps the client-side limit the processing of unnecessary tasks.", "label": "human"}
{"ID": "00010081", "file_name": "Design and develop website for travel social network", "content": "Solution overview We will apply the code splitting technique to solve this problem. In react, there is a concept called lazy load. React supports a function called lazy() and turns the component into a dynamic component, meaning that react loads the bundle containing the returned component when this component is first rendered. Redux supports replacing existing reducers with reducers that users need. With the redux-see into the store saga in redux.", "label": "human"}
{"ID": "00010082", "file_name": "Design and develop website for travel social network", "content": "Results and future development directions We will divide the application into screens, each screen will be a module that manages its state and UI. Each of these modules will export config so that the react-router side can connect between the route and the component. That is shown in the following figure:", "label": "human"}
{"ID": "00010083", "file_name": "Design and develop website for travel social network", "content": "Then the homepage will reuse the logic that we wrote in profileModule. Now, wego to the details of the function initModules :Based on what is exported from each screen module we can derive the corre sponding saga and reducer. Then we can inject it into the redux store.7.1 Conclusion Currently, there are many channels on for people to find out if a certain tourist destination is attractive or not. But currently, there is no website about tourism built in the direction of social networks. Most current travel websites tend to be commercial, often suggesting hotels or air tickets for users to buy. The interface of these websites is often difficult for people to see the information about the places they are interested in.", "label": "human"}
{"ID": "00010084", "file_name": "Design and develop website for travel social network", "content": "With the desire to build an application that helps users who love travel, like to ex perience a new feeling in a strange place, have more perspective on the advantages and disadvantages of places they have never been before quickly and conveniently.", "label": "human"}
{"ID": "00010085", "file_name": "Design and develop website for travel social network", "content": "I have built a system of social networking sites to share the travel experiences thatusers have experienced, suggesting places or hotels for them to stop. When build ing, I tried to apply design technologies, and outstanding system architectures to be able to develop more new features or deploy the system to meet a large number of users in the future. The interface of the website is user-friendly, making it easy to see the post of their favorite destination. Besides, I also develop tools to code programming faster.", "label": "human"}
{"ID": "00010086", "file_name": "Design and develop website for travel social network", "content": "By completing this project, I was able to hone myself with valuable knowledge and skills. From the smallest steps such as coming up with ideas, and surveyingother similar applications and systems, to the steps of business analysis, deploy ment and maintenance, and system upgrade, I have gained valuable experience.", "label": "human"}
{"ID": "00010087", "file_name": "Design and develop website for travel social network", "content": "valuable, useful for building and developing other applications in the future. Be sides, the learning and understanding of technologies and techniques to be able to solve the problems and problems posed by me have been applied flexibly, which isreflected in the results of the good project. this profession. This will be an impor tant and extremely valuable suitcase and knowledge so that I can be confident and steady so that I can step out of school and develop further for my future career.", "label": "human"}
{"ID": "00010088", "file_name": "Design and develop website for travel social network", "content": "Despite spending time and trying to complete the project to the maximum ex tent, due to limited capacity and limited time, the problems in the system are stillrelatively unresolved. Typically, the system’s functions are still not many. Deploy ment to the environment and put into actual use to get reviews from users is not yet available. In addition, there are still some functions and businesses that have been set out from the beginning but have not been implemented in this version. I have grasped these limitations and will overcome them in the future, to improve7.2 Future work The functions provided by the system have met the objectives of the project.", "label": "human"}
{"ID": "00010089", "file_name": "Design and develop website for travel social network", "content": "However, some functions still need to be further improved to provide a better user experience. Besides, to improve the speed of functions under heavy load in webapplications, it is necessary to learn and apply load balancing and parallel com puting techniques to increase data processing performance. I must optimize code and remove unnecessary code. In addition, I will improve more features such as chat, notifications, or stories so that users have a better experience, and have more choices when using the application. If the application is deployed, when there is enough data, I can develop suggested models like destination suggestions, post suggestions, and user suggestions.", "label": "human"}
{"ID": "00010090", "file_name": "Design and develop website for travel social network", "content": "Above is the entire content of the project \"Design and develop website for travel social network\". With limited time and limited skills and experience, my project implementation process inevitably has shortcomings. I look forward to receiving the guidance and comments of the teachers so that the system can be improved in the future. C. Walls, Spring Boot in action . Simon and Schuster, 2015.", "label": "human"}
{"ID": "00010091", "file_name": "Design and develop website for travel social network", "content": "A. Banks and E. Porcello, Learning React: functional web development with React and Redux . \" O’Reilly Media, Inc.\", 2017.", "label": "human"}
{"ID": "00010092", "file_name": "Design and develop website for travel social network", "content": "N. Alshuqayran, N. Ali, and R. Evans, “A systematic mapping study in microservice architecture,” in 2016 IEEE 9th International Conference on Service-Oriented Computing and Applications (SOCA) , IEEE, 2016, pp. 44– 51.", "label": "human"}
{"ID": "00010093", "file_name": "Design and develop website for travel social network", "content": "N. Dmitry and S.-S. Manfred, “On micro-services architecture,” Interna tional Journal of Open Information Technologies , vol. 2, no. 9, pp. 24–27, 2014.", "label": "human"}
{"ID": "00010094", "file_name": "Design and develop website for travel social network", "content": "J. Dong, Y. Zhao, and T. Peng, “A review of design pattern mining techniques,” International Journal of Software Engineering and Knowledge En gineering , vol. 19, no. 06, pp. 823–855, 2009.", "label": "human"}
{"ID": "00020001", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A de Bruijn sequence, or a positioning sequence, (of order k) is a binary se quence in which every possible length- kstring appears exactly once as a substring.", "label": "human"}
{"ID": "00020002", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The uses of de Bruijn sequences have been found in various fields. Recently, anovel application of positioning sequences has been found in quantum communication by Zhang, Oi, Lowndes, et al. They adopt such sequences into HdB sequences to develop a system for synchronizing in quantum channels. Though hav ing shown advantages against other methods , such implementation still hasdrawbacks and there is room for improvements. This thesis focuses on design ing a new constrained de Bruijn sequence and proving its efficiency against HdB sequence.", "label": "human"}
{"ID": "00020003", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Chapter 1 first briefly introduces the QKD protocol, along with the reasonablemotivation to study the synchronization mechanisms in satellite quantum chan nels. Among such mechanisms, the timing and synchronization system proposed by Zhang, Oi, Lowndes, et al. in  is analyzed to recognize its disadvantages.", "label": "human"}
{"ID": "00020004", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The main results of this thesis, which aim to improve those weaknesses, are sum marized. The organization of the whole thesis is given at the end of this chapter.", "label": "human"}
{"ID": "00020005", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Symmetric, public-key (asymmetric), and hash-based cryptography are fundamental pillars of modern cryptography. While symmetric schemes and hash func tions are less vulnerable to quantum attacks, the asymmetric schemes based onfactoring or solving the discrete logarithm problem, for example, Rivest-ShamirAdelman (RSA), Elliptic Curve Cryptography, are completely broken by a quantum adversary via Shor’s algorithm . Currently deployed public key cryptosys tems are used to establish a common secret key between two parties. Doing the same jobs, QKD enables two parties to produce a shared random secret key known only to them. Moreover, QKD can guarantee the security of communication links making them immune to quantum computer-based attacks .", "label": "human"}
{"ID": "00020006", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The first invented QKD protocols are BB84 , and E91 . Since 2005, QKDhas been initially implemented in real life. For example, in 2005, the Univer sity of Geneva and Corning Inc used a fiber optic wire of 307km. In 2007, LosAlamos National Laboratory and the National Institute of Standards and Tech nology (NIST) used the BB84 protocol over a 148.7 km optical fiber. In 2018, Quantum Xchange launched the first quantum network in the U.S., offering 1,000 km of fiber optic cable and 19 colocation centers along the Boston-to-Washington,D.C., corridor and metro hubs. However, due to the intrinsic exponential losses over optical fiber, the deployed QKD systems’ range is restricted to under 1000 km. So as to establish intercontinental secure communication links, which usually require a range over 1000 km, satellite QKD has been proposed as an alternative, with the pioneering Micius satellite. In these systems, the transmitter (satellite) andthe receiver (optical ground station) relentlessly exchange information after mea suring the quantum states. But transmitting faint quantum optical pulses between a satellite and the Earth is challenging due to high channel losses cause by volatility environments and rapid relative motion between two parties.", "label": "human"}
{"ID": "00020007", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "To deal with this problem, reliable and efficient timing and synchronization systems have been proposed in , . In this system, a classical channel is used along with the quantum channel, because of its advantage in synchronization.", "label": "human"}
{"ID": "00020008", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Based on that concept, in , a de Bruijn based timing and synchronization system is introduced using a beacon with an on-off model. In this model, a de Bruijn sequence is transmitted from the satellite to the ground for synchronization.", "label": "human"}
{"ID": "00020009", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The superiority of this system relies on the intrinsic property of the positioning sequence, which is self-located. However, in dBTS, the method  use requires 2pulse slots to modulate 1bit to balance encoding sequence with timing jitter performance. Consequently, the (information) rate of the transmitted sequence, called HdB sequence is 0.5. The formal definition of information rate is given section 2.1.2. This quantity is usually expected to be as high as possible.", "label": "human"}
{"ID": "00020010", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Moreover, to generate positioning sequences, dBTS applies Linear feedback shift register algorithm, which is fast, but depends on finding a suitable primitivepolynomial first. To determine the location of a subsequence in the whole position ing sequence, the system uses a look up table, which is a costly approach. More details about the generate algorithm, look-up table, and the analysis of this system are presented in the next chapter.", "label": "human"}
{"ID": "00020011", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Such flaws of Zhang, Oi, Lowndes, et al. ’s system, fortunately, can still be improved. That is the goal this thesis aims to. The main task here is to design a code satisfying the constraints of dBTS system.", "label": "human"}
{"ID": "00020012", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Problem Statement : Designing a high rate sequence that is capable of posi tioning and avoids long periods with no pulse This problem is similar to constructing a constrained positioning sequence. In this thesis, RdB are developed. The longest RdB sequences, not only have a highrate but also are generated and decoded rapidly. In summary, the contributions of this thesis are listed as follows:", "label": "human"}
{"ID": "00020013", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The rest of this thesis is organized as follows. Chapter 2 gives a brief introduc tion to coding theory and the application of de Bruijn sequences in such a researcharea. Other important results surrounding de Bruijn sequences and their general izations are also provided. Chapter 3 describes precisely the proposed run length limited de Bruijn sequence. For more understanding, the graph presentation of such sequences is presented. Chapter 4 studies the properties of the longest run length limited de Bruijn sequence. This chapter answers the major questions: Howlong is that sequence? What is its rate and maximal asymptotic rate? How to gen erate the longest run length limited de Bruijn sequence of order k? Also, how tolocate the position of each length ksub-string of such a sequence?The combinatorial object is one of the major focuses in coding theory, for instance, binary complementary sequences, Hadamard matrices, and de Bruijn se quences, . . . . Introduced in 1946, de Bruijn sequences have been well studied andapplied in various fields. This thesis is interested in its novel applications, synchro nization in quantum communication.", "label": "human"}
{"ID": "00020014", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In this chapter, section 2.1 gives a brief introduction to coding theory. The de Bruijn sequence, its generalizations and applications are presented in section 2.2, 2.3,and 2.4. Finally, section 2.5 analyzes the de Bruijn based timing and synchroniza tion system proposed by Zhang, Oi, Lowndes, et al. The analysis points out that thecoding schema in such a system can be improved to achieve a higher rate. More over, it’s also necessary to design algorithms that help the system to encode and decode more efficiently.", "label": "human"}
{"ID": "00020015", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Transmitting, storing, protecting data (and so on) are challenging problems be cause of various factors: noisy channels, bandwidth, inter-symbol interference,... Coding theory is the study of the properties of codes and their fitness thathelps dealing with these issues. In academic research, codes are involved in data transmission, data-storage, data-compression, cryptography, error-detection and correction.", "label": "human"}
{"ID": "00020016", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Brief overview The article, ”A Mathematical Theory of Communication” by Claude Shannon, published in 1948, was considered to mark the birth of Coding Theory. In his work, Shannon showed that when a noisy communication channel is given, he defined a number, called the capacity of the channel, such that reliable communication can be achieved at any rate below the channel capacity if proper encoding and decoding techniques are used.", "label": "human"}
{"ID": "00020017", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "For more than half a century, coding theory has seen phenomenal growth. Manycodes have been well-studied and have various applications in real life. For exam ple, Reed-Solomon code is used in 3G, and 4G networks and Turbo code is used in 5G networks. Both Turbo code and LDPC code are channel coding techniques that Data modems, telephone transmission, and NASA Deep Space Network use to get the bit through.", "label": "human"}
{"ID": "00020018", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Source coding plays the role of changing the message source to a code that is suitable for transmitting through the channel. For example, ASCII code is a source coding standard converting each character to a byte of 8 bits is an example of source coding. Another way to think about source coding is to treat it as a compress-decompress process. At the transmitter, the source encoder compresses the message for the purpose of economizing on the length of the transmission. At the other end, the source decoder decompresses the received signal or sequence.", "label": "human"}
{"ID": "00020019", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The commonly used compression algorithms include Huffman code used in JPEG, MPEG, MP3 files, Lempel-Ziv code used in ZIP files,...", "label": "human"}
{"ID": "00020020", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Because of physical and engineering limitations, channels are not ideal: their output may differ from their input because of noise or manufacturing defects. The transmitted message may become distorted and the receiver might not realize that the message was corrupted. Additionally, there are applications, such as magnetic and optical mass storage media, where certain patterns are not allowed to appear in the channel’s bit stream. The main role of channel coding is to overcome suchlimitations by encoding the message again after the source coding while maintain ing the channel as transparent as possible from the source and destination points of view.", "label": "human"}
{"ID": "00020021", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Section 2.1.1 has introduced basic ideas of coding theory. In the next section, this thesis provides the commonly used notations and terminologies of this research field.", "label": "human"}
{"ID": "00020022", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Notation and terminologies The most essential element of coding theory is codeword , which is a sequence of code symbols taken from a code alphabet q. The elements of Σare called code symbols, letters, and bits if q= 2. Aq-ary word of length nover Σis a sequence (or string) w=w1w2. . . w n∈Σnwith each wi∈Σfor all i.In practice, the size of a code alphabet is often the size of a finite field, which is the power of a prime number. Hence, for simplicity, Σcan be treated as a set of the first qnon-negative integers without ambiguity. More particularly, the notation Σ = 0 ,1,2, . . . , q −1can be used instead.", "label": "human"}
{"ID": "00020023", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Definition 2 (Code and Codeword) .Aq-ary block code Cover Σis a nonempty set Cofq−arywords of the same length n. Each element of Cis called a codeword inC.", "label": "human"}
{"ID": "00020024", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The study of a code Cinvolves the following process in an example of channelcoding. Suppose that ΣandΣ′are finite input and output of the channel respec tively. Let m, taken out of Mpossible information words, be a message input to the channel encoder. Through a desired channel encoder, the message mis mapped to a longer codeword c∈Σn. The word cis transmitted through the channel, become y∈Σ′n. After receiving y, the role of the channel decoder is to produce codewordˆcand a decoded information word ˆu, aiming to have c=ˆcandu=ˆu. Conse quently, the mapping at the channel encoder needs to be one-to-one, and the size Observe that, using code C, it takes a sequence of length nto encode a sequence to the message so that the channel can achieve its goal. Accordingly, a quantity concerning this redundancy was introduced, called (information) rate .", "label": "human"}
{"ID": "00020025", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Works in coding theory, including this thesis, are interested in designing codes with a high rate, along with efficient encoder, and decoder, that can be used in specific situations.", "label": "human"}
{"ID": "00020026", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Based on their motive or their intrinsic properties, codes are categorized into ar codes, constrained codes, error-correcting codes, and error-detecting codes, . . .. This thesis focus on the combination of a constrained code, run length limited, and positioning code. A brief introduction to constrained code is given in the next section.2.1.3 Constrained codeConstrained Code is a sub-field of Coding theory, studies to design codes sat isfying given constrained. The inspiration for the research of constrained codescomes from real problems. The transmitted data needs to follow some given stan dards which are necessary for the code to surmount the flaw of the environment.", "label": "human"}
{"ID": "00020027", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "For instance, in CD disc storage, errors tend to occur when there is a sequence of many consecutive 0bits. Consequently, it’s crucial to construct codes that should avoid a long sequence of 0bits. A famous code invented to overcome this challengeis Run length limited code by Immink . RLL codes are defined by 2parame ters: d, k, and denoted by (d, k)-RLL, where dandkare two non-negative integers such that d⩽k. A finite length binary sequence is said to satisfy the (d, k)-RLL constraint if its number of 0’s between 2consecutive 1bits is at least dand at most k.", "label": "human"}
{"ID": "00020028", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "An illustration is a convenient way to begin understanding things. In constrained code, a graph, usually called a labeled graph, is a helpful visualization technique.", "label": "human"}
{"ID": "00020029", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "More particularly, a labeled graph is a directed graph with its vertices and edges labeled. Vertices in the labeled graph are also called states. And the start and end vertices of a directed edge are called initial and terminal states respectively. Given a state v, in-edges of vare edges treating vas a terminal state. Similarly, out-edges ofvare edges taking vas an initial state.", "label": "human"}
{"ID": "00020030", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "For example, the graph in figure 2.2 represents a (d, k)-RLL code. It can be verified that a sequence wsatisfies the (d, k)-RLL constraint if and only if a path whose edge labeling is wexists in the graph.", "label": "human"}
{"ID": "00020031", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Labeled graphs are however more than just visualization tools. Using the finite state splitting algorithm, they become encoders. In a constrained system, a very common problem is designing an encoding algorithm, which maps arbitrary user sequences into sequences obeying the constraints. Nevertheless, it’s crucial to note that there are many kinds of encoders, depending on their objectives. For instance, there are encoders not taking any sequences as input, their goal is just to generatesequences satisfying given constraints. Such encoders are focused on in this thesis.Besides constrained code, another combinatorial object drawing much atten tions in coding theory is positioning code, also known by the name de Bruijn code.", "label": "human"}
{"ID": "00020032", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A de Bruijn sequence (of order k), sometimes called a positioning sequence, over an alphabet Σ, is a sequence of symbols of Σsuch that all subsequences over Σof length kappear exactly once. This section first explains how to use a graph to represent de Bruijn sequences, and then introduces methods to generate or decode such sequences. Important results on the granddaddy, one of the most interesting de Bruijn sequences, which play a significant role in this work, are also given.", "label": "human"}
{"ID": "00020033", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Graph presentation of de Bruijn sequences Since the first time introduced in 1946 by de Bruijn himself, the de Bruijn graphand its related sequences have been well-studied and generalized under numer ous names, including positioning sequences, m-sequences, shift register sequences –. The goal of de Bruijn was to find a recursive algorithm to enumerate the number of cyclic binary sequences of length 2ksuch that each binary k-tuple appears as a window of length kexactly once in each sequence.", "label": "human"}
{"ID": "00020034", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The first results in the de Bruijn graph focused on the alphabet of size 2. Later, in 1951, van Aardenne-Ehrenfest and de Bruijn  generalized the enumeration result for any arbitrary alphabet of finite size q, using a generalized graph for an alphabet Σof size q.", "label": "human"}
{"ID": "00020035", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Definition 4 (de Bruijn graph) .Formally, the de Bruijn Graph of order k,Gkis a directed graph with qk−1vertices, each one is represented by a word of length k−1over an alphabet Σwith qletters. A directed edge from the vertex x= (x0, x1, . . . , x k−2)to the vertex y= (y1, y2, . . . , y k−1), represented by the symbol xk, where xi, yi∈Σ, if and only if xi=yifor all 1⩽i⩽k−2. We call this edge xk the out-edge of x, and the in-edge of y. Progressively, the in-degree and out-degree of a vertex xare the numbers of in-edges and out-edges of xrespectively.", "label": "human"}
{"ID": "00020036", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Path : Apath in the graph is a sequence of edges: e0, e1, . . . , e nsuch that the terminal vertex of edge eiis the the initial vertex of edge ei+1for all 0⩽i⩽n−1.", "label": "human"}
{"ID": "00020037", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Asimple path is a path going through each edge at most one time. Each longestFigure 2.3: de Bruijn graph of order 4,G4.", "label": "human"}
{"ID": "00020038", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "simple path in a de Bruijn graph is an Eulerian cycle. A sequence formed by con catenating the symbol of each edge in the longest simple path in Gkis called a (cyclic) de Bruijn sequence of order k. All the strings of length kappear exactlyonce in each such de Bruijn sequence. The acyclic version of the de Bruijn se quence can be obtained by prepending the sequence representing the first vertex in the corresponding Eulerian cycle to the cyclic one.", "label": "human"}
{"ID": "00020039", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Example 2.1. Consider an Eulerian cycle starting at vertex 000, then the symbols representing the following edges 0,1,0,1,0,0,1,1,1,0,1,1,0,0,0form a de Bruijn sequence order 4. Adding 000to its beginning results in an acylic one:", "label": "human"}
{"ID": "00020040", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The number of longest simple path in Gk, and also the number of de Bruijn sequences, have been proved in  to beq!qk−1 qk.", "label": "human"}
{"ID": "00020041", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Example 2.2. Forq= 2, k= 4, there are 16distinct de Bruijn sequences. From figure 2.3, those de Bruijn sequences are found and listed as follows:0000100110101111 0000100111101011 0000101001101111 0000101001111011 0000101100111101 0000101101001111 0000101111001101 0000101111010011 0000110010111101 0000110100101111 0000110101111001 0000110111100101 0000111100101101 0000111101001011 0000111101011001 0000111101100101 2.2.2 Encode and decode de Bruijn sequencesEncoding de Bruijn sequences concerns generating an arbitrary de Bruijn se quence or a de Bruijn sequence satisfying some given constraints. Finding a de Bruijn sequence is equivalent to seeking an Eulerian cycle in a de Bruijn graph.", "label": "human"}
{"ID": "00020042", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In efficient algorithms to find Eulerian cycles are presented. Especially,the approach in  can be used to generate all binary de Bruijn sequences. How ever, since the graph must be stored, applying such algorithms to find a positioning sequence requires exponential O(qk)space.", "label": "human"}
{"ID": "00020043", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Besides the graph-based approach, there are other well-known methods to con struct such sequences, including LFSR, recursive methods, greedy methods, and concatenation approaches.", "label": "human"}
{"ID": "00020044", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The idea of LFSR is to design a feedback function fmapping length kstrings to symbols of the current string to generate the next symbol until the maximal length polynomials generate maximal length sequences (positioning sequences) having length 2k−1that miss only the all 0string. The downside of this method is that it’s compulsory to find a primitive polynomial first.", "label": "human"}
{"ID": "00020045", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "De Bruijn sequences can also be constructed via recursion by applying Lempel’s amount of space is also required by these recursive strategies.", "label": "human"}
{"ID": "00020046", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The greedy construction starts with a seed string, then repeatedly applies some greedy rule to determine the next symbol of a sequence. The algorithm stops when it is impossible to add another symbol without creating a duplicate substring of length k, or some termination condition is reached. The different explicit greedyrules result in different implementation greedy algorithms , –. Such constructions, however, have a major drawback: they require exponential space.", "label": "human"}
{"ID": "00020047", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Despite many constructions being known, and even a useful survey has been given by Fredricksen , things are not quite the same for the decoding problem.", "label": "human"}
{"ID": "00020048", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "This problem, discovering the position within a particular sequence of any spec ified k-tuple, has been much less well studied. There are just some classical de Bruijn sequences with sub-ar decoding algorithm –.", "label": "human"}
{"ID": "00020049", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Results on lexicographically minimal de Bruijn sequence The lexicographically minimal de Bruijn sequence, or granddaddy sequenceas called by Knuth , is one the most interesting among other de Bruijn se quences. An example of granddaddy is provided in example 2.3.", "label": "human"}
{"ID": "00020050", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The encoding algorithm is actually a concatenation scheme, which is later called FKM algorithm, the abbreviation of Fredrickesen, Kessller, and Maiorana, who discovered this strategy , . Its complexity has been proved to be constant amortized time per symbol by Frank Ruskey et.al  in 1992.", "label": "human"}
{"ID": "00020051", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Though its construction and the related algorithm has been found in 1978, about 40 years ago, the granddaddy’s decoder has just been discovered recently in 2016by Kociumaka, Radoszewski, and W. Rytter . Denote xas a granddaddy se quence of order k, and vis a length karbitrary substring. Then the decoding algorithm, denoted by DKRR, returns DKRR(v)being the one and only position ofvin the whole sequence x. Kociumala et.al also proved that DKRR works inO(k2log(q))-time in the word-RAM model and O(k2)-time in unit-cost RAM model.", "label": "human"}
{"ID": "00020052", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Definition 5 (Universal cycle) .Given a finite set Tkof distinct of combinatorial objects of ”rank k”, an U-cycle of Tkis a cyclic sequence U= (a0, a1, . . . , a n)such that(ai+1, . . . , a i+k),0⩽i⩽n, run through each element of Tk, where index addition is performed modulo n.An order kbinary de Bruijn sequence is eventually an U-cycle of the set of all length kbinary strings. The studies of U-cycle are concerned with the existenceand construction of U-cycles for many combinatorial objects such as strings, per mutations, partitions, subsets, multisets, lattice paths, vector spaces weak orders,etc –. Section 2.3.1 provides results for permutations, partitions, and sub sets of a set of ndistinct symbols, where nis a positive integer. These results were first summarized by Chung, Diaconis, and Graham in .", "label": "human"}
{"ID": "00020053", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Permutations, partitions and subsets of ndistinct symbols n, setSnmay not always contain any U-cycles, such as n= 3. All 6permutations can travel is of length 4, for instance, 123→231→312→123, which still lacks 132,321.", "label": "human"}
{"ID": "00020054", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "However, if order-isomorphism is allowed instead of requiring exact matches, U-cycles of Snexists. More precisely, an U-cycle Un= (a0, a1, . . . , a n!−1),ai∈ to exactly one block (ai+1, . . . , a i+n), where ai=aj≡i( mod n!). Here, two n-tuples a= (a1, a2, . . . , a n)andb= (b1, b2, . . . , b n)are called order-isomorphic, written as a∼b, ifai< aj⇔bi< bjfor all 0< i, j⩽n. An example of U-cycle for S3is :", "label": "human"}
{"ID": "00020055", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The construction of de Bruijn graphs can be imitated to construct the transition graph for Sn. Each permutation plays the role of a vertex. Their suffix of length n− 1is analyzed to establish its edges to other permutations. Takes the vertex 231ofS3as an example. From its suffix 31, one can go to 312. But since order-isomorphism is accepted, and note that 31∼21∼32, there are also edges connecting 231to213 and321. The whole transition graph of S3is shown in figure 2.4.", "label": "human"}
{"ID": "00020056", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "It is proved that the transition graph of Snis Hamiltonian, and a Hamiltonian cycle in the transition graph corresponds to an U-cycle in Sn. Now, the key question is how to represent a U-cycle of an Hamiltonian cycle, like the sequence 1 4 5 2 4 3 represents 123→231→312→132→312→213→123. Even with S3, is5 the smallest number of distinct symbols necessary for an U-cycle. More generally, how many distinct symbols does an U-cycle of Snuse at least? Actually, in S3, one can do better with 4symbols. For example, the sequence 1 4 2 3 4 2 is the representation of a Hamiltonian cycle:", "label": "human"}
{"ID": "00020057", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Conjecture 1. N(n) =n+ 1.Constructing transition graph is also help finding U-cycle for the set of Pnof length n(a0, a1, . . . , a n), where ai=ajindicates the i-th element and j-th element are in the same group of the partition. The transition graph of Pnis illustrated in figure 2.5.", "label": "human"}
{"ID": "00020058", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The transition graph of Pnis proved to be Hamiltonian by showing that it can be clustered to be an Eulerian graph.", "label": "human"}
{"ID": "00020059", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "It is more challenging to study the family k of all k-element subsets of a set of for the case n= 5, k= 2:", "label": "human"}
{"ID": "00020060", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The question about the condition for the existence of the universal cycle forsuch a family is still not answered completely. The difficulty here is that a tran sition graph for\u0002n k\u0003isn’t able to be defined explicitly. This issue is caused by the distinguishing feature of an k-set. More precisely, a k-element subset might occur in any k!possible order in the U-cycle, but it is only allowed to occur once. Fan Chung and Graham made a conjecture on this problem and the first person who can solve it would earn a prize awarded by the author’s conjecture.", "label": "human"}
{"ID": "00020061", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "It’s easy to see that conjecture 2 is true for k= 1,2. Effort on this question has just cracked completely the cases k= 3,4,5(with some aid of a computer), and k= 6whenever nandkare relatively prime( , ). For k⩾7, and k= 6 when nandkare not relatively prime, conjecture 2 remains open.", "label": "human"}
{"ID": "00020062", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Universal cycles algorithms for other classes of sets There are researches focusing on using generalized the FKM algorithm and greedy algorithm to create universal cycles for a class of sets. Moreno proved that this method works for the set of rotations of the lexicographically largest i necklace . The aperiodic strings in the set of all k-ary strings of length ncanbe generated the same way as shown by Au in . All these results are later gen eralized by Joe Sawada et.al in . More particularly, let Sbe the set of length n k-ary strings such that the following closure conditions are obeyed:", "label": "human"}
{"ID": "00020063", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Then, the greedy and FKM algorithm create the lexicographically smallest uni versal cycle of S. Several such classes Sare listed in example 2.4.", "label": "human"}
{"ID": "00020064", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "q is the set of q-ary sequences of length nover alphabet Σ. The following sets satisfy the closure conditions for the existence of universal cycles proved by Sawada .", "label": "human"}
{"ID": "00020065", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Minimum Sum :S∈Σn qis a set of length nstrings with sum over all of its symbol at least s, where sis a given constant.", "label": "human"}
{"ID": "00020066", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Frequency of i < q :S∈Σn qcontains the strings with at most uicopies of i < q . Here, uiis a given constant.", "label": "human"}
{"ID": "00020067", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Avoiding a substring :S∈Σn qcontains the strings that do not contain a given q−1, for some m⩾1, as a cyclic substring.", "label": "human"}
{"ID": "00020068", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Note that, in example 2.4, the union and intersection of the proper sets Sallow to combine the previous results to create more interesting classes of sets that have universal cycles.", "label": "human"}
{"ID": "00020069", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Section 2.3 has provides different research directions and results on the univer sal cycle, which is a generalization of de Bruijn sequences. The applications of de Bruijn sequences and their generalizations will be presented in the next section.2.4 Applications The reason why the de Bruijn graph, its sequence, and its generalizations are having so much attention is due to their diverse important applications. Very soon after the formal definition of this graph was given birth, one of its first applicationswas found in the introduction of shift-register sequences in general and ar feed back registers in particular . Throughout the years, these types of sequences and graphs have found a variety of applications.", "label": "human"}
{"ID": "00020070", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In cryptography, for example, the Baltimore Hilton Inn used de Bruijn sequences to install a cipher lock system for each of its rooms in lieu of the conventional key-lock system . The low-cost n-stage shift register was used to generate maximum-length pseudorandom sequences in stream cipher, though later, this method was proved to be vulnerable to known-plaintext attack .", "label": "human"}
{"ID": "00020071", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "De Bruijn sequences also opened a new field of research surrounding their com plexity. Agnes Hui Chan et.al studied the complexity and the distribution of the complexities of de Bruijn sequences . Especially, for binary sequences withperiod 2n, they come up with a fast algorithm determining its complexity . Ed win on himself analyzed the structure and complexity of nonar binary sequence generators . Tuvi et.al studied the error ar complexity spectrum of binary sequences with period 2n. Also Tuvi, in his joint work with Lampel , found a construction of the de Bruijn sequence to show that the lower bound of its complexity ( 2n−1+n) is attainable for all n.", "label": "human"}
{"ID": "00020072", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In , A.Lampel and M.Cohn are interested in designing a universal test se quence for VLSI (very large-scale integration chip). A binary sequence is called (s, t)-universal, s > t , if when shifted through a register of length s, it exercises every subset of tregister positions. Their proposed method was concatenating a set of de Bruijn sequences of appropriate length. In , Zeev Barzilai .et.al also demonstrated an application of de Bruijn sequence in VLSI self-testing.", "label": "human"}
{"ID": "00020073", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "There are also other applications requiring a two-dimensional version of de Bruijn sequences. And the research about the two-dimensional generalization of de Bruijn sequences comes to call. One well-known version is called pseudo-random arrays. In 1976, Mac Williams and Neil Sloane  gave a simple description of pseudo-random arrays and studied several of their nice properties. In 1988,Tuvi , represented a new version of pseudo-random arrays to construct per fect maps. In another approach by Bruck Stein , he combined a de Bruijnsequence and a half de Bruijn sequence to study its robust and self-location prop erties. Studies – used pseudo-random arrays to with applications to robustundetectable digital watermarking of two-dimensional test images, and structured light.", "label": "human"}
{"ID": "00020074", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "More surprisingly, de Bruijn’s modern applications are even combined with bi ology, like genome assembly as part of DNA sequencing. For example, Chaisson et.al  described a new tool, EULER-USR, for assembling mate-paired shortreads and used it to analyze the question of whether the read length matters. Compeau et.al  represented a method using the de Bruijn graph for genome assembly. In 2001, Pevzner et.al  abandoned the classical “overlap - layout  consensus” approach in favor of a new Eulerian Superpath approach, that, for the first time, resolves the problem of repeats in fragment assembly. Later on, in 2003,Yu Zhang and Michael Waterman , adapted Pevzner’s method to global mul tiple alignment for DNA sequences. In DNA storage, Han Mao et.al ,  studied codes and their rates for DNA sequence profiles. Their studies were based on the de Brujn graph.", "label": "human"}
{"ID": "00020075", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In some new memory technologies, mainly in racetrack memories, and other ones which can be viewed as an l-read channel, synchronization errors (which are shift errors known also as deletions and sticky insertions) occur. By proposing a new de Bruijn-based schema, using a locally-constrained de Bruijn sequence to construct such code, Chee et.al.  are able to increase the rate of codes that correct the synchronization errors. Locally constrained de Bruijn sequences and codes (sets of sequences) are of interest in their own right from both practical and theoretical points of view.", "label": "human"}
{"ID": "00020076", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Recently, in 2021, a novel application of the de Bruijn sequence has been found in quantum communication. Generally, to transmit quantum information between a satellite and the ground station, a timing and synchronization system has been used. Having observed that the intrinsic properties of the positioning sequence are very suitable for this system, Zhang, Oi, Lowndes, et al.  have modulated it into HdB sequence to transmit along the quantum channel. Their system is analyzed in the next section.", "label": "human"}
{"ID": "00020077", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In satellite QKD, the quantum information is synchronized by transmitting along with the classical one. Figure 2.6 shows a high-level view of this schematic.", "label": "human"}
{"ID": "00020078", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The encode process happens at the satellite, where it uses the LFSR algorithmFigure 2.6: High-level satellite Quantum Key Distribution timing and synchronization schematic .", "label": "human"}
{"ID": "00020079", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "to generate a positioning sequence (of order kfor example). The prerequisite of finding a proper primitive polynomial is the main drawback of this encoder.", "label": "human"}
{"ID": "00020080", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The decoding process takes place at the ground station, a look-up table is used to identify the unique position of the received sequences of length k. The complexity of this method is exponential.", "label": "human"}
{"ID": "00020081", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Furthermore, in this model, a sequence of beacon pulses is used to represent a binary de Bruijn sequence. Considering the timing jitter performance, a long period of no-pulses should be forbidden. If one pulse slot is used to represent a binary bit, for example, on is 1 and off is 0, a long run of 0’s in the sequence (which is a long period of no-pulses) would impact the timing jitter. In , two pulse slots are used to represent a single bit (on-on is 1 and on-off is 0) so that one can avoid two consecutive no-pulses. The transmitted sequence is called HdB. However, the above scheme requires 2npulse slots to represent a de Bruijn sequence of length nand needs to receive a sub-sequence of 2 lognpulse slots to locate its position.", "label": "human"}
{"ID": "00020082", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Formally, the HdB sequence’s rate is just 0.5, where rate is a quantity that needs to be as high as possible (the definition of sequences’ rate is given in section 4.2).", "label": "human"}
{"ID": "00020083", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In order to avoid long period of no pulse, the positioning sequences are com bined with run length limited constraints. Such sequences are called Run length limited de Bruijn (RdB) sequences, presented in chapter 3. The RdB sequencesare not just suitable with dBTS system, but also have a higher rate than HdB se quences. More precisely, rate of the longest RdB sequences are log\u0012 2\u0013Table 2.1: Timing and synchronizing system use Hybrid de Bruijn code.", "label": "human"}
{"ID": "00020084", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Satellite Transmited de Bruijn sequenceGround StationRequirement : transmit a de Bruijn se quence of order kRequirement : be able to be positioned, avoid periods of no-pulseRequirement : locate the position of any length ksubsequence Method : use linear feedback shift register algorithmMethod : modulate on-on is 1, on-off is 0Method : use look-up tableDrawback : the pre requisite of finding aproper primitive polynomialDrawback : rate is 0.5Drawback : exponen tial complexity So as to generate one of the longest RdB sequences, based on FKM algorithm, chapter 4 provides an encoder whose time complexity is constant amortized time per symbol. Moreover, to locate the position of an arbitrary proper subsequence in the whole RdB sequence, a decoder is also presented. The proposed decoder modifies the decoding algorithm found by Kociumaka, Radoszewski, and Rytter in , which is currently the state of the art method to position a subsequence in the de Bruijn sequence, and therefore, is better than look-up table.", "label": "human"}
{"ID": "00020085", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Beside, the RdB sequence is even more general and adaptive. More particularly, when the constraint of forbidding pattern 00is relaxed, that is, a longer run of bit 0’s is allowed, the RdB sequence can be easily adjusted to make the its rate higher and still suits the system.In this chapter, new constrained de Bruijn sequences are introduced. Since a de Bruijn sequence is self-located, the run length limited constraint is the only requirement remaining that this sequence needs to satisfy to be used in the dBTS system. Therefore, combining a positioning sequence and a run length limited sequence is a natural solution. That is also how this thesis gave birth to the name:", "label": "human"}
{"ID": "00020086", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Run length limited de Bruijn sequence. Besides, just like other constrained codes, a convenient way to apprehend a code is using a labeled graph. Hence, the graph presentation of these sequences is also provided.", "label": "human"}
{"ID": "00020087", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "This thesis only focuses on the case q= 2and thus drops qin the notation for simplicity. Sequence s=s1s2. . . s n∈Σnis also written without ambiguity.", "label": "human"}
{"ID": "00020088", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Given two sequences x=x1x2. . . x mandy=y1y2. . . y n, denote the concatena tion of xandyto be xy=x1x2. . . x my1y2. . . y n, and denote xkthe concatenation ofkcopies of x. It is said that xis smaller than y, denoted x<y, if there is an index t⩾1, such that xi=yi,∀i⩽t, and xt+1< yt+1. Note that empty sequence is smaller than 0.", "label": "human"}
{"ID": "00020089", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Definition 6. A sequence s= (s1, s2, . . . , s n)is called a s-run length limited (RLL) sequence of length nif each run of 0’s in the sequence shas length at most s, or in other words, the sequence sdoes not contain s+ 1consecutive 0’s as a substring.", "label": "human"}
{"ID": "00020090", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Denote W(n, s)the set of all s-RLL sequences of length nand note that W(n, s) has been well-studied in the literature , . This thesis presents the recursive Lemma 1 (Cardinality of W(n, s)).Letn, sbe two non-negative integers. Then Proof. For the first equation, when n⩽s, all sequences of length nbelong toWhen n > s , every sequence in W(n, s)is of the form 0i1x, where x∈W(n− i−1, s)for0⩽i⩽s. Additionally, for every x∈W(n−i−1, s), the sequence 0i1xis an element of W(n, s). This bijection brings the second equation.", "label": "human"}
{"ID": "00020091", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Definition 7 (Run length limited de Bruijn (RdB) sequence) .A sequence s= (s1, s2, . . . , s n)∈Σnis called a (k, s)-run length limited de Bruijn (RdB) sequence of length nif it is a de Bruijn sequence of order kand a s-RLL sequence of length n.", "label": "human"}
{"ID": "00020092", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Note that, when s⩾k, a(k, s)-RdB sequence is just an original de Bruijn sequence. If s=k−1, any (k, k−1)-RdB sequence can be achieved from a de Bruijn sequence removing 1letter 0in the subsequence 0k. Based on those observations, case s⩾k−1is considered to be trivial. Therefore, this thesis concentrates on the case s < k−1. And thus, in the rest of this thesis, sis always assumed to be smaller than k−1.", "label": "human"}
{"ID": "00020093", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "It is well-known that given k, the maximal length nof a binary acyclic de Bruijn sequence is n= 2k+k−1. Let N(k, s)be the maximal length of a (k, s)-RdBsequence. This thesis is interested in finding the exact value of N(k, s). The moti vation of this task is explained clearly in section 4.2, which concerns the rate of a sequence.For further demonstration, the next section presents the graph presentation for the(k, s)-RdB sequence.", "label": "human"}
{"ID": "00020094", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In this section, a labeled graph, called (k, s)-RdB graph, is used to represent (k, s)-RdB sequences. Just like a de Bruijn graph of order k, any simple path in (k, s)-Rdb graph represents a (k, s)-RdB sequence.", "label": "human"}
{"ID": "00020095", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A(k, s)-RdB graph can be achieved by eliminating all the vertices containing more than sconsecutive letter 0in the de Bruijn graph Gk. As a result, the vertices of a(k, s)-RdB graph are represented by binary sequences of length k−1which don’t contain pattern 0s+1.", "label": "human"}
{"ID": "00020096", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The illustration for de Bruijn graph of order 4,G4, was given in figure 2.3. To obtain (4,1)-Rdb graph from there, vertices 000,001,100are deleted. Figure 3.1 demonstrates the (4,1)-RdB graph.", "label": "human"}
{"ID": "00020097", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Denote the (k, s)-RdB graph to be Gk,s= (Vk−1,s, Ek,s), where Vk−1,sis the set of all vertices and Ek,sis the set of all edges. The following lemmas determining the cardinality of Vk−1,sandEk,s Lemma 2 (Number of vertices ).", "label": "human"}
{"ID": "00020098", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Proof. This proof is deduced directly from the construction of Gk,ssince its set of all vertices is the set of all length k−1sequences containing at most sconsecutive letters 0.", "label": "human"}
{"ID": "00020099", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Lemma 3 (Number of edges ).Proof. Observe that for both x,y∈W(k−1, s), if there is an edge from vertex x= (x1, . . . , x k−1)to vertex y=y1, . . . , y k−1, then (x1, . . . , x k−1, yk−1)∈W(k, s).", "label": "human"}
{"ID": "00020100", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Besides, for each s-RLL sequence x= (x1,..., x k)∈W(k, s), its prefix and suffix, (x1, . . . , x k−1)and(x2, . . . , x k), are both s-RLL sequence of length k−1.", "label": "human"}
{"ID": "00020101", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Example 3.2. According to lemma 2 and lemma 3, (4,1)-RdB graph has V3,1 the number of vertices and edges in figure 3.1.", "label": "human"}
{"ID": "00020102", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Letu= (u1, u2,..., u k−1)andv= (v1, v2,..., v k−1)be arbitrary vertices in RdB graph. Starting at v, the following sequence of edges’ labels (1, u1, u2, . . . , u k−1) apparently forms a proper path going from vtouin RdB graph. Similarly, the sequence of edges’ labels (1, v1, v2, . . . , v k−1)beginning at uis also a directed path from utov. This is sufficient to conclude that the connectivity of RdB graphs is preserved.SEQUENCE Chapter 4 concerns in determining the rate of RdB sequence. Besides, designingefficient encoder and decoder for a longest RdB sequence are also critical contri butions.", "label": "human"}
{"ID": "00020103", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "To calculate the rate and maximal asymptotic rate of RdB sequence, first, resultson the maximal length of a RdB sequence are presented. After that, efficient al gorithms to generate a longest RdB sequence and locate any sub-sequence in such sequence are also provided.", "label": "human"}
{"ID": "00020104", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The rate of de Bruijn sequences can be determined by understanding its longest length. Section 4.2 provides a formal definition of rate and maximal asymptotic rate of the de Bruijn sequence. This section concerns finding the longest simple path in Gk,s, which corresponds to the longest (k, s)-RdB sequence.", "label": "human"}
{"ID": "00020105", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "LetN(k, s)is the maximal length of a (k, s)-RdB sequence, and ℓ(Gk,s)be the length of the longest simple path in Gk,s. Recall that a length lsimple path in Gk,s is equivalent to a (k, s)-RdB sequence of length l+k−1. Therefore, N(k, s) = ℓ(Gk,s) +k−1.", "label": "human"}
{"ID": "00020106", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The de Bruijn graph Gkis actually an Eulerian graph because each vertex has exactly two in-coming edges and two out-coming edges. This results in its longest path visiting each edge exactly once and has a length of 2k. However, (k, s)-RdB graph Gk,sdoesn’t have the same property since the in-degree and out-degree of each vertex can be one or two. Thus, a simple path that visits all edges of the graph may not exist.", "label": "human"}
{"ID": "00020107", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "To overcome this issue, the upper bound U(k, s)for the length of the longest simple path is first determined in this section. Then, U(k, s) =U(k, s) +k−1 is the upper bound for the length of longest (k, s)-RdB sequence. This work later proves that such bound can be achieved by proposing an efficient encoder returning a sequence of length U(k, s)in section 4.3.1. Hence, it’s sufficient to conclude that the upper bound U(k, s)is also the length of the longest simple path. In other words, ℓ(Gk,s) =U(k, s), and N(k, s) =U(k, s) Before deriving the explicit formula of maximal length, it’s necessary to analyze more meticulously the in-degree and out-degree of all vertices. Given 0⩽i, j⩽s, define:Vk−1,s i,j=n x:x∈Vk−1,s,x[1, i+ 1] = 0i1, x[k−1−j, k−1] = 10jo That is, Vk−1,s i,j is the set of all vertices in Gk,ssatisfying the first i+ 1letters are (0,0, . . . , 0,1)and the last j+ 1letters are (1,0,0, . . . , 0). Lemma 4 summaries the properties of Vk−1,s i,j the helps finding U(k, s).", "label": "human"}
{"ID": "00020108", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "For each element x∈Vk−1,s i,j , its subsequence, x[i+ 1, k−2−j], can be any sequence of length k−i−j−3such that more than sconsecutive letter 0’s is forbidden. Hence x[i+ 1, k−2−j]∈W(k−i−j−3, s). Reversely, given an arbitrary sequence y∈W(k−i−j−3, s), the string 0i1y10jis a sequence inVk−1,s i,j . It comes to the conclusion that there is a bijection from Vk−1,s i,j to W(k−i−j−3, s). In other word,\f\f\fVk−1,s 2. Since Vk−1,s i,j∪Vk−1,s i′,j′=∅with (i, j)̸= (i′, j′), and i, jcannot exceed s, thus, P 0⩽i,j⩽s\f\f\fVk−1,s i,j\f\f\f=\f\fVk−1,s\f\f.", "label": "human"}
{"ID": "00020109", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Theorem1 (Longest simple path ).LetC= min ( s−1, k−s−2). The length ofthe longest path in Gk,s,ℓ(Gk,s), is equal to U(k, s), where:", "label": "human"}
{"ID": "00020110", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": ".1) As mentioned above, proof of theorem 1 is divided into 2 parts. While the first one claims ℓ(Gk,s)⩽U(k, s), the second one shows that there exists a sequence can achieve the length of U(k, s)+k−1. This section provides the proof of the first part (lemma 5). Proof for the second part is available in section 4.3.", "label": "human"}
{"ID": "00020111", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Definition 8 (Balance and unbalanced vertex) .A vertex with the quantity of in coming edge equal to the quantity of out-coming edge is called a balanced vertex.", "label": "human"}
{"ID": "00020112", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Recall that a path is defined to be a sequence of edges. A vertex vis said to be (lying) in or belong to a path P, denoted by v∈P, ifvhas edges in P. It’s also fair to say that Pgoes through v. Besides, vis called the end (or the start) vertex ofPif its last (first) edge ends (begins) at v.", "label": "human"}
{"ID": "00020113", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Suppose Pto be a longest simple path in Gk,s. In other word, Pachieves the length ℓ(Gk,s). Some observations about Pare given in the following claims.", "label": "human"}
{"ID": "00020114", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Claim 1. All the vertices in P, if not a start or end vertex, must have the number of in-edges and out-edges equal in P.", "label": "human"}
{"ID": "00020115", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Proof. Letvbe a vertex in P,vis neither start nor end vertex. Then whenever P comes to vby an in-edge, it must go out of vby an out-edge. So the claim 1 is true.", "label": "human"}
{"ID": "00020116", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Claim 2. Every balance vertex in Phas their quantity of in-edges and out-edges inPequal, even if one of them is the start or end vertex.", "label": "human"}
{"ID": "00020117", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Proof. Letvbe a balanced vertex and Pgoes through v. Ifvis neither end nor start vertex, by claim 2, vhas the number of in-edges and out-edges in Pequal.", "label": "human"}
{"ID": "00020118", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Without loss of generality, assume that vis the start vertex. This results in the number of out-edges of vbeing equal or has 1edges more than its number of out-edges. If these two quantities are equal, the proof is done. Otherwise, denote e′to ate′is a proper simple path RdB graph, but longer than P, which contradicts to the assumption about the longest property of P.", "label": "human"}
{"ID": "00020119", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Claim 3. Letu= 0s1x1t0jbe a right-unbalanced vertex. Then the shortest path going from uto an arbitrary left-unbalanced vertex lengthen s−j.", "label": "human"}
{"ID": "00020120", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Proof. A left-unbalanced vertex is represented by a sequence whose suffix of length sis filled by 0. Hence, a path from uto a left-unbalanced vertex must contain atleast s−jedges labeled 0. In fact, a path of length s−jconnecting uto a left unbalanced vertex exists, which is the path of all 0labeled edges. This path comes from uto0s−j1x1t0s.", "label": "human"}
{"ID": "00020121", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Proof for lemma 5. Define 1x1tto be a sequence of length tsuch that start and end letters are both 1. Let L=C j=0 u:u= 0j1x1t0s, s+t+j=k−1 be the set of all left-unbalanced vertices Letv= 0j1x1t0sbe an arbitrary vertex in Lsuch that visn’t the end-vertex of pathP.", "label": "human"}
{"ID": "00020122", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "It can be proved that there is a path Pvof length s−jsatisfying all of its edges not lying in Pand its end-vertex is v. The path Pvis constructed backwardly as follows:", "label": "human"}
{"ID": "00020123", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Starts with Pv=∅. As v h as 2 in-edges and 1 out-edges, there’s at least 1 in-edge evofvnot lying in P. Of course, ev’s label is 0. Adds evtoPv. Let Continue adding this edge to the head of Pv. Denote a2a10j1x10s−2to be the initial state of this edge. Now, Pvcan be represented as below:", "label": "human"}
{"ID": "00020124", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "If l=s−j, the proof is done. Otherwise, it’s obvious that al···a2a10j1x1t0s−l is balance, hence, by claim 2, it also has at least 1in-edge not lying in P, and one can continue adding such edge to the head of Pv.", "label": "human"}
{"ID": "00020125", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "It can be shown that for each u, v∈Lsuch that neither unorvis the end vertex of the last edge of P, paths PuandPvare edge-disjoint.", "label": "human"}
{"ID": "00020126", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Represent Pu= [eu,1, eu,2,···, eu,i],Pv= [ev,1, ev,2,···, ev,j]. Assume to the contrary that ∃t⩽i, l⩽jsatisfying eu,t=ev,l. Without loss of generalization, we suppose that i−t⩽j−l. As all edges in PuandPvare labeled 0, we must have eu,t+1=ev,l+1,···, eu,i=ev,l+(i−t).", "label": "human"}
{"ID": "00020127", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "If l+i−t=j, we have PuandPvhave the same last edge but different terminal states, which is impossible. Otherwise, the path ev,l+i−t+1,···, ev,jis the path connecting utov. But the length of this path is smaller than s, which is also absurd.", "label": "human"}
{"ID": "00020128", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Summary, for each vertex in Lsuch that visn’t the end-vertex of the last edge in pathP, there is a path Pvof length s−jsatisfying all of its edges not lying in P and takes vto be its end-vertex. Moreover, all these such paths are edge-disjoint, and there can be only 1end-vertex of the last edge in path ℓ(Gk,s), the total edgesof all such path Puis:", "label": "human"}
{"ID": "00020129", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The rates of sequences are the proportion of the data stream that is useful (non redundant), which tell how much useful information is transmitted. The sequence’s rate actually originates from the information rate. Recall that, in definition 3, the n. If a (k, s)-RdB sequence xk,sis considered to be a code Ck,s, each of its size kwindows is treated as a codeword. The size of Ck,sis exactly the length of xk,sminus k, butthe offset kcan be omitted under log calculation. Hence:", "label": "human"}
{"ID": "00020130", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Note that, a high rate is usually preferred. Accordingly, with each given pair (k, s), the maximal rate of all (k, s)-RdB sequence is defined.", "label": "human"}
{"ID": "00020131", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Having the explicit formula of N(k, s)determined makes it easier to calculate the maximal asymptotic rate of the (k, s)-RdB sequence. The following equation is a direct consequence of theorem 1:", "label": "human"}
{"ID": "00020132", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Theorem 2 below shows that the rate of (k,1)-RdB sequence is better than therate of HdB sequence. Therefore, it’s able to use (k,1)-RdB sequence for the sys tem in  instead to increase the rate, speed of encoding, and decoding of the transmitted signals.", "label": "human"}
{"ID": "00020133", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "This section presents a construction of a (k, s)-RdB sequence ck,s. Furthermore, given a substring of length kof the sequence ck,s, a fast decoding algorithm to determine the location of the given substring is provided. The complexity of the decoding algorithm is sub-ar with respect to the length of ck,s. There are some1 1 0.9358 0.8649 . . . 0.6942 0.6942 0.6942 0.6942 2 1.1610 1.0566 1 . . . 0.8791 0.8791 0.8791 0.8791 3 1.1610 1.1073 1.0425 . . . 0.9468 0.9468 0.9468 0.9468 4 1.1610 1.1073 1.0620 . . . 0.9752 0.9752 0.9752 0.9752 5 1.1610 1.1073 1.0620 . . . 0.9881 0.9881 0.9881 0.9881 6 1.1610 1.1073 1.0620 . . . 0.9942 0.9942 0.9942 0.9942 7 1.1610 1.1073 1.0620 . . . 0.9971 0.9971 0.9971 0.9971 8 1.1610 1.1073 1.0620 . . . 0.9986 0.9986 0.9986 0.9986 Table 4.2: The convergence of Rk,s with sfrom 1to8 classical de Bruijn sequences with sub-ar decoding algorithm –. This work uses the minimal de Bruijn sequence, constructed in , , and some special properties of Lyndon words to construct a (k, s)-RdB.", "label": "human"}
{"ID": "00020134", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Definition 12 (Lyndon words ).A sequence wis a Lyndon word if and only if it’s strictly smaller than all of its rotation.", "label": "human"}
{"ID": "00020135", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Example 4.1 (Lyndon words). The word 00101 is a Lyndon word since it is smaller than all of its rotations: 01010 ,10100 ,01001 ,10010 . The word 01100 is not a Lyndon word, since one of its rotations, 00011 , is smaller than it. The word 011011 is also not a Lyndon word, as its cyclic rotation by 3letters is equal to it.", "label": "human"}
{"ID": "00020136", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Encoder for a (k, s)-RdB sequenceIn 1978, Fredricksen and Maiorana  proposed the FKM algorithm to effi ciently construct the lexicographically minimal de Bruijn sequence, which is later called the granddaddy sequence by Knuth . The algorithm was based on their finding of the connection between the de Bruijn sequence and Lyndon words.", "label": "human"}
{"ID": "00020137", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Lemma 6 () .The lexicographically minimal de Bruijn sequence of order k (k-MdB) is the concatenation of all Lyndon words whose length is a divisor of kin the lexicographical order.", "label": "human"}
{"ID": "00020138", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Example 4.2 (Decomposition of 6-MdB sequence). Recall that 6-MdB sequenceAs stated in lemma 6, it can be decomposed in lexicographically order into Lyndon words listed follows: 000101 001 001101 01 011 1 This thesis observes that it is able to append a prefix to a suffix of k-MdB to obtain a (k, s)-RdB sequence, i.e., in the cycle representing k-MdB, there are arcsrepresenting (k, s)-RdB sequences. To illustrate this idea, figure 4.1 gives an ex ample for k= 6ands= 2, where the blue arc and the red arc indicate the prefix and the suffix respectively. Any substring of the concatenation of the prefix and suffix is a (6,2)-RdB sequence.", "label": "human"}
{"ID": "00020139", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Construction 1. Letx= (x1, . . . , x n)be the k-MdB constructed from Lemma 6 anduk,s= 0s+11k−s−1be a Lyndon word of length ksatisfying the first s+ 1letters are all 0’s and the last k−s−1letters are all 1’s. By the intrinsic property of de Bruijn sequences, there exists only one index isuch that uk,s=x[i, i+k−1] = (xi, . . . , x i+k−1). Denote the word ck,s= (xi+1, . . . , x n,0,0, . . . , 0), obtained by adding sletters 0to the end of the suffix of x, from index i+1to the end. Theorem 4 below claims that ck,sis a(k, s)-RdB sequence.", "label": "human"}
{"ID": "00020140", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "This thesis later proves that ck,sis even the longest (k, s)-RdB sequence.Figure 4.1: Example for k= 6, s= 2. In the circle of 6-MdB, an arbitrary substring of the concatenation of suffix and prefix in the picture is a (6,2)-RdB sequence.", "label": "human"}
{"ID": "00020141", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "be the set of all Lyndon words whose lengths are divisors of n. The formal encoder to construct a (k, s)-RdB sequence is given in algorithm 1.", "label": "human"}
{"ID": "00020142", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Output: (k, s)-RLL dBs w←emptystring /*remove the first letter of w, which is 0, and add sletters 0to the end */ w=w[2, ℓ]0s break return w The set Ł(n)in lexicographically order can be generated in constant amortizedtime by applying FKM algorithm (analyzed in ), or by another algorithm devel oped by Duval in . In algorithm 1, the most consuming time step is to produce the set Ł(n), and hence, its complexity is the complexity of the algorithm used to bring out Ł(n) is taken from the granddaddy of order 6given above. Adding 2letter 0to the end of it obtains:", "label": "human"}
{"ID": "00020143", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Proof. First, it’s necessary to show that each substring of length kappears at most once in ck,s. Note that the granddaddy sequence xobtained from Lemma 6 is a cyclic de Bruijn sequence, and ck,sis actually a substring of x. Hence, ck,sjust contains each substring of size kat most once.", "label": "human"}
{"ID": "00020144", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Now, claiming that ck,sdoesn’t contain any patterns 0s+1will complete the theo rem. This can be proved by considering the property of Lyndon words. It’s obviousto see that uk,s= 0s+11k−s−1is the largest Lyndon word containing s+ 1consecu tive symbols 0. Hence, every Lyndon word decomposed from ck,sdoesn’t take 0s+1 as a substring. Moreover, the last symbol of all Lyndon words but 0is1. Therefore, 0s+1will not appear in the combination of Lyndon words larger than uk,s. Adding 0s1k−s−1to the beginning and sletters 0to the end of this combination resulting inck,swon’t change this property. So, it’s able to conclude that ck,sis indeed a (k, s)-RdB sequence.", "label": "human"}
{"ID": "00020145", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Decoder for a (k, s)-RdB sequence In , the Hybrid de Bruijn sequence of order kafter being received needs to be decoded for correcting errors. More particularly, it’s necessary to indicate the exact location of an arbitrary sequence of length kin the Hybrid de Bruijn sequence. To do that, they proposed to use a look-up table, which is an exponential complex method.", "label": "human"}
{"ID": "00020146", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Similarly, it’s essential for this work to decode ck,s. In 2016, Kociumaka, Ra doszewski, and Rytter presented the first sub-ar decoding algorithm DKRR for the minimal de Bruijn sequences. And since ck,sis a substring of a minimal deBruijn sequence, it’s able to modify DKRR to decode ck,sin sub-ar time.", "label": "human"}
{"ID": "00020147", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Leti=DKRR(uk,s)be the position of the word uk,sin the granddaddy sequence of order kx. Recall that, from Construction 1, we have ck,s= (xi+1, . . . , x n,0s).", "label": "human"}
{"ID": "00020148", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Thus, for each length kword vlying in ck,s, its location in ck,sis to location of v inxminus j, unless they are of the form 1j0k−jfor all 1⩽j⩽swhich appear at the end of ck,s. The formal description of our decoding algorithm is shown in algorithm 2.", "label": "human"}
{"ID": "00020149", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Algorithm 2: Decode (k,s)-RdB ck,s Input : A word v= (v1, . . . , v k)of length k Output: a is the location of vinck,s i← D KRR(uk,s); /*DKRR is the decoder of the minimal de Bruijn sequence in  */ ifv= 1j0k−j,then return n−i+ 1−(k−j); else return DKRR(v)−i; 4.3.3 The optimality of our construction This section gives proof for the claim stated in section 4.1, that is, the encoder produces sequence ck,swhose length equals to to upper bound U(k, s), and thus, ck,sis the longest the (k, s)-RdB sequence. In order to do so, ck,s’s length, denoted byℓ(ck,s), is needed calculating first. It’s then essential to show that ℓ(ck,s)is equal toU(k, s)by some algebraic transformations.", "label": "human"}
{"ID": "00020150", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Given a word u, denote ⟨u⟩to be its minimal rotation. For instance, the minimal rotation of 010110 is 001011, or, the minimal rotation of 010101 is itself. For every word v, we define:", "label": "human"}
{"ID": "00020151", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "S(v) =n exceed v. The following example 4.4 lists all element of S(v)withv= 01101 .whose minimal rotations are at most vis:", "label": "human"}
{"ID": "00020152", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Equals to the length of the prefix of the granddaddy sequence x, from the beginning to the sub-string v. Recall that uk,sis also a Lyndon word, one has:", "label": "human"}
{"ID": "00020153", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "To be the set of all words in S(uk,s)satisfying its prefix of length i+ 1is0i1and its suffix of length j+ 1is10j.", "label": "human"}
{"ID": "00020154", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "S(uk,s) = 1 +X If we fix 1⩽t⩽k, there are k−t+ 1pairs (i, j)such that t=k−i−j. If i+j⩽sthen the sub-string 1x1tmust contain s+ 1consecutive 0’s (consequently,C1=X i,j⩾0; where M= max( s+ 3, k−s).", "label": "human"}
{"ID": "00020155", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Ifk > i +j > s then the sub-string (xi+2,..., x k−j−1)can be any word of length C2=X i,j⩾0; t=1(k−t+ 1)At. (4.13) From Equations (4.11), (4.12), (4.13), we get the result in Lemma 7.", "label": "human"}
{"ID": "00020156", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Where C1 and C2 are defined in Equation 4.12 and 4.13. It’s now ready to prove the following lemma, which states that the proposed construction is optimal.", "label": "human"}
{"ID": "00020157", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Case 2: M=s+ 3, C=s−1 when k= 2s+ 2, s < k −1. The LHS is the same as in the first case, meanwhile, the RHS is :", "label": "human"}
{"ID": "00020158", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "In conclusion, in all 3cases, the correctness of equation 4.15 is verified, hence, Lemma 8 is proved.Summary In this thesis, Run length limited de Bruijn sequences are introduced and studied to replace Hybrid de Bruijn sequence in dBTS system. Compare to HdB sequences, RdB sequences not only have a higher rate but are also more general and adaptive.", "label": "human"}
{"ID": "00020159", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "The main results of this thesis include the explicit formula of the maximal length and maximal asymptotic rate of RdB sequences. To achieve such length and rate,an encoding algorithm is presented. This thesis also provides proof of the opti mality of the encoder. To locate the position of a proper substring in the whole encoded sequence, a decoding algorithm is proposed based on the decoder of thegranddaddy sequence. The encoder and decoder are both based on state-of-the art algorithms. The encoder’s complexity is constant amortized time per symbol, and the decoder’s complexity is sub-ar with respect to the length of the RdB sequence.", "label": "human"}
{"ID": "00020160", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Future works In future work, it’s critical to analyze deeper about the RdB sequence undersome other constraints like weight constraint or local constraint. The current re sults right now just focus on the alphabet of size 2. The study of the more generalalphabet will raise many more questions in combinatorics and algorithm. Espe cially, results for the alphabet of size 4will be valuable in the research of DNA storage as well as DNA sequencing, a very interesting field recently.", "label": "human"}
{"ID": "00020161", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Publications 1. Yeow Meng Chee, Duc Tu Dao, Tien Long Nguyen , Duy Hoang Ta, VanKhu Vu. ”Run Length Limited de Bruijn Sequences for Quantum Communi cations”, The 2022 IEEE International Symposium on Information Theory.", "label": "human"}
{"ID": "00020162", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Tran Ba Trung, Lijun Chang, Nguyen Tien Long , Kai Yao, Huynh Thi Thanh Binh. ”Verification-Free Approaches to Efficient Locally Densest SubgraphDiscovery”, The 39th IEEE International Conference on Data Engineering. P. Zhang, D. K. Oi, D. Lowndes, and J. G. Rarity, “Timing and synchronisa tion for high-loss free-space quantum communication with hybrid de bruijn codes,” IET Quantum Communication , vol. 2, no. 3, pp. 80–89, 2021.", "label": "human"}
{"ID": "00020163", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "P. W. Shor, “Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer,” SIAM review , vol. 41, no. 2, pp. 303– 332, 1999.", "label": "human"}
{"ID": "00020164", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "V . Gheorghiu and M. Mosca, “Benchmarking the quantum cryptanalysis of symmetric, public-key and hash-based cryptographic schemes,” arXiv preprint arXiv:1902.02332 , 2019.", "label": "human"}
{"ID": "00020165", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "C.H.Bennett and G. Brassard, “Quantum cryptography: Public key distri bution and coin tossing,” in Proceedings of IEEE International Conference on Computers, Systems and Signal Processing , IEEE, vol. 175, 1984, p. 8.", "label": "human"}
{"ID": "00020166", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "I.Khader, H. Bergeron, L. C. Sinclair, W. C. Swann, N. R. Newbury, andJ.-D. Desch ˆenes, “Time synchronization over a free-space optical communi cation channel,” Optica , vol. 5, no. 12, pp. 1542–1548, 2018.", "label": "human"}
{"ID": "00020167", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "S.Duan, S. Cong, and Y . Song, “A survey on quantum positioning system,” International Journal of Modelling and Simulation , vol. 41, no. 4, pp. 265– 283, 2021.", "label": "human"}
{"ID": "00020168", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "L.Song, F. Geng, Z. Song, B.-Z. Li, and Y .-J. Yuan, “Robust data storage in dna by de bruijn graph-based decoding,” 2021.", "label": "human"}
{"ID": "00020169", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "T. Etzion and A. Lempel, “Algorithms for the generation of full-length shift register sequences,” IEEE Transactions on Information Theory , vol. 30, no. 3, pp. 480–484, 1984.", "label": "human"}
{"ID": "00020170", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "H. Fredricksen, “A survey of full length nonar shift register cycle algo rithms,” SIAM review , vol. 24, no. 2, pp. 195–221, 1982. A. Lempel, “On a homomorphism of the de bruijn graph and its applications to the design of feedback shift registers,” IEEE Transactions on Computers , vol. 100, no. 12, pp. 1204–1209, 1970.", "label": "human"}
{"ID": "00020171", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "M.Cohn and A. Lempel, “On fast m-sequence transforms (corresp.),” IEEE Transactions on Information Theory , vol. 23, no. 1, pp. 135–137, 1977.", "label": "human"}
{"ID": "00020172", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "M. Fleury, “Deux problemes de geometrie de situation,” Journal de mathe matiques elementaires , vol. 2, no. 2, pp. 257–261, 1883.", "label": "human"}
{"ID": "00020173", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "C. Hierholzer and C. Wiener, “ ¨Uber die m ¨oglichkeit, einen linienzug ohnewiederholung und ohne unterbrechung zu umfahren,” Mathematische An nalen , vol. 6, no. 1, pp. 30–32, 1873.", "label": "human"}
{"ID": "00020174", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "M. H. Martin, “A problem in arrangements,” Bulletin of the American Math ematical Society , vol. 40, no. 12, pp. 859–864, 1934.", "label": "human"}
{"ID": "00020175", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A. M. Alhakim, “A simple combinatorial algorithm for de bruijn sequences,” The American Mathematical Monthly , vol. 117, no. 8, pp. 728–732, 2010.", "label": "human"}
{"ID": "00020176", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A. Alhakim, E. Sala, and J. Sawada, “Revisiting the prefer-same and prefer opposite de bruijn sequence constructions,” Theoretical Computer Science , vol. 852, pp. 73–77, 2021.", "label": "human"}
{"ID": "00020177", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "C. J. Mitchell, T. Etzion, and K. G. Paterson, “A method for constructing decodable de bruijn sequences,” IEEE Transactions on Information Theory , vol. 42, no. 5, pp. 1472–1478, 1996.", "label": "human"}
{"ID": "00020178", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "J. Tuliani, “De bruijn sequences with efficient decoding algorithms,” Dis crete Mathematics , vol. 226, no. 1-3, pp. 313–336, 2001.", "label": "human"}
{"ID": "00020179", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "T. Kociumaka, J. Radoszewski, and W. Rytter, “Efficient ranking of lyndon words and decoding lexicographically minimal de bruijn sequence,” SIAM Journal on Discrete Mathematics , vol. 30, no. 4, pp. 2027–2046, 2016.", "label": "human"}
{"ID": "00020180", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "D. E. Knuth, Art of Computer Programming, Volume 4, Fascicle 4, The: Generating All Trees–History of Combinatorial Generation . Addison-Wesley Pro fessional, 2013.", "label": "human"}
{"ID": "00020181", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "H. Fredricksen and J. Maiorana, “Necklaces of beads in k colors and k-ary de bruijn sequences,” Discrete Mathematics , vol. 23, no. 3, pp. 207–210, 1978.", "label": "human"}
{"ID": "00020182", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "H. Fredricksen and I. J. Kessler, “An algorithm for generating necklaces of beads in two colors,” Discrete mathematics , vol. 61, no. 2-3, pp. 181–188, 1986. F. Ruskey, C. Savage, and T. M. Y . Wang, “Generating necklaces,” Journal of Algorithms , vol. 13, no. 3, pp. 414–430, 1992.", "label": "human"}
{"ID": "00020183", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "F. Chung, P. Diaconis, and R. Graham, “Universal cycles for combinatorial structures,” Discrete Mathematics , vol. 110, no. 1-3, pp. 43–59, 1992.", "label": "human"}
{"ID": "00020184", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "V . Horan and G. Hurlbert, “Universal cycles for weak orders,” SIAM Journal on Discrete Mathematics , vol. 27, no. 3, pp. 1360–1371, 2013.", "label": "human"}
{"ID": "00020185", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "B.Jackson, B. Stevens, and G. Hurlbert, “Research problems on gray codes and universal cycles,” Discrete Mathematics , vol. 309, no. 17, pp. 5341– 5348, 2009.", "label": "human"}
{"ID": "00020186", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "G. Hurlbert, T. Johnson, and J. Zahl, “On universal cycles for multisets,” Discrete mathematics , vol. 309, no. 17, pp. 5321–5327, 2009.", "label": "human"}
{"ID": "00020187", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "B. W. Jackson, J. Buhler, and R. Mayer, “A recursive construction for univer sal cycles of 2-subspaces,” Discrete mathematics , vol. 309, no. 17, pp. 5328– 5331, 2009.", "label": "human"}
{"ID": "00020188", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "G.Hurlbert, “On universal cycles for k-subsets of an n-set,” SIAM Journal on Discrete Mathematics , vol. 7, no. 4, pp. 598–604, 1994.", "label": "human"}
{"ID": "00020189", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "E. Moreno, “On the theorem of fredricksen and maiorana about de bruijn sequences,” Advances in Applied Mathematics , vol. 33, no. 2, pp. 413–415, 2004.", "label": "human"}
{"ID": "00020190", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Y. H. Au, “Generalized de bruijn words for primitive words and powers,” Discrete Mathematics , vol. 338, no. 12, pp. 2320–2331, 2015.", "label": "human"}
{"ID": "00020191", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "J.Sawada, A. Williams, and D. Wong, “Generalizing the classic greedy andnecklace constructions of de bruijn sequences and universal cycles,” the elec tronic journal of combinatorics , P1–24, 2016.", "label": "human"}
{"ID": "00020192", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A. H. Chan, R. A. Games, and E. L. Key, “On the complexities of de bruijn sequences,” Journal of Combinatorial Theory, Series A , vol. 33, no. 3, pp. 233– 246, 1982. R. Games and A. Chan, “A fast algorithm for determining the complexity ofa binary sequence with period 2ˆ n (corresp.),” IEEE Transactions on Infor mation Theory , vol. 29, no. 1, pp. 144–146, 1983.", "label": "human"}
{"ID": "00020193", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "E. Key, “An analysis of the structure and complexity of nonar binary sequence generators,” IEEE Transactions on Information Theory , vol. 22, no. 6, pp. 732–736, 1976.", "label": "human"}
{"ID": "00020194", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "T. Etzion, N. Kalouptsidis, N. Kolokotronis, K. Limniotis, and K. G. Pater son, “Properties of the error ar complexity spectrum,” IEEE Transactions on Information Theory , vol. 55, no. 10, pp. 4681–4686, 2009.", "label": "human"}
{"ID": "00020195", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "T. Etzion and A. Lempel, “Construction of de bruijn sequences of mini mal complexity,” IEEE Transactions on Information Theory , vol. 30, no. 5, pp. 705–709, 1984.", "label": "human"}
{"ID": "00020196", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A. Lempel and M. Cohn, “Design of universal test sequences for vlsi,” IEEE transactions on information theory , vol. 31, no. 1, pp. 10–17, 1985.", "label": "human"}
{"ID": "00020197", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Z. Barzilai, D. Coppersmith, and A. L. Rosenberg, “Exhaustive generation of bit patterns with applications to vlsi self-testing,” IEEE Transactions on Computers , vol. 32, no. 02, pp. 190–194, 1983.", "label": "human"}
{"ID": "00020198", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "F. J. MacWilliams and N. J. Sloane, “Pseudo-random sequences and arrays,” Proceedings of the IEEE , vol. 64, no. 12, pp. 1715–1729, 1976.", "label": "human"}
{"ID": "00020199", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "T. Etzion, “Constructions for perfect maps and pseudorandom arrays,” IEEE Transactions on information theory , vol. 34, no. 5, pp. 1308–1316, 1988.", "label": "human"}
{"ID": "00020200", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "A. M. Bruckstein, T. Etzion, R. Giryes, N. Gordon, R. J. Holt, and D. Shuldiner,“Simple and robust binary self-location patterns,” IEEE transactions on in formation theory , vol. 58, no. 7, pp. 4884–4889, 2012.", "label": "human"}
{"ID": "00020201", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Y .-C. Hsieh, “Decoding structured light patterns for three-dimensional imag ing systems,” Pattern Recognition , vol. 34, no. 2, pp. 343–349, 2001.", "label": "human"}
{"ID": "00020202", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "R. A. Morano, C. Ozturk, R. Conn, S. Dubin, S. Zietz, and J. Nissano, “Structured light using pseudorandom codes,” IEEE Transactions on Pattern Anal ysis and Machine Intelligence , vol. 20, no. 3, pp. 322–327, 1998.", "label": "human"}
{"ID": "00020203", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "J. Pages, J. Salvi, C. Collewet, and J. Forest, “Optimised de bruijn patterns for one-shot shape acquisition,” Image and Vision Computing , vol. 23, no. 8, pp. 707–720, 2005.", "label": "human"}
{"ID": "00020204", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "J. Salvi, S. Fernandez, T. Pribanic, and X. Llado, “A state of the art in struc tured light patterns for surface profilometry,” Pattern recognition , vol. 43, no. 8, pp. 2666–2680, 2010. R. G. Van Schyndel, A. Z. Tirkel, and C. F. Osborne, “A digital watermark,” inProceedings of 1st international conference on image processing , IEEE, vol. 2, 1994, pp. 86–90.", "label": "human"}
{"ID": "00020205", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "M. J. Chaisson, D. Brinza, and P. A. Pevzner, “De novo fragment assem bly with short mate-paired reads: Does the read length matter?” Genome research , vol. 19, no. 2, pp. 336–346, 2009.", "label": "human"}
{"ID": "00020206", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "P. E. Compeau, P. A. Pevzner, and G. Tesler, “How to apply de bruijn graphs to genome assembly,” Nature biotechnology , vol. 29, no. 11, pp. 987–991, 2011.", "label": "human"}
{"ID": "00020207", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "P. A. Pevzner, H. Tang, and M. S. Waterman, “A new approach to fragment assembly in dna sequencing,” in Proceedings of the fifth annual international conference on Computational biology , 2001, pp. 256–267.", "label": "human"}
{"ID": "00020208", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Y . Zhang and M. S. Waterman, “An eulerian path approach to global multiple alignment for dna sequences,” Journal of Computational Biology , vol. 10, no. 6, pp. 803–819, 2003.", "label": "human"}
{"ID": "00020209", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Z. Chang, J. Chrisnata, M. F. Ezerman, and H. M. Kiah, “Rates of dna se quence profiles for practical values of read lengths,” IEEE Transactions on Information Theory , vol. 63, no. 11, pp. 7166–7177, 2017.", "label": "human"}
{"ID": "00020210", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "H. M. Kiah, G. J. Puleo, and O. Milenkovic, “Codes for dna sequence pro files,” IEEE Transactions on Information Theory , vol. 62, no. 6, pp. 3125– 3146, 2016.", "label": "human"}
{"ID": "00020211", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "Y. M. Chee, T. Etzion, H. M. Kiah, S. Marcovich, A. Vardy, E. Yaakobi, et al. , “Locally-constrained de bruijn codes: Properties, enumeration, code constructions, and applications,” IEEE Transactions on Information Theory , vol. 67, no. 12, pp. 7857–7875, 2021.", "label": "human"}
{"ID": "00020212", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "O.F. Kurmaev, “Constant-weight and constant-charge binary run-length lim ited codes,” IEEE transactions on information theory , vol. 57, no. 7, pp. 4497– 4515, 2011.", "label": "human"}
{"ID": "00020213", "file_name": "Run length limited de Bruijn sequences for quantum communication", "content": "J.-P. Duval, “G ´en´eration d’une section des classes de conjugaison et ar bre des mots de lyndon de longueur born ´ee,”Theoretical computer science , vol. 60, no. 3, pp. 255–283, 1988.", "label": "human"}
{"ID": "00030001", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In this introductory chapter, we embark on an enlightening journey that estab lishes the foundation for our research project. Here, we present a comprehensive overview, delving into the motivations behind our research, the contributions itaims to make, and the well-structured roadmap that guides us through the investi gation of our research domain.", "label": "human"}
{"ID": "00030002", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Blockchain technology, as exemplified by Bitcoin  and Ethereum  net works, has experienced significant growth and garnered widespread attention dueto its unique characteristics and prospective benefits. Blockchain has revolution ized many industries, including finance, supply chain, healthcare, and more, by providing a decentralized, transparent, and immutable platform for record-keeping and value transmission. However, conventional web technologies and systems offer their own set of benefits and advantages. Bridging the gap between blockchain andconventional web technologies can unleash a wealth of opportunities and syner gies, resulting in a more robust and adaptable digital ecosystem.", "label": "human"}
{"ID": "00030003", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "One of the key benefits of blockchain technology lies in its ability to provide trust and transparency. The Bitcoin network, for instance, enables peer-topeer transactions without the need for intermediaries, fostering trust among par ticipants and reducing transaction costs. Ethereum, on the other hand, extendsblockchain capabilities by supporting programmable smart contracts, enabling decentralized applications (DApps) with a wide range of use cases. Meanwhile, traditional web technologies offer a well-established infrastructure, user-friendly inter faces, and extensive compatibility with existing systems. By combining the benefitsof both blockchain networks like Bitcoin and Ethereum and traditional web tech nologies, we can create a powerful hybrid solution that leverages the transparency of blockchain while maintaining the usability and familiarity of the traditional web.", "label": "human"}
{"ID": "00030004", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "By facilitating self-sovereign identities and data control, blockchain technology promotes decentralization and empowers individuals. Users can have ownership and control over their digital assets and personal data, decreasing their dependenceon centralized entities. This paradigm shift is facilitated by Bitcoin’s decentralized network architecture and Ethereum’s decentralized application platform. Tra ditional web technologies, on the other hand, provide users with convenience and familiarity via centralized authentication systems, social logins, and widespread standards. As demonstrated by Bitcoin and Ethereum, integrating these featuresinto the blockchain ecosystem can improve user experience, encourage adoption, and bridge the gap between conventional web users and blockchain applications.", "label": "human"}
{"ID": "00030005", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The growth and benefits of blockchain technology, exemplified by networks likeBitcoin and Ethereum, combined with the advantages of traditional web technolo gies, highlight the importance of bridging the gap between the two. By leveraging the strengths of both systems, we can create a hybrid solution that harnesses the transparency, security, and decentralization of blockchain while maintaining the usability, compatibility, and familiarity of the traditional web. This convergence unlocks new possibilities, expands the reach of blockchain applications, and paves the way for a more interconnected and inclusive digital future. Consequently, the objective of this thesis, a social login solution for Dapps using SSS and verified by DKG, is to combine the advantages of blockchain technology and conventional web authentication.", "label": "human"}
{"ID": "00030006", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Due to the fact that this solution is a large undertaking involving the implemen tation of numerous modules by numerous individuals, it is evident that I did not design and construct the system alone and that other developers participated in itscreation. In addition, I was responsible for devising and implementing the mech anisms for the executors to share secrets and generate private keys for end users.", "label": "human"}
{"ID": "00030007", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "I implement the majority of the project’s features, with the exception of Shamir’salgorithm for sharing secrets and the Distributed Key Generation protocol. In ad dition, I designed and implemented the majority of the data structures contained in smart contracts and the decentralized storage called Eueno. In addition, this system has a unique architecture for securing and enriching the user experience, as well as enabling developers to integrate existing Dapps seamlessly.", "label": "human"}
{"ID": "00030008", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The present thesis is organized into six distinct chapters, each of which fulfills a specific objective in the comprehensive investigation of the research subject matter.", "label": "human"}
{"ID": "00030009", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Chapter 1 serves as the introductory section of this thesis, wherein the underlying motivation driving the study is established. Furthermore, this chapter highlights the significant contributions made by the research and provides a comprehensiveout of the overall structure of the thesis. Chapter 2 of this thesis aims to es tablish a comprehensive understanding of fundamental concepts that are crucial tothe subject matter. These concepts include blockchain, transactions, blocks, wal lets, Shamir’s secret sharing, distributed key generation, smart contracts, executor for decentralized applications (DApps), and social login for Web3. By delving intothese concepts, this chapter lays the groundwork for the subsequent analysis andexploration of the topic at hand. Chapter 3 of this study presents the proposed so lution, which outs an innovative approach that has been adopted to effectively tackle the challenges that have been identified. Chapter 4 delves into an in-depth analysis of the technical issues and design considerations encountered throughout the implementation process. This chapter aims to address and shed light on thevarious challenges that were confronted during the execution of the project. Chap ter 5 of this study presents a comprehensive evaluation of the proposed solution,offering valuable insights into its performance and usability. In conclusion, Chap ter 6 serves as the final segment of this thesis, wherein the findings are succinctly summarized and potential avenues for future research are deliberated upon. The inclusion of a reference section within a thesis serves the purpose of meticulously documenting all the sources that have been cited throughout the research, thereby upholding the academic integrity of the study.The background section of this thesis provides a comprehensive overview of thekey concepts and technologies that serve as the foundation for our proposed solution. This chapter examines the fundamental characteristics of blockchain technol ogy, what social login for Web3 is, what a smart contract is, and the fundamental comprehension and utilization scenarios of Shamir’s secret sharing and distributedkey generation. Understanding these concepts is crucial for appreciating our solu tion’s motivations and its potential impact on the decentralized digital landscape.", "label": "human"}
{"ID": "00030010", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Blockchain technology has emerged as a revolutionary innovation with the potential to transform industries and revolutionize how digital transactions are conducted. It provides a decentralized and transparent platform for secure and un changeable record-keeping, eliminating the need for intermediaries and facilitating peer-to-peer interactions. This chapter provides a concise introduction to blockchain technology, highlighting its historical context, the problem it seeks to solve, and the primary contributions of its first author. In 2008, an anonymous person or group of people using the alias Satoshi Nakamoto  introduced the concept of blockchainfor the first time. The seminal whitepaper titled \"Bitcoin: A Peer-to-Peer Elec tronic Cash System\" by Satoshi Nakamoto outd the fundamental principles andarchitecture of blockchain technology as a solution to the issues of trust and decentralized digital currency. Bitcoin’s introduction of blockchain represented a sig nificant milestone in the evolution of cryptocurrencies and decentralized systems.", "label": "human"}
{"ID": "00030011", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Traditional centralized systems’ lack of trust and security is the issue blockchain seeks to address. The reliance of centralized systems on a single trusted authority to validate and authenticate transactions leaves room for manipulation, deception,and censorship. Blockchain technology addresses these issues by establishing a de centralized network of nodes where consensus mechanisms guarantee the validity and integrity of transactions without requiring a central authority. The first author, Satoshi Nakamoto, introduced a secure and decentralized framework for digitalcurrency transactions, laying the groundwork for blockchain technology. Combining existing cryptographic techniques, such as hash functions and digital signa tures, with a distributed ledger system was Nakamoto’s most significant innovation.", "label": "human"}
{"ID": "00030012", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "This innovation facilitated the creation of a transparent and tamper-resistant ledger of transactions, ensuring the integrity and immutability of blockchain data. SinceNakamoto’s original work, blockchain technology has expanded beyond cryptocur-rencies such as Bitcoin. It has implications in numerous industries, including fi nance, supply chain management, and healthcare, among others. The blockchain’s decentralized nature provides opportunities for greater transparency, efficiency,and trust in these industries, paving the way for innovative solutions and new busi ness models.", "label": "human"}
{"ID": "00030013", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Transactions Transactions are the most important part of the Bitcoin system. Everything else in bitcoin is designed to ensure that transactions can be created, propagated on the network, validated, and finally added to the global ledger of transactions (the blockchain). Transactions are data structures that encode the transfer of valuebetween participants in the Bitcoin system. Each transaction is a public entry in bitcoin’s blockchain, the global double-entry bookkeeping ledger\" according to \"Mas tering Bitcoin: Unlocking Digital Cryptocurrencies\" by Andreas M. Antonopoulos , which implies that transactions are fundamental components of blockchain technology, serving as the building blocks for the transfer and exchange of digitalassets. Blockchain networks’ security and trustworthiness rely heavily on transac tions. They are intended to be verifiable and immutable, providing a transparent and auditable log of all blockchain activities. By recording each transaction on thedistributed ledger, participants are able to trace the history and origin of digital as sets, fostering accountability and preventing double spending. Multiple stages are involved in the creation of a transaction. The sender initiates the transaction by specifying the recipient’s address and the desired transfer amount. The originatorthen signs the transaction with their private key, ensuring the transaction’s authenticity and integrity. Once the transaction has been digitally signed, it is disseminated to the network for validation and inclusion in a block. The validation proce dure involves verifying the digital signature of the transaction using the sender’s public key, thereby ensuring that the transaction has not been tampered with and that the originator has sufficient funds to complete the transfer. The transactionis submitted to a pool of pending transactions awaiting confirmation after valida tion. Miners, who are tasked with safeguarding the blockchain, select transactions from the pool and incorporate them into a new block. A consensus mechanism, such as proof-of-work or proof-of-stake, is then used to add the transaction to the blockchain.The creation of transactions on the blockchain enables participants totransmit digital assets without the need for intermediaries in a transparent and secure manner. It assures the system’s integrity by employing cryptographic tech niques to authenticate and authorize transactions, thereby rendering the process tamper-proof and fraud-resistant.2.1.2 Blocks A block in a blockchain is a fundamental element that is crucial to the network’sstructure and functionality. It functions as a repository for a collection of transac tions and other pertinent data. Each block is comprised of a block preamble, which includes metadata such as the block’s unique identifier, timestamp, and a referenceto the previous block, establishing a chronological order. The block contains trans actions, which represent numerous actions within the blockchain network. Thesetransactions include sender and recipient addresses, digital signatures for authen tication, and additional pertinent information. The block also contains a Merkletree root , which provides an efficient method for verifying the validity of trans actions contained within the block. In addition, each block is allocated a unique block hash that is generated by a cryptographic hash function. This block hashserves as a digital fingerprint for the block’s content and ensures its immutabil ity. In proof-of-work consensus algorithms, for instance, miners compete to find a nonce value that, when combined with the block header, satisfies specific criteria, thereby adding a layer of security through the solution of computational puzzles.", "label": "human"}
{"ID": "00030014", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Key and address Key and address are foundational concepts pertaining to user identification and transaction security in the context of blockchain technology and cryptocurrencies.", "label": "human"}
{"ID": "00030015", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "A key, also known as a cryptographic key, is a fragment of information utilized incryptographic algorithms for a variety of purposes, including encryption, decryp tion, and digital signatures. Typically, in the context of blockchain, keys are used to secure access to digital assets and to authenticate transactions. There are various mathematically related key categories, including private and public keys. A private key is a secret, randomly generated number that is kept covert by the user. It is usedto generate digital signatures, which verify the integrity and authenticity of trans actions. The private key should be stored in a secure location and never shared with anyone. If a third party obtains access to the private key, they may be able to take control of the associated digital assets. On the other hand, an address is a cryptographic representation of a user’s public key. In a blockchain network, it is a string of alphanumeric characters that functions as a unique identifier for receiving transactions or messages. The public key is used to generate addresses, but they do not disclose any information about the private key. When sending a transaction to a particular user in a blockchain network, the recipient’s address is used as thedestination. The address functions as a pseudonymous identifier, providing privacy and security. The recipient can then access and manage the digital assets associated with that address using their private key.", "label": "human"}
{"ID": "00030016", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "WalletA cryptocurrency wallet is a software application or hardware device that en ables users to store, administer, and interact with their digital assets in a secure manner. Wallets play a crucial role in the adoption and use of cryptocurrencies by both consumers, enhancing the overall experience with a variety of advantages.", "label": "human"}
{"ID": "00030017", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "They provide a secure solution for storing private keys, which are required for accessing and controlling cryptocurrencies. Wallets enable users to transfer and receive funds, track their transaction history, and monitor their account balancesby storing private keys securely. Wallets typically include features such as ad dress book administration, transaction history, and real-time market data, providingusers with a comprehensive set of tools for managing their cryptocurrency hold ings. One important aspect of wallet security is the implementation of industry standards, such as the BIP39 specification , in the generation and managementof mnemonic phrases or seed phrases. The BIP39 specification ensures that wal lets adhere to a standardized method for generating mnemonic phrases, which arehuman-readable sets of words. These phrases can be used to derive the crypto graphic keys necessary to access and manage cryptocurrency funds. By adopting the BIP39 specification, wallets provide users with a consistent and reliable way to backup and restore their wallets, offering an additional layer of security and ease of use. MetaMask  is a prominent example of a cryptocurrency wallet. MetaMaskis a wallet extension for web browsers that enables users to interact with Ethereum based decentralized applications (DApps) directly from the browser. It provides a user-friendly and secure interface for interacting with Ethereum accounts and theblockchain. MetaMask provides a straightforward and intuitive interface that inte grates seamlessly with popular web browsers such as Chrome, Firefox, and Brave.", "label": "human"}
{"ID": "00030018", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Within minutes, users can install the MetaMask extension and configure their Ethereum wallet. After configuring the wallet, users can access their Ethereum accounts, view their token balances, and conduct transactions.", "label": "human"}
{"ID": "00030019", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Consensus The concept of consensus holds paramount importance in the realm of blockchain technology as it serves to guarantee the agreement and validity of transactionsthroughout the network. This mechanism encompasses a process by which decentralized nodes within the network collectively establish agreement regarding thecurrent state of the blockchain. This paper examines two prevalent consensus algo rithms, namely Proof of Work (PoW) and Proof of Stake (PoS).", "label": "human"}
{"ID": "00030020", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "PoW consensus algorithm, initially pioneered by Bitcoin , serves as the foun dational mechanism for validating transactions and maintaining the integrity of the blockchain network. In the context of PoW, the participants referred to as miners engage in a competitive process aimed at solving intricate mathematical puzzles. In the realm of blockchain technology, the initial miner who successfully unravels the intricate puzzle is duly acknowledged and bestowed with a reward, subsequently appending a novel block to the existing chain of transactions. The aforementioned process necessitates a substantial amount of computational resources and incurs a considerable level of energy expenditure. The security of a blockchain system is upheld through the utilization of PoW, which effectively deters malicious entitiesfrom tampering with previous transactions. This is achieved by imposing a signif icant computational burden on any attempts to modify the blockchain’s historical records.", "label": "human"}
{"ID": "00030021", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "PoS  consensus algorithm serves as a viable alternative to the PoW mecha nism, with the primary objective of mitigating the concerns pertaining to energy consumption commonly associated with PoW. In the PoS consensus mechanism,the selection of validators to generate new blocks is determined by their cryptocur rency holdings and their willingness to \"stake\" said holdings as collateral. The selection of validators is typically conducted through a deterministic procedure, which frequently takes into consideration factors such as the magnitude of theirstake and the duration for which they have maintained it. PoS consensus mecha nism is widely acknowledged for its superior energy efficiency in comparison tothe PoW mechanism, primarily due to its reduced reliance on intensive computa tional resources.", "label": "human"}
{"ID": "00030022", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The utilization of both PoW and PoS consensus mechanisms presents distinctbenefits and limitations. PoW consensus mechanism is renowned for its robust se curity measures, albeit at the cost of significant resource consumption. Conversely,the PoS protocol boasts energy efficiency advantages, yet it may exhibit vulnerabil ity to specific forms of attacks. The selection between PoW and PoS is contingent upon the distinct objectives and prerequisites of a blockchain network.", "label": "human"}
{"ID": "00030023", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Shamir’s secret sharing is a fundamental cryptographic algorithm that plays a vital role in assuring the secure distribution and storage of data across a variety ofapplications. This ingenious algorithm, developed by Adi Shamir in 1979, employsthe principles of polynomial interpolation to divide a confidential secret into multi ple shares. Then, these shares are distributed to various participants, each of whom holds a unique piece of the puzzle. The genius resides in the fact that the original secret can only be reconstructed by combining a minimum number of shares. The implementation of Shamir’s secret sharing begins with the selection of the secret to be protected. The secret is then used as the constant element in a polynomial of a specified degree. This polynomial is the basis for constructing the shares. The evaluation of the polynomial at specific points corresponds to the allocation of shares to each participant. The flexibility of Shamir’s secret sharing is its greatest asset. The threshold required to reconstruct the secret can be modified based on the system’s particular requirements. If the threshold is set to \"k,\" for instance, any combination of \"k\" or more shares can be used to recover the original secret. As long as the minimum threshold is maintained, this provides a robust mechanism for ensuring resilience against loss or larceny of shares. Shamir’s disclosure of asecret has a wide range of applications in various discips. It is frequently em ployed in cryptographic key management, in which a sensitive cryptographic key is divided into portions and distributed to key holders. This adds an additional layer of security to critical systems by ensuring that no single individual can access thekey without the cooperation of multiple parties.// Here is a straightforward il lustration of how Shamir’s secret sharing works. Suppose I wish to divide a secret value of 42 into 5 portions with a threshold of 3. By evaluating a polynomial at various points, the shares are generated. Share 1: (1, 17), Share 2: (2, 23), Share 3: (3, 38), Share 4: (4, 14) Share 5: (5, 7) x represents the point on the polynomial curve, while y is the value of the polynomial at that point. Now, I need at least three shares to reconstruct the secret. Consider the shares 2, 3, and 4. I can use these shares to interpolate the polynomial and determine the value at x = 0 that corresponds to our confidential value of 42 by employing interpolation. Using the Lagrange interpolation formula , the secret can be calculated:", "label": "human"}
{"ID": "00030024", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The Distributed Key Generation (DKG) protocol is at the vanguard of contemporary cryptographic mechanisms, offering a revolutionary method for collabora tively generating shared secret keys among multiple parties without the need for acentralized trusted authority. By removing the need for a single point of control,the DKG protocol significantly improves security, making it an indispensable in strument for protecting sensitive data and vital systems. The fundamental principle of the DKG protocol is its capacity to decentralize the generation and distribution of the secret key among all participants. This collaborative effort ensures that no single party has complete knowledge of the confidential key, thereby mitigating therisk of a single point of failure and reducing the number of exploitable vulnerabil ities. The protocol consists of distinct segments, each of which plays a vital role in generating a shared secret key, the protocol’s ultimate objective. In the initial stages of the key generation phase, the parties generate the secret key jointly. Thedistribution of these shares to the participants signifies the distribution phase. Ver ification is the next stage, during which each party verifies the received shares to ensure their authenticity and integrity. The true strength of the DKG protocol rests in the reconstruction phase, where the mathematical combination of the distributed shares is used to reconstruct the final confidential key. Importantly, the success ofthis reconstruction requires the participation of a minimum number of trustwor thy parties. This threshold ensures that even if some parties are compromised or conduct maliciously, the security of the final secret key remains uncompromised so long as the minimum number of honest participants is maintained. Numerous advantages make DKG protocols an adaptable and indispensable resource for a variety of applications. DKG protocols enable parties to collaboratively perform computations on sensitive data without disclosing their individual inputs, ensuring privacy and confidentiality. The DKG protocol facilitates the secure generation anddistribution of cryptographic keys in cryptographic key management, safeguard ing against unauthorized access and key compromise. Moreover, DKG protocols benefit threshold cryptography by enabling secure operations that necessitate the participation of a predefined threshold of parties. Secure communication protocolscan also utilize DKG protocols to establish secure channels and prevent data in terception and surveillance. The Pedersen DKG protocol, proposed by Torben Pedersen  in 1991, was used in the thesis. The Pedersen DKG protocol utilizespolynomial interpolation techniques and cryptographic primitives to achieve secure and distributed key generation. It provides a robust mechanism for establish ing shared secret keys without relying on a trusted central authority. The protocolinvolves several steps, including key generation, sharing, verification, and recon struction.The Pedersen DKG protocol utilizes polynomial interpolation techniques and cryptographic primitives to achieve secure and distributed key generation. It provides a robust mechanism for establishing shared secret keys without relying on a trusted central authority. The protocol involves several steps, including keygeneration, sharing, verification, and reconstruction.", "label": "human"}
{"ID": "00030025", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "History and definationSmart contracts are agreements that automatically carry out their obligations because they are encoded in code. By eliminating the need for middlemen and supplying a safe and decentralized method to facilitate and enforce agreements or trans actions, these contracts automatically execute and enforce themselves. The idea ofsmart contracts has been around since the 1990s, and computer scientist Nick Sz abo  is credited with coining the term. However, smart contracts did not receivemuch attention or widespread use until the advent of blockchain technology, partic ularly with the launch of Ethereum  in 2015. A Turing-complete programminglanguage was introduced by Ethereum, a decentralized blockchain platform, allowing for the creation and execution of sophisticated smart contracts. This innova tion paved the way for the development of decentralized applications (DApps) that might use smart contracts to secure and automate a variety of activities, including voting systems, supply chain management, and financial transactions. Since then,smart contracts have become more well-known and are being investigated in a vari ety of sectors and industries for their potential to transform conventional corporate operations. Their immutability and transparency, along with the ability to automate processes and get rid of middlemen, have the potential to improve workflow, boost productivity, and cut costs.", "label": "human"}
{"ID": "00030026", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Practical use casesSmart contracts have become a game-changing technology with several real world applications in a wide range of industries. These self-executing contracts, which are inscribed on a blockchain, allow for secure and automated transactions, doing away with the need for middlemen and enhancing participant trust. Smart contracts have transformed lending platforms, decentralized exchanges, and yield farming protocols in the field of DeFi . Smart contracts offer a transparentand effective ecosystem for decentralized financial applications by automating fi nancial transactions and following established regulations. Likewise, supply chain management has benefited from smart contracts. By facilitating seamless tracking and verification of commodities along the supply chain, these contracts improve traceability, lower fraud, and stream logistical operations. Smart contracts have simplified real estate transactions by enabling property transfers, escrow services, and rental agreements. Smart contracts increase efficiency and transparency in the real estate sector by doing away with middlemen and automating repetitive opera-tions.", "label": "human"}
{"ID": "00030027", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In this thesis, the smart contract plays a pivotal role in the ecosystem by ful filling a multitude of significant responsibilities. The storage and maintenance ofconfiguration updates for the Perdesen Distributed Key Generation (DKG) pro tocol is a primary responsibility. The smart contract is responsible for managing a whitelist of decentralized applications (DApps) that utilize the aforementionedsolution. This mechanism ensures that only authorized DApps are able to partic ipate in the protocol. The smart contract is designed to enable the asynchronous execution of the Perdesen DKG protocol rounds, which is a fundamental feature of its functionality. The process entails the antecedent creation of cryptographic keys through the secure retention of encrypted shares for each node involved in theoperation. The implementation of a smart contract facilitates the asynchronous ex ecution of the key generation procedure, thereby enhancing operational efficiencyand scalability. The transparent management of the key generation process is re garded as a fundamental characteristic of the smart contract. The implementationof transparency in the process is paramount to guaranteeing the privacy and security of participants’ private keys. The provision of transparency enables participants to authenticate the advancement and soundness of the key generation procedure while upholding the confidentiality of their private key data. The smart con tract assumes a crucial function in the verification of signatures from nodes that are involved in the process. The implementation of a verification process within the Perdesen Distributed Key Generation (DKG) protocol serves to guarantee thatexclusively legitimate users are allocated roles during each round of the crypto graphic scheme. Through the process of signature verification, the smart contract ensures the integrity and authenticity of the nodes involved, thereby augmenting the overall security and dependability of the protocol.", "label": "human"}
{"ID": "00030028", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In the domain of blockchain-based decentralized applications (DApps), the executor plays a crucial role in facilitating the execution of blockchain network transactions. As the backend component of a DApp, the executor functions as an intermediary between the user-facing frontend and the blockchain. It is primarily re sponsible for establishing a connection to the blockchain, submitting transactionson behalf of users, and managing various interactions with the smart contract. Management of the user’s private key or mnemonic is a fundamental aspect of an ex ecutor’s functionality. A crucial piece of cryptographic information, the private key enables the authentication of transactions and verifies the identity of blockchain users. In some implementations, the private key is stored as a mnemonic, whichis a string of phrases that serves as a human-readable representation of the key.", "label": "human"}
{"ID": "00030029", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "By storing the mnemonic securely in the backend, the executor can access it when required to sign transactions on behalf of the frontend, thereby ensuring a seamless and secure user experience. Executors serve as verifiers and assigners within the Perdesen Distributed Key Generation (DKG) protocol in the context of the thesis.", "label": "human"}
{"ID": "00030030", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "As part of this cryptographic protocol, multiple participants generate a shared se cret key without relying on a central authority that can be trusted. The executorsare responsible for confirming the correctness and impartiality of the smart con tract’s round assignment procedure. Executors contribute to the overall security and resilience of the decentralized system by functioning as dependable parties.", "label": "human"}
{"ID": "00030031", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Their function in the DKG protocol ensures that the key generation and distribu tion process is carried out with diligence and impartiality, thereby protecting theshared secret key’s integrity. In addition, their participation in validating the ve racity of the protocol adds an additional layer of confidence to the entire system, as it ensures that the generated secret key is genuine and can be used securely in cryptographic operations.", "label": "human"}
{"ID": "00030032", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Web3 and DappsWeb3 and Decentralized Applications (DApps) have emerged as critical com ponents of the evolution of the internet and digital ecosystems. Web3 is the vision of a more decentralized and user-centric internet, in which individuals have greatercontrol over their data, identity, and digital interactions. It is a collection of tech nologies, protocols, and frameworks designed to empower users, cultivate trust, and facilitate peer-to-peer interactions. DApps, on the other hand, are applications that are created on top of decentralized networks and typically utilize blockchain technology. These applications inherit Web3’s fundamental principles, including decentralization, transparency, and user ownership. From financial services andgovernance platforms to gaming and social media applications, they provide a va riety of features. The development and adoption of Web3 and DApps have been supported by a growing body of research and innovation. Several academic papersand technical publications have contributed to the advancement of these technologies. For instance, the paper by Wood et al. titled \"Ethereum: A Secure Decen tralized Generalized Transaction Ledger\" provides a comprehensive overview ofthe Ethereum platform and its underlying principles . Another significant con tribution is the work by Swan, who explores the concept of \"Token Economy\" in his book \"Token Economy: How the Web3 Reinvents Value Exchange.\" The book delves into the transformative potential of tokenization and its implications for vari-ous industries . Moreover, the paper by Buterin et al. titled \"A Next-Generation Smart Contract and Decentralized Application Platform\" introduces the Ethereum platform, highlighting its unique features and use cases . This paper serves as a foundational reference for understanding the capabilities and potential of DApps built on Ethereum.", "label": "human"}
{"ID": "00030033", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Social login and OAuth Social login is a prevalent method of authentication that enables users to log in to websites and applications using their existing social media accounts. Users areno longer required to establish new accounts and remember additional login cre dentials. Instead, users can merely click on a social media button, such as \"Sign inwith Facebook\" or \"Sign in with Google,\" to authenticate themselves. Social regis tration is supported by the OAuth2 (Open Authorization 2.0)  protocol, which provides a secure and standardized authentication framework. When a user logs in with a social media account, the website or application sends them to the respectivesocial media platform for authentication. The user is then presented with a con sent interface that describes the data to which the website or application requests access. Once the user grants permission, the social media platform provides thewebsite or application with an access token that can be used to retrieve user infor mation and authenticate the user’s identity. Using OAuth2 for social authentication has multiple advantages. It increases security by removing the need for websites and applications to store user credentials. Instead, the obligation for authenticationfalls on the shoulders of the most reputable social media platforms. Second, so cial login streams the user experience by allowing users to log in with a fewclicks and avoid the inconvenience of creating new accounts. It also allows web sites and applications to utilize the extensive user profile data available on social media platforms, including user names, profile pictures, and email addresses, for personalization and customization.", "label": "human"}
{"ID": "00030034", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Social login benefits DApps The technical complexity of Web3 technology, with its underlying blockchain,cryptographic keys, and smart contracts, can be intimidating for ordinary consumers. Understanding and navigating these complexities can be a significant bar rier to entry for non-technical individuals, impeding the widespread adoption and utility of Web3 platforms. The decentralized nature of Web3 can exacerbate this problem, resulting in fragmented user experiences and inconsistent user interfaces,which makes it difficult for non-technical users to interact effectively with decen tralized applications. To resolve these issues, it is essential to simplify the userexperience and increase Web3 technologies’ accessibility. By refining complicatedprocesses and providing user-friendly interfaces, we can enable regular users to ex ploit Web3’s potential without being overwhelmed by its technicalities. A design that is user-friendly and intuitive can make Web3 applications more accessible tothe general public, thereby promoting their widespread adoption. Using smart contracts, the Pedersen Distributed Key Generation (DKG) protocol, and Shamir se cret sharing, the proposed solution presented in this thesis seeks to enhance the usability of Web3 applications. Using these cryptographic techniques, the system can generate keys in a secure and distributed manner, thereby protecting sensitive data and enhancing user privacy and security. In addition, the solution addresses the difficulties encountered by non-technical users by removing the complexities of Web3 technologies, allowing them to interact with the system without difficulty.", "label": "human"}
{"ID": "00030035", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "By incorporating smart contracts, users can access decentralized applications with out needing to delve into the fundamentals of blockchain operations. The Pedersen DKG protocol and Shamir secret sharing mechanisms provide a robust and securemethod for generating and exchanging cryptographic keys, ensuring that users re tain control over their data while still taking advantage of Web3’s decentralized nature. This thesis ultimately seeks to democratize Web3 technologies by makingthem more inclusive and accessible to a wider audience. By lowering entry bar riers and enhancing the user experience, the proposed solution aims to unleashthe full potential of Web3 for regular users, allowing them to confidently and eas ily participate in the decentralized ecosystem. The objective is to advance a more user-friendly, secure, and decentralized digital landscape through a combination of technological innovations and user-centric design.Chapter 3 will provide a thorough examination of the system characteristics and architecture of our novel social login system. This chapter provides a fundamental understanding of the complex mechanisms and distinguishing characteristics that set our system apart in the decentralized oracle network field. Next, the chapter will provide a detailed description of the system architecture. The social login systemhas been divided into three sub-processes to enhance clarity and address its in herent complexity. This section will provide a comprehensive explanation of each sub-process, emphasizing its distinct functionalities and responsibilities within the overall system flow. By breaking down the system into separate phases, readers can understand the specific steps required to process a user’s request and smoothly execute the social login mechanism.", "label": "human"}
{"ID": "00030036", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "This study examines the efficacy and adaptability of a system that utilizes conventional social login methods to augment the UX of DApps. The following char acteristics can be more detailed:", "label": "human"}
{"ID": "00030037", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Security - combining the potential benefits of blockchain smart-contract, SSS,and Pedersen DKG protocol. The security infrastructure of the system is estab lished upon the utilization of blockchain smart contracts. Programmable contracts,operating on a decentralized network, guarantee the attributes of transparency, im mutability, and tamper-proof execution of operations. Shamir secret sharing is usedto fortify the protection of cryptographic keys and other forms of private infor mation. This method entails breaking up a secret into smaller pieces and givingthem to several parties. The Petersen DKG protocol distributes and secures cryp tographic key generation, ensuring system security. This system lets a group of people generate a shared cryptographic key without anyone having the full key.", "label": "human"}
{"ID": "00030038", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Efficacy and adaptability - By leveraging blockchain’s decentralized nature,system eliminates the reliance on centralized identity providers, reducing the potential for single points of failure and enhancing security. Additionally, blockchain based identity systems enable instant verification of user credentials, eliminating the need for lengthy verification processes and reducing transaction times. The open solution’s architecture enables seamless integration with any DApps, making it easier for developers to adopt and implement with their products.", "label": "human"}
{"ID": "00030039", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "User-friendly - This solution supports popular authentication mechanisms such as social login which are widely used in the traditional web. This familiarity allowsusers to leverage their existing accounts and authentication methods, reducing the learning curve and providing a seamless transition into the Web3 space. Users caneasily authenticate their identities across multiple DApps using a unified and stan dardized protocol, without the need to remember and manage multiple usernames and passwords. This eliminates the hassle of creating and maintaining numerous accounts, making the user experience more streamd and efficient.", "label": "human"}
{"ID": "00030040", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Scalability - Compatible with any type of social authentication, including Facebook, Google, and Twitter. Utilizing a decentralized architecture increased the request’s performance and volume by spreading it across multiple executors and par allel handling processes.3.2 Overall of system Figure 3.1: Overall the system Figure 3.1 depicts the exhaustive and intricate request flow of a user interactingwith the social login system. This intricate process has been meticulously subdi vided into three distinct sub-processes, each with a specific function, to facilitatea clearer and more comprehensive comprehension of the system’s overall func tionality and interactions. The user’s voyage begins when they initiate a request, at which point they choose the convenience and security of the social login feature.", "label": "human"}
{"ID": "00030041", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Subsequently, the initial sub-process begins, meticulously validating the user’s input and ensuring the request’s highest level of security. This validation phase is es sential for protecting against potential vulnerabilities and maintaining the system’s integrity. After the request has successfully passed the initial validation phase, the second sub-process authenticates the social logon credentials against the relevantprovider’s robust authentication system. This crucial phase ensures the authentic ity of the user’s identity and restricts system access to only authorized individuals.", "label": "human"}
{"ID": "00030042", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The rigorous authentication procedure protects against unauthorized access and fosters a secure environment for user interactions. The third sub-process assumescontrol upon successful authentication of the social logon credentials, orchestrat ing the logic for constructing the encryption key and the assignment key. Thesekeys are essential to assuring the security and confidentiality of user informationthroughout their interaction with the system. The encryption key ensures that sensi tive information remains confidential and protected from potential breaches, whilethe assignment key optimizes the user experience by facilitating the seamless as signment of roles and permissions. Throughout this complex process, the systememploys smart contracts and blockchain technology, which serve as the founda tion for preserving and protecting user data for the duration of the blockchain’s active state. By leveraging the capabilities of smart contracts and blockchain, the system maintains a decentralized and transparent infrastructure, thereby nurturing user confidence.", "label": "human"}
{"ID": "00030043", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "This phase begins the secure process of user authentication and authorization. Atthe authorization endpoint, the user is presented with a login and authorizationprompt, where they authenticate themselves securely and grant the required permissions. This step ensures that only authorized users have access to the application’s resources and can perform particular operations, thereby protecting the ap plication’s integrity and sensitive data. The Auth0 server redirects the user back to the application with an authorization code following successful authentication andassent. This authorization code is a crucial component of the subsequent authentication and authorization processes. The application then exchanges this authoriza tion code along with its own credentials and client ID with the token endpoint ofAuth0. The Auth0 server meticulously verifies this exchange, ensuring the authen ticity and validity of the supplied data. Upon successful authentication, the Auth0 server issues the application both an access token and an ID token. During the authentication and authorization procedure, these tokens serve unique functions.", "label": "human"}
{"ID": "00030044", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The access token functions as proof of authorization, allowing the application toauthenticate future requests on behalf of the user. It grants access to protected re sources and API endpoints, facilitating secure and seamless application-to-server communication. The access token is typically included in API request parameters by the application, facilitating secure data exchange and interactions. The ID token, on the other hand, comprises vital user information, which facilitates identification and authentication within the application. It may contain information such as the user’s email address, identify, and other pertinent attributes. The ID token enables the application to recognize the user and customize the user’s experience within the application, thereby creating a personalized, user-centric environment. Auth0 is a highly dependable and efficient authentication and authorization solution due toits extensive feature set and stringent security measures. Auth0 assures the confidentiality and integrity of user data throughout the entire authentication and autho rization procedure by adhering to secure protocols and industry best practices. Its seamless integration with multiple authentication methods and customizable user experiences make it a valuable asset for application developers seeking to improve the security and usability of their software.3.2.2 Requesting encKey for Executors Figure 3.3: Request assign the share The process of ensuring secure and effective authentication and authorization in the system, as depicted in Figure 3.3, consists of multiple phases working in concert to provide a seamless user experience. The SDK, which functions as the interface between the user’s device and the system, is central to this process. The SDK transmits the idToken or accessToken, along with the appName and clientId, to the executors whenever the user initiates the authentication process. As essential system components, the executors play a crucial role in authenticating the user’s credentials and ensuring secure smart contract interaction. They begin by querying the smart contract to retrieve the app’s essential authentication and authorization parameters and configuration data. This data is essential for establishing a secure and trusted connection between the user and the application. Executors initiate thevalidation procedure after receiving the data from the smart contract. It is essen tial to validate the integrity and authenticity of the data extracted from the idToken or accessToken to ensure that the user’s credentials have not been altered during transmission and are valid. When a new user attempts authentication, the executors generate a unique key for that user. This key functions as a digital identifier and is securely associated with the user’s authenticated email address. This phase ensures that each user within the system has a unique and distinguishable key, allowing for secure and efficient user management. The smart contract encrypts the shares using the private keys of the nodes that participated in the protocol as part of thedistributed key generation process. The encrypted shares are transmitted in a secure manner to the executors, who can decrypt them with their own private keys. This secure decryption safeguards the shares’ confidentiality and integrity, preventing unauthorized access. The executors reconstruct the final share and promptly return it to the SDK after decrypting the shares. These shares play a crucial role in the subsequent phases of authentication and authorization, enabling the user to access and interact with decentralized applications (DApps) within the ecosystem withconfidence and security. By strictly adhering to this exhaustive and complex pro cedure, the system guarantees that user authentication and authorization are both effective and secure. The combination of smart contracts, Shamir secret sharing, and the Pedersen DKG protocol enables the system to offer a robust, trustworthy,and user-friendly Web3 authentication solution. This comprehensive strategy ad dresses the complexities of Web3 technologies and promotes widespread adoption and utility by improving the security, accessibility, and overall user experience of decentralized applications.", "label": "human"}
{"ID": "00030045", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The SDK initiates a query request to the metadata repository whenever the need arises to reconstruct the private key. The backend retrieves the encrypted sharesassociated with the specified user and application from the database upon receiv ing the query. The query result, including the encrypted shares, is cached in aRedis database to boost performance and accelerate subsequent requests. After re ceiving the encrypted shares, the SDK initiates the reconstruction process. TheSDK decrypts each share using its respective decryption key. Only authorized pro cesses have access to these decryption keys, which are managed securely within the SDK. The SDK recovers the original confidential information contained within each share by decrypting the shares. The SDK combines the decrypted shares usinginterpolation algorithms, such as Lagrange interpolation, to generate the final pri vate key. Using the available shares, this mathematical calculation interpolates the absent portions of the private key. The SDK successfully reconstructs the original private key through this procedure. Throughout the entirety of the reconstruction process, robust encryption algorithms and secure key management procedures are used to protect the privacy and integrity of the private key. The implementation of Shamir’s scheme for secret sharing is essential for enhancing security because itdistributes the key across multiple shares, making it resistant to single points of fail ure or compromise. Our system guarantees the safety and reliability of the privatekey’s retrieval by implementing this exhaustive and secure reconstruction proce dure. This feature enables users to securely access their Web3 ecosystem accountsand confidently execute authorized operations. In addition, the comprehensive se curity measures ensure that the private key remains protected and inaccessible tounauthorized entities, giving users peace of mind when interacting with decen tralized applications (DApps) and the broader Web3 ecosystem. This procedure’s meticulous design and execution exemplify the system’s dedication to providing a secure and user-friendly Web3 authentication solution.3.3 Asynchronous create encKey process Figure 3.5: Asynchronous create encKeyThe asynchronous creation of the encKey process is a crucial and ingenious el ement of the system’s architecture, as it is intended to maximize efficiency andresource utilization. Without running the Distributed Key Generation (DKG) pro tocol each time, this method ensures that keys can be assigned to users quickly and seamlessly, without the need to run the protocol each time. By generating a poolof unused encKeys in advance, the system significantly reduces the time and com putational overhead required for key assignment, ultimately augmenting the userexperience. The executors, the pillars of the encKey generation procedure, are re sponsible for initiating the procedure. They constantly monitor the current round’s status and the number of inactive keys. When the system detects a need for new keys, such as when the present state is null or in the \"waitfordealer\" phase, and the number of idle keys falls below the anticipated threshold, the executors initiate the subsequent round. This proactive strategy ensures that the system is always readyto meet user demands and minimizes any potential delays in key assignment. During the initial phase of the round, known as the \"sharing dealer\" phase, the execu tors combine and distribute their individual confidential shares to the designated sharing dealer. This strategic partnership permits each executor to contribute to the procedure without disclosing sensitive information that could compromise theoverall secret key. By effectively sharing their secret shares, the executors dissemi nate the secret in a manner that maintains the keys’ security and integrity. Once the\"sharing dealer\" phase is effectively completed, the protocol seamlessly transitions to the \"waitforrows\" phase. In this phase, the executors generate their own public key shares using the shared secrets obtained in the previous phase. These public key exchanges are essential to the conclusion of the key generation process, as they guarantee the authenticity and validity of the user-assigned keys. The system is now well-prepared for the assignment of encKeys to users, as the \"waitforrows\" phase has concluded. When a user requests their key, the system assigns the correct round to their assigned key and provides it, ensuring a speedy and efficient assignment.", "label": "human"}
{"ID": "00030046", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "By adopting this asynchronous method for encKey generation, the system obtains a number of substantial benefits. First, it optimizes resource usage by eliminating theneedless re-execution of the DKG protocol for each key assignment. Second, it im proves the scalability and performance of the system, allowing it to manage a large number of user requests without compromising response times. Lastly, it assuresa secure and seamless workflow for encKey generation and assignment, reinforc ing the system’s dedication to user convenience and data security. In conclusion, the incorporation of the DKG protocol and the effectiveness of the asynchronous encKey creation procedure demonstrate the innovative and sophisticated nature ofthe system’s design. The system’s ability to efficiently generate and assign encK eys contributes to its overall robustness, allowing Web3 ecosystem users to enjoy asecure and user-friendly experience.In the fourth chapter of this dissertation, I delve into the complexities and tech nical aspects of our innovative social authentication system. It is a comprehensiveguide for comprehending the architecture, design, and implementation of the sys tem. This chapter provides a detailed analysis of a number of crucial components, casting light on the obstacles encountered during development and the solutions employed to overcome them.", "label": "human"}
{"ID": "00030047", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The figure 4.1 depicts the general usecases of Social login system. There are two actors included in the system. The first one is User who will use the main function social login. The table below describes more detail about functionalities of usecase:No Use Case Description 1Regiser User using their social account such as: Google, facebook, ... for signing up the web3 spaces 2Login User using their social account such as: Google, facebook, ... for signing in the web3 spaces 3View the private key and shares descriptionUser fully controls and manages their private key and their shares.", "label": "human"}
{"ID": "00030048", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "No Use Case Description 1Create encKey Executor run the phases of Pedersen Protocol for pre-creating the encKey for user to encrypt their share.", "label": "human"}
{"ID": "00030049", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Provide signatureExecutors communicate with one another via sig natures; if the number of valid signatures exceedsthe threshold, anyone can delegate a key to a spe cific user via a multi-signature mechanism.", "label": "human"}
{"ID": "00030050", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "For a better understanding of the use cases, I’d like to include the corresponding activity diagrams beneath each specification.Usecase code UC001 Usecase name Social login Actor User Pre-condition At least have 1 social account Main flow of eventNo Actor Action1 User Select social lo gin type2 System Redirect to au thorize3 Auth0 Redirect to login and autho rization form 4 User Authenticate and consent 5 Auth0 Redirect withsingle use au thorization code6 System Send code clientId and creden tials to get oauth token 7 Auth0 Verify code,cliendId, cre dentials 8 Auth0 Send idToken, access token and refresh token 9 System Authenticate theidToken or ac cess token 10 System Assign encKey for user 11 System Send shares 12 System Contruct the encKey 13 System Construct the private Key Alternative flow of eventNo Actor Action 5b Auth0 Return error if the authenticate and consent fail or rejected 8b Auth0 Response with error becausefail in verifica tion Table 4.3: Sign up specificationFigure 4.2: Signing up activity Figure 4.2 is an activity diagram that illustrates the process, how users interact with the system, and the connections between the components. The SDK acts as a bridge between users and the remainder of the system, while Executors and Auth0 validate users’ identities. In addition, executors assign and provide the requirements for user encKey and private key construction.Usecase code UC001 Usecase name Social login Actor User Pre-condition At least have 1 social account Main flow of eventNo Actor Action1 User Select social lo gin type2 System Redirect to au thorize3 Auth0 Redirect to login and autho rization form 4 User Authenticate and consent 5 Auth0 Redirect withsingle use au thorization code6 System Send code clientId and creden tials to get oauth token 7 Auth0 Verify code,cliendId, cre dentials 8 Auth0 Send idToken, access token and refresh token 9 System Authenticate theidToken or ac cess token 10 System Send shares 11 System Contruct the encKey 12 System Construct the private Key Alternative flow of eventNo Actor Action 5b Auth0 Return error if the authenticate and consent fail or rejected 8b Auth0 Response with error becausefail in verifica tion Table 4.4: Sign in specificationFigure 4.3: Signing in activity Similar to figure 4.2, figure 4.3 describes in detail how users login into the system and how the system’s components interact.Usecase code UC001 Usecase name Social login Actor User Pre-condition At least have 1 social account Main flow of eventNo Actor Action1 User Select social lo gin type2 System Redirect to au thorize3 Auth0 Redirect to login and autho rization form 4 User Authenticate and consent 5 Auth0 Redirect withsingle use au thorization code6 System Send code clientId and creden tials to get oauth token 7 Auth0 Verify code,cliendId, cre dentials 8 Auth0 Send idToken, access token and refresh token 9 System Authenticate theidToken or ac cess token 10 System Send shares 12 System Contruct the encKey 13 System Query metadata 14 System Return shares description 15 System View private key and share description Alternative flow of eventNo Actor Action 5b Auth0 Return error if the authenticate and consent fail or rejected 8b Auth0 Response with error becausefail in verifica tionFigure 4.4: View private key and shares description activity The last use case, showing in 4.4, for the user involves viewing their private keyand their shares. This functionality allows users to have full control and manage ment over their shares, even outside the system. By providing access to their privatekey and the corresponding shares, users can securely store this information in a lo cation of their choice, such as a hardware wallet or an encrypted off storage.", "label": "human"}
{"ID": "00030051", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "This feature enhances the security and flexibility of the system, as users have thefreedom to manage their shares independently and ensure the safety of their cryp tographic assets. Additionally, by being able to view their private key and shares, users can also perform off verifications and audits, ensuring the integrity and accuracy of their cryptographic operations.Usecase code UC001 Usecase name Social login Actor Executor Pre-condition Executor is a member of DKG Main flow of eventNo Actor Action 1 Executor create encKey 2 Executor Query config and number of idle keys 3 Executor Share dealer phase4 Smart contract Store the com mitments and shares 5 Smart contract Auto update round status6 Excutor Query the cur rent round statusand round infor mation 7 Executor Construct the final shares and the pubkey share from theround informa tion 8 Executor Share row phase9 Smart contract Store the com mitments and shares 10 Smart contract Auto update round status11 Smart contract Push the com plete round to the pool Alternative flow of eventNo Actor Action 3b Executor Stop and waitthe next time in voking Table 4.6: Executor contributes in the DKG protocolFigure 4.5: Executor contributes in the DKG protocol activity diagram The participation of an executor in the encKey creation procedure is crucial forthe successful operation of the system. The executor, as a special actor, plays an ac tive role in contributing to the system’s functioning. The process involves multiple steps and interactions between the executor and the public smart contract deployed on the blockchain.", "label": "human"}
{"ID": "00030052", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Usecase code UC001 Usecase name Social login Actor Executor Pre-condition Executor is a member of DKG Main flow of eventNo Actor Action 1 Executor Assign key 2 Executor Send idToken or accessToken to Auth0 3 Auth0 Verify token4 Auth0 Send verify re sponses 5 Executor Validate theuser informa tion6 Executor Send the sig natures for the client for aggregate7 Executor Validate signa tures 8 Executor Send request assign key with signatures to smart contract9 Smart contract Process the re quest Alternative flow of eventNo Actor Action 6b Executor Reject request ifinvalid user in formation 8b Executor Reject request ifthe valid signatures is not exceed the thresh olds Table 4.7: Executor assigns keyFigure 4.6: View private key and shares description activity Figure 4.6 provides a detailed illustration of the process in which an executor assigns an encKey to a user in the social login system for Web3. This diagramshowcases the interactions between three key components: Auth0, the smart con tract, and the executor.", "label": "human"}
{"ID": "00030053", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In addition to the blockchain technology, smart contracts, and oracles described in the background section, I would like to describe other system-building tools and libraries.", "label": "human"}
{"ID": "00030054", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "ExpressJsExpress.js is a well-known web application framework for Node.js that facili tates the construction of scalable and robust web applications. It offers a minimal-istic and adaptable approach to web development, making it simple for developers to construct server-side applications.", "label": "human"}
{"ID": "00030055", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "One of the primary benefits of Express.js is its simplicity and usability. It pro vides developers with a framework that is minimal and agnostic, allowing them to structure their applications according to their needs. Express.js adheres to amiddleware-based architecture, enabling developers to easily incorporate middle ware components to handle various application aspects, such as routing, request processing, and error handling.", "label": "human"}
{"ID": "00030056", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Express.js  is widely recognized for its robust routing capabilities. It of fers a concise and straightforward syntax for defining routes and managing various HTTP methods, including GET, POST, PUT, and DELETE. Express.js makes it simple to define routes for handling incoming requests and performing operationssuch as retrieving data from a database, processing the data, and returning the ap propriate response to the client.", "label": "human"}
{"ID": "00030057", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Within the system architecture, Express.js serves as a robust and versatile serverframework that plays a vital role in handling the requests associated with the meta data of the system. Leveraging the power of Express.js, the backend of the system is equipped with the capability to receive, process, and respond to various types of requests related to the metadata. Overall, the utilization of Express.js as the serverframework for handling metadata requests empowers the system to efficiently manage and process metadata-related operations. Its robust routing system, extensi ble middleware ecosystem, and high-performance nature make Express.js an idealchoice for building scalable and reliable backend systems that handle metadata ef fectively.", "label": "human"}
{"ID": "00030058", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "JSON-RPC and Jayson library JSON-RPC is a remote procedure call protocol encoded in JSON. It allows for the execution of remote procedures on a server and the exchange of structured data between the client and the server. In the system, JSON-RPC is employed to facilitate communication between different components and services, enabling the invocation of remote procedures and the transmission of data in a standardized andefficient manner. The utilization of JSON-RPC ensures interoperability and seam less integration between various system components.", "label": "human"}
{"ID": "00030059", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The Jayson library, a JSON-RPC implementation for Node.js, is used to manage JSON-RPC communication between the client and server. Jayson is a frame work for creating JSON-RPC servers and clients in Node.js that is lightweight and efficient. It simplifies the creation and management of JSON-RPC requests and responses, facilitating integration with the server and client components of the sys-tem. You can define the server-side methods that will be exposed to clients via JSON-RPC using Jayson. Jayson handles the serialization and deserialization of JSON-RPC messages. These methods can be implemented as functions or class methods. It offers a convenient API for managing the request payload, extracting the method name and parameters, and executing the appropriate server-side logic.", "label": "human"}
{"ID": "00030060", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The Jayson library integrates seamlessly with the Express.js server, allowing the server component of the system to process incoming JSON-RPC requests usingthe specified server-side methods. It offers an elegant and efficient solution for im plementing JSON-RPC communication in Node.js, making it an excellent choice for the communication layer of the system.", "label": "human"}
{"ID": "00030061", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The Jayson library is incorporated in the system to process JSON-RPC requests from the client to the executor component. This decision is made because the role of the executor predominantly entails handling and processing requests unrelated to database operations. Using Jayson for JSON-RPC communication allows theexecutor to efficiently manage requests without requiring direct database interac tion. JSON-RPC requests may include information and instructions for the executorto perform particular duties or computations, such as generating shares, decrypt ing data, or validating signatures. The executor processes these requests, carriesout the required logic, and returns the appropriate response to the client. Imple menting JSON-RPC for the executor enables a clean separation of concerns, as the executor component is exclusively focused on executing the requested tasks and does not interact directly with the databases. This design decision streams the executor’s responsibilities and improves its capacity to respond to client requests.", "label": "human"}
{"ID": "00030062", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Using a well-established library such as Jayson also facilitates the implementa tion of JSON-RPC communication, resulting in a robust and dependable solution.", "label": "human"}
{"ID": "00030063", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The library manages the serialization and deserialization of JSON-RPC messages,ensuring that requests and responses are formatted correctly and are compatible be tween the client and executor. This simplifiees the development process and helps keep the communication protocol consistent and compatible.", "label": "human"}
{"ID": "00030064", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "DatabaseMySQL is an extensively utilized open-source relational database manage ment system (RDBMS) for storing and querying structured data. In your system, MySQL is used exclusively for storing and querying metadata in the metadata backend section. MySQL offers a dependable and effective method for storing structured data in tables, with support for a variety of data types and indexingoptions. It provides comprehensive transactional capabilities, ensuring data consistency and integrity during concurrent operations. MySQL’s robust query language,SQL (Structured Query Language), enables efficient data retrieval and manipu lation through a variety of query operations, including filtering, sorting, joining, and aggregating. The metadata backend section of the system is responsible for managing and storing metadata associated with user authentication, authorization,and other pertinent data. MySQL functions as the underlying database technol ogy for the structured storage of this metadata. In the future, the metadata may include encrypted shares or ecrypted information of multiple system modules. Byleveraging MySQL, the system can take advantage of its scalability and perfor mance enhancements, enabling it to efficiently manage large volumes of metadata.", "label": "human"}
{"ID": "00030065", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In addition, MySQL provides security mechanisms, data backup and recovery, and replication options, all of which contribute to the dependability and accessibility of your metadata storage.", "label": "human"}
{"ID": "00030066", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Frontend The frontend of the system plays a critical role as it enables users or clients to interact with the system in a seamless and user-friendly manner. It serves as the interface through which users can access the system’s features, functionalities, and data.", "label": "human"}
{"ID": "00030067", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Tkey is a GitHub-hosted open-source library designed to provide cryptographickey management capabilities. The library seeks to simplify the handling and management of cryptographic keys, making it easier for application developers to im plement robust security measures. The Tkey library provides a vast array of keygeneration, storage, and usage-related features and functions. It supports a vari ety of cryptographic algorithms, such as symmetric and asymmetric encryption, digital signatures, and hash functions. This enables developers to employ various cryptographic techniques based on their particular requirements. Tkey’s emphasis on security is one of its primary features. The library employs key management best practices, such as secure key storage, protection against unauthorized access,and secure key sharing protocols. Tkey adheres to industry standards and recom mendations to assure the privacy, integrity, and accessibility of cryptographic keys.", "label": "human"}
{"ID": "00030068", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In addition, Tkey provides a simple and intuitive API, easing the integration ofcryptographic key management into applications. The library provides develop ers with comprehensive documentation and implementation examples. Based on the foundation provided by the Tkey open-source library, our system extendsits functionality by implementing modules that are specifically tailored to our ap plication’s needs. These custom modules enhance Tkey’s compatibility with our system’s architecture by enhancing its primary features.4.2.4 Virtualization Docker is an open-source platform that has revolutionized the way applications are developed, shipped, and deployed. It provides developers with a powerful set of tools to automate the packaging and deployment of applications inside lightweight, portable containers. By leveraging containerization technology, Docker enables thecreation of isolated environments that encapsulate an application and its depen dencies. This ensures that the application runs consistently and predictably across different systems, regardless of the underlying infrastructure.", "label": "human"}
{"ID": "00030069", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Containers are self-contained units that contain everything needed to run an application, including the code, runtime, system tools, and libraries. They offeradvantages such as isolation, scalability, and reproducibility. With Docker, devel opers can package their applications along with all the necessary dependencies into a container image, which can then be deployed on any system that has Dockerinstalled. This eliminates the need for complex setup processes and reduces com patibility issues between different environments.", "label": "human"}
{"ID": "00030070", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Docker Compose is a complementary tool to Docker that simplifies the manage ment of multi-container applications. It allows developers to define and configure multiple containers, their networks, and volumes using a simple YAML file. Thismakes it easier to define complex, interconnected services and orchestrate their deployment. With Docker Compose, developers can quickly spin up an entire appli cation stack with a single command, making the development and testing process more efficient.", "label": "human"}
{"ID": "00030071", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In the context of this thesis, Docker plays a crucial role in encapsulating the application and its dependencies, ensuring portability and consistency. By using Docker, the application can be packaged into a container image, making it highlyportable and enabling easy deployment across different environments. Docker compose is utilized during the development phase to define and manage the various services and dependencies required by the application. This allows for rapid system configuration and simplifies the process of setting up a development environment.", "label": "human"}
{"ID": "00030072", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Rust, wasm and cosmwasmRust is a systems programming language known for its emphasis on perfor mance, reliability, and safety. It offers a high level of control over system resources while providing memory safety guarantees through its ownership and borrowing system. Rust’s combination of low-level control and high-level abstractions makesit well-suited for building efficient and secure software, including blockchain ap plications.", "label": "human"}
{"ID": "00030073", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "WebAssembly (Wasm) is a binary instruction format that allows for the exe-cution of code on a variety of platforms, including web browsers. It provides a portable and efficient runtime environment for running code at near-native speeds.", "label": "human"}
{"ID": "00030074", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Rust is one of the languages that can compile to WebAssembly, allowing develop ers to leverage Rust’s performance and safety features in web-based applications.", "label": "human"}
{"ID": "00030075", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "CosmWasm is a specific implementation of WebAssembly designed for smart contract development within the Cosmos ecosystem. It extends the capabilities ofWebAssembly to support the unique requirements of blockchain-based smart contracts. With CosmWasm, developers can write smart contracts in Rust and compile them to WebAssembly, leveraging the language’s safety guarantees and per formance optimizations. CosmWasm provides a secure execution environment for these smart contracts, ensuring the integrity and correctness of their execution on the blockchain.", "label": "human"}
{"ID": "00030076", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The combination of Rust, WebAssembly, and CosmWasm offers several benefits for blockchain development. Rust’s memory safety features help mitigate vulnerabilities and potential exploits in smart contracts, reducing the risk of secu rity breaches. WebAssembly enables efficient execution of the compiled Rust code across different platforms, allowing for interoperability and portability. CosmWasm, as an implementation of WebAssembly tailored for blockchain smart contracts,provides a secure and optimized environment for executing Rust-based smart con tracts within the Cosmos ecosystem.4.3 Diagram design 4.3.1 Sequence diagram Figure 4.7: Register sequence diagram The diagram 4.7 depicts the registration procedure for a new encKey. The user must select the social registration type and successfully complete the validation procedure.Figure 4.8: Login sequence diagram The diagram 4.8 depicts the social authentication system’s sign-in procedure.", "label": "human"}
{"ID": "00030077", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Entity diagram In the context of the centralized system described in this thesis, it is possible that the traditional Entity-Relationship (ER) diagram does not completely capture the unique characteristics of the metadata storage in the smart contract. Instead,we can depict the entities and their relationships within the system using an alter nate representation. This system’s smart contract serves as the central repositoryfor metadata associated with user identities and encKeys. It operates as a decentralized database, storing and managing user-specific data on the blockchain us ing key-value pairings. The key-value approach is ideally suited for the metadatamodule because it facilitates efficient data retrieval and assures data integrity and immutability. In this context, the entities and their relationships can be described as follows:", "label": "human"}
{"ID": "00030078", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Attribute Type Required Description index number yes The index of the member in the system plays vital role in reconstructing the encKey pub_key Binary yes The pubkey of the executor participating in the system address Addr yes The address of the executor participating in the systemend_point string yes end_point is the url to ex ecutor node, which for the request in the SDK Table 4.8: Member entity detailAttribute Type Required Description members Vec<Member> yes The member or executors operate the system total number yes Total member participate in the system owner Addr yes The address of the owner of the system expected_key_num number yes The number of expected keys are in idle pool deadline_time number yes The maxium duration of creating a key dealers number yes Thresholds for the 2 phase Wait for dealers\" and Wait for rows\" Table 4.9: Config entity detail Attribute Type Required Description index number yes The index of executor in the system commitments Vec<Binary> no The commitments of shares of executor for the rows rows Vec<Binary> no The encrypted shares for other executors pk_share Binary no The pubkey of the final share of executor Table 4.10: Membershare entity detail Attribute Type Required Description round_status number yes The status of the round, there are 4 status includein: WaitForDealers, Wait ForRows, WaitForAssign, and Assigned member_shares Vec<Membershare> no The shares of executor for round dead Vec<Binary> no The dead of this round Table 4.11: RoundInfo entity detail4.4 Message design 4.4.1 Smart contract messageCosmWasm  is a smart contract platform that has been developed utiliz ing the Cosmos SDK, a blockchain framework specifically designed for the construction of DApps. CosmWasm offers a robust and optimized framework forthe execution of intelligent contracts across diverse blockchain networks, ensur ing both security and efficiency. The CosmWasm smart contract model is foundedupon the actor model, a widely adopted paradigm utilized in the design of concur rent and distributed systems. The actor model is a computational paradigm in which each smart contract is conceptualized as an actor. An actor is an autonomous entity capable of receiving messages, performing computations on them, and transmitting messages to other actors. In the CosmWasm smart contract model, the actors are characterized by their isolation from one another, with communication occurring exclusively through the exchange of messages.", "label": "human"}
{"ID": "00030079", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Instantiate message The concept of instantiation messages pertains to the process of instantiating and deploying a smart contract on the blockchain.", "label": "human"}
{"ID": "00030080", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Field Type Required Descriptionmembers Vec<Member> yes The information of executors participate in the sys tem dealers u8 yes Thresholds of the system for passing each phaseowner string yes Owner of the smart con tract expected_key_num uint yes The expected number of key in idle pool deadline_time uint yes The maxium duration of 1 round Table 4.12: Instantiate message detail 4.4.1.2 Execute message The execute message serves as the primary interface for processing incoming messages and executing the contract’s logic in accordance with the provided input.", "label": "human"}
{"ID": "00030081", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Every execute message contained within the executor message enumeration pos sesses a distinct structure and data payload, thereby empowering the smart contract to effectively react to a wide array of interactions originating from users or other entities within the blockchain ecosystem.The following tables provide a more comprehensive description of each execute message:", "label": "human"}
{"ID": "00030082", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Field Type Required Description rows Vec<Binary> yes The shares given to eachparticipant in the DKG pro tocol in order to construct their final share for encKey.", "label": "human"}
{"ID": "00030083", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "commitments Vec<Binary> yes The commitments are to confirm that the rows originate from the precise source Table 4.13: ShareDealerMsg detail Field Type Required Description pk_share Binary yes pk_share is the pubkey of the final share that theexecutor reconstructs us ing rows and commitments from the share dealer.", "label": "human"}
{"ID": "00030084", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Field Type Required Description round_id uint yes The id of the round round_status usize yes The status of the roundmembers_shares Vec<MemberShare> yes The details about the mem bershares of the round deadline uint yes The deadline of the round Table 4.18: RoundInfoResponse detailField Type Required Descriptionmembers Vec<Member> yes The information of the ex ecutor participating in the system total uint yes The number of the executor dealer uint yes Thresholds of the system owner string yes Owner of the system expected_key_num uint yes The number of expected keys in idle pool Table 4.19: ConfigResponse detail Field Type Required Description verifier string yes The app that need to query user email start_after string yes The exclude bound start of the querylimit uint no Number of verifierId. De fault is 10 Table 4.20: ListVerifierIdMsg detail Field Type Required Description verifier string yes The app that need to query user email list_verifier_id Vec<string> yes List of the email or user_id of the app Table 4.21: ListVerifierIdResponse detail Field Type Required Description msg Binary yes The mesage that was signed by executor sigs Vec<Binary> yes Signatures for the message pub_keys Vec<Binary> yes The public key of executors signed the message Table 4.22: VerifyMemberMsg detail 4.4.2 JRPC message The executor plays a crucial role in the creation and distribution of encryption keys to users. The executor exposes four essential JSON-RPC (JRPC) methods tofacilitate this functionality:AssignKeyCommitmentRequest - The executor uses this JRPC method to re quest the user’s commitment to a new encryption key. The user will commit to the key without disclosing its actual value. This phase verifies that the user intends to generate a valid encryption key.", "label": "human"}
{"ID": "00030085", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "AssignKeyRequest - The executor uses this JRPC method to request the actual encryption key from the user after obtaining the user’s commitment. The user will provide the encrypted key in accordance with the commitment, ensuring that the key remains secret until later phases of the process.", "label": "human"}
{"ID": "00030086", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "CommitmentRequest - The executor uses this JRPC method to request thecommitments made by other executors in the system. To proceed with the encryption key generation process and accomplish the desired level of security and con sensus, other executors’ commitments are required.", "label": "human"}
{"ID": "00030087", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "ShareRequest - Lastly, the executor uses the ShareRequest JRPC method to re quest shares from other executors in order to reconstruct the encryption key. As part of the distributed key generation protocol, the executor must obtain portions from multiple other executors.", "label": "human"}
{"ID": "00030088", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Field Type Required Description jsonrpc string yes The version of JRPC. Must be \"2.0\" method string yes The method will call in the json-rpc server id number yes An identifier established by the Client params Object yes A Structured value that holds the parameter valuesto be used during the invo cation of the method Table 4.23: General JPRC request detailField Type Required Description jsonrpc string yes The version of JRPC. Must be \"2.0\"result string no This member is RE QUIRED on success.This member MUST NOT exist if there was an error invoking the method.The value of this member is determined by the method invoked on the Server.", "label": "human"}
{"ID": "00030089", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "id number yes An identifier established by the Clienterror Object no This member is RE QUIRED on error.This member MUST NOT exist if there was no errortriggered during invoca tion.The value for this member MUST be an Object Table 4.24: General JPRC response detail The subsequent tables will describe in detail the request parameters and the response value:", "label": "human"}
{"ID": "00030090", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Field Type Required Description tokencommitment string yes The hash of the idToken or access token receive from Autho0 temppubX string yes The pubkey in X axis of temp key established in the reconstruct process tempubY string yes The pubkey in Y axis of temp key established in the reconstruct process Table 4.25: CommitmentRequest parameters detailField Type Required Description signature string yes The signature of executor sign on datadata string yes The data is signed by ex ecutornodepubX string yes The pubkey in X axis of ex ecutor node using for verifynodepubY string yes The pubkey in Y axis of ex ecutor node using for verify Table 4.26: CommitmentRequest response value detail Field Type Required Description verifier string yes The name of the app that registered in the system verifier_id string yes The email or user_id of user idToken string yes The idtoken of the Auth0nodesignatures Object yes The result of the commit ment request Table 4.27: ShareResponseRequest parameters detail Field Type Required Description Publickey string yes The publickey of the first commitment Share string yes The share encrypted withthe client’s public tempo rary key. This portion is used to reconstruct encKey.", "label": "human"}
{"ID": "00030091", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Metadata Object yes The description of the share, which is necessary for decrypting the share Table 4.28: ShareRespone result value detailField Type Required Description tokencommitment string yes The hash of the idToken or access token receive from Auth0verifier string yes The app that using the sys temverifier_id string yes Email or useri_id respec tively in the app Table 4.29: AssignKeyCommitmentRequest parameters detail Field Type Required Description data Object yes The publickey of the first commitment nodepubx string yes The publickey in X-axis of executor nodepuby string yes The publickey in Y-axis of executor signature string yes The signature of the data in stringtify verifierIdSignature string yes The signature was signed by executor about the userid or email Table 4.30: AssignKeyCommitmentResponse value detail Field Type Required Description idToken string yes The publickey of the first commitment verifier string yes The publickey in X-axis of executor verifier_id string yes The publickey in Y-axis of executor nodesignatures Object yes The response of theassignKeyCommitmentRe sponse in stringtify Table 4.31: AssignKeyRequest parameter detailField Type Required Descriptionstatus bool yes The response of the assignKeyRequest. If the sta tus fail, the system will retry until 5 times.", "label": "human"}
{"ID": "00030092", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "HTTPS requestThe HTTPS request is an integral element of the system’s communication be tween the client and the metadata server. It allows the client to perform CRUD operations on the server’s database-stored metadata. The HTTPS protocol is used to ensure secure and encrypted communication between the client and the server,thereby safeguarding data and guaranteeing the privacy and integrity of transac tions. When a client needs to create new metadata, it transmits an HTTPS POST request containing the required information to the server. The server processes the request, verifies the data, and adds the newly generated metadata to its database.", "label": "human"}
{"ID": "00030093", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The client sends an HTTPS GET request to the server for reading data, specifying the unique identifier of the metadata or any other criteria for retrieving specific entries. The server retrieves the requested data from the database and returns it in response to the client.", "label": "human"}
{"ID": "00030094", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The tables below illustrate in detail about the messages and responses of the HTTPS request:Field Type Required Description pub_key_X string yes The pubkey in X-axis of encKey or the share of client pub_key_Y string yes The pubkey in Y-axis of encKey or the share of client set_data Object no The data will be store in themetadata server. If not ex ist, the request will be the query request signature string yes the signature of the data that will be store in the server namespace string no The namespace will store in the database. Default is tkey\" Table 4.33: The https request detail Field Type Required Description status bool yes Status of the request to the server.", "label": "human"}
{"ID": "00030095", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "metadata Object no If the request is made us ing the GET method, the server’s response will be the metadata.", "label": "human"}
{"ID": "00030096", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "This section will analyze the performance of the four kind of JRPC request that are essential for the login and registration use cases of the system. The requests are crucial for facilitating communication between the SDK and executors, and their performance significantly affects the overall efficiency and user experience of the system.", "label": "human"}
{"ID": "00030097", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "AssignKeyCommitmentRequest -The AssignKeyCommitmentRequest is a crit ical step that acts as an aggregator for executor signatures, paving the way for the subsequent AssignKeyRequest AssignKeyRequest -In the AssignKeyRequest, a user initiates the process of being registered within the system. The user provides their idToken and thesignatures obtained from the AssignKeyCommitmentRequest to achieve con sensus across the nodesCommitmentRequest -The CommitmentRequest is a request sent by a regis tered user who already exists within the system. Through this request, the userseeks to obtain aggregated signatures from the nodes, facilitating the subse quent ShareRequest process ShareRequest -The ShareRequest process is initiated by users who wish to retrieve their encrypted share of the cryptographic key. This encrypted share is a crucial component that allows users to reconstruct their encKey, which is necessary for secure authentication.", "label": "human"}
{"ID": "00030098", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "To assess the performance of JRPC requests, we will conduct thorough testing andgather data on response times, request rates, and throughput. The objective is to as sess the system’s performance under different loads and detect any bottlenecks orareas that require enhancement. Furthermore, we will assess the influence of var ious factors, including network latency and system resources, on the performanceof JRPC requests.The performance analysis will offer valuable insights into the system’s scala bility and its capacity to handle a high volume of users and concurrent requests.", "label": "human"}
{"ID": "00030099", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Optimizing the performance of critical JRPC requests can enhance system responsiveness, reduce latency, and improve the user experience during login and regis tration.", "label": "human"}
{"ID": "00030100", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "To conduct tests, I utilize the autocannon package, which can be executed di rectly in Node.js with the following hyperparameters:", "label": "human"}
{"ID": "00030101", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "–Processor: Apple M1 Pro, 6 performance cores(600 - 3220 MHz) and 2 power efficiency core(600 - 2064 MHz) –Memory: 16GB 5.1.1 CommitmentRequest Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 0 ms 0 ms 5 ms 8 ms 0.93 ms 2.08 ms 71 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 4073 4073 6631 8359 6850.5 1134.82 4073 Bytes/Sec 5.66 MB 5.66 MB 9.22 MB 11.6 MB 9.52 MB 1.58 MB 5.66 MB Table 5.1: 10 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 4 ms 9 ms 29 ms 36 ms 10.66 ms 8.48 ms 406 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 5391 5391 9247 10647 8964.4 1496.42 5391 Bytes/Sec 7.5 MB 7.5 MB 12.9 MB 14.8 MB 12.5 MB 2.08 MB 7.49 MB Table 5.2: 100 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 26 ms 57 ms 134 ms 284 ms 97.63 ms 461.09 ms 9882 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 3837 3837 9607 10495 8381.9 2219.44 3836 Bytes/Sec 5.33 MB 5.33 MB 13.4 MB 14.6 MB 11.6 MB 3.09 MB 5.33 MB Table 5.3: 1000 connections performanceStat 2.5% 50% 97.5% 99% Avg Stdev Max Latency (ms) 177 273 1961 2454 436.85 434.88 2551 Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 361 361 1582 4531 2246.6 1550.91 361 Bytes/Sec 330 kB 330 kB 1.44 MB 4.14 MB 2.05 MB 1.42 MB 330 kB Table 5.4: 2000 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency (ms) 194 417 2923 3688 611.3 578.23 4015 Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 1975 1975 3379 3779 3026.6 683.61 1975 Bytes/Sec 1.8 MB 1.8 MB 3.08 MB 3.45 MB 2.76 MB 624 kB 1.8 MB Table 5.5: 4000 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency (ms) 167 1672 5490 5668 2095.88 1205.08 5740 Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 185 185 364 802 472.9 216.68 185 Bytes/Sec 169 kB 169 kB 333 kB 733 kB 432 kB 198 kB 169 kB Table 5.6: 8000 connections performance Figure 5.1: Commitment request latency and throughput  chart The provided data provides insightful insights into the performance analysis of various connection types. The analysis includes key metrics such as latency, request per second (req/sec), and throughput, which cast light on the server’s efficiency andresponsiveness under different conditions. The latency, or the time it takes for a re quest to travel from the client to the server and return, is a crucial indicator of theresponsiveness of a system. The 2.5th percentile and median latency values rep resent the latency encountered by the quickest 2.5% and median requests, respec-tively. The 97.5th and 99th percentiles, on the other hand, represent the latencyfor the majority of requests, with only a minor fraction experiencing higher laten cies. The average latency provides a comprehensive view of the system’s response time, whereas the standard deviation indicates the variation in latency values. The maximum latency represents the response time at its apex, as measured during theanalysis. The request per second (req/sec) metric gauges the server’s ability to pro cess incoming requests. The values for the 1st and 2.5th percentiles represent the slowest 1% and 2.5% of observed requests, respectively.", "label": "human"}
{"ID": "00030102", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The median value indicates the rate at which half of the requests were pro cessed, while the 97.5th percentile represents the rate at which the majority of requests were processed. The average req/sec across all connections provides an aggregate measure of the server’s performance, whereas the standard deviation illustrates the processing capacity variation of the server. Throughput, which ismeasured in megabytes per second (MB/s), represents the quantity of data trans mitted or received per second. Similar to the latency and req/sec values, the 2.5th percentile, median, 97.5th percentile, 99th percentile, average, standard deviation, and maximum values represent various aspects of the data transmission efficacy.", "label": "human"}
{"ID": "00030103", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "This data analysis helps determine the performance characteristics of the systemunder various connection conditions. Lower latency values indicate quicker re sponse times and a superior user experience, with the 2.5th percentile and median latencies being especially significant for the majority of user interactions. Higherlatency percentiles may indicate intermittent performance issues or congestion dur ing peak usage periods. In the meantime, higher req/sec values indicate a server’sability to process more requests concurrently, allowing for more fluid user interac tions during periods of high traffic. The standard deviation values for latency and req/sec demonstrate the performance variance. The smaller the standard deviation,the more consistent and predictable the performance. Monitoring throughput is es sential for determining the efficacy of data transmission, with higher throughput values indicating superior data exchange.", "label": "human"}
{"ID": "00030104", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The 2.5th percentile throughput values are generally low, ranging between 13 kilobytes and zero bytes, indicating slower data transmission rates for certain queries.", "label": "human"}
{"ID": "00030105", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The median throughput, which is equal to the 50th percentile, ranges from 13 kB to0 B, representing the typical data transmission rate. The 97.5th percentile through put ranges between 24.8 kB and 56.4 kB, representing the data transmission rate for the preponderance of requests. The 99th percentile throughput ranges between 25,4 kB and 215 kB, representing the data transmission rate for a larger proportion ofrequests. The average throughput ranges from 13 kilobytes to 60,9 kilobytes, rep resenting an overall measure of the efficacy of data transmission. The throughput standard deviation ranges from 7.01 kB to 65.5 kB, illustrating the variability ofdata transmission rates. In conclusion, this exhaustive data analysis provides useful insights into the performance characteristics of the system under various con nection types. By comprehending these metrics, system administrators can make informed decisions, optimize performance, and ensure a smooth and effective userexperience. In addition, monitoring these metrics over time can help identify per formance constraints and plan for future scaling and enhancements to meet user demands effectively.", "label": "human"}
{"ID": "00030106", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "AssignKeyCommitmentRequest Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 285 ms 305 ms 478 ms 522 ms 323.71 ms 52.36 ms 681 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 208 208 307 339 304.7 39.09 208 Bytes/Sec 301 kB 301 kB 444 kB 491 kB 441 kB 56.6 kB 301 kB Table 5.14: 10 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 667 ms 2259 ms 4025 ms 4232 ms 2240.57 ms 676.53 ms 4521 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 237 237 432 467 399.4 80.26 237 Bytes/Sec 343 kB 343 kB 625 kB 676 kB 578 kB 116 kB 343 kB Table 5.15: 100 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 667 ms 2259 ms 4025 ms 4232 ms 2240.57 ms 676.53 ms 4521 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 237 237 432 467 399.4 80.26 237 Bytes/Sec 343 kB 343 kB 625 kB 676 kB 578 kB 116 kB 343 kB Table 5.16: 1000 connections performanceStat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 1424 ms 4072 ms 8894 ms 9215 ms 4506.43 ms 1571.21 ms 9503 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 0 0 293 989 323.11 272.29 4 Bytes/Sec 0 B 0 B 424 kB 1.43 MB 468 kB 394 kB 5.79 kB Table 5.17: 2000 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 1772 ms 3590 ms 8309 ms 9188 ms 4012.8 ms 1665.44 ms 9911 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 4 4 444 487 378.9 144.53 4 Bytes/Sec 5.79 kB 5.79 kB 643 kB 689 kB 547 kB 208 kB 5.79 kB Table 5.18: 4000 connections Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 3777 ms 5542 ms 9288 ms 9986 ms 5796.96 ms 1613.39 ms 10251 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 0 0 318 623 288.5 198.5 1 Bytes/Sec 0 B 0 B 460 kB 902 kB 417 kB 287 kB 991 B Table 5.19: 8000-connections-performance Figure 5.3: AssignKeyCommitment request latency and throughput  chart The provided dataset comprises performance metrics for various connection types, ranging from ten to eight thousand connections. These metrics are essential for evaluating the system’s efficacy and comprehending its behavior under differentload conditions. The 2.5th percentile latency ranges from approximately 285 mil liseconds to 1162 milliseconds, indicating that only a small percentage of requests experience extremely fast response times. The median latency (50th percentile) ranges between 305 and 2633 milliseconds, representing typical response times forthe majority of queries. The 97.5th percentile latency ranges between 478 and 3503milliseconds, representing the response times for the overwhelming majority of re quests. In a similar fashion, the 99th percentile latency ranges from 522 ms to 3567 ms, encompassing response times for an even greater proportion of queries, as wellas some outliers. The average latency ranges from 323.71 ms to 2549.27 ms, repre senting the system’s response time as a whole. The range of 52.36 to 552.1 ms for the standard deviation of latency illustrates the variation in response times acrossqueries. The maximal latency ranges between 681 and 5960 milliseconds, repre senting the longest response time observed throughout the analysis. The 1st and2.5th percentile values for req/sec are generally low, ranging from 43 to 208, indi cating that only a small proportion of requests are processed at the slowest rates.", "label": "human"}
{"ID": "00030107", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "coming requests. The range of 39.09 to 153.81 for the standard deviation of req/sec demonstrates the variability of processing rates.", "label": "human"}
{"ID": "00030108", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The 2.5th percentile throughput values are generally low, ranging from 232 kB to 62.2 kB, indicating that some queries have slower data transmission rates. The median throughput, which corresponds to the 50th percentile, ranges from 263 kilobytes to 62.2 kilobytes, representing the average data transmission rate. The 97.5th percentile throughput ranges between 583 kB and 562 kB, representing the data transfer rate for the plurality of requests. The 99th percentile throughput ranges between 669 kB and 899 kB, representing the data transmission rate for a greaterproportion of requests. The range of 441 kB to 525 kB for the average through put provides an overall measure of data transmission efficacy. The range of 56.6 kB to 223 kB for the standard deviation of throughput illustrates the variabilityof data transmission rates. In conclusion, this comprehensive data analysis illu minates the performance characteristics of the system across various connection types. By comprehending these metrics, system administrators are able to make informed decisions, optimize performance, and guarantee a seamless and effective user experience. In addition, continuous monitoring of these metrics enables the identification of performance constraints and the planning of future scaling and enhancements to effectively meet user demands.5.1.4 AssignKey Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 447 ms 465 ms 2193 ms 2225 ms 547.96 ms 343.23 ms 2230 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 4 4 20 25 17.7 6.28 4 Bytes/Sec 3.44 kB 3.44 kB 17.2 kB 21.5 kB 15.2 kB 5.4 kB 3.44 kB Table 5.20: 10 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 453 ms 500 ms 784 ms 834 ms 539.74 ms 96.42 ms 1154 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 96 96 185 219 180.8 35.31 96 Bytes/Sec 82.6 kB 82.6 kB 159 kB 188 kB 155 kB 30.4 kB 82.6 kB Table 5.21: 100 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency 837 ms 1561 ms 6822 ms 8665 ms 1842.51 ms 1257.83 ms 9971 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 68 68 277 387 265.9 91.27 68 Bytes/Sec 58.5 kB 58.5 kB 238 kB 333 kB 229 kB 78.5 kB 58.5 kB Table 5.22: 1000 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency (ms) 1644 ms 3205 ms 8045 ms 8391 ms 3589.12 ms 1408.48 ms 9823 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 4 4 360 536 347.1 142.23 4 Bytes/Sec 3.64 kB 3.64 kB 328 kB 488 kB 316 kB 129 kB 3.64 kB Table 5.23: 2000 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency (ms) 2168 ms 3930 ms 8805 ms 9295 ms 4506.56 ms 1746.61 ms 10174 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 0 0 392 628 360.8 199.87 53 Bytes/Sec 0 B 0 B 357 kB 572 kB 328 kB 182 kB 48.2 kB Table 5.24: 4000 connections performance Stat 2.5% 50% 97.5% 99% Avg Stdev Max Latency (ms) 2652 ms 5541 ms 10021 ms 10150 ms 5999.93 ms 2079.53 ms 10862 ms Stat 1% 2.5% 50% 97.5% Avg Stdev Min Req/Sec 0 0 304 664 297.4 198.39 4 Bytes/Sec 0 B 0 B 277 kB 605 kB 271 kB 181 kB 3.64 kB Table 5.25: 8000 connections performanceFigure 5.4: AssignKey request latency and throughput  chart The median latency for 1000 connections is 1561 milliseconds, whereas the 2.5th percentile latency is approximately 837 milliseconds. The 97.5th and 99th percentile latencies are 6822 ms and 8665 ms, indicating response times for theoverwhelming majority of requests. The mean latency is 1842.51 ms and the standard deviation is 1257.83 ms. This instance reveals a maximal latency of 9971 mil liseconds.For 2000 connections, the 2.5th percentile latency is approximately 1644milliseconds, while the 50th percentile latency is approximately 3205 millisec onds. 97.5 percentile and 99 percentile latencies are 8045 and 8391 milliseconds, respectively. Average latency for 2000 connections is 3589.12 ms, with a standard deviation of 1408.48 ms. The longest recorded latency is 9823 milliseconds. The 2.5th percentile latency for 4000 connections is approximately 2168 ms, whereas the 50th percentile latency is approximately 3930 ms. The 97.5th percentile and 99th percentile latencies are 8805 and 9295 milliseconds, respectively. The average latency for 4000 connections is 4506.56 ms, with a standard deviation of 1746.61 ms. 10174 milliseconds is the greatest observed latency in this scenario.", "label": "human"}
{"ID": "00030109", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The median throughput for 1000 connections is 58.5 kB, with the 2.5th per centile throughput being approximately 58.5 kB. The throughputs for the 97.5thand 99th percentiles are 238 kB and 333 kB, respectively. The average throughput for 1000 connections is 229 kilobytes, with a standard deviation of 78.5 kilo bytes. The highest throughput measured is 58.5 kB. For 2000 connections, the2.5th percentile throughput is approximately 3.64 kilobytes, while the 50th per centile throughput is also 3.64 kilobytes. The throughputs for the 97.5th and 99th percentiles are 328 kB and 488 kB, respectively. The standard deviation for 2000connections is 129 kB, while the average throughput is 316 kB. 3.64 kB is the maximum throughput observed. The median and 2.5th percentile throughputs for 4000 connections are both 0 bytes, signifying extremely low or no throughput. Thethroughputs for the 97.5th and 99th percentiles are 357 kB and 572 kB, respec tively. The standard deviation of the average throughput for 4000 connections is 182 kB. Maximum throughput measured in this instance is 48.2 kilobytes.", "label": "human"}
{"ID": "00030110", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Web3Auth is a decentralized oracle network that exhibits similarities with the thesis project. The system also incorporates Shamir’s Secret Sharing and DKG (Distributed Key Generation) protocol. Web3Auth provides various key features, as follows:", "label": "human"}
{"ID": "00030111", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Seamless onboarding -Web3Auth uses social login to allow users to sign up for dapps with just a few clicks. This makes it easy for users to get started with dapps, and it also helps to improve the user experience.", "label": "human"}
{"ID": "00030112", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Multi-party computation (MPC) -Web3Auth uses MPC to provide a secure and private way for users to share their keys. This allows users to collaborate on dapps without having to reveal their private keys. MPC is a cryptographic protocol that allows multiple parties to jointly compute a function without revealing their individual inputs. This makes it a very secure way for users to share their keys, as only the final result of the computation is revealed.", "label": "human"}
{"ID": "00030113", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The implementation of nodes for constructing keys of Web3Authen is complex due to the presence of multiple layers within its structure.", "label": "human"}
{"ID": "00030114", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The persistence of user data is not guaranteed due to the storage of metadata in a database. If the organization fails to manage this properly, it can result in the loss of information, leading to significant damages.", "label": "human"}
{"ID": "00030115", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Web3Auth is not yet widely adopted by dapps, so users may not be able to use their Web3Auth keys on all of the dapps that they want to use. This is because the platform is still relatively new, and it is not yet as widely integrated with dapps as other platforms, such as MetaMask.", "label": "human"}
{"ID": "00030116", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "To successfully execute projects, various infrastructure components must beoperational, with particular emphasis on the node’s involvement in registeringand creating encryption keys. Scaling out can result in significant infrastruc ture costs.", "label": "human"}
{"ID": "00030117", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "By utilizing smart contracts and blockchain technology, user data can be stored and secured in a decentralized manner, guaranteeing its durability and security as long as the blockchain network remains operational.", "label": "human"}
{"ID": "00030118", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "By transferring the responsibility of constructing encKey and assignKey to the smart contract, the need for implementing intricate nodes to handle consensus between nodes, such as Web3Auth, is eliminated.", "label": "human"}
{"ID": "00030119", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The system’s complexity decreased, resulting in significant reductions in infrastructure and debugging costs.The concluding chapter of this thesis serves as a summary of the principal findings and contributions of the research presented in the antecedent chapters. In ad dition, I discuss the limitations of our study and acknowledge any restrictions that may have affected our findings. Ahead of time, I out potential future researchavenues, spotlighting unexplored areas that can build upon the foundation estab lished by this thesis.", "label": "human"}
{"ID": "00030120", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In conclusion, the system being discussed is an innovative and efficient solu tion for addressing identity and authorization challenges in the Web3 domain. Thissystem has the potential to revolutionize on authentication and access by in corporating advanced features and functionalities. This solution utilizes advanced technologies such as blockchain, social login, and user-controlled encryption keys.", "label": "human"}
{"ID": "00030121", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "It also incorporates robust security measures like smart contracts, Shamir’s secret sharing, and the Pedersen DKG protocol. These features provide a seamless and secure user experience, enabling individuals to confidently engage with the Web3 ecosystem.", "label": "human"}
{"ID": "00030122", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The system’s user-friendly interface facilitates convenient navigation through the authentication and authorization processes, making it a notable strength. The incorporation of social login enables a smooth and recognizable authenticationprocess, minimizing obstacles and improving user acceptance. In addition, user controlled encryption keys offer individuals increased control and ownership of their private data, effectively addressing the escalating concerns surrounding data privacy and security.", "label": "human"}
{"ID": "00030123", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Moreover, the system’s capacity to stream and automate the authorization process greatly improves efficiency and convenience. Virtualization technologyenables the establishment of a uniform and stable deployment environment, facili tating the configuration and scalability of applications as required. The utilizationof Express.js as the backend and JSON-RPC for communication enhances the system’s robustness and performance, facilitating seamless and dependable interac tions among various components.", "label": "human"}
{"ID": "00030124", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The system’s capacity to tackle the urgent issues of identity and authoriza tion in the Web3 domain renders it a valuable asset for individuals, developers,and businesses. Decentralized applications are being increasingly adopted and uti lized across various industries, leading to innovation and growth within the Web3ecosystem. The Web3 landscape is constantly changing, and the system is prepared to adapt and provide secure and efficient solutions for identity and authorization in the decentralized digital world.", "label": "human"}
{"ID": "00030125", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "The system’s beta version shows promise by offering support for Google Auth0 and web browsers. The development has promising prospects for the system, as there are plans to enhance its compatibility and extend its reach. The roadmapentails incorporating support for additional reputable authentication providers, in cluding Facebook, Apple, Reddit, and others. The system seeks to expand its userbase and provide users with a greater variety of authentication options by integrat ing with well-known authentication services. This integration allows for seamless identity verification.", "label": "human"}
{"ID": "00030126", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Additionally, there are plans to improve the accessibility of the system by ex panding its compatibility to various platforms, such as mobile devices and iPads.", "label": "human"}
{"ID": "00030127", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "This expansion will enhance user interaction by accommodating various devices,thereby fostering inclusivity and improving user experience. The adoption of mobile platforms is essential for accommodating the growing number of users access ing the Web3 ecosystem via smartphones and tablets.", "label": "human"}
{"ID": "00030128", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "In the context of cross-device support, the system currently does not offer the capability to share the private key across multiple devices. However, this feature has been identified as a critical target for future development and enhancement of the social login device. The ability to seamlessly and securely share the private key across different devices is crucial to providing users with a consistent and flexibleexperience. S. Nakamoto, Bitcoin: A peer-to-peer electronic cash system , 2008. [On line]. Available:  (visited on 06/19/2023).", "label": "human"}
{"ID": "00030129", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "V. Buterin and G. Wood, Ethereum: A next-generation smart contract and decentralized application platform , 2014. [On]. Available:  thereum.org/whitepaper/ (visited on 06/19/2023).", "label": "human"}
{"ID": "00030130", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "R. C. Merkle, “A digital signature based on a conventional encryption func tion,” in Advances in Cryptology - CRYPTO’87 , Springer, 1987, pp. 369– 378. DOI:10.1007/3-540-48184-2_32 .", "label": "human"}
{"ID": "00030131", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "Bitcoin BIP-0039 Contributors, Bip39: Mnemonic code for generating de terministic keys , Bitcoin Improvement Proposal, Accessed on 2023-06-19, 2013. [Online]. Available:  /blob/master/bip-0039.mediawiki .", "label": "human"}
{"ID": "00030132", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "T. P. Pedersen, “A threshold cryptosystem without a trusted party,” in Ad vances in Cryptology — EUROCRYPT’91 , Springer, 1991, pp. 522–526.", "label": "human"}
{"ID": "00030133", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "N. Szabo, “Formalizing and securing relationships on public networks,” in First Monday , vol. 2, University of Illinois at Chicago Library, 1997. DOI:", "label": "human"}
{"ID": "00030134", "file_name": "A social login solution for Web3 using Shamir’s secret sharing and verified DKG", "content": "C. van der Veen, DeFi and the Future of Finance: A Comprehensive Guide to Decentralized Finance . Packt Publishing, 2021, ISBN: 978-1801073687.", "label": "human"}
{"ID": "00040001", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "In the field of information technology, IT Helpdesk is part of the IT department,responsible for receiving and answering technical inquiries and questions from cus tomers. IT Helpdesk provides technical software support and consulting, providestechnology services, and solves technology and computer related problems. Communication is often done through a variety of means such as email, phone, web site, or on chat. Entering the 4.0 era - the era of electronic technology with the rise of programming-related professions, IT Helpdesk plays an undeniable role in maintaining the stability and performance of IT systems in every organization.", "label": "human"}
{"ID": "00040002", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "ANSV Telecommunications Equipment Company Limited (part of VNPT Tech nology, Vietnam Posts and Telecommunications Group) is a system integrator, providing information technology products, solutions and services in Vietnam.", "label": "human"}
{"ID": "00040003", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Although there are many types of electronic telecommunications equipment thathave been provided to individual and business customers, along with many information technology solutions and services that have been deployed, customer sup port regarding information Products as well as technology solutions are carried out mainly via email and phone. Today the IT helpdesk department in ANSV could be overwhelmed with loads of requests from the clients through email, which is an inefficient way to store and manage information of each request. Tracking downthe list of requests is also an issue. For the goals to ensure the achievements of ex panding to new clients, ANSV’s IT support department needs a better alternative way to manage, store, and retrieve information.", "label": "human"}
{"ID": "00040004", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Through interning and participating in professional work in the IT departmentat ANSV, I have learned solutions to improve the effectiveness of technical sup port for customers and potential partners of ANSV. With the spirit of eagerness to learn, along with the guidance and advice from senior staff of the IT department,I found that building a helpdesk website will be a comprehensive alternative so lution to improve customer technical support efficiency, contributing partly to the development of ANSV company.", "label": "human"}
{"ID": "00040005", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "When customers want to find out product information such as electronic telecom munications equipment, solutions and services, or requests for project technicalsupport implemented by ANSV, customers will send email to the IT support de partment for a response. When the IT support receives the email, IT support willprovide the requested service. Receiving requests and storing request information from customers via email is not optimal due to lack of tracking and monitoring.", "label": "human"}
{"ID": "00040006", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "A better management system is required for receiving, responding to, monitoring, and retrieving client requests. It is also important for the IT support department because ANSV is planning to expand to new major clients.", "label": "human"}
{"ID": "00040007", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The goal of this project is to replace the current way of sending customer re quests through email with a helpdesk management system. For this, a helpdesk website is developed and built, and the requests can be received and responded through the website.", "label": "human"}
{"ID": "00040008", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Develop and build a Helpdesk website with a customer management system implemented for the ANSV. The software architect pattern in this project is Model View Control and applied with the programming language of Odoo and HTML.", "label": "human"}
{"ID": "00040009", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "When customers request support, they will access ANSV’s customer sup port website on their devices such as computers, phones... After registering and logging in information, their requests will be aggregated into ANSV’s helpdesk system.", "label": "human"}
{"ID": "00040010", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Customer requests are classified, prioritized, and the requests are transferred to the IT support team, with assigned personnel in charge.", "label": "human"}
{"ID": "00040011", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Processing progress and time to resolve support requests of each IT staff mem ber are monitored and controlled and are tied to each specific product and project.", "label": "human"}
{"ID": "00040012", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Customer request monitoring is supported according to the policy, scope andtime, and it is also specified through the establishment of Service Level Agree ments (SLA).", "label": "human"}
{"ID": "00040013", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Customers can proactively monitor the progress of their requests through a portal of the system without needing to contact support staff.", "label": "human"}
{"ID": "00040014", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Chapter 2: This chapter presents a practical survey on topics related to the content of graduation projects. An overall assessment of the helpdesk system functionality is presented which includes: system analysis and design, use case diagrams, decomposition, and specifications.", "label": "human"}
{"ID": "00040015", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Chapter 3: This chapter focuses on technologies used in the process of building and developing the helpdesk system, including: introduction to the tech nologies, main features, advantages and disadvantages.", "label": "human"}
{"ID": "00040016", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Chapter 5: This chapter discusses contributions of the graduation project, challenges encountered during the development and implementation process as well as how to overcome them.", "label": "human"}
{"ID": "00040017", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "References: A list of references used in the thesis.2.1 Status survey Students conduct a detailed survey on the current status of support activities ofthe IT Helpdesk department at the Company and research current helpdesk appli cations on the market.", "label": "human"}
{"ID": "00040018", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Based on the request of department head: \"Build web helpdesk software to support customers who are members of technology projects that the Company is build ing and implementing\" for survey to get information about current operating status and information about software being used:", "label": "human"}
{"ID": "00040019", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The Company’s IT helpdesk department is using software to support handling internal requests for project members who are employees in the company. This software is a windows-based helpdesk application.", "label": "human"}
{"ID": "00040020", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Scope of the software use:For internal use only, Manually enter ticket infor mation while incoming phone calls and email With the requirement to build an additional web-based helpdesk application to support project members from outside the company, students researched helpdesksoftware systems on the market and conducted a comparison to establish the specific requirements for the software being developed. The goal is to create the software that meets the Company’s current requirements, including the task of improv ing customer experience and ensuring consistency in response information to the outsiders.", "label": "human"}
{"ID": "00040021", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The future market insights revokes a survey that reveals that 68 %of consumers prefer brands with efficient customer service while over 75 %want immediate, single-interaction resolutions.", "label": "human"}
{"ID": "00040022", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "And the business research insights affirms in the report on 25/12/2023 that the global help desk software market size was USD 969.6mil in 2020 and market is projected to touch USD 2825.23mil by 2031 with growth rate at 10.2 %during the forecast period.", "label": "human"}
{"ID": "00040023", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The market has witnessed significant growth and transformation of the help desk software in recents, driven by various factors. One of the key drivers of this expansion is the versatile nature of the software, which caters to a wide range of industries and sectors. Whether it is healthcare, finance, retail or technology, helpdesk software offers comprehensive support solutions that stream communication, ticket management, and issue resolution. Its adaptability and customizationoptions make it a preferred choice for business seeking efficient and scalable cus tomer support systems. The ability to integrate with other software solutions and provide multi-channel support further enhances its appeal, allowing organizations to deliver exceptional customer experiences.", "label": "human"}
{"ID": "00040024", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "In come up with the final functions for software showing in this thesis, the stu dent has studied a number of help desk softwares in different segmentation, by types (cloud based and web based help desk software) and by end users (large enterprises and SMEs-small and medium enterprises users) and picked up three representatives for comparison.", "label": "human"}
{"ID": "00040025", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "ZohoThis software is considered as the good one for small companies and sales focused teams. This is a customer relationship management tool and also makes a support solution for customer interaction.", "label": "human"}
{"ID": "00040026", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Pros of Zoho: The software includes CRM, Marketing, Accounting, MeetingScheduling, Reporting tools as well as integration with payment gateways, multi currency support, and sales process automation capabilities.", "label": "human"}
{"ID": "00040027", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Simple data collect and publish database online Manage tickets in one place Omni channel ticketing system Set up Assignment rules to send the tickets to the right department and agent automatically Set SLAs to highlight which tickets need immediate attention and to ensure no tickets go unansweredDashboard helps to see essential metrics, like ticket traffic, customer hap piness ratings, and the most threaded tickets. Support team can also create reports to monitor team’s performance Zoho provides AI-powered tool to its top-tier plans Cons of Zoho:", "label": "human"}
{"ID": "00040028", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Low-tier users (free plan users) are limited by: being missed out on sales fore casting deficient, limited number of users on system, no calendar booking and no customization No Ongoing Executive support: some customers aren’t satisfied with Zoho’s customer support•It’s difficult to set up integration with third-party party apps Zendesk This software is considered as the good one for enterprise teams. They make amulti channel support solution that includes features like a shared inbox, a knowl edge and live chat tools.", "label": "human"}
{"ID": "00040029", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "An all-in-one lead generation and customer service platform Chat, phone, email, and social media all in one place Provides a lot of customization options Extensive, powerful reporting and analytics Robust integration with third-party applications and systems Supports multiple languages Can track customer history across different mediums or departments Easy to set up teams on the platform Cons of Zendesk:", "label": "human"}
{"ID": "00040030", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Potentially high price tag with complicated pricing plans Doesn’t provide robust integration with ecommerce platforms like Shopify, Magento, or BigCommerce Best support features are only available at higher pricing tiers Not the right ticket management system for ecommerce and small businessesRequires a significant amount of time and effort to get familiar with the soft ware User interface is not intuitive or customizable Jira Service Management Jira Service Management is generally associated with engineering and technicalteams due to its relation to Atlassian’s more widely known Jira project manage ment tool. The platform is a great ITSM solution that lets your team tackle request, change, incident, problem, asset, configuration, and knowledge management all in one place. It allows you to build out self-service portals for end-users and has collaboration features like a shared inbox for managing email and chat requests.", "label": "human"}
{"ID": "00040031", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Combined with custom workflows, AI tools, and reporting capabilities, the plat-form makes responding to user requests a simple and efficient process. Pros of JiraSM Ease of doing categorize tickets (service requests, incidents, problems, and changes) by organizing and prioritizing these requests in a single place, and keeps helpdesk team on track with goals (or service level agreements) It’s a good tool to track tickets and projects There are some very useful and well-designed default reports included for ticket statistics Great customizableFlexible to map around any team structure, workflow, or level of agile matu rities Good for project management Rich Reporting and Analytics Cons of Jira Limited file size upload Reports are not reusable Students come up with important features that need to be developed for the product presented in this thesis, including 7 main components in the table below:", "label": "human"}
{"ID": "00040032", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "account registration, system login, sending requests, processing requests. request, chat, SLA and reporting.Features Odoo Helpdesk Register Provides required information fieldsLog in Customers log in to the system via gmail and above created password Send requests Send request by fill in the available registration form, tickets will be created on the internal interface Handling tickets Admin processes and approves the tickets. When the tickets are being approved, it will be handed over to the agent. Whenever the ticket status changes, customers will be informed right away.", "label": "human"}
{"ID": "00040033", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Chat Chatter provides support for communication with customers for each of the individual tickets. With this 2 way support, customers will get convenient in sending up further questions as well as provide helpdesk team additional information to solve problem better SLA Set a resolve timeline for tickets.", "label": "human"}
{"ID": "00040034", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Helpdesk team and Customer. Each actor would perform a different role play in the system.Actors Description Helpdesk teamManage system’s user information, including Customer account management (CRUD) Team members account management (CRUD) SLA workflow management (CRUD) Approve the customer’s newly registered account Ticketing operation Accept and confirm requests to be handled (CRUD) Assign tickets to relevant team members (CRUD) Chat management (CRUD) Approve new threads of ticket handling (CRUD, SLA set) Change the status of the tickets’ handling progress Report and Dashboard Built-in report CustomerManage account information Manage own profile Change password Raise and submit request View request summary Join the chat room Give feedback and rate the satisfaction to the support Table 2.2: The system overview The general use case diagram of the system is shown in the figure below.", "label": "human"}
{"ID": "00040035", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "They set permissions to:who can view the portal, who can send requests to a service project, who customers can share requests with, Project permissions depend on the portal-only customer access settings, which means you can have different customer permissions for a service project depending on the people who need to access it.", "label": "human"}
{"ID": "00040036", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Project admins can create SLA goals that specify the types of requests you want to track and the time it should take to resolve them. From there, you can define the conditions and calendars that impact when SLA measurements start, pause, stop (for example, stopping when your office is closed for a public holiday), or cancel.", "label": "human"}
{"ID": "00040037", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Once you have set up SLAs for a project, your team members will be able to see how each request raised by a customer should be prioritized to meet the team service goals. Once you have set up SLAs for a project, team members can view their SLAs and plan which tasks need to be resolved first.", "label": "human"}
{"ID": "00040038", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Dashboard has great capabilities for emulating the appropriate workflows, for having all issues reported by customers in a centralized place and for enabling the Helpdesk team to effectively manage and respond to these issues.", "label": "human"}
{"ID": "00040039", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "This software intends to provide a list of charts and metrics that help teams tomonitor and to quickly answer many questions about the effectiveness and produc tivity of the Helpdesk teams. For examples:", "label": "human"}
{"ID": "00040040", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Ticket Backlog. How many issues are in the queue? How many are urgent? What percentage of the issues are reopened? Customer Satisfaction (CSAT). How satisfied are our customers? What is our Average Customer Satisfaction (CSAT) Score?•Average Resolution Time (ART) and Average Handle Time (AHT). How quickly do we deliver? Do we improve over time?Service Level Agreement (SLA). Do we match the SLA promised to the cus tomers? What issues took longer than expected and how many? Throughput or Team Velocity. How much work do we get done per time unit? Do we improve over time? Is the flow stable? Are there any bottlenecks in our flow? Are there issues that stay far too long in the backlog, or stuck in a workflow status? Figure 2.9: Report and Dashboard use case diagram2.2.3 Business process a, The activity diagram of the customer registration The following diagram describes the customer registration process. It uses adocument called register form to engage with customers and allow them to sign up/register for the helpdesk service and communication of the service progress.", "label": "human"}
{"ID": "00040041", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "In the absence of an effective ticketing system, IT service desk teams may endup blindsided regarding the context of an incident, its priority, or the person whosubmitted the ticket. This may lead to a drop in help desk productivity and subop timal employee experiences.", "label": "human"}
{"ID": "00040042", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "With respect to this matter, the application wishes to help balance the ticket queue and technician availability and applies the right SLA to the ticket based on predefined automation rules plus proactive escalation capabilities that steer clear of SLA violations.", "label": "human"}
{"ID": "00040043", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "In this work, the student will go over how an IT ticketing system works. Look back, we see that in small and medium businesses (SMBs), employees may simplywalk up to an IT technician to report an issue or request a service. Such organiza tions, with smaller support teams, may use a support email system, a spreadsheet,or even a homegrown ticketing system to track tickets and resolve issues. How ever, as organizations scale, these legacy solutions do not cut it for helpdesk teams.", "label": "human"}
{"ID": "00040044", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Relying on emails or spreadsheets to track and resolve tickets may quickly turn tiresome, create bottlenecks, and impact efficiency, which may stonewall strategic IT projects.", "label": "human"}
{"ID": "00040045", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The IT ticketing system acts as the single point of contact between end users and the IT service provider. It helps Helpdesk teams consolidate support requestsfrom different channels into tickets, store them, and manage them centrally. Fut ther, it also helps categorize, prioritize, and assign these tickets according to preset policies, ensuring that Helpdesk teams stay efficient and organized.", "label": "human"}
{"ID": "00040046", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "All conversations with the end user can also be documented within the ticketing system, helping technicians be context-aware when tickets are assigned or escalated to them.", "label": "human"}
{"ID": "00040047", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Farther scope, student look forward to work out the IT service managemetn (ITSM) platform, which includes problem management, change management, and IT asset management. It is referred to as a standalone tool that works as as part of a broader ITSM platform with an array of ticketing capabilities, including but not limited to:", "label": "human"}
{"ID": "00040048", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "A user-friendly self-service portal for end users to log and track tickets, browse knowledge articles, and use other self-service capabilities.", "label": "human"}
{"ID": "00040049", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Native and third-party integrations with business and IT management apps.Figure 2.13: Ticketing operations activity diagram2.3 Functional description 2.3.1 Customer registration Name Customer registration Main Actor Customers Using purpose Allows the new customers to regist an account with the helpdesk system Trigger event The new customers perform the sign ·up process to ccreate an account (using email address or sign up with Google), using function “Sign up for a new account” Input Demographic info of customers and email address Assumptions The newly creating customer account is clearly for submit to the system, and the register form runs smoothly Pre-conditions Customers fill in all the required information in the Register form Output The updated list of all accounts in the system after portal engine verifies the new creates Main flow of events•Customer access the URL of the helpdesk system Point in the register for new account create Fill in the account registration information Send the registration information Perform the account verification via email Exception flow of events•In the step 4 of the main flow, if the system found out any invalid fields input then customers need to be key-in the valid data until validation done In the step 5 of the main flow, if customers would not verify account via email, system admin will delete that account from system Post-conditions When the new customer account successfully created, be sure that the account info is relevant to the company services and projects Table 2.3: The functional description of customer register for an account2.3.2 Customers manage accounts Name Customers manage accounts Main Actor Customers Using purpose Allows customers to register a new account with the system Trigger event Customers perform the function “Manage your account” that help customer manages their account and initiates the request to helpdesk team Input Demographic info of customers (First Name, Last Name, Gender, etc,.), email address, username/password, and the request content Assumptions None Pre-conditions Customers successfully log inOutput CRUD process for account and set request prioritization suc cessfully done Main flow of events•Customers select “Manage your account” Customers key in the account information Customers select ”Send” to send ticket infoException flow of events•At step 2 of the main scenario, if the fields marked as re quired are missing information or wrong format of data is entered, the system will return a message asking for full information.", "label": "human"}
{"ID": "00040050", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "At step 3 of the main scenario, the password field will have to be filled in twice, if the two values do not match, the system will return an error message At step 3 of the main scenario, if the information entered is identical with the information of the accounts already existing in the system (e.g. information field acting asthe primary key), the system will return an error mes sage.", "label": "human"}
{"ID": "00040051", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Post-conditions The customer account will be edited and in the admin dash board with the status ‘edited’ on the specified date and time.", "label": "human"}
{"ID": "00040052", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Main flow of events•Administrator check the list of accounts in the helpdesk system Select an account with a status of inactivated Verify account profileChange the status of the account to activated if the pro file is valid Exception flow of events•In step 2 of the main scenario, if there is no account in inactivated status, the administrator does not need to verify any account profile.", "label": "human"}
{"ID": "00040053", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "In step 4 of the main scenario, if the account’s profile is invalid, the administrator will delete that account from the system.", "label": "human"}
{"ID": "00040054", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Post-conditions After the administrator performs the account verification,make sure that there are no accounts in the system in an in active state. If so, they need to be verified to be activated or removed from the system.", "label": "human"}
{"ID": "00040055", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "•In step 2 of the main scenario, if something goes wrong, the transaction will be rolled back Post-conditions The up-to-date list of tickets that have been raised by the cus tomers Table 2.6: The functional description of the customers submit tickets2.3.5 Helpdesk team configs SLA policies Name Helpdesk team configs SLA policies Main Actor Helpdesk team authorized member Using purpose Allows the helpdesk team to add new policies and/or edit current policies to the list of SLA policies available in the systemTrigger event The authorized helpdesk team members performs the con figurations function Input Information about the types of requests that helpdesk team want to track and the time limitation for team to resolve them SLA details:", "label": "human"}
{"ID": "00040056", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Assumptions There is a newly created SLA policy by the authorized helpdesk team member in the system waiting for publishing Pre-conditions User logged in successfully as role of an authorized helpdesk team member Output The up-to-date list of all SLA policies in the policies’ storage Main flow of events•Log in to the Configuration menu Select \"Helpdesk team setting page\" or \"SLA policies\" Enter the information for SLA policies Select “Save” Exception flow of events•In step 3 of the main scenario, if the information enteredis identical with the information of the SLA policies already existing in the system (e.g. field acting as the pri mary key), the system will return an error message.", "label": "human"}
{"ID": "00040057", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "In step 3 of the main scenario, if the fields marked as required are missing information, the system will return a message asking for full information.", "label": "human"}
{"ID": "00040058", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "At step 3 of the main scenario, if the wrong format of data is entered, the system returns a message asking to enter the correct format of the information.", "label": "human"}
{"ID": "00040059", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Post-conditions None Table 2.7: The functional description of the SLA configs2.3.6 Helpdesk team handling tickets Name Helpdesk team handling tickets Main Actor Helpdesk team authorized member Using purpose Allows the helpdesk team to balance the ticket queue and technician availability and applies the right SLA to the ticketbased on predefined automation rules plus proactive escala tion capabilities that steer clear of SLA violations.", "label": "human"}
{"ID": "00040060", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The platform should work consistently across different web browsers and de vices.2.4.2 Content management The content management system should maintain a version history of content,allowing users to revert to previous versions and track changes over time. A work flow should be in place, ensuring that the helpdesk team can craft ticketing and business processes in a timely manner.", "label": "human"}
{"ID": "00040061", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The system should have regular data backups and an effective recovery mecha nism to safeguard against data loss due to hardware failure, accidental deletion, or other unforeseen events.", "label": "human"}
{"ID": "00040062", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Throughput: The system should efficiently process and handle multiple user requests simultaneously.The project works in the form of a full-stack web application. A Full-stack web application is based on the client-server model. It consists of three key elementswith various technologies that work as a combination for the application to func tion. In this project, the front-end is built using a combination of technologies such as Hypertext Markup Language (HTML), JavaScript, Cascading Style Sheets (CSS) and Qweb. The back-end tools are Python, Odoo and ORM, whereas the database includes PostgreSQL.", "label": "human"}
{"ID": "00040063", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "HTML Overview HTML (Hypertext Markup Language) is the standard markup language used to create and structure web pages. It forms the backbone of websites and is the fundamental building block for presenting content on the internet. HTML uses tags to define elements, such as headings, paragraphs, images, links, and forms, among others. Each tag represents a specific content or structure, and they are nested within one another to create a hierarchical structure for the web page.", "label": "human"}
{"ID": "00040064", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "HTML documents are plain text files with a .html extension and can be created and edited using basic text editors. When a web browser loads an HTML page, it reads the markup and displays the content accordingly. HTML is complemented by CSS (Cascading Style Sheets) and JavaScript, which respectively handle the presentation and behavior of web pages.", "label": "human"}
{"ID": "00040065", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "With HTML, developers can create user-friendly, accessible, and interactiveweb pages that adapt to different devices and screen sizes. It enables the inclusion of multimedia, facilitates navigation through hyperlinks, and allows data in put through forms. HTML5, the latest version of HTML, introduced several newelements and features, further enhancing the possibilities for modern web develop ment.", "label": "human"}
{"ID": "00040066", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "How HTML worksHTML is usually stored in files that use the .htm or .html extension. A web site can include hundreds or even thousands of these HTML files kept in various directories.", "label": "human"}
{"ID": "00040067", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The browser then reads the HTML in the files and displays it. Some web applica tions don’t use static HTML but generate it in response to specific actions on theirservers.", "label": "human"}
{"ID": "00040068", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "CSS Overview CSS (Cascading Style Sheets) is a crucial part of web development, responsiblefor styling the visual appearance of HTML elements on web pages. It works in con junction with HTML by separating content from presentation, enabling developers to control layout, colors, fonts, and other design aspects. CSS achieves this by usingselectors to target specific HTML elements and applying styles through property value pairs. These styles can be written directly within the HTML document (instyles), embedded in a style tag within the document (internal styles), or linked ex ternally in a separate .css file (external styles). The cascading nature of CSS allows multiple styles to be applied to an element, with specificity determining the order of precedence.", "label": "human"}
{"ID": "00040069", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "CSS empowers developers to create responsive and adaptive designs through media queries, which adjust styles based on the user’s screen size and device. This ensures a seamless user experience across various platforms. Additionally, CSS offers the flexibility to create interactive effects and animations, enhancing user engagement.", "label": "human"}
{"ID": "00040070", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "External stylesheets enable the reuse of styles across multiple pages, promotingcode modularity and easy maintenance. Selectors and pseudo-classes further en hance CSS’s capabilities by allowing the targeting of specific states and attributes of elements 3.2.2 How CSS works CSS uses a simple English based syntax with a set of rules that govern it.", "label": "human"}
{"ID": "00040071", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Like mentioned before, HTML was never intended to use style elements, only the markup of the page. It was created to merely describe the content.", "label": "human"}
{"ID": "00040072", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The CSS syntax structure is pretty simple. It has a selector and a declaration block. An element is selected and then declared what to do with it. The selector points to the HTML elements with a style. The declaration block contains one or more declarations separated by semicolons.", "label": "human"}
{"ID": "00040073", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Each declaration includes a CSS property name and a value, separated by acolon. A CSS declaration always ends with a semicolon, and declaration blocks are surrounded by curly braces.", "label": "human"}
{"ID": "00040074", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "JavaScript Overview JavaScript is a high-level, interpreted programming language primarily used for front-end web development. It enables dynamic and interactive web page creationby manipulating HTML and CSS content directly in users’ browsers. As a client side scripting language, JavaScript executes in real-time, responding to user actions and enhancing the user experience.", "label": "human"}
{"ID": "00040075", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Key features of JavaScript include its event-driven nature, which allows developers to attach event handlers to elements, enabling actions based on user inter actions like clicks or keystrokes. JavaScript interacts with the Document Object Model (DOM), representing the page’s structure, and can modify it dynamically to update content or create new elements.", "label": "human"}
{"ID": "00040076", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Beyond frontend development, JavaScript has expanded its scope to include server-side development through platforms like Node.js. This allows developersto use a single language for both client-side and server-side tasks, facilitating full stack development and real-time applications.", "label": "human"}
{"ID": "00040077", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "JavaScript’s widespread adoption and active community have led to the devel opment of numerous libraries and frameworks, such as React, Angular, and Vue.js, which provide tools and abstractions to simplify complex web development tasks.", "label": "human"}
{"ID": "00040078", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "How JavaScript worksJavaScript is a high-level, interpreted programming language used for web de velopment. When a web page is loaded, the browser’s JavaScript engine processesthe code, creating a Document Object Model (DOM) representing the page’s struc ture. The engine then executes the JavaScript code  by , interacting with theDOM to modify content, styles, and behavior dynamically. JavaScript is singlethreaded, meaning it processes one task at a time, but supports asynchronous operations through callbacks, promises, and async/await. This enables non-blocking be havior, essential for handling user interactions and making AJAX requests. JavaScript is versatile, capable of running on both client and server sides. It plays a crucial role in creating interactive and responsive web applications, allowing developers to enhance user experiences and add dynamic functionalities to websites Some features of JavaScript:", "label": "human"}
{"ID": "00040079", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Prototypal Inheritance: JavaScript uses prototypes to enable object inheri tance, allowing objects to inherit properties and methods from other objects.", "label": "human"}
{"ID": "00040080", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Functions as First-Class Citizens: Functions in JavaScript are treated as first class citizens, meaning they can be assigned to variables, passed as arguments, and returned from other functions.", "label": "human"}
{"ID": "00040081", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Closures: JavaScript supports closures, which allow functions to remember and access variables from their outer scope, even after the outer function has completed.", "label": "human"}
{"ID": "00040082", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Asynchronous Programming: JavaScript provides mechanisms like callbacks,promises, and async/await to handle asynchronous operations, making it suit able for tasks like making API calls.", "label": "human"}
{"ID": "00040083", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Event-Driven Architecture: JavaScript is widely used for event-driven programming, where actions like button clicks trigger events that execute corre sponding functions.", "label": "human"}
{"ID": "00040084", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "DOM Manipulation: JavaScript can modify the Document Object Model (DOM) of a web page, allowing developers to dynamically change content, styles, and interact with user input.", "label": "human"}
{"ID": "00040085", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Qweb OverviewQWeb is a templating engine used by odoo. It is an XML language-based tem plating engine and is mainly used for generating reports and pages. Qweb is also known as a report engine. Qweb template used for reporting and also for HTMLfragments and pages. Using Qweb, we can customize reports according to our pur poses like styling, formatting, and many more.", "label": "human"}
{"ID": "00040086", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "An ERP system contains many modules for performing various operations to run a business workflow efficiently. Despite this, every organization wants to know its progress, and they have to present the growth to their boards or authorities, which is when reports come in handy. Therefore, Odoo provides various report projections, such as PDFs, graphical presentations, pivot tables, etc.", "label": "human"}
{"ID": "00040087", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Odoo uses Qweb as a reporting engine or template engine. By using Qweb, we can create reports in Odoo. Reports can be designed using XML as per your requirements. Odoo Qweb Report is also an OpenERP/Odoo XML based reporting engine. It allows us to manipulate data easily by using XMLIn Odoo, to render PDFs from the Qweb templates, we use templates defined in HTML format which will render the PDF report from Qweb.", "label": "human"}
{"ID": "00040088", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "How Qweb works Odoo has different kinds of actions for different operations. For example, reports are generated when the report action is triggered. The model will recognize the report action ‘ir.actions.report’ used in the record.", "label": "human"}
{"ID": "00040089", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Here is an example of a report action. You can create an xml file inside your report directory. By using the HTML, the templates are designed. You can specify the structure of your report inside the <template> tag. By using the <t-call=” ”/> tag, you can call the other templates in your custom reports.", "label": "human"}
{"ID": "00040090", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The Id reportfleetid is the external id which you specify inside your report ac tion. For example, you can specify the header and footer of your report by using <header> and <footer> tags, or you can call an external id by using the <t-call=” ”/> tags. You can also generate Qweb reports from the wizard. Thus in odoo, one can easily create/custom Qweb reports.", "label": "human"}
{"ID": "00040091", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Python Overview Python is a multipurpose, high-level, object-oriented programming language —three properties that make it popular with coders and developers. Python is multi purpose because it can be used to create software and apps, design websites, and automate repetitive tasks. Web developers and data scientists like Python for its broad range of companion libraries, accessible syntax, and portability. The library tools and packages help developers shorten and stream their coding time, and many programmers appreciate that Python requires less time to build projects.", "label": "human"}
{"ID": "00040092", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "As a high-level language, Python uses an easy-to-read command syntax that itconverts to machine code. It also works on the Mac, Windows, and Linux plat forms, making it accessible to nearly every programmer.", "label": "human"}
{"ID": "00040093", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "How python programs work A Python program starts as a text file written in a code editor, saved with a.py extension. The Python interpreter reads this source code, analyzes it, and exe cutes it  by . During this process, it performs lexical analysis, parsing, and execution. Optionally, the source code can be compiled into bytecode for faster ex-ecution. The Python interpreter acts as a virtual machine, executing the code by converting it into machine-specific binary code. The program may utilize library modules for various tasks. When run, it can interact with the system, process data, and produce output. Any errors or exceptions are handled during execution.", "label": "human"}
{"ID": "00040094", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Python is a high-level programming language known for its simplicity and read ability. To understand how a Python program works, let’s break it down into several key steps as following:", "label": "human"}
{"ID": "00040095", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Code Editor: You start by writing your Python code in a code editor. This is where you create your program and save it with a .py extension. A code editor provides features for writing and editing code, such as syntax highlighting and code completion.", "label": "human"}
{"ID": "00040096", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Python is typically an interpreted language, meaning it doesn’t require explicit compilation before running. However, in some cases, your Python code may becompiled into bytecode. This compiled bytecode is saved in .pyc files. The com pilation is not something you usually do manually; it’s managed by the Python interpreter. Bytecode:", "label": "human"}
{"ID": "00040097", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Bytecode is an intermediate representation of your Python code. It’s a low-level, platform-independent format that the Python interpreter can execute. Bytecode files (.pyc) are generated to improve execution speed. If the .pyc file exists andis newer than the source code, Python uses it for faster execution. Python Inter preter (Virtual Machine):", "label": "human"}
{"ID": "00040098", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The Python interpreter is responsible for executing your Python code.You exe cute the Python program in your terminal or command prompt.", "label": "human"}
{"ID": "00040099", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Odoo Overview Odoo, also known as Odoo ERP and previously called OpenERP, is a versatile open-source business management software. It comes with complete integrationand customization capabilities, catering to offer a comprehensive solution for over seeing diverse facets of eCommerce operations.", "label": "human"}
{"ID": "00040100", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Among its noteworthy functionalities are sales and marketing management, cus tomer relations, project oversight, manufacturing, inventory control, accounting,human resource administration, customer service handling, and a plethora of otherapplications. As a result, Odoo is adept at fulfilling the real-world business require ments of enterprises spanning all sizes and budget ranges, across many industries.", "label": "human"}
{"ID": "00040101", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Advantages of OdooEase of use: The Odoo interface boasts a simple and intuitive design, with mod ules logically and systematically organized. As a result, new users will quickly become proficient without investing an excessive amount of time.", "label": "human"}
{"ID": "00040102", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "End-to-end Features and Modules: Odoo offers an expansive array of features and modules, spanning from fundamental to advanced, to address all requirements for effective business management and operations. These encompass tasks such as sales management, marketing, customer support, accounting, inventory control, and manufacturing.", "label": "human"}
{"ID": "00040103", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Modules Integration: Previously, businesses used to store information and data within individual department databases, leading to challenges in accessing andsharing information across departments. With Odoo, apart from providing the necessary modules for management and operations, it also aids businesses by integrat ing and storing data from all departments in a unified database, facilitating quicker and more convenient management and tracking.", "label": "human"}
{"ID": "00040104", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Display Complete Data: Besides storage and integration, Odoo also holds the advantage of presenting comprehensive information. For instance, the ability to showcase detailed and complete data assists businesses in effectively managingproduct inventory levels on a daily or monthly basis, encompassing future ship ments that have not yet been recorded.", "label": "human"}
{"ID": "00040105", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "It Can Be Customizable: Another benefit of Odoo software pertains to its cus tomization potential. Odoo allows users to tailor the software to their requirementswithout the necessity of writing code. Thanks to its intuitive and user-friendly inter face, individuals without extensive programming skills can also make adjustments.", "label": "human"}
{"ID": "00040106", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "ORM Overview ORM (Object Relational Mapping) is a concept or technique which acts as abridge between your programming language and your database. The Object Rela tional Mapping helps to execute SQL queries without writing them explicitly. Once the ORM is configured in an application, the user can use the OOP concepts like classes and objects to interact with the database.", "label": "human"}
{"ID": "00040107", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Odoo is considered the best open ERP platform in the market. Odoo is known for its managerial capacity and intuitiveness to perform determined actions of thebusiness. Being open-source, a large community of developers works on the Odooframework at a time. And for this reason, it is important that you have a well structured ORM to make SQL operations.", "label": "human"}
{"ID": "00040108", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Fortunately, Odoo encompasses a well-structured ORM API, which allows the developers to interact with the database via some methods and operations. Odoo uses some tools and packages like psycopg2 to build a proper ORM API.", "label": "human"}
{"ID": "00040109", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "It starts from the basic CRUD (create, read, update, delete) operations. Mean while, it also includes other operations such as data importing to the database, exporting to files, and so forth.", "label": "human"}
{"ID": "00040110", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "PostgreSQL overview PostgreSQL, commonly known as Postgres, is a powerful open-source relationaldatabase management system (RDBMS). It is renowned for its robustness, scalabil ity, and extensive feature set. Postgres follows the ACID (Atomicity, Consistency, Isolation, Durability) principles, ensuring data integrity and reliability.", "label": "human"}
{"ID": "00040111", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Postgres supports a wide range of SQL functionalities, including complex queries, advanced indexing, and transaction management. It also offers additional features such as support for JSON and other semi-structured data types, making it flexible for modern application development.", "label": "human"}
{"ID": "00040112", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "With its extensibility, Postgres allows users to define custom data types, func tions, and stored procedures, enabling tailored solutions to specific requirements. It provides built-in support for concurrency control, enabling multiple users to access and modify data concurrently.", "label": "human"}
{"ID": "00040113", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Postgres has a vibrant and active community that continuously contributes to itsdevelopment and provides extensive documentation and support. It runs on various platforms and is used in diverse domains, including web applications, enterprise systems, geospatial applications, and scientific research.", "label": "human"}
{"ID": "00040114", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "When a client application sends a query to PostgreSQL, the query is first parsed and analyzed by the query parser. The query is then passed to the query optimizer, which generates an efficient execution plan based on indexes, statistics, and cost estimates. This plan is then executed by the query executor.", "label": "human"}
{"ID": "00040115", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "PostgreSQL uses a multi-version concurrency control (MVCC) system to handle concurrent transactions. MVCC allows multiple transactions to read and write data simultaneously without interfering with each other, ensuring data consistency and avoiding data contention.", "label": "human"}
{"ID": "00040116", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Data in PostgreSQL is stored in tables, organized within databases. Each tableconsists of rows and columns, and data is persisted on disk in data files. Post greSQL provides various storage engines, allowing developers to optimize data storage based on specific needs.", "label": "human"}
{"ID": "00040117", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "PostgreSQL supports transactions that adhere to the ACID properties, ensuring data integrity. Transactions can be committed or rolled back, allowing developers to maintain data consistency during complex operations.", "label": "human"}
{"ID": "00040118", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "PostgreSQL’s extensibility is a key feature. It allows users to create user-defined data types, functions, and operators, making it highly customizable for different use cases.", "label": "human"}
{"ID": "00040119", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "To ensure security, PostgreSQL provides features like user authentication, role based access control, and SSL encryption to protect data from unauthorized access.", "label": "human"}
{"ID": "00040120", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Furthermore, PostgreSQL supports replication for high availability and faulttolerance. Synchronous and asynchronous replication methods ensure data redun dancy and accessibility, even in the case of hardware failures.", "label": "human"}
{"ID": "00040121", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Relational Database Management System: PostgreSQL is a mature and fullyfeatured relational database management system. It provides a robust and re liable foundation for storing and managing structured data.", "label": "human"}
{"ID": "00040122", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Open-Source and Free: PostgreSQL is an open-source database, which meansit is freely available and can be used, modified, and distributed without any licensing costs. This makes it a cost-effective choice for both small and large projects.", "label": "human"}
{"ID": "00040123", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Extensive Feature Set: PostgreSQL offers a wide range of advanced features, including support for ACID transactions, SQL compliance, complex queries, indexing options, data replication, and more. It provides powerful tools for data management and analysis.", "label": "human"}
{"ID": "00040124", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Scalability and Performance: PostgreSQL is designed to handle high-traffic applications and large datasets. It supports parallel processing, multi-version concurrency control (MVCC), and various optimization techniques to ensure efficient query execution and scalability.", "label": "human"}
{"ID": "00040125", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Flexibility and Compatibility: PostgreSQL supports a variety of data types, including JSON, arrays, and custom types. It also offers compatibility withSQL standards and provides extensions for specialized data types and func tionalities.", "label": "human"}
{"ID": "00040126", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Community Support: PostgreSQL has a large and active community of devel opers and users who contribute to its development, provide support, and share knowledge. This community-driven nature ensures continuous improvement, security updates, and the availability of resources and documentation.", "label": "human"}
{"ID": "00040127", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Integration and Ecosystem: PostgreSQL integrates well with other tools and technologies, making it suitable for building complex software ecosystems. It has drivers and connectors for various programming languages, frameworks, and platforms.", "label": "human"}
{"ID": "00040128", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Cross-Platform Compatibility: PostgreSQL is available on multiple platforms,including Windows, macOS, Linux, and Unix-like systems, allowing develop ers to deploy their applications on their preferred operating systems.", "label": "human"}
{"ID": "00040129", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Web Applications: PostgreSQL is an excellent choice for web applications that require reliable data storage and retrieval. It can handle high volumes of concurrent users and complex data relationships, making it suitable for e-commerce platforms, content management systems, social networks, and more.", "label": "human"}
{"ID": "00040130", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Content Management Systems (CMS): PostgreSQL is often used as the back end database for content management systems due to its reliability, scalability, and ability to handle complex data structures. It can efficiently store and re-trieve content-related data, such as articles, images, user profiles, and more.", "label": "human"}
{"ID": "00040131", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Docker OverviewDocker is an open-source platform that enables developers to automate the de ployment, scaling, and management of applications within lightweight, portable containers. Containers are self-sufficient units that include everything needed to run the application, including the code, runtime, system tools, and libraries. Thisencapsulation ensures consistency across different environments, from develop ment to production, eliminating the ”works on my machine” problem.", "label": "human"}
{"ID": "00040132", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "At the core of Docker is the Docker Engine, which provides the container run time and orchestration capabilities. Developers can create Docker images, whichserve as templates for containers, defining the application’s configuration and dependencies. These images are stored in registries, making it easy to share and dis tribute applications.", "label": "human"}
{"ID": "00040133", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "With Docker, applications can be deployed quickly and efficiently, reducing de ployment time and resource consumption. Containers are isolated from the host system and from other containers, enhancing security and enabling microservices architecture. Docker also facilitates horizontal scaling, allowing applications to be easily replicated across multiple containers to handle increased demand.", "label": "human"}
{"ID": "00040134", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Docker’s ecosystem includes a vast collection of pre-built images and tools that simplify development and integration processes. It works seamlessly with popularcloud platforms and container orchestration tools like Kubernetes, enabling devel opers to build, deploy, and manage applications at scale.", "label": "human"}
{"ID": "00040135", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "How Docker works Docker is a containerization platform that allows developers to create, deploy,and run applications in isolated and lightweight containers. Here’s a detailed ex planation of how Docker works:", "label": "human"}
{"ID": "00040136", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Docker Architecture: Docker follows a client-server architecture. The Docker client is a command- tool or a graphical user interface that interacts with the Docker daemon. The Docker daemon is a background process responsible for building, running, and managing containers.", "label": "human"}
{"ID": "00040137", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Docker Images: To create a Docker container, you need a Docker image. An image is a lightweight, standalone, and executable software package that includes everything needed to run an application - code, runtime, libraries, dependencies, and system tools. Images are built using a Dockerfile, which contains instructionsfor assembling the image . Docker Registry: Docker images are stored in a registry, like Docker Hub or a private registry. Docker Hub is a cloud-based registry where you can find and share public Docker images. Private registries allow organizations to store their custom images securely.", "label": "human"}
{"ID": "00040138", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Docker Container: A container is a runtime instance of a Docker image. It is an isolated environment that runs on the host OS kernel, ensuring consistency across different environments. Containers share the host OS kernel but have their separate filesystem, processes, and network.", "label": "human"}
{"ID": "00040139", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Container Lifecycle: When you run a Docker container, the Docker daemon pulls the required image from the registry if it’s not already available locally. The daemon then creates a container from the image, and the application inside the container starts running.", "label": "human"}
{"ID": "00040140", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Container Isolation : Containers offer isolation from the host system and other containers. This isolation ensures that applications running in one container do not interfere with other containers or the host system.", "label": "human"}
{"ID": "00040141", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Docker Networking: Docker provides various networking options, allowingcontainers to communicate with each other and with the host system. Docker cre ates virtual networks for containers, enabling seamless communication between containers on the same network.", "label": "human"}
{"ID": "00040142", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Container Management: Docker provides a set of commands and APIs to man age containers efficiently. Developers can start, stop, restart, pause, and re- move containers using these commands.", "label": "human"}
{"ID": "00040143", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Docker Compose: Docker Compose is a tool that allows you to define multi container applications using a YAML file. It simplifies the process of managing complex applications with multiple services and their interconnections.4.1 Architecture design 4.1.1 Software architecture selection a, Odoo MVC modelOdoo follows the Model-View-Controller (MVC) architecture. The MVC de sign pattern is a software architectural pattern commonly used in web development frameworks.", "label": "human"}
{"ID": "00040144", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The MVC (Model-View-Controller) is a software architectural pattern commonly used in software development. It separates an application into three inter connected components: the Model, the View, and the Controller. Each componenthas a specific role and responsibility, making the codebase more organized, modu lar, and maintainable.", "label": "human"}
{"ID": "00040145", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Model: The Model represents the data and business logic of the application. It handles data storage, retrieval, and manipulation. It encapsulates the application’s data structure and implements the rules and operations related to that data. Odoo uses ORM (Object-Relational Mapping) to interact with the database, and models in Odoo correspond to database tables.", "label": "human"}
{"ID": "00040146", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "View: The View is responsible for presenting the data to the user. It defines how the data is displayed and provides an interface for user interaction. The View receives data from the Model and formats it appropriately to be presented to the user.", "label": "human"}
{"ID": "00040147", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Controller: In Odoo, the concept of controllers is not as explicitly defined as it is in some other web frameworks that strictly adhere to the Model-View-Controller (MVC) pattern. However, in the context of Odoo, you can think of controllers as the Python code that manages the flow of data between the model and the view, handling user interactions and triggering appropriate responses.", "label": "human"}
{"ID": "00040148", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Odoo extends the MVC architecture to include other components like the \"Action\" layer, which defines how user interactions map to specific actions. Addition ally, Odoo has a modular structure, allowing developers to create separate modules that encapsulate specific functionalities, which aligns with the modular nature of MVC.b, Software architrecture description For this graduation thesis, the model applied is MVC. The MVC architectural pattern is used to organize the codebase and manage the data tier, presentation tier, and business logic.", "label": "human"}
{"ID": "00040149", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Models in Odoo are implemented using the Object-Relational Mapping (ORM) system, which allows developers to interact with the database using Python classes.", "label": "human"}
{"ID": "00040150", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Each model corresponds to a table in the database and encapsulates the business logic related to a particular data entity.Here some class model example:", "label": "human"}
{"ID": "00040151", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Model Description Sla.py Class SLA represent the Service Level Agreement of Ticket, it’s has attributes criteria to match the ticket,working period of time of agreement Stages.py Class Stages represent the Stage of Ticket, has attributes like, name, and Mail Template will send to customer when ticket move to this StagesTicket.py Class Ticket represents the ticket which is created by Customer or Agents, with attributes like title, priority,Team sup port,. . .", "label": "human"}
{"ID": "00040152", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "View: a view is a representation of data that determines how records are displayed to users and how users interact with those records. Views define the struc ture and layout of the user interface, specifying how data from Odoo models is presented on the screen.Views are XML files, views define the structure of theuser interface by specifying the arrangement of fields, buttons, and other UI ele ments on the screen. This includes organizing data in forms, lists, trees, kanban boards, and other view types. Here are some example samples that render the data above.", "label": "human"}
{"ID": "00040153", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "View Description ticket_view.xml Display list,kanban,activity,form view of tickets from model Ticket sla_view.xml Display list, form view of sla from model SLA model Stages_view.xml Display list, form view of Stages from model Stages model Table 4.2: View in Module.", "label": "human"}
{"ID": "00040154", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Controller: Controllers in Odoo often work in conjunction with the ORM (ObjectRelational Mapping) system and are responsible for handling HTTP requests, rout-ing, and processing user actions. The controller in Odoo are mainly use to corre sponding and get request from portal user (user can only access on website only and can’t access to the odoo system) Controller Description ticketWebform Get the Post Form for customer to create a ticket ticketDetailView Get the details of a specific ticket of a customer , including its title,assignee,team support... and other information.", "label": "human"}
{"ID": "00040155", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Overall designBased on the diagram above, the packages are identified and divided into subapplications: Helpdesk, Project, Customer, Agent, Admin, Authentication.Each pack age represents a part of the helpdesk system and contains corresponding classes and functionalities.", "label": "human"}
{"ID": "00040156", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The “Customer”, “Agent”, “Admin” packages depend on “Authentication” pack age for user authentication and authorization The “Ticket”, “Project” depends on “Customer”, “Agent”, “Admin” packages for user authentication and authorization .Also the “Helpdesk” depends on the “Project” package for access Project information and Product of the Project.Figure 4.1: Overall package diagram The ”Authentication” package acts as a central component that provides userauthentication and security features to all other packages. The ” Helpdesk” pack age serves as a bridge between the ”Agent” and ”Customer” packages, providing functionalities for creating a ticket sent from “Customer” to “Agent” and ”Admin”.", "label": "human"}
{"ID": "00040157", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The ”Admin” package has administrative privileges to manage all users and tickets in the entire system. The ”Project” package provides a information for customer, agent to based on that to create a ticket and information 4.1.3 Detailed package design Package diagram for system authentication: All packages - Admin, Agent, Customer are dependent on the ”Authentication” package. The ”Authentication”package serves as a central component that provides user authentication and secu rity. Users will be authenticated and authorized to access system resources. Model Admin, Model Agent, and Model Customer all inherit from Model User.Figure 4.2: Package diagram for system authentication Package diagram for ticket management: “Project\" package model can have 1 or many ticket that related to the project on “Project” package, and the same for all package “Customer”, “Agent”, “Admin”, which mean for customers ,they can have multiple ticket that created by them.,and for Internal User(“Agent”, “Admin”) they can have 1 or many ticket that they assign to. The “Helpdesk” package is also the bridge for Customer and Agent to discussions, Chat.", "label": "human"}
{"ID": "00040158", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Users can interact with the HelpDesk controller differently. Example, Customers can only view or close a ticket but cannot edit information about the ticket. Admins can received ticket is created by customer, assign it to Agent Figure 4.3: Package diagram for ticket management4.2 Detailed design 4.2.1 User interface design a, Portal Screen Screen Description Login•The login page includes a login form with therequired information: Username and Pass word, in addition, the user also needs to choose to log in as a portal user/internal user.", "label": "human"}
{"ID": "00040159", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Optional: Users can choose to remember lo gin information by clicking ”Remember me” Optional: Users can choose to reset password by clicking ”Forgot password” Customer Account registration Customer account registration page includes aninformation registration form for learners with re quired information such as: Full name, Email, Company name, VAT, Phone, Street, City, Zip, Country, State,. . .", "label": "human"}
{"ID": "00040160", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Password reset User is required to enter the account password re covery email. The password recovery link will be send to the email address entered in earlier Homepage The homepage is the introduce information about the website, it overview about the company Product Overview The Product overview includes about the product image of product, project which product belong toProduct Details The Product overview includes the product de tails, component of product, . . .", "label": "human"}
{"ID": "00040161", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Ticket List View The Ticket List view show all tickets which cre ated by customer and not other ticket which not created by themTicket Details Form The Ticket Details page included some important information about the ticket ,created by cus tomer which included : Ticket name, assignee, team support , created date, Stage of the ticket, description question. It also have the chatter to support interact between user portal and internal portal which assign to the ticket Ticket Form Create in Portal The form create ticket included all information to create a ticket : Name, email, phone, Job, TicketSubject, Project, Product, Priority ticket, Descrip tion/Question Ticket Table 4.4: Description of the portal screenb, Internal Screen Screen Description Ticket List View A ticket list view displays a summary of helpdesk tickets, showing key information such as ticket ID, subject, status, priority, and assignee. Users can often customize and filter the list based on various criteria.", "label": "human"}
{"ID": "00040162", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Ticket Details Clicking on a ticket in the list view should open a detailedview. This view typically includes more comprehensive in formation about the ticket, such as the description of theissue, customer details, communication history, and any re lated attachments.", "label": "human"}
{"ID": "00040163", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Ticket Overflow Helpdesk applications usually support a ticket workflow that allows users to move tickets through different stages, suchas \"Open,\" \"In Progress,\" Solved\" and \"Closed.\" Workflow related actions and buttons may be integrated into the ticket interface.", "label": "human"}
{"ID": "00040164", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Customer Details Integrating customer information directly within the helpdesk interface is common. This can include contact details, customer history, phone,company,. . .", "label": "human"}
{"ID": "00040165", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Overview It’s the personal dashboard page included the informationabout the log in user ticket: Open ticket, Major Ticket, Criti cal Ticket, Open Hour of ticket, Amount of Failed Ticket DashBoard It’s the summary DashBoard page included the information about all the ticket which is “Open”,Closed”,”All”,”Unassigned” Amount of the Rating Ticket Table 4.5: Description of the internal screenc, User interface design standard Featured Description Web Client Odoo primarily uses a web-based client for its user interface.", "label": "human"}
{"ID": "00040166", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The web client is designed to be responsive, allowing users to access Odoo applications from various devices, including desktops, tablets, and mobile phones.", "label": "human"}
{"ID": "00040167", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Form view Form views in Odoo present data in a structured manner, with fields organized logically. Users can edit data directly within forms, and the design aims for clarity and efficiency in data input List view List views display records in a tabular format, allowing usersto scan and manipulate multiple records efficiently. They of ten include sorting and filtering optionsKanban view Some applications in Odoo use Kanban views, which visual ize data as cards that can be moved between different stages.", "label": "human"}
{"ID": "00040168", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "This is particularly useful for managing workflowsSearch and filters Odoo provides powerful search and filtering capabilities, al lowing users to quickly find and analyze data. Users can save custom filters for future use Responsive Design•Designing a responsive web UI involves creating a user interface that dynamically adapts to different screen sizes and devices, ensuring a seamless user experienceacross desktops, tablets, and smartphones.The key el ements include a flexible layout, scalable images, and font sizes, as well as intuitive navigation By prioritizing readability, usability, and consistency, a well-designed responsive UI enables users to access and interact with the content effortlessly, regardless of the device they are using.", "label": "human"}
{"ID": "00040169", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Icons and Symbols Icons and symbols are used consistently throughout the interface to represent actions, status, and different types of in formation. This helps users quickly understand and interpret the interface.", "label": "human"}
{"ID": "00040170", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Contextual Menu Contextual menus provide relevant actions based on the user’s current context, streamlining the user experience and reducing unnecessary navigation.", "label": "human"}
{"ID": "00040171", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "create(): represent user behavior to create ticket record update(): represent user behavior to update ticket record unlink(): represent user behavior to delete ticket record message _new(): represent user behavior to comment in the ticket chat box•create _activity(): represent user behavior to create activity for the ticket record message _log(): represent user behavior to add message log in chatter, this only can view and add by the internal user Figure 4.10: Users Class HelpdeskTicket Class has the following attributes : id, ref, active, name, team _id, priority, customer _id, stage _id, type _id, tag _id, description, project _id, sla _status _id, assign _to id is primary key ,all the many2one fields are foreign keys Some notable methods:", "label": "human"}
{"ID": "00040172", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "get_sla_criteria(): represents the ticket when create, will find the sla which match up the criteria•send_mail(): represents the action when the ticket change state it will send the mail to notify the customer Figure 4.11: HelpdeskTicket Classb, Sequence Diagrams Customer Register sequence Figure 4.12: Customer Register sequence Customer create ticket sequenceFigure 4.13: Customer create ticket sequence Admin management ticket sequence Figure 4.14: Admin management ticket sequence Message send to customer sequenceFigure 4.15: Message send to customer sequence4.2.3 Database design a, E-R Diagram Figure 4.16: E-R Diagram b, Database design Figure 4.17 shows design for table Ticket table,where id is the primary key andcustomer _id, assignee _id, project _id are foreign keys associated with the Cus tomer, User, Project tableFigure 4.17: Ticket design Figure 4.18 shows design table Project where id is the primary key and manager _id is foreign key associated with the User Figure 4.18: Project designFigure 4.19 shows design table SLA where id is primary key and team _id,project _id, reach _stage are foreign keys associated with Team, Project, Stage ta bles Figure 4.19: SLA design Figure 4.20 shows design table Customer where id is primary key. acive attribute mean if account ever login to the website, or login now.", "label": "human"}
{"ID": "00040173", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Attributes Statistics My Helpdesk module source code 75MB Entire Odoo Source code 1.4GB Table 4.8: list of libraries and tools 4.3.3 Illustration of main functions a, Received ticket from user Users login to the website, if a customer wants to have a question or issue, or maybe just want some review about the product of the company, they can switch to the Ticket Tab menu in the nav bar, it will represent the form view to the customer.", "label": "human"}
{"ID": "00040174", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The Form view included: Name, email, phone, job of Customer, and some fields related to the ticket which the customer is about to create.Figure 4.22: Form ticket portal Screen b, Customer view ticket they created, and chatter If the Customer want to get updates of the Ticket they created, they can go to the account information document and check the ticket record, the view support chatter so if they want to ask more questions, interact with internal user who assigned to ticket, or even more they can send the file attachment through chatter to make the Support Agent easier to find the solution for the ticket.Figure 4.23: Details ticket portal Screen c, Admin approved and assign TicketWhen Ticket is created by customer, the admin will check the Ticket’s infor mation then admin will approve and assign ticket to which agent will supporting, solving this ticket Figure 4.24: Details ticket internal Screend, Ticket add SLA period of time If the admin adds the SLA for the ticket ,the admin will have to fill the fields data ticket that satisfied the criteria of the SLA. The Criteria section in SLA is used to identify what tickets this policy will be applied to. The Target - Reach Stage is the stage a ticket needs to reach, and the time allotted to reach that stage, in order to satisfy the SLA policy.", "label": "human"}
{"ID": "00040175", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Digital Ocean provides reliable and scalable infrastructure that allows developersto easily host and manage their applications, ensuring a smooth and efficient de ployment process 4.5.1 Deployment Set up by Step After create a droplet and log into CMD of the Server Step 1 : Update apt-get update -y apt-get upgrade -y Step 2: Setup Swap Space # free -h df -h sudo fallocate -l 512M /swapfile sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile sudo cp /etc/fstab /etc/fstab.bak Step 3: Tuning Swap Space cat /proc/sys/vm/swappiness cat /proc/sys/vm/vfs_cache_pressure sudo sysctl vm.swappiness=10 sudo sysctl vm.vfs_cache_pressure=50 sudo nano /etc/sysctl.conf vm.swappiness=10•vm.vfs_cache_pressure=50 Step 4: Installing Odoo Dependenciessudo apt install python3-pip python3-dev python3-venv python3-wheel libxml2 dev libpq-dev libjpeg8-dev liblcms2-dev libxslt1-dev zlib1g-dev libsasl2-devlibldap2-dev build-essential git libssl-dev libffi-dev libmysqlclient-dev libjpeg dev libblas-dev libatlas-base-dev libssl3 Step 5: Creating a System User sudo useradd -m -d /opt/odoo16 -U -r -s /bin/bash odoo16 Step 6: installing and Configuring PostgreSQL sudo apt install postgresql sudo su - postgres -c \"createuser -s hoc\" Step 7: Installing wkhtmltopdf sudo wget  sudo chmod +x wkhtmltox_0.12.6.1-2.jammy_amd64.deb sudo apt install ./wkhtmltox_0.12.6.1-2.jammy_amd64.deb ln -s /usr/local/bin/wkhtmltopdf /usr/bin/wkhtmltopdf wkhtmltopdf –version Step 8: Installing and Configuring my Odoo 16 Source code sudo su - odoo16 git clone  –depth 1 /opt/odoo16/odoo cd /opt/odoo16 python3 -m venv odoo-venv source odoo-venv/bin/activate pip3 install wheel nano odoo/requirements.txt libsass==0.20.1 pip3 install -r odoo/requirements.txt deactivate mkdir /opt/odoo15/odoo-custom-addons•exit sudo nano /etc/odoo15.conf [options] ; This is the password that allows database operations:", "label": "human"}
{"ID": "00040176", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "admin_passwd = my_admin_passwd db_host = False db_port = False db_user = hoc db_password = False addons_path = /opt/odoo15/odoo/addons,/opt/odoo15/odoo-custom-addons logfile = /var/log/odoo/odoo15.log sudo chown odoo16: /etc/odoo.conf mkdir /var/log/odoo/ chown odoo15:root /var/log/odoo/ Step 9: Creating Systemd Unit File sudo nano /etc/systemd/system/odoo15.service [Unit] Description=Odoo15 Requires=postgresql.service After=network.target postgresql.service [Service] Type=simple SyslogIdentifier=odoo16 PermissionsStartOnly=true User=odoo16 Group=odoo16ExecStart=/opt/odoo16/odoo-venv/bin/python3 /opt/odoo16/odoo/odoo-bin  c /etc/odoo.conf StandardOutput=journal+console[Install] WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl enable –now odoo16 sudo systemctl status odoo16 sudo journalctl -u odoo16 Step 10: Setup Swap Space free -h df -h sudo fallocate -l 512M /swapfile sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile sudo cp /etc/fstab /etc/fstab.bak Step 11: Tuning Swap Space cat /proc/sys/vm/swappiness cat /proc/sys/vm/vfs_cache_pressure sudo sysctl vm.swappiness=10 sudo sysctl vm.vfs_cache_pressure=50 sudo nano /etc/sysctl.conf vm.swappiness=10vm.vfs_cache_pressure=50The aim of this project is to fully deploy the helpdesk website to ANSV re cent clients of the IT support. The helpdesk website is to manage the process of a customer support system. In the scope of this project, my efforts are focused onmanaging SLA policies in the website helpdesk system. Alongside the above as pect, the priority in the frontend is a functional design where the client can send a request according to the technical product and project requirement. An advanced backend user interface is also the priority of the project.", "label": "human"}
{"ID": "00040177", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "SLA ProblemThe ANSV’s current IT customer support system does not have SLA function ality. SLA or Service Level Agreement policy is an important factor when it comes to an agreement between a company or person who provides the service and the client who purchases the service or product. SLA as such is not a contract instead we can term it a very significant part of a contract. This policy helps the serviceprovider and the customer to come in terms regarding the services offered, respon siveness, support, etc. The support here can mean technical assistance or response to email queries or phone calls.", "label": "human"}
{"ID": "00040178", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Ticket Service Level Agreement is the agreed upon turnaround time in which aticket needs to be answered or resolved. It may depend on priority levels such as low, medium, or high. For example, if the SLA of first resolution time is 4 hours, all tickets that were attended to within 4 hours meet the SLA.", "label": "human"}
{"ID": "00040179", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Proposed solution The EDF scheduling algorithmAs presented in the Chapter 4: Experiment and Evaluation, when a ticket is cre ated by a customer, the Admin will check the ticket’s information, then the Admin will approve and assign the ticket to which staff for supporting and solving this ticket. The most important point here is that the Admin needs to identify which policies from SLA criteria will be applied to this ticket. In real-time systems, due to different ticket priorities, ticket scheduling is often overloaded, which leads to a decrease in the success rate of ticket scheduling and the waste of system resources.", "label": "human"}
{"ID": "00040180", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "To solve this problem, I used the earliest dead first (EDF) scheduling algo rithm, a typical representative of the dynamic priority scheduling algorithm. Theticket dead, ticket value, energy consumption, and other parameters were in troduced. The tickets were optimized by combining the ticket load value with the ticket priority, which increased the number of tickets scheduled and improved the utilization rate of system resources.", "label": "human"}
{"ID": "00040181", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Determine the weights of the indicators using and then obtain the priorityFigure 5.3: Hierarchical structure model diagram of the tickets Pi. three indicators were introduced: ticket running time, ticket value, and ticket energy consumption.", "label": "human"}
{"ID": "00040182", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Calculate the comprehensive priority Pi, using the value density method, which combines the ticket load value with the priority Pi.", "label": "human"}
{"ID": "00040183", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Whenever a new ticket was added to the ticket set, it was necessary to redefine the priority of the ticket and refresh the priority scheduling subset.", "label": "human"}
{"ID": "00040184", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "To assign the ticket to which staff for supporting and solving this ticket, a hierarchi cal model is established including the solution layer, the criteria layer and the target layer, which were used to determine the values of targets kv, kc and ke. The target layer aimed to get reasonable kv, kc and ke values. The criteria layer influenced the factor affecting the dead miss rate, which included ticket running time, ticket value and ticket energy consumption. The solution layer supplied five groups of kv, kc and ke for the five staff as an example.", "label": "human"}
{"ID": "00040185", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The website helpdesk helps us to prepare and manage guides for a better relationship between the service provider and the customer. While engaging in busi ness with the clients there should be SLA policies regarding the response time that the company will require to address the ticket, the service period, period of free service and paid service, service charge, etc. SLA policy is something that is mea-surable. Besides, these policies make us responsible to manage the requirements of the customer and define the services included.", "label": "human"}
{"ID": "00040186", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Using the above algorithm assists us to configure SLA policies and supports us to incorporate this policy with helpdesk management. The configuration of SLA policies in the Helpdesk system has menus like Overview, Tickets, Reporting, and Configuration. We can configure different features using the Configuration menu and can add details like:", "label": "human"}
{"ID": "00040187", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Team: The name of the team that will be taking care of clients who are part of this particular policy will be given here.", "label": "human"}
{"ID": "00040188", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Minimum Priority: The priority is demonstrated in the form of stars. The max imum number of stars here is three and if we check all three stars, the ticket is of the highest priority. If no star is lit up then it is of less priority.", "label": "human"}
{"ID": "00040189", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Ticket Type: We can create different ticket types based on the queries or requests received by the company. The SLA policy can be enabled for particular types of tickets Tags: Tags help the helpdesk team members to get an idea about the terms ofservice in the SLA policy. In the above image, tags are given as repair and ser vice. That means the SLA policy is applicable if the ticket is for repair or service operations.", "label": "human"}
{"ID": "00040190", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Track processing progress and control the time it takes to resolve each em ployee’s support request with integration with work time management when the support request is tied to a specific project.", "label": "human"}
{"ID": "00040191", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Monitor support policies and ensure customers are supported according to the policy, scope and timeframe through establishing Service Level Agreements (SLAs).", "label": "human"}
{"ID": "00040192", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Allows customers to proactively track the progress of their support requests through the portal without needing to contact support staff, helping to increasebusiness interaction and experience with customers.", "label": "human"}
{"ID": "00040193", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Design Problem The old system design interface is based on the Windows platform which does not have new features such as chat dialog boxes and automatic notification of ticket processing to customers. The current processing system is also not flexible due to the use of packaged software, and after a long time of use, there are no updates to new features: data updates and reports are all done manually.", "label": "human"}
{"ID": "00040194", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Requirement Analysis: Analyzing the system’s requirements, business pro cesses, and particularly the behavior of end-users to thoroughly understand the project’s needs and goals. This ensures that the interface is designed to meet the correct requirements and deliver the best user experience.", "label": "human"}
{"ID": "00040195", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Wireframing: Creating wireframes, which are basic visual representations of the interface layout, to establish the structure and flow of the application.", "label": "human"}
{"ID": "00040196", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Creating a consistent layout with high brand recognition. Rational use of vi sual elements to create a harmonious and appealing interface.", "label": "human"}
{"ID": "00040197", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "User Experience (UX): Enhancing the user experience by identifying and op timizing the workflow of tasks in the system, arranging interface elements logically and comprehensively, and creating smooth and efficient operationsand interactions. Ensuring a consistent user experience across different de vices.", "label": "human"}
{"ID": "00040198", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Cross-platform Design: Designing a responsive interface that ensures it dis plays well on various devices with different screen sizes, including desktops, mobile devices, and tablets.", "label": "human"}
{"ID": "00040199", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Usability Testing: I conducted usability testing with real users to validate the design, gather feedback, and make necessary improvements for better user satis- faction.5.2.3 Experimental results The application interface has been implemented with a high level of completion, fully meeting all the functional requirements of the system. The interface ensures that all system functions operate accurately and effectively. New user experiencedesign in the helpdesk system has optimized the operating process with the follow ing benefits:", "label": "human"}
{"ID": "00040200", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Enhance user experience, improve service quality: 1) Automatically send emails notifying customers of implementation progress when processing stages change;2) Allow customers to rate support staff and provide feedback on their expe rience after the support request has been processed; 3) It is a basis to help managers evaluate the quality of their staff; 4) Increase customer loyalty when response time to support needs is significantly improved from methodical, scientific and quick management of support requests.", "label": "human"}
{"ID": "00040201", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Multi-criteria analysis and reporting in the customer support center: 1)Ag gregate support requests by many criteria (completed, incomplete, processing time, etc.), reported in visual charts (column, , pie) in real time; 2) Helps managers have an overview, understand the volume of support requests, track processing status and distribute implementation personnel; 3) Helps businesses have information and statistics to perfect and improve service quality at each customer touch point.6.1 AchievementsThe thesis successfully designed and built a helpdesk website, which has pro vided more effective support in managing and tracking requests from ANSV’s customers. With the system built using the open source OdooErp language, it is possible to customize and develop software features quickly according to customer requirements. During the process of implementing the graduation project, students achieved the following results and lessons learned:", "label": "human"}
{"ID": "00040202", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Learning how to deploy web applications using Python programming lan guage and Odoo framework. Familiarizing with the relevant technologies and libraries such as Qweb and ORM.", "label": "human"}
{"ID": "00040203", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Studying the methodology of this project, starting with planning, designing with MVC software architect pattern Learning how to analyse and design system architecture using UML diagrams to visualize and model the system’s architecture, interactions, and data flow.", "label": "human"}
{"ID": "00040204", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Due to the limited time to complete the project, the website helpdesk still has some limitations that need to be overcome:", "label": "human"}
{"ID": "00040205", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The system can not be integrated with the current software of the customersupport department at ANSV. Because the current software is managing cus tomer requests via email and phone, the integration will help both systems operate more effectively.", "label": "human"}
{"ID": "00040206", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "A scalability technique may be necessary to enhance the system’s ability to handle increased traffic and user load. The maintenance would also check the system would handle the load and the effect of response time. In that case, the result would showcase a result of the scalability of the system.", "label": "human"}
{"ID": "00040207", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Integrate with software of other departments in ANSV such as Sales (quota tion information, orders, pricing policies, promotions, incentives...) and CRM (recording potential customers. Interactions and full history storage,. . . ).", "label": "human"}
{"ID": "00040208", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Additional security techniques should be explored and applied to limit theexposure of customer databases on the system and minimize potential vulner abilities.", "label": "human"}
{"ID": "00040209", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "The phone message function could be an improvement for the complaint management system project in the ANSV. The telephony integration with the sys tem helps to raise a new ticket directly from a voice call, and automatically returns the ticket reference to the customer instantly on the phone. The voice tickets function embeds the audio clip directly into the ticket, so ANSV staff have all the call details easily to hand. Regina Obe, Leo Hsu, PostgreSQL: Up and Running , 3rd Edition. O’Reilly Media, Inc, 2017.", "label": "human"}
{"ID": "00040210", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Ravi Chandra Chaitanya Guntupalli, “User interface design - methods and qualities of a good user interface design”. M.S. thesis, University West, Swe- den, 2008.", "label": "human"}
{"ID": "00040211", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Yoon IC., Sussman A., Memon A., Porter A. Effective and scalable soft ware compatibility testing. In: Proceedings of the 2008 international symposium on Software testing and analysis . 2008. pp. 63-74.", "label": "human"}
{"ID": "00040212", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Integration of the Helpdesk System with Messaging Service: A Case Study Approach . In: 2021 9th International Conference on Cyber and IT Service Manage ment (CITSM). IEEE; 2021. pp. 1-5.", "label": "human"}
{"ID": "00040213", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Stankovic, John A.., Spuri, Marco., Ramamritham, Krithi., Buttazzo, Gior gio C. Dead Scheduling for Real-Time Systems: EDF and Related Algorithms .", "label": "human"}
{"ID": "00040214", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Rachmawati E., Kom M., Kom M. Web-Based Ticketing System Helpdesk Application Using CodeIgniter Framework (Case Study: PT Commonwealth Life) .", "label": "human"}
{"ID": "00040215", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Reis, Daniel., Mader, Greg. Odoo 15 Development Essentials: Enhance Your Odoo Development Skills to Create Powerful Business Applications . United Kingdom: Packt Publishing, 2022.", "label": "human"}
{"ID": "00040216", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "Downey, Tim. Web development with Java using Hibernate, JSPs and Servlets . Germany: Springer London, 2007. L. H. Regina Obe, PostgreSQL: Up and Running . O’Reilly Media, Inc, 2017.", "label": "human"}
{"ID": "00040217", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "R. C. C. Guntupalli, User interface design - methods and qualities of a good user interface design . M.S. thesis, University West, Swe- den, 2008.", "label": "human"}
{"ID": "00040218", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "M. A. P. A. Yoon IC. Sussman A., Effective and scalable software com patibility testing. In: Proceedings of the 2008 international symposium on Software testing and analysis . 2008.", "label": "human"}
{"ID": "00040219", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "K. D. S. I. G. D. H. A. Hardianto H. Shofi IM., Integration of the Helpdesk System with Messaging Service: A Case Study Approach . 9th International Conference on Cyber and IT Service Management (CITSM). IEEE; 2021, 2021.", "label": "human"}
{"ID": "00040220", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "S. M. R. K. B. G. C. Stankovic John A.., Dead Scheduling for Real-Time Systems: EDF and Related Algorithms . Switzerland: Springer US, 2012.", "label": "human"}
{"ID": "00040221", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "K. M. Rachmawati E. Kom M., Web-Based Ticketing System Helpdesk Appli cation Using CodeIgniter Framework (Case Study:PT Commonwealth Life) .", "label": "human"}
{"ID": "00040222", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "N. C. Agrawal R., Challenges of big data storage and management . Global Journal of Information Technology: Emerging Technologies, 2016.", "label": "human"}
{"ID": "00040223", "file_name": "Developing and building website Helpdesk using OdooErp", "content": "D. Reis, Odoo 15 Development Essentials: Enhance Your Odoo Development Skills to Create Powerful Business Applications . United Kingdom: Packt Publishing, 2022.", "label": "human"}
{"ID": "00050001", "file_name": "Android Malware Scanner", "content": "The Android operating system has become the most widely used platform in the mobile world, but this growth has also brought significant security challenges.", "label": "human"}
{"ID": "00050002", "file_name": "Android Malware Scanner", "content": "Malicious applications continue to pose serious threats to user privacy and data security. As malware becomes more sophisticated, it is increasingly difficult to detect and mitigate these threats using traditional methods.", "label": "human"}
{"ID": "00050003", "file_name": "Android Malware Scanner", "content": "This problem is particularly important for developers and organizations that rely on Android applications, as security vulnerabilities can lead to data breaches, loss of user trust, and financial damages. However, existing tools often lack the detailed analysis and flexibility needed to address these challenges effectively.", "label": "human"}
{"ID": "00050004", "file_name": "Android Malware Scanner", "content": "To tackle this issue, this project introduces Androlyzer, a framework designed to analyze Android files. By performing both static and dynamic analysis, Androlyzer helps identify malware, detect vulnerabilities, and assess the overall security of applications. The system generates detailed reports to assist developers and security professionals in improving the safety of their applications.", "label": "human"}
{"ID": "00050005", "file_name": "Android Malware Scanner", "content": "The goal of this project is to provide a practical tool that contributes to enhanc ing Android application security while also supporting the broader effort to create a safer mobile ecosystem.", "label": "human"}
{"ID": "00050006", "file_name": "Android Malware Scanner", "content": "Overview of Current Solutions In the Android ecosystem, malware analysis has become increasingly important due to the growing prevalence of malicious applications. Current approaches to malware analysis can be divided into static and dynamic methods, each with its own strengths and limitations.", "label": "human"}
{"ID": "00050007", "file_name": "Android Malware Scanner", "content": "Static Analysis: This method involves examining the structure, code, and re sources of an application without executing it. Static analysis is efficient andcan uncover embedded malicious code, permissions, and configurations. How ever, it struggles to detect runtime behaviors or obfuscation techniques used by advanced malware.", "label": "human"}
{"ID": "00050008", "file_name": "Android Malware Scanner", "content": "Dynamic Analysis: This approach observes the behavior of an application dur ing execution in a controlled environment. It can detect malicious activities such as unauthorized data exfiltration or suspicious API calls. While effective, dynamic analysis is resource-intensive, time-consuming, and often requirescomplex setups.", "label": "human"}
{"ID": "00050009", "file_name": "Android Malware Scanner", "content": "Despite their advantages, current solutions often face challenges such as scalability, ease of use, and adaptability to evolving malware techniques. Additionally, many existing methods are difficult to integrate into automated workflows, limiting their application in fast-paced development environments.", "label": "human"}
{"ID": "00050010", "file_name": "Android Malware Scanner", "content": "Identified Limitations and Proposed Focus Based on the current state of Android malware analysis tools, several limitations have been identified that highlight the need for a more efficient, flexible solution.", "label": "human"}
{"ID": "00050011", "file_name": "Android Malware Scanner", "content": "Lack of Comprehensive Analysis Tools Complexity and Resource-Intensiveness Limited Automation and Integration 1.2.3 Objectives and Scope Our graduation thesis aims to develop an Android malware analysis framework, addressing key gaps in existing solutions. The primary objectives of this project are:", "label": "human"}
{"ID": "00050012", "file_name": "Android Malware Scanner", "content": "The scope of this thesis will cover the full development cycle of the Androlyzer framework, from the initial design to implementation and evaluation. The main features will include:", "label": "human"}
{"ID": "00050013", "file_name": "Android Malware Scanner", "content": "Scalability : Supporting batch processing and handling large numbers of files efficiently.This project aims to provide a practical solution to improve Android malwareanalysis by combining user-friendly design with comprehensive, automated features. The goal is to create a versatile tool that can be utilized by developers, secu rity professionals, and researchers to enhance the security of Android applications.", "label": "human"}
{"ID": "00050014", "file_name": "Android Malware Scanner", "content": "In the following chapters, we will detail the specific methodologies used, the design and implementation processes, and the evaluation of the application’s effectiveness in addressing the identified limitations.", "label": "human"}
{"ID": "00050015", "file_name": "Android Malware Scanner", "content": "From the clearly defined tasks to be addressed in Section 1.2, we propose our tentative solution following the sequence below:", "label": "human"}
{"ID": "00050016", "file_name": "Android Malware Scanner", "content": "Approach and Methodology : Our approach focuses on utilizing modern web development technologies combined with both static and dynamic analysis techniques. The framework will be built with flexibility in mind, supporting both manual and automated processes. By using Django for the backend andintegrating APIs, we ensure scalability and adaptability to various environ ments. The system will support batch processing for handling large sets of files and will be capable of producing detailed reports for malware analysis.", "label": "human"}
{"ID": "00050017", "file_name": "Android Malware Scanner", "content": "Brief Description of Solution : Our solution involves the development of a web-based task and project management application, leveraging technologies such as React.js for the frontend and Spring for the backend. The applicationwill feature intuitive user interfaces for task creation, assignment, and track ing, along with collaborative functionalities to facilitate team communication and coordination.", "label": "human"}
{"ID": "00050018", "file_name": "Android Malware Scanner", "content": "Main Contributions : The primary contribution of our project lies in provid ing a user-friendly and comprehensive solution to the challenges of task andproject management. By integrating agile principles with modern web tech nologies, we aim to offer an efficient and adaptable platform that enhances productivity and collaboration within teams. The expected outcome is a robust application that streams task management processes, resulting in improved workflow efficiency and project success.", "label": "human"}
{"ID": "00050019", "file_name": "Android Malware Scanner", "content": "In the subsequent chapters, we will delve deeper into the specifics of our pro posed solution, including the detailed design and implementation aspects, as well as the evaluation of its effectiveness in addressing the identified tasks.1.4 Thesis organization The remaining sections of this graduation thesis are organized as follows:", "label": "human"}
{"ID": "00050020", "file_name": "Android Malware Scanner", "content": "Chapter 2: Requirement Survey and AnalysisThis chapter provides an overview of the requirements for task and project manage ment applications, including an analysis of user needs and existing solutions in the market. The chapter explores the key features and functionalities desired by users, which serve as the foundation for the development of our solution.", "label": "human"}
{"ID": "00050021", "file_name": "Android Malware Scanner", "content": "Chapter 3: Methodology In this chapter, we present the methodology adopted in the development of our task and project management application. The chapter discusses the agile principles and modern web development technologies utilized in our approach, outlining the rationale behind their selection and implementation.", "label": "human"}
{"ID": "00050022", "file_name": "Android Malware Scanner", "content": "Chapter 4: Design, Implementation, and EvaluationChapter 4 delves into the detailed design and implementation of our proposed solu tion. It covers the architectural design of the application, the development process, and the evaluation of its effectiveness in meeting the identified requirements. This chapter provides insights into the technical aspects of our project and showcases the functionalities of the application.", "label": "human"}
{"ID": "00050023", "file_name": "Android Malware Scanner", "content": "Chapter 5: Solution and Contribution In this chapter, we present the final solution developed as part of this thesis and discuss its contributions to the field of task and project management. The chapter highlights the innovative features of our application and its potential impact on improving workflow efficiency and productivity in professional settings.", "label": "human"}
{"ID": "00050024", "file_name": "Android Malware Scanner", "content": "Chapter 6: Conclusion and Future WorkThe concluding chapter summarizes the key findings and contributions of this the sis. It provides insights into the limitations of the current solution and suggests areas for future research and development. The chapter concludes with reflections on the overall project and its implications for future work in the field.", "label": "human"}
{"ID": "00050025", "file_name": "Android Malware Scanner", "content": "Each chapter follows a structured format, beginning with an overview of its contents and concluding with a summary of key findings and implications. This organization ensures clarity and coherence in presenting the research conducted and the outcomes achieved throughout this thesis.2.1 General use case diagramFigure 4.6 depicts the overview use case diagram for the task and project man agement application. The primary actor in this system is the user, who interactswith the application to perform a variety of functions essential for effective mal ware analaysis. The second actor is admin, that CRUD and manage the information of the user. Below is a detailed explanation of the actors and the main use cases identified in the diagram.", "label": "human"}
{"ID": "00050026", "file_name": "Android Malware Scanner", "content": "Admin : A privileged actor in the system. The admin’s responsibilities include managing user accounts (e.g., adding, updating, or deactivating accounts),monitoring system performance, reviewing and resolving reported issues, managing permissions, configuring system settings, and ensuring the smooth op eration of the application.", "label": "human"}
{"ID": "00050027", "file_name": "Android Malware Scanner", "content": "See Decompiled Code : This sub-use case will allow the user to view decom piled Java or Kotlin source code from the file.", "label": "human"}
{"ID": "00050028", "file_name": "Android Malware Scanner", "content": "See Smali Source Code : This sub-use case will enable the user to inspect the Smali source code generated from the file.", "label": "human"}
{"ID": "00050029", "file_name": "Android Malware Scanner", "content": "Do Specific Dynamic Analysis : This sub-use case will allow user to do some more specific analysis dynamically View Dynamic Analysis Report : This sub-use case will allow the user to view the dynamic analysis report.", "label": "human"}
{"ID": "00050030", "file_name": "Android Malware Scanner", "content": "Download Decompiled Code / Smali Code : This sub-use case will enable the user to download the decompiled source code or Smali code.", "label": "human"}
{"ID": "00050031", "file_name": "Android Malware Scanner", "content": "Create User : This sub-use case will allow user to create new user profile.•View User Information : This sub-use case will allow admin to view user informations.", "label": "human"}
{"ID": "00050032", "file_name": "Android Malware Scanner", "content": "The use case diagram in Figure 4.6 provides a high-level overview of the system’s functionalities. It has some normal functions as well as some specific func tion, I will refer to some specific function later in Chapter 3.", "label": "human"}
{"ID": "00050033", "file_name": "Android Malware Scanner", "content": "Rescan Use CaseThe Rescan use case encompasses all the functionalities that allow users to ef ficiently reanalyze previously uploaded files. This section breaks down the Rescan use case into more specific sub-use cases. The primary goal is to enable users to reanalyze files with updated configurations, retrieve updated results, and ensure comprehensive assessment. Below is a detailed breakdown and explanation of each sub-use case.", "label": "human"}
{"ID": "00050034", "file_name": "Android Malware Scanner", "content": "Actors Involved : User•Description : The user initiates a rescan of a previously uploade file. This process may involve selecting the file from the recent analysis history and optionally configuring updated analysis parameters.", "label": "human"}
{"ID": "00050035", "file_name": "Android Malware Scanner", "content": "Check Recent Scans Use Case The Check Recent Scans use case encompasses all the functionalities that allow users to manage and interact with their recently analyzed files effectively. This section breaks down the Check Recent Scans use case into more specific sub-use cases. The primary goal is to enable users to compare, delete, and select analyzed files for further actions. Below is a detailed breakdown and explanation of each sub-use case.", "label": "human"}
{"ID": "00050036", "file_name": "Android Malware Scanner", "content": "Delete Analyzed File : This sub-use case enables users to remove an analyzed file from the recent scans list. By selecting a file and confirming the action,users can permanently delete the file and its associated data from the system.", "label": "human"}
{"ID": "00050037", "file_name": "Android Malware Scanner", "content": "Select Analyzed File : This sub-use case allows users to choose a specific filefrom the recent scans list for additional actions such as rescanning, download ing, or viewing detailed results.", "label": "human"}
{"ID": "00050038", "file_name": "Android Malware Scanner", "content": "Actors Involved : User Description : The user selects two previously analyzed files to compare their results, highlighting differences in the analysis outcomes.", "label": "human"}
{"ID": "00050039", "file_name": "Android Malware Scanner", "content": "Actors Involved : User Description : The user deletes a file from the list of recent scans, removing its associated data from the system.", "label": "human"}
{"ID": "00050040", "file_name": "Android Malware Scanner", "content": "Preconditions : The file to be deleted must exist in the recent scans list, and the user must have the necessary permissions.", "label": "human"}
{"ID": "00050041", "file_name": "Android Malware Scanner", "content": "Postconditions : The selected file is permanently removed from the system and no longer appears in the recent scans list.", "label": "human"}
{"ID": "00050042", "file_name": "Android Malware Scanner", "content": "Actors Involved : User Description : The user selects a previously analyzed file from the recent scans list for further actions such as rescanning or downloading.", "label": "human"}
{"ID": "00050043", "file_name": "Android Malware Scanner", "content": "Postconditions : The selected file is highlighted or marked, enabling the user to proceed with additional operations.2.2.3 Login/Register Use Case Figure 2.4: Use Case Diagram for Task and Project Management ApplicationTheLogin/Register use case allows users to authenticate and manage their ac cess to the system. This use case is decomposed into the following sub-use cases:", "label": "human"}
{"ID": "00050044", "file_name": "Android Malware Scanner", "content": "Login : This sub-use case allows existing users to access the system by enteringtheir credentials, such as username and password. Upon successful authenti cation, users are granted access to the system’s features and data. When the user selects the Login option, they are prompted to enter their username and password. If the credentials are valid, the system grants access and redirects the user to the dashboard.", "label": "human"}
{"ID": "00050045", "file_name": "Android Malware Scanner", "content": "Register : This sub-use case enables new users to create an account in the sys tem. Users provide necessary information such as name, email, password, and other required details to register and gain access to the system. When a new user opts to Register, they must fill out a registration form with their personal details and create a password. Upon successful registration, the system creates a new user account and logs the user in.", "label": "human"}
{"ID": "00050046", "file_name": "Android Malware Scanner", "content": "Logout : This sub-use case allows users to securely log out from the system.Logging out ensures that the user’s session is terminated, and access to the system is revoked until the user logs in again. Users can log out by selecting the Logout option, which securely ends their session and redirects them to the login page.", "label": "human"}
{"ID": "00050047", "file_name": "Android Malware Scanner", "content": "Change Password : This sub-use case allows users to change their currentpassword to a new one. This is essential for maintaining account security, es pecially if a user suspects that their current password has been compromised.", "label": "human"}
{"ID": "00050048", "file_name": "Android Malware Scanner", "content": "When a user selects the Change Password option, they are prompted to en ter their current password for verification, followed by the new password theywish to set. Upon successful validation, the system updates the user’s pass word and confirms the change.", "label": "human"}
{"ID": "00050049", "file_name": "Android Malware Scanner", "content": "View file information Figure 2.5: Use Case Diagram for Task and Project Management Application TheView File Information feature allows users to view detailed information about an uploaded file, including general metadata, security and malware analysis, reconnaissance data, and the ability to generate comprehensive reports. This feature helps users assess the potential risks and overall integrity of the file.", "label": "human"}
{"ID": "00050050", "file_name": "Android Malware Scanner", "content": "View General Information : This sub-use case provides the user with basic metadata and file details about the uploaded file. This information includes the file name, file size, hash values (MD5/SHA1/SHA256), version, packagename, and other essential attributes. This step is important for verifying the authenticity of the file and understanding its general properties.", "label": "human"}
{"ID": "00050051", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view general information about the up loaded file, including its size, hashes, version, and other metadata.", "label": "human"}
{"ID": "00050052", "file_name": "Android Malware Scanner", "content": "Generate Report : This sub-use case enables the user to generate a comprehensive report summarizing the results of the security analysis, malware anal ysis, and general information. The report can be exported in various formats,such as PDF or JSON, for further review or sharing. The user can select spe cific details to include in the report or generate a complete report with all findings.", "label": "human"}
{"ID": "00050053", "file_name": "Android Malware Scanner", "content": "Actors Involved : User – Preconditions : The file must be analyzed, and the user must have access to the analysis results.", "label": "human"}
{"ID": "00050054", "file_name": "Android Malware Scanner", "content": "View Signer Certificate : This sub-use case allows users to examine the dig ital signer certificate associated with the uploaded file. The signer certificate provides important details such as the certificate’s validity, issuer, subject, and associated signatures. Users can use this feature to verify the authenticity and integrity of the file.", "label": "human"}
{"ID": "00050055", "file_name": "Android Malware Scanner", "content": "Actors Involved : User – Preconditions : The file must be uploaded, and the system must extract the signer certificate from the file.", "label": "human"}
{"ID": "00050056", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view the signer certificate details, including validity dates, issuer information, and any issues related to the certificate’s authenticity.", "label": "human"}
{"ID": "00050057", "file_name": "Android Malware Scanner", "content": "View Security Analysis : This sub-use case provides users with detailed re sults of the security analysis conducted on the uploaded file. The securityanalysis examines the file for vulnerabilities, insecure configurations, permis sions issues, and any potential security risks. The user can access a report that highlights specific vulnerabilities, such as insecure permissions or the use of outdated cryptography.", "label": "human"}
{"ID": "00050058", "file_name": "Android Malware Scanner", "content": "Actors Involved : User – Preconditions : The file must be uploaded, and the system must complete the security analysis.", "label": "human"}
{"ID": "00050059", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view the security analysis report, which includes any identified vulnerabilities or issues within the file.", "label": "human"}
{"ID": "00050060", "file_name": "Android Malware Scanner", "content": "View Android API : This sub-use case allows users to view and analyze the Android APIs used by the application under analysis. By examining the APIs, users can gain insight into the app’s behavior, permissions, and functionality, which may assist in identifying any suspicious or malicious activities. This feature helps ensure that all necessary API interactions are properly monitored and understood during dynamic analysis.", "label": "human"}
{"ID": "00050061", "file_name": "Android Malware Scanner", "content": "Actors Involved : User – Preconditions : The application must be uploaded, and the system must have started the analysis process to detect the APIs used by the app.", "label": "human"}
{"ID": "00050062", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view the list of Android APIs utilized by the application, including their associated classes, methods, and permissions.", "label": "human"}
{"ID": "00050063", "file_name": "Android Malware Scanner", "content": "View Malware Analysis : This sub-use case enables the user to view the re-sults of a malware analysis performed on the uploaded file. The system checks the file for known malware signatures and suspicious behavior patterns, such as data exfiltration, unauthorized network communication, or malicious code execution. If any malware is detected, the system generates a report detailing the type of malware and its potential impact.", "label": "human"}
{"ID": "00050064", "file_name": "Android Malware Scanner", "content": "Actors Involved : User– Preconditions : The file must be uploaded and the malware analysis pro cess must be completed.", "label": "human"}
{"ID": "00050065", "file_name": "Android Malware Scanner", "content": "View Browsable Activities : This sub-use case allows users to view a list of browsable activities within the uploaded file. Browsable activities are entry points in the application that can be invoked directly by the user or external entities, such as other apps or the system. Understanding these activities can help assess potential security risks, such as unintended exposure of sensitive features.", "label": "human"}
{"ID": "00050066", "file_name": "Android Malware Scanner", "content": "Actors Involved : User – Preconditions : The file must be uploaded, and the system must extract the activity components from the file’s manifest or metadata.", "label": "human"}
{"ID": "00050067", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view a list of browsable activities, including their names, intents, and any associated security configurations or risks.", "label": "human"}
{"ID": "00050068", "file_name": "Android Malware Scanner", "content": "View Reconnaissance Data : This sub-use case allows the user to view reconnaissance data extracted from the uploaded file. The system provides informa tion about the app’s components, such as its permissions, services, activities, and external communication (network requests, API calls, etc.). This helps users assess the app’s interactions with external services and understand its potential for data leakage or privacy issues.", "label": "human"}
{"ID": "00050069", "file_name": "Android Malware Scanner", "content": "View Permissions : This sub-use case enables users to review the permissions requested or declared by the uploaded file. The permissions provide insightsinto the level of access and control the file seeks over system resources, which can help identify potential privacy or security concerns.", "label": "human"}
{"ID": "00050070", "file_name": "Android Malware Scanner", "content": "Actors Involved : User – Preconditions : The file must be uploaded, and the system must analyze and extract the permissions declared in the file.", "label": "human"}
{"ID": "00050071", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view a detailed list of permissions, including their purpose, criticality, and potential security or privacy implica tions.", "label": "human"}
{"ID": "00050072", "file_name": "Android Malware Scanner", "content": "Android Binary Analysis : This sub-use case focuses on analyzing the binary code of an Android application (APK). The goal of Android Binary Analysis is to uncover any vulnerabilities, reverse-engineer the app to understand itslogic, or identify any malicious behavior present in the application. This pro cess includes extracting, disassembling, and analyzing the APK’s components to gain insights into the app’s behavior, permissions, and potential risks.", "label": "human"}
{"ID": "00050073", "file_name": "Android Malware Scanner", "content": "Actors Involved : User, Static Analysis Tools, Dynamic Analysis Tools – Preconditions : The Android APK file must be uploaded, and the analysis environment (static or dynamic analysis tools) must be set up.", "label": "human"}
{"ID": "00050074", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view a detailed analysis of the APK, in cluding extracted resources, code structures, APIs, permissions, and any identified security issues.", "label": "human"}
{"ID": "00050075", "file_name": "Android Malware Scanner", "content": "Take Screenshot : This sub-use case involves capturing a screenshot of the device or emulator screen during Android analysis. Screenshots are useful for documenting the application’s state, UI behavior, or for visual confirmation of specific test scenarios.", "label": "human"}
{"ID": "00050076", "file_name": "Android Malware Scanner", "content": "A screenshot of the device/emulator screen is captured and saved as an image file on the analysis system.*The user can view and analyze the screenshot for documentation or further investigation.", "label": "human"}
{"ID": "00050077", "file_name": "Android Malware Scanner", "content": "Unset HTTP/HTTPS Proxy : This use case involves removing any HTTP or HTTPS proxy settings configured on an Android device or emulator. This is necessary to ensure that network traffic flows directly without being routed through a proxy, which can interfere with analysis or alter the behavior of applications.", "label": "human"}
{"ID": "00050078", "file_name": "Android Malware Scanner", "content": "Execute ADB/Frida Script : This sub-use case enables the execution of ADB(Android Debug Bridge) commands or Frida scripts within an Android ap plication environment to automate certain tasks, modify the behavior of an app during dynamic analysis, or inject hooks for monitoring the application’s runtime behavior. This can be particularly useful in reverse engineering or penetration testing scenarios.", "label": "human"}
{"ID": "00050079", "file_name": "Android Malware Scanner", "content": "Actors Involved : User, ADB/Frida Tools, Android Device/Emulator – Preconditions : The Android device or emulator must be connected, thetarget application must be running or available for analysis, and the re quired ADB or Frida scripts must be prepared.", "label": "human"}
{"ID": "00050080", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can execute the ADB or Frida script, allowing for dynamic analysis, hooking API functions, intercepting network traffic, or modifying app behavior during runtime.", "label": "human"}
{"ID": "00050081", "file_name": "Android Malware Scanner", "content": "TLS/SSL Security Tester : This sub-use case is designed to test and evaluatethe security of TLS/SSL configurations used by the Android application, es pecially when interacting with web services or APIs. It checks the strength of encryption, certificate validity, and other security parameters that ensure the communication channel is secure against attacks such as man-in-the-middle (MITM) or downgrade attacks.", "label": "human"}
{"ID": "00050082", "file_name": "Android Malware Scanner", "content": "Actors Involved : User, Android Application, Web Service/Server– Preconditions : The Android application must be configured to communicate with web services over TLS/SSL, and the server-side TLS/SSL con figuration must be available for testing.", "label": "human"}
{"ID": "00050083", "file_name": "Android Malware Scanner", "content": "Postconditions : The user is provided with a report on the security posture of the TLS/SSL configuration, including weaknesses, certificate issues, supported protocols, and ciphers.", "label": "human"}
{"ID": "00050084", "file_name": "Android Malware Scanner", "content": "Exported Activity Tester : This sub-use case involves identifying and testing exported activities in an Android application to ensure they are secure and do not expose sensitive functionality to unauthorized entities. Exported activities are components of an Android app that can be accessed by other apps, and improper configurations can lead to security vulnerabilities.", "label": "human"}
{"ID": "00050085", "file_name": "Android Malware Scanner", "content": "Logcat Stream : This sub-use case allows users to capture and view real-time logs generated by an Android device or emulator. These logs provide insights into the behavior of the system and applications, making it a valuable tool for developers, testers, and security analysts.", "label": "human"}
{"ID": "00050086", "file_name": "Android Malware Scanner", "content": "Get File DependenciesThis sub-use case enables users to identify and analyze the dependencies associated with an Android application or library file. Dependency analysis pro vides insights into the external libraries, frameworks, or components the file relies on for functionality.", "label": "human"}
{"ID": "00050087", "file_name": "Android Malware Scanner", "content": "See Smali/Decompiled Code Use Case Figure 2.8: Use Case Diagram for Task and Project Management Application Description : This use case allows users to view the Smali or decompiled sourcecode of an uploaded file. The Smali code represents the intermediate-level representation of the, while the decompiled code provides a higher-level, humanreadable representation (e.g., Java or Kotlin). These functionalities help users un derstand the internal workings of the application, detect malicious behavior, and analyze its structure.", "label": "human"}
{"ID": "00050088", "file_name": "Android Malware Scanner", "content": "Description : This sub-use case allows the user to navigate through the s or sections of the code. The user can scroll, jump to specific methods or classes, or use search functionality to locate particular code fragments.", "label": "human"}
{"ID": "00050089", "file_name": "Android Malware Scanner", "content": "Description : This sub-use case allows the user to select a specific readmode for viewing the code. The user can choose between different pre sentation modes such as raw Smali, decompiled Java/Kotlin code, or a simplified view that highlights key components.", "label": "human"}
{"ID": "00050090", "file_name": "Android Malware Scanner", "content": "The user can switch between different modes as needed.2.2.8 Download FileTheDownload File feature allows users to download various types of files generated during the analysis process. This includes downloading a PDF report con taining detailed analysis results, Smali or decompiled code for further inspection, and screenshots for visual reference. Below are the sub-use cases associated with the Download File functionality.", "label": "human"}
{"ID": "00050091", "file_name": "Android Malware Scanner", "content": "Download PDF Report : This sub-use case enables the user to download a PDF report that summarizes the results of the analysis. The report includes details from the security analysis, malware analysis, general file information, and reconnaissance data. The user can download the PDF for documentation or further examination.", "label": "human"}
{"ID": "00050092", "file_name": "Android Malware Scanner", "content": "Download Smali/Decompiled Code : This sub-use case allows the user todownload the Smali code or decompiled source code of the uploaded file. Af ter analysis, the system decompiles the file to provide the user with the Smali code or Java source code for inspection. This is useful for security researchers or developers who want to review the underlying code of the application.", "label": "human"}
{"ID": "00050093", "file_name": "Android Malware Scanner", "content": "Download Screenshot : This sub-use case enables the user to download a screenshot captured during the analysis process. The system takes screenshots of the file’s behavior during runtime or as it interacts with the system. Thesescreenshots may capture key information such as app screens, suspicious be havior, or other visual evidence of security issues.", "label": "human"}
{"ID": "00050094", "file_name": "Android Malware Scanner", "content": "Actors Involved : User – Preconditions : The file must have been analyzed, and screenshots mustbe available.– Postconditions : The user can download a screenshot that captures rele vant app behavior or security-related visuals.", "label": "human"}
{"ID": "00050095", "file_name": "Android Malware Scanner", "content": "View Dynamic Analysis Report Figure 2.9: Use Case Diagram for Task and Project Management Application TheAPI Monitor functionality allows users to monitor and log all API callsmade by the uploaded Android application during runtime. This includes track ing system APIs, third-party library calls, network requests, and any other relevantinteractions. The user can view detailed logs of each API call, monitor its param eters, and assess whether any API calls are suspicious or malicious. Below are the sub-use cases associated with the API Monitor functionality.", "label": "human"}
{"ID": "00050096", "file_name": "Android Malware Scanner", "content": "View Dynamic Analysis Report : This sub-use case enables the user to re view the results of a dynamic analysis conducted on the uploaded Android application. The dynamic analysis observes the application’s behavior during execution, capturing details such as API calls, network requests, file systeminteractions, and permission usage. The user can view a comprehensive re port highlighting significant actions performed by the application, potentialsecurity risks, and suspicious activities. This functionality aids in identify ing runtime vulnerabilities and understanding the application’s impact on the system.– Actors Involved : User – Preconditions : The file must be uploaded, and the anroid instance must be run.", "label": "human"}
{"ID": "00050097", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view a detailed dynamic analysis report, in cluding runtime behaviors, API interactions, and potential security risks.", "label": "human"}
{"ID": "00050098", "file_name": "Android Malware Scanner", "content": "TLS/SSL Security Tester : This sub-use case allows the user to evaluate the security of TLS/SSL configurations in the uploaded Android application. The system analyzes the application to identify its usage of TLS/SSL protocols, certificate validation processes, and encryption mechanisms. It also checksfor vulnerabilities such as weak ciphers, outdated protocols, and improper cer tificate validation, which could expose the application to man-in-the-middle (MITM) attacks or data breaches.", "label": "human"}
{"ID": "00050099", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view a report on the application’s TLS/SSLimplementation, including potential vulnerabilities, insecure configura tions, and recommendations for strengthening security.", "label": "human"}
{"ID": "00050100", "file_name": "Android Malware Scanner", "content": "Log Suspicious API Calls : This sub-use case logs suspicious API calls that may indicate malicious behavior or security vulnerabilities. The system tracksAPI calls that access sensitive data, request unnecessary permissions, or exhibit unusual behavior (such as excessive network calls or unknown thirdparty API requests). The user can review these suspicious calls and take ap propriate action.", "label": "human"}
{"ID": "00050101", "file_name": "Android Malware Scanner", "content": "Postconditions : The user is alerted to or can view suspicious API calls that may represent malicious activity or vulnerabilities.", "label": "human"}
{"ID": "00050102", "file_name": "Android Malware Scanner", "content": "View API Call Details : This sub-use case allows the user to view detailed information about a specific API call, such as its arguments, return values, execution time, and associated network requests. The user can analyze these details to determine whether the API call is functioning as expected or if there are security concerns associated with it.– Actors Involved : User – Preconditions : The file must be analyzed, and the app must be executing for API call tracking to be active.", "label": "human"}
{"ID": "00050103", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can view detailed information about individual API calls, including any potential security issues or abnormal behavior.", "label": "human"}
{"ID": "00050104", "file_name": "Android Malware Scanner", "content": "Generate API Logs Report : This sub-use case allows the user to generate a report summarizing all monitored API calls, including network requests and suspicious activities. The report can be downloaded in various formats, such as PDF or JSON, for further analysis or sharing with colleagues.", "label": "human"}
{"ID": "00050105", "file_name": "Android Malware Scanner", "content": "Postconditions : The user can generate and download a report summariz ing all the tracked API calls and network interactions.", "label": "human"}
{"ID": "00050106", "file_name": "Android Malware Scanner", "content": "Purpose : Allow the admin to create new users for the system, assigning roles and access permissions as necessary.2.2.11 Delete User Actors Involved : Admin Preconditions :", "label": "human"}
{"ID": "00050107", "file_name": "Android Malware Scanner", "content": "Purpose : Provide the admin with a clear overview of all users and their roles,enabling effective user management.This chapter introduces the technologies and platforms utilized in the project management and task management application. Each technology is analyzed in the context of how it addresses the specific problems or requirements identified.", "label": "human"}
{"ID": "00050108", "file_name": "Android Malware Scanner", "content": "Bootstrap : Simplifies the design of the frontend interface with its prebuilt responsive components, ensuring a consistent and user-friendly experience across devices.", "label": "human"}
{"ID": "00050109", "file_name": "Android Malware Scanner", "content": "Django : Serves as the primary backend framework, handling routing, database interactions, and API endpoints. Django’s scalability and modular structure make it suitable for building complex web applications.", "label": "human"}
{"ID": "00050110", "file_name": "Android Malware Scanner", "content": "SQLite3 : Provides a lightweight and efficient database solution for storing analysis results, user data, and application configurations. Its simplicity andfile-based storage are well-suited for development and small-scale deploy ment.", "label": "human"}
{"ID": "00050111", "file_name": "Android Malware Scanner", "content": "ADB (Android Debug Bridge) : Enables communication with Android de vices, supporting tasks like app installation, debugging, and runtime behaviormonitoring.", "label": "human"}
{"ID": "00050112", "file_name": "Android Malware Scanner", "content": "First I check the validity of the provided checksum (MD5 hash) and whether the file exists in the database ( RecentScanResult ).", "label": "human"}
{"ID": "00050113", "file_name": "Android Malware Scanner", "content": "Certificate Information: Extracts certificate information (hardcoded certificates or keystore).*Code Analysis: The app’s code is analyzed using tools like apkid_analysis , code_analysis , andbehaviour_analysis .", "label": "human"}
{"ID": "00050114", "file_name": "Android Malware Scanner", "content": "Malware Detection: The static analyzer checks the app for malwarerelated indicators, such as suspicious permissions, domains, and other be havior that might point to malicious intent.", "label": "human"}
{"ID": "00050115", "file_name": "Android Malware Scanner", "content": "Firebase and Domain Check: The app is also analyzed for Firebase us age, and any domains extracted from the app are checked for malware using MalwareDomainCheck .", "label": "human"}
{"ID": "00050116", "file_name": "Android Malware Scanner", "content": "Saving Results to Database: After the analysis, the results are saved in the database ( StaticAnalyzer ), including detailed information about the app’s permissions, code, libraries, certificates, and other aspects.", "label": "human"}
{"ID": "00050117", "file_name": "Android Malware Scanner", "content": "Reporting: The analysis results are either returned as a JSON object (for API requests) or rendered on a template for web-based display.", "label": "human"}
{"ID": "00050118", "file_name": "Android Malware Scanner", "content": "Signer Certificate The method for analyzing and verifying a signer’s certificate involves several steps to ensure the validity and integrity of the certificate and the signing process.", "label": "human"}
{"ID": "00050119", "file_name": "Android Malware Scanner", "content": "Debug Certificate: Check if the certificate contains CN=Android De bug. If true, the APK is using a debug certificate, which is insecure for production.", "label": "human"}
{"ID": "00050120", "file_name": "Android Malware Scanner", "content": "Input/OutputInput: The analysis starts with the input of a signed file (e.g., an APK, exe cutable, or document) and its associated certificate. The certificate typically contains the public key used to verify the authenticity of the signer.", "label": "human"}
{"ID": "00050121", "file_name": "Android Malware Scanner", "content": "Trust Chain Status: Information about whether the certificate was issued by a trusted CA and whether the trust chain is intact.3.3.3 Permissions The methodology for analyzing application permissions focuses on identifying and categorizing permissions requested by the application, followed by comparing them to predefined lists of potentially dangerous or suspicious permissions.", "label": "human"}
{"ID": "00050122", "file_name": "Android Malware Scanner", "content": "Top Malware Permissions: TOP_MALWARE_PERMISSIONS is a list of permissions that are often abused by malware. These permissions can grant access to sensitive data or allow potentially harmful actions. Some of these permissions include:", "label": "human"}
{"ID": "00050123", "file_name": "Android Malware Scanner", "content": "android.permission.ACCESS_COARSE_LOCATION *android.permission.SEND_SMS *android.permission.READ_SMS *android.permission.RECORD_AUDIO *android.permission.READ_CONTACTS *android.permission.WRITE_EXTERNAL_STORAGE– Other Abused Permissions: OTHER_PERMISSIONS is a list of permis sions that can also be abused in certain contexts, although they may not always be inherently malicious. Examples include:", "label": "human"}
{"ID": "00050124", "file_name": "Android Malware Scanner", "content": "checksum : A unique identifier (e.g., hash) for the APK being analyzed.·perms : A list of permissions extracted from the APK.", "label": "human"}
{"ID": "00050125", "file_name": "Android Malware Scanner", "content": "top\\_malware_permissions: [’android.permission.READ\\_SMS’, ’android.permission.SEND\\_SMS’], ’other\\_abused\\_permissions’: [’android.permission.BLUETOOTH’, ’android.permission.ACCESS\\_BACKGROUND\\_LOCATION’], ’total\\_malware\\_permissions’: 24, ’total\\_other\\_permissions’: 42 b, Input/Output Input: The analysis starts with two key pieces of input:", "label": "human"}
{"ID": "00050126", "file_name": "Android Malware Scanner", "content": "Output: The analysis concludes by logging the successful completion of the permission review and generating a detailed report that includes:–The list of risky permissions identified.", "label": "human"}
{"ID": "00050127", "file_name": "Android Malware Scanner", "content": "View browsable activities The methodology for identifying browsable activities in an Android application involves scanning the AndroidManifest.xml file to find activities that have intent filters which allow external apps or web content to invoke them.", "label": "human"}
{"ID": "00050128", "file_name": "Android Malware Scanner", "content": "MethodlogyIdentifying Browsable Activities: Browsable activities are identified by look ing for <intent-filter> elements within the manifest file which is apart of uploaded file that include an <action> tag with the value an droid.intent.action.VIEW . These are the activities that can be launched by external intents, such as web links or external apps.", "label": "human"}
{"ID": "00050129", "file_name": "Android Malware Scanner", "content": "Analyzing Intent Filters: For each activity in the manifest, the tool checks whether it has any <intent-filter> elements with the android.intent.action.VIEW action. It also checks for:", "label": "human"}
{"ID": "00050130", "file_name": "Android Malware Scanner", "content": "Flagging Potentially Dangerous Activities: If an activity is found to be brows able (i.e., has an intent filter with android.intent.action.VIEW ), the method evaluates the activity for potential security risks, such as:", "label": "human"}
{"ID": "00050131", "file_name": "Android Malware Scanner", "content": "Unrestricted Intent Filters: Activities that accept any URL or are too permissive in the paths they support, making them vulnerable to arbitrary external input.", "label": "human"}
{"ID": "00050132", "file_name": "Android Malware Scanner", "content": "Sensitive Data Exposure: If the activity allows access to sensitive data, such as user information or system resources, based on the external URL.", "label": "human"}
{"ID": "00050133", "file_name": "Android Malware Scanner", "content": "Vulnerabilities: If the activity could be exploited for injection or other attacks due to improper input handling, it is considered a high-risk activity.", "label": "human"}
{"ID": "00050134", "file_name": "Android Malware Scanner", "content": "Input/Output Input: The method accepts the application’s AndroidManifest.xml file,which contains the definitions for all components, including activities, ser vices, and content providers.", "label": "human"}
{"ID": "00050135", "file_name": "Android Malware Scanner", "content": "Reconnaissance The methodology for recognizing sensitive information within an application’s code or configuration files involves scanning the application’s files for patterns indicative of sensitive data.", "label": "human"}
{"ID": "00050136", "file_name": "Android Malware Scanner", "content": "MethodlogyPattern Recognition: The method uses predefined patterns (regular expres sions) to identify potentially sensitive data within the file uploaded. Thesepatterns can include:", "label": "human"}
{"ID": "00050137", "file_name": "Android Malware Scanner", "content": "API keys and tokens: Typically identified by certain prefixes or lengths that are unique to the API provider (e.g., AIzaSy... for Google API keys).", "label": "human"}
{"ID": "00050138", "file_name": "Android Malware Scanner", "content": "For email addresses, the method checks if the pattern appears in placeswhere they would be used, such as in user authentication or communica tion modules.", "label": "human"}
{"ID": "00050139", "file_name": "Android Malware Scanner", "content": "For API keys and tokens, the method cross-checks the context in whichthey are used, ensuring they are not part of debug information or hard coded in ways that could lead to leakage.", "label": "human"}
{"ID": "00050140", "file_name": "Android Malware Scanner", "content": "A set of regular expressions or patterns designed to detect sensitive in formation, such as email addresses, API keys, authentication tokens, and passwords.", "label": "human"}
{"ID": "00050141", "file_name": "Android Malware Scanner", "content": "A risk assessment based on the type and visibility of the sensitive in formation (e.g., high risk for exposed API keys, medium risk for email addresses).", "label": "human"}
{"ID": "00050142", "file_name": "Android Malware Scanner", "content": "Security Analysis The Security Analysis process focuses on identifying potential vulnerabilities in an Android application by scanning its codebase and configurations. It includes tasks like checking for common security flaws such as SQL injection, improper data handling, or hardcoded sensitive information. The analysis also checks for issues with third-party libraries, insecure API usage, and weak encryption methods.", "label": "human"}
{"ID": "00050143", "file_name": "Android Malware Scanner", "content": "This helps ensure the application follows best security practices and reduces the risk of attacks.Figure 3.1: Security Analysis a, Network Security The objective of network security analysis is to evaluate the safety of networkcommunications used by the file uploaded. This analysis focuses on checking com pliance with secure protocols such as HTTPS and TLS, detecting vulnerabilities like unencrypted data transmission, hardcoded keys, or insecure API endpoints.1. Methodology Configuration Retrieval :", "label": "human"}
{"ID": "00050144", "file_name": "Android Malware Scanner", "content": "It checks the source type to determine if the file is in Android Studio source files or the APK uploaded processed by ‘apktool‘.", "label": "human"}
{"ID": "00050145", "file_name": "Android Malware Scanner", "content": "config (str): The name of the network security configuration file to analyze. If the file name is not provided, the function attempts to find a default network security configuration file.", "label": "human"}
{"ID": "00050146", "file_name": "Android Malware Scanner", "content": "src_type (bool): A flag indicating whether the source is Android Studio project files ( True ) or an APK file ( False ).", "label": "human"}
{"ID": "00050147", "file_name": "Android Malware Scanner", "content": "network_summary : A summary of the findings, with counts of is sues categorized by severity (e.g., high ,warning ,secure ).", "label": "human"}
{"ID": "00050148", "file_name": "Android Malware Scanner", "content": "Certificate AnalysisDigital certificates are crucial for ensuring the security of network communi cations. This analysis aims to verify the validity and trustworthiness of SSL/TLScertificates used by the application. It includes checking for self-signed certificates, expired certificates, and ensuring proper certificate pinning. Misconfigura tions that may lead to vulnerabilities like SSL stripping are also analyzed.", "label": "human"}
{"ID": "00050149", "file_name": "Android Malware Scanner", "content": "Methodology Extracting Certificate Data: Log the error and display a message withthe –First, extract the APK using a tool like apktool orunzip .", "label": "human"}
{"ID": "00050150", "file_name": "Android Malware Scanner", "content": "Use a library or tool such as apksigtool to extract certificate data, including the public key, signature algorithm, and hash algorithm.", "label": "human"}
{"ID": "00050151", "file_name": "Android Malware Scanner", "content": "apksigner verify –verbose <apk_file> –Check for the presence of signature versions (e.g., v1, v2, v3, v4) and ensure that secure signing algorithms (e.g., SHA-256) are used.", "label": "human"}
{"ID": "00050152", "file_name": "Android Malware Scanner", "content": "Ensure that the app is signed using secure certificates and not a de bug certificate, which is often used in development but should not be present in production apps.", "label": "human"}
{"ID": "00050153", "file_name": "Android Malware Scanner", "content": "Manifest Analysis The analysis of the AndroidManifest.xml file focuses on examining the permissions requested by the application, as well as its activities, services, and other components. The objective is to ensure that the requested permissions align with the application’s functionality and that no permissions are overprivileged or abused.", "label": "human"}
{"ID": "00050154", "file_name": "Android Malware Scanner", "content": "MethodologyRetrieve Manifest File: The manifest file is extracted from the file uploaded. This involves parsing the APK structure to locate the MANI FEST.MF file, which holds crucial metadata about the app.", "label": "human"}
{"ID": "00050155", "file_name": "Android Malware Scanner", "content": "Parse Manifest Data: Once the manifest file is obtained, the system parses the contents to extract key information, such as:", "label": "human"}
{"ID": "00050156", "file_name": "Android Malware Scanner", "content": "Input/Ouput Input Takes the checksum of the application, the application path, and the manifest data extracted from the file. The manifest data typically includes information about the app’s permissions, components, and configurations.", "label": "human"}
{"ID": "00050157", "file_name": "Android Malware Scanner", "content": "Completion Logs the successful completion of the manifest analysis andreturns the findings, which include details about permissions, compo nents, and any security risks identified.", "label": "human"}
{"ID": "00050158", "file_name": "Android Malware Scanner", "content": "This includes reviewing the use of insecure APIs, programming errors, hardcoded secrets, and other anomalous behaviors. The analysis can be conducted on source code or compiled binaries.", "label": "human"}
{"ID": "00050159", "file_name": "Android Malware Scanner", "content": "It checks the source type to determine if the file is in Android Studio source files or an APK processed by ‘apktool‘.", "label": "human"}
{"ID": "00050160", "file_name": "Android Malware Scanner", "content": "Findings are collected with descriptions, severity levels, and scope (which domains or certificates are affected).–A summary tracks the number of findings in each severity category:", "label": "human"}
{"ID": "00050161", "file_name": "Android Malware Scanner", "content": "API Analysis Results: Results from analyzing the APIs used by the application, highlighting any security risks associated with their usage.", "label": "human"}
{"ID": "00050162", "file_name": "Android Malware Scanner", "content": "NIAP Scan Findings: Security compliance findings based on the NIAP (National Information Assurance Partnership) guides.*URLs and Emails Extracted: A list of extracted URLs and emailaddresses found in the code, which may pose security risks if hard coded.", "label": "human"}
{"ID": "00050163", "file_name": "Android Malware Scanner", "content": "Structured Report: A comprehensive, structured report combin ing all the findings from the different analysis phases. This report includes severity levels, actionable insights, and a summary of the application’s security posture.", "label": "human"}
{"ID": "00050164", "file_name": "Android Malware Scanner", "content": "NIAP Analysis The analysis based on the National Information Assurance Partnership (NIAP) standards evaluates the application against specific guides and requirements.", "label": "human"}
{"ID": "00050165", "file_name": "Android Malware Scanner", "content": "If the scan returns results and contains a ‘choice_matcher‘ key, the value of ‘choice_matcher‘ is returned, which likely contains the scan findings.", "label": "human"}
{"ID": "00050166", "file_name": "Android Malware Scanner", "content": "If an exception occurs during any of the scanning steps, the error is loggedwith ‘logger.exception(msg)‘, and the scan status is updated with the ex ception details.", "label": "human"}
{"ID": "00050167", "file_name": "Android Malware Scanner", "content": "Input/Output Input Takes the checksum of the application, rule set, file extensions to analyze, paths to scan, and optionally the paths to ignore. It also takes an apath parameter which specifies an alternative path if necessary.", "label": "human"}
{"ID": "00050168", "file_name": "Android Malware Scanner", "content": "Firebase AnalysisFirebase is often used as a backend for mobile applications. This analysis exam ines Firebase configurations, such as database security, user authentication setups, and related APIs. The goal is to ensure that no vulnerabilities exist in the storage and handling of user data.", "label": "human"}
{"ID": "00050169", "file_name": "Android Malware Scanner", "content": "The analysis searches for Firebase-related URLs in the app’s source code, specifically URLs containing the domain firebaseio.com , which are Firebase Database URLs.", "label": "human"}
{"ID": "00050170", "file_name": "Android Malware Scanner", "content": "For each Firebase URL found, the system checks whether the Firebasedatabase is open and accessible over the internet without authentica tion.", "label": "human"}
{"ID": "00050171", "file_name": "Android Malware Scanner", "content": "The analysis continues to check whether the Firebase Remote Configfeature is enabled for the app. This involves verifying Firebase config uration information via the API.", "label": "human"}
{"ID": "00050172", "file_name": "Android Malware Scanner", "content": "If Remote Config is enabled, the system checks whether the configura tions contain sensitive information. If they do, a warning-level finding is recorded.", "label": "human"}
{"ID": "00050173", "file_name": "Android Malware Scanner", "content": "After completing the checks for both Firebase Database and Firebase Remote Config, all findings are compiled and categorized by severity.", "label": "human"}
{"ID": "00050174", "file_name": "Android Malware Scanner", "content": "The results are returned as a list of findings, each with a detailed de scription of the issue, severity level, and any additional information if applicable.•Input/Output – Input Takes the checksum of the application and the application’s analysis dictionary. It also requires access to the app’s URL list and credentials related to Firebase (such as google_api_key andgoogle_app_id ).", "label": "human"}
{"ID": "00050175", "file_name": "Android Malware Scanner", "content": "Malware Analysis Malware Analysis in the context of Android applications involves examining an app for malicious behavior and threats. This includes identifying harmful code, such as spyware, trojans, or adware, and analyzing the app’s permissions, API calls, and network communications to detect unusual or suspicious activity. Static and dynamic analysis techniques are used to uncover hidden malware signatures,analyze behaviors in a controlled environment, and check for exploitative vulnera bilities. The goal is to ensure the app does not compromise user security or privacy and to identify potential threats before deployment.Figure 3.2: Malware Analysis a, APKiD Analysis The objective of APKiD analysis is to detect signs of obfuscation, packing, or the use of unusual frameworks in the APK file. This helps identify if the application is intentionally hiding its code or employing unclear methods to evade analysis.", "label": "human"}
{"ID": "00050176", "file_name": "Android Malware Scanner", "content": "If enabled, the APKID module is imported. If the module is missing, an error is logged and the scan status is updated.", "label": "human"}
{"ID": "00050177", "file_name": "Android Malware Scanner", "content": "If the necessary dependencies for analysis (e.g., yara-python) are miss ing or if an issue occurs, the process handles the error gracefully and logs the failure.", "label": "human"}
{"ID": "00050178", "file_name": "Android Malware Scanner", "content": "Any file paths that include extraneous details (e.g., paths with a ‘!‘ symbol) are cleaned up to retain only the relevant filenames.", "label": "human"}
{"ID": "00050179", "file_name": "Android Malware Scanner", "content": "The final results are organized into a dictionary, where the filename serves as the key and the detected matches are stored as the value.", "label": "human"}
{"ID": "00050180", "file_name": "Android Malware Scanner", "content": "Behavioral AnalysisBehavioral analysis examines the runtime behavior of the application in a sand box or test device environment to identify suspicious activities. These behaviors may include sending user data to unknown servers, unauthorized access to system resources, or other malicious actions. Key aspects include:", "label": "human"}
{"ID": "00050181", "file_name": "Android Malware Scanner", "content": "The behavior rules file is located and the relevant Android source di rectory is identified using the provided application directory.", "label": "human"}
{"ID": "00050182", "file_name": "Android Malware Scanner", "content": "A message indicating the start of Android Behavior Analysis is logged.–The current status of the scan is updated by appending the log message to the scan status.", "label": "human"}
{"ID": "00050183", "file_name": "Android Malware Scanner", "content": "Input/OutputInput Takes the checksum of the application, the directory path contain ing the application’s source code, and the type of the application (e.g., Android application type).", "label": "human"}
{"ID": "00050184", "file_name": "Android Malware Scanner", "content": "Abused Permission This analysis evaluates the permissions requested by the application to identify any unnecessary or abused permissions. The goal is to ensure that the permissions requested align with the app’s functionality. Key aspects include:", "label": "human"}
{"ID": "00050185", "file_name": "Android Malware Scanner", "content": "Domain Malware CheckThis analysis checks the domains the application communicates with to deter mine if they are blacklisted or associated with malicious activities. Key aspects include:", "label": "human"}
{"ID": "00050186", "file_name": "Android Malware Scanner", "content": "It uses the IP2Location library to get geolocation data and checks if the domain is located in countries or regions under sanction (e.g., OFAC list).", "label": "human"}
{"ID": "00050187", "file_name": "Android Malware Scanner", "content": "Themalware_check method reads a list of known malware do mains and compares it with the domains extracted from the URLs.", "label": "human"}
{"ID": "00050188", "file_name": "Android Malware Scanner", "content": "Themaltrail_check method reads a separate list of malicious domains from the Maltrail database and checks if any of the extracted domains match the entries.", "label": "human"}
{"ID": "00050189", "file_name": "Android Malware Scanner", "content": "The domains are then extracted and analyzed using the methods described above (update, malware check, maltrail check, and geoloca tion).", "label": "human"}
{"ID": "00050190", "file_name": "Android Malware Scanner", "content": "How I dynamically emulated the Anroid app? a, Set up the Android Emulator or Genymotion First, you need to have an emulator running the application you want to test or analyze. You can use Android Studio’s built-in emulator or Genymotion as an alternative.", "label": "human"}
{"ID": "00050191", "file_name": "Android Malware Scanner", "content": "From the AVD Manager , select the virtual device and click on the green Play button to start the emulator.", "label": "human"}
{"ID": "00050192", "file_name": "Android Malware Scanner", "content": "Connect to the Emulator via ADB Once the emulator or Genymotion instance is running, you can interact with it using ADB commands.", "label": "human"}
{"ID": "00050193", "file_name": "Android Malware Scanner", "content": "Get ADB path and excute command by python: In my project, i will get theadb path by the environment variable or it can be set through the file set tings.py Start the ADB server:", "label": "human"}
{"ID": "00050194", "file_name": "Android Malware Scanner", "content": "I extracting parameters, such as reinstall andinstall , from the request. The values are obtained using either request.POST for API calls or request.GET for web requests.", "label": "human"}
{"ID": "00050195", "file_name": "Android Malware Scanner", "content": "A check is made to validate the checksum parameter using the is_md5() function to ensure it’s a valid MD5 hash.", "label": "human"}
{"ID": "00050196", "file_name": "Android Malware Scanner", "content": "The exported activities, regular activities, and deeplinks are retrieved from the database, if available. If no static analysis data is found, a warning is logged.", "label": "human"}
{"ID": "00050197", "file_name": "Android Malware Scanner", "content": "The function checks if the Android version is compatible with the envi ronment. If the version is outdated or unsupported, it initiates the Alyzing process using env.alyzy_init() .", "label": "human"}
{"ID": "00050198", "file_name": "Android Malware Scanner", "content": "If the install parameter is set to 1, the APK corresponding to the checksum is installed on the device using env.install_apk() .", "label": "human"}
{"ID": "00050199", "file_name": "Android Malware Scanner", "content": "A response context is prepared containing details about the package, hash, Android version, and other relevant information.3.4.3 Logcat Stream TheLogcatStream method provides a way to capture and analyze Android log messages in real-time. The following steps out the approach:", "label": "human"}
{"ID": "00050200", "file_name": "Android Malware Scanner", "content": "It creates a new process group gand runs the adb logcat com mand to stream logs for the given package.", "label": "human"}
{"ID": "00050201", "file_name": "Android Malware Scanner", "content": "A helper function read_process is used to read the output of the Logcat process.–It reads the s of the Logcat output and yields them as events in the format data: <log line> .", "label": "human"}
{"ID": "00050202", "file_name": "Android Malware Scanner", "content": "The method returns a StreamingHttpResponse to stream thelogs to the client in real-time, with the content type set to text/event stream .", "label": "human"}
{"ID": "00050203", "file_name": "Android Malware Scanner", "content": "Intercept and Modify Application Behavior: Frida allows dynamic analysis by intercepting method calls, modifying parameters, and observing the app’sruntime behavior. This is essential for understanding how the application inter acts with sensitive data or APIs, and for identifying potential security issues, such as hardcoded credentials, improper data handling, or malicious actions.", "label": "human"}
{"ID": "00050204", "file_name": "Android Malware Scanner", "content": "API Hooking: By hooking into specific functions or API calls, Frida can monitor how the app interacts with system services, such as networking, filesystem, or cryptographic functions. This helps detect interactions with sensi tive APIs that could indicate malicious behavior, such as unauthorized data access or information exfiltration.", "label": "human"}
{"ID": "00050205", "file_name": "Android Malware Scanner", "content": "Dynamic Runtime Analysis: Frida enables the inspection of app behavior while it is running. This includes observing dynamically loaded classes, func-tions, and methods, providing valuable insights into how different components interact in real-time. This is crucial for detecting issues that may not be visible through static code analysis.", "label": "human"}
{"ID": "00050206", "file_name": "Android Malware Scanner", "content": "Manipulate Application Inputs and Outputs: Analysts can modify or inject inputs into the application to test its response to specific scenarios. This is particularly useful for identifying vulnerabilities related to input validation, such as buffer overflows or improper error handling.", "label": "human"}
{"ID": "00050207", "file_name": "Android Malware Scanner", "content": "Monitor Data Flow and Communication: Frida allows the monitoring of data exchanges between the application and external resources (e.g., databases, APIs, or cloud services). This is important for detecting potential data leaks, unauthorized data transmissions, or communication with malicious servers.", "label": "human"}
{"ID": "00050208", "file_name": "Android Malware Scanner", "content": "Bypass Security Mechanisms: Many Android apps implement security mech anisms such as root detection, anti-debugging, or encryption. Frida can helpbypass these protections by manipulating the app’s runtime environment, en abling more thorough inspection and testing.", "label": "human"}
{"ID": "00050209", "file_name": "Android Malware Scanner", "content": "For each script, it constructs the file path in frida_scripts/android/others .–If the script file exists and the path is safe (no path traversal), it reads the file content.", "label": "human"}
{"ID": "00050210", "file_name": "Android Malware Scanner", "content": "Input/Output Input Accepts the APK directory, MD5 hash, and package name of theapplication. It uses these to gather dynamic logs, clipboard data, and re lated files.•Output Generates a structured report containing:", "label": "human"}
{"ID": "00050211", "file_name": "Android Malware Scanner", "content": "Exported Activity Tester TheExported Activity Tester identify potentially insecure activities within an Android application. Activities in Android apps are components that define a single screen with a user interface. Some activities, if improperly configured, may expose sensitive functionality or information to malicious actors. This tester focuses on identifying activities that are exported and accessible by other applications or users.", "label": "human"}
{"ID": "00050212", "file_name": "Android Malware Scanner", "content": "Anexported activity refers to an activity that is declared with the exported attribute set to true in the application’s manifest file. This makes the activity accessible to other apps or external entities, which can invoke it, potentially leading to unauthorized access, privilege escalation, or other vulnerabilities.", "label": "human"}
{"ID": "00050213", "file_name": "Android Malware Scanner", "content": "Purpose of the Exported Activity TesterThe main goal of the exported activity tester is to identify activities that are unin tentionally exposed to external applications. These activities could allow malicious apps to interact with the target app’s internal components, potentially causing the following issues:", "label": "human"}
{"ID": "00050214", "file_name": "Android Malware Scanner", "content": "MethodologyManifest Inspection: The first step is to parse the app’s AndroidMan ifest.xml file to identify activities with the exported attribute set totrue .", "label": "human"}
{"ID": "00050215", "file_name": "Android Malware Scanner", "content": "Activity Invocation: Once exported activities are identified, the tester attempts to invoke these activities using intents, with a focus on those that could lead to unintended behavior or security risks.", "label": "human"}
{"ID": "00050216", "file_name": "Android Malware Scanner", "content": "Permissions Check: The tester checks the permissions required to invoke the exported activities, identifying cases where weak or missing permis-sion checks could allow unauthorized access.", "label": "human"}
{"ID": "00050217", "file_name": "Android Malware Scanner", "content": "Analysis of Behavior: The tester analyzes the behavior of the invoked exported activities to detect any abnormal or insecure behavior, such as leaking sensitive data, improper access control, or unintended side effects.", "label": "human"}
{"ID": "00050218", "file_name": "Android Malware Scanner", "content": "Unset HTTP ProxyIn Android analysis, especially during network traffic analysis or malware re verse engineering, the device or emulator may be configured to route traffic through an HTTP proxy to capture requests and responses. However, there are situations where unsetting the HTTP proxy is essential for a proper analysis or to ensure that network traffic is not interfered with by any external tools or proxies.", "label": "human"}
{"ID": "00050219", "file_name": "Android Malware Scanner", "content": "The proxy might be altering network traffic in ways that are undesirable, such as injecting additional data or modifying request headers.", "label": "human"}
{"ID": "00050220", "file_name": "Android Malware Scanner", "content": "Methodology – Manual Method: Navigate to the device’s Wi-Fi settings, select thenetwork, and choose \"Proxy\" to set it to \"None\" or remove any pre configured proxy settings.", "label": "human"}
{"ID": "00050221", "file_name": "Android Malware Scanner", "content": "Programmatic Method: Use the setHttpProxy method in the Android API to programmatically unset the proxy. This might be donewithin an application or script designed to reset network configurations during dynamic analysis.– Command Line: On rooted devices or emulators, the unset com mand in the terminal can be used to remove the proxy environment variables:", "label": "human"}
{"ID": "00050222", "file_name": "Android Malware Scanner", "content": "unset http_proxy unset https_proxy Conclusion Unsetting the HTTP proxy in Android analysis is an importantstep to ensure accurate and unmodified data flows when conducting tests, especially in network-based analysis or when evaluating the behavior of ma licious applications. It helps analysts avoid potential issues related to proxy interference and provides a cleaner environment for analysis.4.1 Software Architecture Design 4.1.1 Modular Design The system is divided into distinct modules or components, each responsible for specific functionalities:", "label": "human"}
{"ID": "00050223", "file_name": "Android Malware Scanner", "content": "Data Layer : Responsible for input/output operations, such as reading logs, fetching files, and extracting metadata. Examples include get_log_data , get_app_files , andextract_urls_domains_emails .", "label": "human"}
{"ID": "00050224", "file_name": "Android Malware Scanner", "content": "Processing/Business Logic Layer : Contains the core logic for analyzing data, running scanners, and extracting meaningful information. Examples include run_analysis andniap_scan .", "label": "human"}
{"ID": "00050225", "file_name": "Android Malware Scanner", "content": "Timeouts and Performance : Operations use timeout settings (e.g., set tings.SAST_TIMEOUT ) to prevent resource overuse.a, Asynchronous and Parallel Design Asynchronous workflows are supported using mechanisms such as run_with_timeout .", "label": "human"}
{"ID": "00050226", "file_name": "Android Malware Scanner", "content": "Benefits of the Architecture Scalability : The modular design allows easy addition of new analysis types or extension of existing functionalities.", "label": "human"}
{"ID": "00050227", "file_name": "Android Malware Scanner", "content": "User interface design Resolution: 1080x1920 (Full HD) Screen Size: 5.5 inches Color Depth: 16 million colors (24-bit) Aspect Ratio: 16:9 Refresh Rate: 60Hz Pixels Per Inch (PPI): 400 PPI Supported Display Modes: Portrait, Landscape4.2.2 Web Interface Figure 4.1: Main page The page layout is divided into several sections, each responsible for different parts of the user interface. The major sections are:", "label": "human"}
{"ID": "00050228", "file_name": "Android Malware Scanner", "content": "Navigation Bar: Contains links to various parts of the application, such as SCANS, DYNAMIC ANALYZER, and user account management options.", "label": "human"}
{"ID": "00050229", "file_name": "Android Malware Scanner", "content": "Detailed Description The HTML file uses several Django template tags for dynamic content, such as loading user information and scan data. Below is a detailed breakdown of each section:", "label": "human"}
{"ID": "00050230", "file_name": "Android Malware Scanner", "content": "Section Description Navigation Bar Contains navigation links to \"SCANS\", \"DYNAMIC ANALYZER\", and user account options. If the user is authenticated, a dropdown menu with user details and management options is displayed.", "label": "human"}
{"ID": "00050231", "file_name": "Android Malware Scanner", "content": "File Upload Section Users can either drag and drop a file or click the upload button to choose a file. The file input allows multiple files to be uploaded. There is a progress bar that updates the user on the upload progress. The section also includes a small instruction text for drag-and-drop.", "label": "human"}
{"ID": "00050232", "file_name": "Android Malware Scanner", "content": "Footer The footer includes links to the recent scans and dynamic analyzer sections. It also displays a copyright message with the current year. Additionally, a message appears informing the user that the analysis has started, and a download input field is provided for scanning packages.Figure 4.2: Theme for Dynamic Analysis Page This interface is the starting page of Dynamic Analysis, it has a button that let us go into the main page Figure 4.3: Theme for Static Analyzer page This interface is the screen of Static Analysis page, it has all general information that can help us to explore about the analyzed file Side Bar It has some fields that help user to explore each field:", "label": "human"}
{"ID": "00050233", "file_name": "Android Malware Scanner", "content": "Rescan: Rescan the file and see if there’s some field that didn’t explored yet –Manage suppression: Change or view the suppression of the file –Start dynamic analysis: Button that help us to start on dynamic analyzing–Scan logs: View the logs generated in the scanning process Signer Certificate: Check if the binary is signed, as well as some information like hash, md5, etc,....", "label": "human"}
{"ID": "00050234", "file_name": "Android Malware Scanner", "content": "Browsable Activities: Activities that can be accessed through intents (a mes saging mechanism in Android) from other apps or sources, like web browsers, other apps, or even the system.", "label": "human"}
{"ID": "00050235", "file_name": "Android Malware Scanner", "content": "Security Analysis: View the behaviour of file, check if it has some suspicious action Malware Analysis: View the malware behaviour if the app has Reconnaissance: Button for reconnaissance PDF Report: Button to print the whole report Start Dynamic Analysis: Button to start Dynamic Analysis Figure 4.4: Theme for recent scanning results This interface is designed to allow easy navigation and management of scan results, Header and SidebarThe page utilizes a layout template with a sidebar, which is collapsed by de fault.", "label": "human"}
{"ID": "00050236", "file_name": "Android Malware Scanner", "content": "The header section is present but empty in this case.Main Content Area Title Section : A header titled \"Recent Scans\" with a rocket icon to represent the section.", "label": "human"}
{"ID": "00050237", "file_name": "Android Malware Scanner", "content": "APP : Displays the app’s icon, name, version, and package name. If the scan is incomplete, a warning badge appears.", "label": "human"}
{"ID": "00050238", "file_name": "Android Malware Scanner", "content": "ACTIONS : Includes buttons for actions like viewing the static report, downloading the binary, starting a diff/compare operation, or deleting the scan.", "label": "human"}
{"ID": "00050239", "file_name": "Android Malware Scanner", "content": "A dropdown menu allows users to change the number of items per page (e.g., 5, 10, 20, etc.).4.2.4 Database design Figure 4.5: Database for Androlyzer Application Table: auth_permission Column Name Description id Unique identifier for the permission.", "label": "human"}
{"ID": "00050240", "file_name": "Android Malware Scanner", "content": "StaticAnalysis_recentscanresult: I just need to get a list of recent scans without needing to know additional details about the analyzed files or any analysis results.", "label": "human"}
{"ID": "00050241", "file_name": "Android Malware Scanner", "content": "StaticAnalysis_staticanalyzer: I only want to know the components of an ap plication (e.g., activities, services, libraries, etc.) without needing to combine this with scan results or suppressed findings.", "label": "human"}
{"ID": "00050242", "file_name": "Android Malware Scanner", "content": "StaticAnalysis_suppressfindings: I want to know which findings have beensuppressed without needing to concern yourself with the scan or detailed anal ysis results.", "label": "human"}
{"ID": "00050243", "file_name": "Android Malware Scanner", "content": "module/  utility‘-- templates/ # Folder containing global templates for the project ‘-- base.html # A base template used across the project Explanation of Components manage.py : This is the main file for managing the Django project. It is used to run the server, create apps, perform migrations, and other tasks.", "label": "human"}
{"ID": "00050244", "file_name": "Android Malware Scanner", "content": "settings.py : The main configuration file for the project, containing set tings for the database, installed apps, paths, and other configurations.", "label": "human"}
{"ID": "00050245", "file_name": "Android Malware Scanner", "content": "apps/ : A folder containing individual Django apps. Each app is a separate module that may include models, views, URLs, migrations, etc.", "label": "human"}
{"ID": "00050246", "file_name": "Android Malware Scanner", "content": "Libraries and Tools In this subsection, I will leverage a range of tools and libraries that are crucial for building a robust Android malware analysis application. The chosen stack is designed to ensure flexibility, scalability, and security for the analysis of Android applications.", "label": "human"}
{"ID": "00050247", "file_name": "Android Malware Scanner", "content": "Purpose Tools URL IDE Microsoft Visual Studio Code  Frontend framework Bootstrap  Backend framework Django  Analysis Tools Apktools  Analysis Tools Jadx  Analysis Tools Dex2jar  Analysis Tools Frida  Library lxml  Library requests  Library bs4  Library colorlog  Library tldextract  Library paramiko  Library bcrypt  Library tzdata  Library pdfkit  Library google-play-scraper  Table 4.9: List of library and tools 4.4.2 Illustration of main functions a, Cert Analysis This will display the results of the Certificate Analysis function:", "label": "human"}
{"ID": "00050248", "file_name": "Android Malware Scanner", "content": "Severity : This column indicates the severity level of the security issue, typ ically categorized as info, warning, high, or similar. The severity level helps prioritize addressing critical issues first.", "label": "human"}
{"ID": "00050249", "file_name": "Android Malware Scanner", "content": "Description : This column provides a detailed explanation of the security issue, including why it is significant and the potential consequences if left un resolved. It may also include the conditions under which the issue occurs and its specific impact on the application.", "label": "human"}
{"ID": "00050250", "file_name": "Android Malware Scanner", "content": "From APK Resource : APK Resource refers to the non-source code components that are packaged within the APK (Android Package) file. These re sources are crucial elements that enable the application to function and display content. This displayed the strings extracted from this location/Figure 4.9: Enter Caption From Code : These strings are defined or directly used in the application’s source code. They are often not part of the user interface but relate to the app’s internal logic or configuration.", "label": "human"}
{"ID": "00050251", "file_name": "Android Malware Scanner", "content": "LogCat Streaming This function will log real time behaviour, you can click on the Stop Streaming to pause the logging process, and continue by click the Continue Streaming button Here is the contents of a logging line:", "label": "human"}
{"ID": "00050252", "file_name": "Android Malware Scanner", "content": "TID (Thread ID): 672 is the ID of the thread handling this event (same as PID, as it is the main thread).", "label": "human"}
{"ID": "00050253", "file_name": "Android Malware Scanner", "content": "Log Level: The letter Istands for INFO , indicating this is a standard infor mational message, not a warning or an error.", "label": "human"}
{"ID": "00050254", "file_name": "Android Malware Scanner", "content": "Component: The event originates from the PackageManager , the systemcomponent responsible for managing application packages, including their in stallation, uninstallation, and permissions.", "label": "human"}
{"ID": "00050255", "file_name": "Android Malware Scanner", "content": "This permission allows an app to collect usage information about other apps (e.g., app usage time). It is considered sensitive and protected by the system.Figure 4.10: The Screenshot after taken Protection Level: The value protectionLevel=114 indicates the level of protection for the permission. This number signifies that the permissionmay require special approval, such as user consent or administrator permis sion.", "label": "human"}
{"ID": "00050256", "file_name": "Android Malware Scanner", "content": "Flags: Theflags=0x3048be44 represent additional information about the permission’s state or behavior. These flags are encoded in binary and used internally by the system.", "label": "human"}
{"ID": "00050257", "file_name": "Android Malware Scanner", "content": "Developer Implications: If you are the developer of the application com.rsksbgdkgcae.fvogspmykjv ,investigate why the permission was revoked. Ensure the app handles permis sion loss gracefully to prevent errors or unexpected behavior.", "label": "human"}
{"ID": "00050258", "file_name": "Android Malware Scanner", "content": "Take Screenshot I can click on the Screenshot button, after clicked, there will be a log displayed that the image is taken or not:", "label": "human"}
{"ID": "00050259", "file_name": "Android Malware Scanner", "content": "After take screenshot, i can view the image in the section of the dynamic analysisreport:Figure 4.11: Enter CaptionThe solution provided by this Android malware analysis application offers sig nificant benefits to both regular users and security professionals, addressing their unique needs in the realm of mobile security.", "label": "human"}
{"ID": "00050260", "file_name": "Android Malware Scanner", "content": "The application is designed with a user-friendly interface that simplifies the pro cess of detecting and understanding potential malware threats. Regular users often lack the technical knowledge to understand the complexities of malware behavior, so this tool provides an accessible way for them to stay informed about the security risks associated with the apps they use.", "label": "human"}
{"ID": "00050261", "file_name": "Android Malware Scanner", "content": "Malware Information Access : Users will receive detailed, easy-to-understand information about malware, including how it operates, what kind of damageit might cause, and how to protect their devices from it. This will be espe cially valuable for users who are not familiar with technical terms or in-depth security analysis.", "label": "human"}
{"ID": "00050262", "file_name": "Android Malware Scanner", "content": "Suspicious Behavior Detection : The app will analyze Android applications for suspicious or harmful behaviors, such as unusual permissions, suspicious API calls, or abnormal network activity. Regular users can see a clear report of any identified risks, which will empower them to make informed decisions about whether to keep or uninstall specific apps.", "label": "human"}
{"ID": "00050263", "file_name": "Android Malware Scanner", "content": "Educational Tool : It serves as an educational tool for non-technical users,increasing their awareness of mobile security threats and helping them under stand what constitutes safe and unsafe behavior in mobile applications.", "label": "human"}
{"ID": "00050264", "file_name": "Android Malware Scanner", "content": "For security professionals, the application will provide a more technical and in-depth solution for analyzing Android malware. It will stream the process of identifying threats, accelerating their research and analysis workflow, which is critical in a fast-evolving cybersecurity landscape.", "label": "human"}
{"ID": "00050265", "file_name": "Android Malware Scanner", "content": "Malware Research Acceleration : Security researchers often spend a signifi cant amount of time reverse-engineering malware to understand its behavior.", "label": "human"}
{"ID": "00050266", "file_name": "Android Malware Scanner", "content": "This application will provide an automated, detailed analysis of suspicious apps, giving experts quick access to critical information, such as the list of suspicious activities, permissions, API calls, and potential vulnerabilities that the app might exploit.•Detailed Behavior Analysis : Experts can leverage the app to study how a malware sample interacts with the system, network, and other apps. This caninclude detecting obfuscation techniques, understanding the persistence mech anisms used by the malware, and identifying any exfiltration of sensitive data.", "label": "human"}
{"ID": "00050267", "file_name": "Android Malware Scanner", "content": "Threat Intelligence Sharing : The insights gained from the app can be shared within the security community, contributing to the broader understanding of emerging threats. Security researchers can use the app as a starting point for further investigation and collaboration, enhancing the collective knowledge about Android malware.", "label": "human"}
{"ID": "00050268", "file_name": "Android Malware Scanner", "content": "Customized Analysis Features : The app will provide tools that cater to the specific needs of security researchers, such as the ability to integrate with other malware analysis frameworks or create custom reports. These features allow researchers to go beyond the basic analysis and perform a more tailored and detailed investigation.", "label": "human"}
{"ID": "00050269", "file_name": "Android Malware Scanner", "content": "This Android malware analysis application creates a bridge between two differ ent groups—regular users and security professionals—by offering solutions that cater to both. It empowers regular users to take control of their device’s security in an accessible and understandable way, while providing the tools necessary forsecurity experts to conduct more efficient, deeper investigations into mobile mal ware threats. By providing detailed, actionable information and fostering a deeperunderstanding of Android security, this application contributes to making the mo bile ecosystem safer for everyone, from casual users to industry professionals.In this project, we developed a comprehensive framework for analyzing Android applications, focusing on both static and dynamic analysis. The platform enables users to interact with critical functionalities such as rescanning APKs, comparinganalysis results, managing recent scans, and obtaining detailed insights through de compiled code and Smali views. These features collectively enhance the efficiency and accuracy of security analysis, providing valuable tools for both researchers and practitioners in the field of mobile application security.", "label": "human"}
{"ID": "00050270", "file_name": "Android Malware Scanner", "content": "Enhanced Dynamic Analysis : Future work can incorporate more robust be havioral analysis by integrating runtime monitoring tools, such as capturing real-time network traffic or tracking system-level interactions.", "label": "human"}
{"ID": "00050271", "file_name": "Android Malware Scanner", "content": "Improved Reporting Capabilities : Adding more visualization options, suchas interactive graphs and customizable dashboards, would enhance the usabil ity of analysis reports.", "label": "human"}
{"ID": "00050272", "file_name": "Android Malware Scanner", "content": "Machine Learning Integration : Leveraging machine learning models for au tomated malware detection and classification could significantly improve the framework’s detection capabilities.", "label": "human"}
{"ID": "00050273", "file_name": "Android Malware Scanner", "content": "Scalability and Cloud Integration : Extending the framework to support distributed and scalable analysis in the cloud would allow handling larger work loads and improving processing speeds.", "label": "human"}
{"ID": "00050274", "file_name": "Android Malware Scanner", "content": "Community Collaboration : Incorporating collaborative features, such as ashared database of known threats and patterns, could foster a stronger ecosys tem for malware detection and prevention.", "label": "human"}
{"ID": "00050275", "file_name": "Android Malware Scanner", "content": "By addressing these aspects, the platform can evolve into a more versatile and powerful solution for Android security analysis, catering to a broader audience and tackling emerging challenges in the cybersecurity domain.•Django  BootStrap:  Python:  Android Malware Analysis:  /english/33093-introduction-to-android-malware-ana lysis.pdf", "label": "human"}
{"ID": "00060001", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "PCB (Printed Circuit Board)( figure 1.1) is a multi-layer and non-conductive printed circuit board in which all the electronic components are connected togetheron a circuit board and with a base underneath. When there is no PCB, the compo nents are connected by wires, which increases the complexity and the reliability is not high, so it is not possible to create a circuit as large as the motherboard. In a PCB, all the components are connected wirelessly and are wired internally, thusreducing the complexity of the overall circuit design. PCBs are used for power sup ply and connections between components. PCB can customize any specificationsaccording to user requirements. You can encounter PCB in many electronic de vices such as: TV, mobile phone, digital camera, computer parts such as: Graphics card, Motherboard. . . It is also used in many fields. such as: Medical equipment, industrial machinery, automotive industry, lighting...", "label": "human"}
{"ID": "00060002", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "In particular, the quality of the assembly of the components on the PCB directly influences the performance and service life of electronic equipment. Traditional manual inspection of PCBs is inefficient, and has a high error rate, which makes itdifficult to adapt to industrial situations. Automatic inspection based on machine vision is increasingly applied in fields related to PCB inspection. Thus, automaticvisual inspection of PCBs has become a popular research topic in the area of indus trial inspection. In addition, the flexibility of modern automatic production systems could be improved significantly if the production equipment was able to effectively and automatically recognize and inspect the PCB.", "label": "human"}
{"ID": "00060003", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The task of testing the quality of solder joints on printed circuit boards (PCBs)is crucial in ensuring the functionality and reliability of electronic devices. Tradi tional manual testing methods are time consuming and prone to human error, so automated testing methods using computer vision techniques are becoming more and more popular. One such method is to use segmentation algorithms to check the quality of welds.", "label": "human"}
{"ID": "00060004", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The process begins with taking pictures of the solder joints on the PCB. These images are then processed to extract the region of interest, which is the weld. This is done using a segmentation algorithm that separates the match from the background.", "label": "human"}
{"ID": "00060005", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The segmented joint region is then analyzed to extract features that describe the joint, such as its shape, size, and texture.", "label": "human"}
{"ID": "00060006", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Once the features have been extracted, machine learning algorithms are used to classify the match as acceptable or faulty. This is done by training the algorithm on a set of labeled images, where each image is annotated with its corresponding class label. The trained algorithm can then be applied to the new images to classify the joints.", "label": "human"}
{"ID": "00060007", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The use of segmentation algorithms to check the quality of solder joints on PCBs has several advantages over traditional manual inspection methods. It is more accurate and consistent, as the algorithms are not prone to human error. In addition, the process is faster because inspection can be performed in real time, reducing the time required for inspection and increasing production efficiency.", "label": "human"}
{"ID": "00060008", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Furthermore, using segmentation algorithms to check the quality of welds has the potential to reduce overall manufacturing costs. By automating the inspection process, it reduces the need for manual labor and reduces the risk of human error,which can lead to costly rework and repairs. The use of machine learning algo rithms also provides a consistent and objective method for assessing the quality of welds, which can help reduce the risk of missed errors.", "label": "human"}
{"ID": "00060009", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Another benefit of using the segmentation algorithm to check the quality ofwelds is that it can provide more detailed information about the welds. For example, algorithms can analyze the shape and size of a joint, as well as its texture, to identify any anomalies that could indicate an error. This information can be used to improve the design of the joint or the manufacturing process to reduce the risk of future failure.", "label": "human"}
{"ID": "00060010", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "It is important to note that the use of segmentation algorithms for quality inspec tion of welds requires a certain level of expertise and technical knowledge. This includes a solid understanding of computer vision techniques, machine learning algorithms, and the physics of welds. It also requires access to high-quality images of the joints and a reliable method to annotate these images with corresponding class labels.", "label": "human"}
{"ID": "00060011", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "In conclusion, the use of segmentation algorithms to check the quality of solderjoints on PCBs is a valuable tool for improving the quality, efficiency and cost effectiveness of electronic device manufacturing. . It provides a fast, accurate and consistent method for assessing the quality of welds, which can help reduce the risk of defects and improve the reliability and functionality of electronic devices.", "label": "human"}
{"ID": "00060012", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Final Result: Returns the final result to the user, including the identified faults and their location in the solder pin image.2.1 Theory of machine learning In the current industrial revolution 4.0, the fact that computers are gradually replacing humans is no longer strange to us. Computers are doing well at repetitive human tasks, even better, our job just needs to pre-programmed the functions and the computer will execute them correctly.", "label": "human"}
{"ID": "00060013", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "So what if we can’t specifically program the computer to do a certain job? This is where we need machine learning, instead of humans pointing out specific steps to solve a problem, machines can learn through observation from data.", "label": "human"}
{"ID": "00060014", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "What is machine learning?Machine learning (ML) (figure 2.1) or machine learning is a branch of artifi cial intelligence (AI). Machine Learning is concerned with studying and building techniques that allow systems to \"learn\" automatically from data to solve specific problems. Machine Learning focuses on using data and algorithms to mimic how humans learn, then gradually improving its accuracy.", "label": "human"}
{"ID": "00060015", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "A specific example for Machine Learning is that machines can \"learn\" to clas sify email messages as spam or not, and then sort them into the corresponding folder.", "label": "human"}
{"ID": "00060016", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Dataset (also known as data corpus or data stock): is the unprocessed primitive data set that you have collected in the data collection step. A dataset will contain many data points.", "label": "human"}
{"ID": "00060017", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Data point: is a data point, each data point represents an observation. Each data point has many different characteristics or attributes, which are divided into two types: numeric data and non-numerical data (e.g. string) (non-numerical/categorical).", "label": "human"}
{"ID": "00060018", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Training data and test data: Dataset will usually be divided into these two sets, training data is used to train the model, test data is used to predict results and evaluate the model. If there is a problem that people will give these two sets, you don’t need to divide anymore, for a problem only for each dataset, you have to split.", "label": "human"}
{"ID": "00060019", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Features vector: is a feature vector, each of which represents a data point in the dataset. Each n-dimensional vector represents the features of the data point, each feature is one-dimensional and must be numeric data. Models can only be trained from these feature vectors, so the dataset needs to be converted to a set of feature vectors.", "label": "human"}
{"ID": "00060020", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Model: are the models used to train on a training data according to the algorithm of that model. The model can then make predictions or make decisions based on what they have learned.2.1.3 Workflow Figure 2.2: Machine learning workflow Cụ thể từng bước trong machine learning workflow như sau như sau:", "label": "human"}
{"ID": "00060021", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Step 1: Data collection: In order for the computer to learn you need a dataset, you can collect them yourself or get previously published data sets. Note that you must collect from an official source, so the new data is accurate and the machine can learn properly and achieve higher efficiency. Step 2: Preprocessing: This step is used to normalize data, remove unnecessary attributes, assign data labels, encode some features, extract features, reduce data but still ensure results... This step is time consuming. The most time is proportional to the amount of data you have.", "label": "human"}
{"ID": "00060022", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Training model: This step is the step where you train the model or let it learn on the data you collected and processed in the first two steps. Step 4: Evaluating model: After training the model, we need to use the measures to evaluate the model, depending on the different measures, the model is also evaluated well or not. Model accuracy above 80% is considered good. Step 5: Improve: After evaluating the model, the models with poor accuracy need to be retrained, we will repeat from step 3, until the expected accuracy is reached. The total time of the last 3 steps is about 30% of the total execution time.", "label": "human"}
{"ID": "00060023", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Grouping Machine Learning AlgorithmsThere are many ways to classify Machine Learning, usually, Machine Learn ing will be divided into four groups: Supervised learning, Unsupervised learning, Semi-supervised learning and Reinforcement learning. There are several ways of grouping without Semi-supervised learning or Reinforcement learning.a, Supervised Learning Figure 2.3: Supervised LearningSupervised learning( figure 2.3) is an algorithm that predicts the output (out come) of a new data (new input) based on previously known (input, outcome) pairs.", "label": "human"}
{"ID": "00060024", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "This data pair is also known as (data, label), i.e. (data, label). Supervised learning is the most popular group of Machine Learning algorithms.", "label": "human"}
{"ID": "00060025", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Classfication: A problem is called classification if the labels of the input data are divided into a finite number of groups. For example, Gmail determines if an email is spam; Credit bureaus determine whether a customer is able to pay off a debt. The three examples above fall into this category.", "label": "human"}
{"ID": "00060026", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Regression: If the label is not divided into groups but a specific real value. For example, how much will a house with x m2 width have y bedrooms and z km from the city center?b, Unsupervised Learning Figure 2.4: Unsupervised LearningIn this algorithm, we do not know the label but only the input data. The unsu pervised learning algorithm will rely on the structure of the data to do a certain job, such as clustering or reducing the dimension of the data to facilitate storage and computation.", "label": "human"}
{"ID": "00060027", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Algorithms of this kind are called Unsupervised learning because unlike Su pervised learning, we don’t know the exact answer for each input data.", "label": "human"}
{"ID": "00060028", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Clustering: A problem that groups all data X into small groups based on the relevance of the data in each group. For example, grouping customers based on purchasing behavior. This is like giving a child lots of puzzle pieces with different shapes and colors, for example triangles, squares, circles with blue and red colors, and then asking them to sort them into groups. . Even though children don’t know which pieces correspond to which shape or color, they will most likely still be able to sort the puzzle pieces by color or shape.", "label": "human"}
{"ID": "00060029", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Semi-Supervised Learning: Problems where we have a large amount of data X but only a part of them is labeled is called Semi-Supervised Learning. The problems in this group fall between the two groups mentioned above. A good example of this group is having only a portion of images or text labeled (e.g. photographs of people, animals or scientific or political texts) and most other photographs/texts.", "label": "human"}
{"ID": "00060030", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "unlabelled collected from the internet. In fact, a lot of Machine Learning problemsfall into this group because the collection of labeled data takes a lot of time and is expensive. Many types of data even require expert labeling (such as medical images). In contrast, unlabelled data can be obtained at low cost from the internet.", "label": "human"}
{"ID": "00060031", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Some Machine Learning Algorithms To perform the conversion from input to desired output, we can use different models. Machine learning is not a single type of algorithm; You may have heard of Support Vector Machine (SVM), Naive Bayes, Decision Trees, or Deep learning.", "label": "human"}
{"ID": "00060032", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "These algorithms all try to solve the same problem: Learn how to convert every input into the exact output of which it belongs.", "label": "human"}
{"ID": "00060033", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "These machine learning algorithms use different models/techniques to perform the learning process and represent knowledge of what it is being learned. Every machine learning algorithm tries to make the simplest assumptions that can be true for most of the samples in the training data set.", "label": "human"}
{"ID": "00060034", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Support Vector MachinesAn algorithm tries to construct a hyperplane in multidimensional space to dis tinguish objects of different classes; How to make the distance between the two closest objects with different labels have the maximum distance. The idea of the algorithm is extremely simple, but the model is very complex and effective. In fact,in some problems, SVM is a machine learning model that gives the best perfor mance.", "label": "human"}
{"ID": "00060035", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Probabilistic Models These models try to solve the problem using a probability distribution. One of the most popular algorithms is the Naive Bayes classifier; It uses Bayesian theory and assumes the features are independent. The strength of the probabilistic model is that it is simple but effective. Its output is not only the label, but also the probability that represents the accuracy for that result.", "label": "human"}
{"ID": "00060036", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Deep learningCurrently a trend in machine learning based on artificial neural network mod els (Artificial Neural Networks). Neural networks take an approach to connecting and using ideas the way the human brain works. They consist of large numbers of interconnected neurons; organized into layers. Deep learning is constantly being developed with new deeper constructs. It not only tries to learn, but also constructs structures representing important features automatically.2.1.6 Applications of Machine LearningMachine learning is extremely applied in today’s life in all fields: Finance banking, Biology, Agriculture, Search and extract, Information, Automation, Robotics, Chemistry, Internet, Space, Science, Advertisement, Natural language processing, Computer vision.", "label": "human"}
{"ID": "00060037", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "And there are many areas where machine learning can be applied, machine learning has proven to be extremely effective, outperforming humans in specific areas where they are applied.", "label": "human"}
{"ID": "00060038", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "For example, simple weather forecast, people will use calculations and observations, records about the past weather to forecast the weather of the next days. How ever, what if there are extremely many observations made, maybe up to millions, billions of observations, then it is impossible for humans to perform calculations on such big data. Furthermore, calculations with such large data can be error-prone and lead to erroneous predictions. At this time, applying machine learning to let computers learn from observations recorded in the past, they can predict future weather with much higher accuracy than humans predict.", "label": "human"}
{"ID": "00060039", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Because of the popularity and effectiveness of machine learning, knowing andlearning about machine learning is definitely a great advantage in today’s 4.0 tech nology era.", "label": "human"}
{"ID": "00060040", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Overview Neural Network is a series of algorithms devised to find basic relationships in a set of data. Through imitating how it works from the human brain. In other words, an artificial neural network is considered a system of artificial neurons. These can often be organic or artificial in nature.", "label": "human"}
{"ID": "00060041", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Neural Network has the ability to adapt to any changes from the input. Therefore, it can produce all the results in the best possible way without you having to redesign the output criteria.", "label": "human"}
{"ID": "00060042", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Input layer (input layer): This layer is located on the leftmost side of the network, representing the inputs of the network.", "label": "human"}
{"ID": "00060043", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The hidden layer (hidden layer): This layer is located between the input and output layers and represents the logical inference process of the network.", "label": "human"}
{"ID": "00060044", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "At each layer, the number of network nodes (neurons) can be different depending on the problem and solution. But often when working, the hidden layers have the same number of neurons. In addition, neurons in layers are often paired together to form a fully connected network. Then we can calculate the size of the network based on the number of layers and the number of neurons.2.2.4 Neural Network Application Artificial neural networks are applied to many fields such as: finance, trading, business analysis, business planning and product maintenance. Neural Network is also widely used for other business activities such as: forecasting weather, and finding solutions for marketing research, risk assessment and fraud detection.", "label": "human"}
{"ID": "00060045", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "In many cases, artificial neural networks are also used to evaluate and unearth trading opportunities based on historical data analysis. Neural networks are alsovery popularly applied to distinguish the dependencies between the nonar in puts of the input. This is a problem that other technical analysis models cannot meet. However, the accuracy of applying artificial neural networks to stock price predictions is completely different.", "label": "human"}
{"ID": "00060046", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Convolutional Neural Network(CNN) is one of the advanced Deep Learning models. It helps us to build intelligent systems with high accuracy. Currently, CNN is widely used in the problem of recognizing objects in images.", "label": "human"}
{"ID": "00060047", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "CNN also has quite a long history. The original architecture of the CNN modelwas introduced by a Japanese computer scientist in 1980. Then, in 1998, Yan Le Cun first trained the CNN model with backpropagation algorithm for handwriting recognition problem. . However, it wasn’t until 2012, when a Ukrainian computerscientist Alex Krizhevsky built a CNN (AlexNet) model and used GPUs to accel erate deep nets training to achieve the top 1 in the Computer Vision competition.", "label": "human"}
{"ID": "00060048", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Annually ImageNet with the top 5 classification error reduced by more than 10% compared to previous traditional models, created a strong wave of using deep CNN with GPU support to solve more and more problems. in Computer Vision.", "label": "human"}
{"ID": "00060049", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Basic classes of convolutional neural networksConvolutional neural network consists of basic layers: convolutional layer, pool ing layer, nonar layer, fully connected layer.", "label": "human"}
{"ID": "00060050", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Convolutional layer The convolutional layer is the most important and also the first layer of the convolutional neural network model. This class has the main function of detecting spatially efficient features. In this layer there are 4 main objects: input matrix, filters, and receptive field, feature map. The convolution layer takes as input a 3-dimensional matrix and a set of filters to learn. This filter will slide through each position on the image to calculate the convolution between the filter and the corresponding part of the image. This corresponding part of the image is called thereceptive field.", "label": "human"}
{"ID": "00060051", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "These features include basic features such as corners, edges, and colors, or more complex features such as image textures. Since the filter scans the entire image, These features can be located anywhere in the image, even if the image is rotated left/right, these features will still be detected. The filter size is one of the most important parameters of the convolutional layer. This size is proportional to the number of parameters to be learned at each convolution layer and is the parameter that determines the receptive field of this layer. The most common filter size is 3x3.", "label": "human"}
{"ID": "00060052", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The filter size of the convolutional layer is mostly odd, like 3x3 or 5x5. For an odd filter size, the feature map values will define a focal point in the foreground layer. If we choose a filter of size 2x2, 4x4, then we will have difficulty finding the corresponding position of the feature map values in the image space.", "label": "human"}
{"ID": "00060053", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The stride parameter, represents the number of pixels you need to move each time you slide the filter over the image. When stride is 1, we move the kernel by 1 pixel. When stride is 2( figure 2.8) then we move the kernel by 2 pixels and so on.", "label": "human"}
{"ID": "00060054", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "One of the reasons that this function is added into an artificial neural network in order to help the network learn complex patterns in the data. These functions introduce nonar real-world properties to artificial neural networks. Basically, in a simple neural network, x is defined as inputs, w weights, and we pass f (x) that is the value passed to the output of the network. This will then be the final output or the input of another layer.", "label": "human"}
{"ID": "00060055", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "If the activation function is not applied, the output signal becomes a simple ar function. A neural network without activation function will act as a ar regression with limited learning power. But we also want our neural network to learn non-ar states as we give it complex real-world information such as image, video, text, and sound.", "label": "human"}
{"ID": "00060056", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Some popular activation functions:ReLU( figure 2.11) f(x) =max (0, x) ReLU function is its derivative both are monotonic. The function returns 0 if it receives any negative input, but for any positive value x, it returns that value back.", "label": "human"}
{"ID": "00060057", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The activations functions that were used mostly before ReLU such as sigmoidor tanh activation function saturated. This means that large values snap to 1.0 and small values snap to -1 or 0 for tanh and sigmoid respectively. Further, the functions are only really sensitive to changes around their mid-point of their input, such as 0.5 for sigmoid and 0.0 for tanh. This caused them to have a problem called vanishing gradient problem. Let us briefly see what vanishing gradient problem is.", "label": "human"}
{"ID": "00060058", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Neural Networks are trained using the process gradient descent. The gradient descent consists of the backward propagation step which is basically chain rule to get the change in weights in order to reduce the loss after every epoch. It is important to note that the derivatives play an important role in updating of weights.", "label": "human"}
{"ID": "00060059", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Now when we use activation functions such as sigmoid or tanh, whose derivatives have only decent values from a range of -2 to 2 and are flat elsewhere, the gradient keeps decreasing with the increasing number of layers.", "label": "human"}
{"ID": "00060060", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "This reduces the value of the gradient for the initial layers and those layers are not able to learn properly. In other words, their gradients tend to vanish because of the depth of the network and the activation shifting the value to zero. This is called the vanishing gradient problem.", "label": "human"}
{"ID": "00060061", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "ReLU, on the other hand, does not face this problem as its slope doesn’t plateau, or “saturate,” when the input gets large. Due to this reason models using ReLU activation function converge faster.", "label": "human"}
{"ID": "00060062", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "But there are some problems with ReLU activation function such as explod ing gradient. The exploding gradient is opposite of vanishing gradient and occurswhere large error gradients accumulate and result in very large updates to neu ral network model weights during training. Due to this, the model is unstable and unable to learn from your training data.", "label": "human"}
{"ID": "00060063", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Also, there is a downside for being zero for all negative values and this problem is called “dying ReLU.”A ReLU neuron is “dead” if it’s stuck in the negative side and always outputs 0. Because the slope of ReLU in the negative range is also 0, once a neuron gets negative, it’s unlikely for it to recover. Such neurons are not playing any role in discriminating the input and is essentially useless. Over time you may end up with a large part of your network doing nothing. The dying problem is likely to occur when the learning rate is too high or there is a large negative bias.", "label": "human"}
{"ID": "00060064", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Leaky ReLU( figure2.12)Leaky ReLU is defined to address this problem. Instead of defining the ReLU ac tivation function as 0 for negative values of inputs(x), we define it as an extremely small ar component of x. Here is the formula for this activation function.", "label": "human"}
{"ID": "00060065", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "f(x) =max (0.01∗x, x) This function returns x if it receives any positive input, but for any negative value of x, it returns a really small value which is 0.01 times x. Thus it gives an output for negative values as well. By making this small modification, the gradient of the left side of the graph comes out to be a non zero value. Hence we would no longer encounter dead neurons in that region.", "label": "human"}
{"ID": "00060066", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The structure of a convolutional neural network A convolutional neural network is a collection of convolutional layers that are superimposed and uses nonar activation functions such as ReLU and tanh to activate the weights in the node. This class, after passing the function, will be weighted in the nodes. These classes, after having passed the activation function, can generate more abstract information for the next classes.", "label": "human"}
{"ID": "00060067", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "In it, the pooling layer will give you invariant for displacement, scaling and rota tion. The local associativity will show you the low to high levels of representation,information with abstraction through convolution from the filters. The CNN model has layers that are linked together based on the convolution mechanism.", "label": "human"}
{"ID": "00060068", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Subsequent layers will result from convolutions from the previous layer, so youwill have the best local connections. Thus, each neuron in the next layer gener ated from the resulting filter will be applied to the local image area of an existing neuron. While training the network, the CNN will automatically learn the values through the filter layer based on how the user performs.", "label": "human"}
{"ID": "00060069", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Local receptive field: This class is responsible for separating and filtering data, image information and selecting image areas with the highest use value.", "label": "human"}
{"ID": "00060070", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Shared weights and bias: This layer helps to minimize the number of parameters that have the main effect of this factor in the CNN network. In each convolution there will be different feature maps and each feature has the ability to help detect some features in the image.", "label": "human"}
{"ID": "00060071", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Pooling layer: Pooling layer is the last layer and has the effect of simplifying the output information. That is, after completing the calculation and scanning through the layers, go to the pooling layer to remove unnecessary information. From there, produce the results as desired by the user.", "label": "human"}
{"ID": "00060072", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "OpenCV a, Define OpenCV (Open Source Computer Vision) is an open-source computer vision and machine learning library developed by Intel and maintained by the OpenCV community. It is a cross-platform library written in C++ and provides APIs for several programming languages, including Python and Java.", "label": "human"}
{"ID": "00060073", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "OpenCV provides a wide range of computer vision functions and algorithms,including image and video processing, feature detection and extraction, object de tection and tracking, camera calibration, and machine learning. It also includes areal-time computer vision module that can process live video streams from web cams, video files, or network cameras.", "label": "human"}
{"ID": "00060074", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "OpenCV is widely used in industry and academia for a variety of applications,including robotics, surveillance, medical imaging, and augmented reality. Its cross platform support, real-time processing capabilities, and easy integration with other software and systems make it a popular choice for developers and researchers inthe computer vision field.", "label": "human"}
{"ID": "00060075", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Real-time processing: OpenCV provides real-time image processing capabilities,making it suitable for use in applications such as robotics and autonomous vehi cles.", "label": "human"}
{"ID": "00060076", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Easy integration: OpenCV provides APIs for several programming languages, mak ing it easy to integrate with existing software and systems.", "label": "human"}
{"ID": "00060077", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Large community: OpenCV has a large and active community of developers and users who contribute to the library, provide support, and share knowledge.", "label": "human"}
{"ID": "00060078", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Computer vision: OpenCV is primarily used for computer vision applications,including image and video processing, feature detection and extraction, object de tection and tracking, camera calibration, and stereo vision.", "label": "human"}
{"ID": "00060079", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Medical imaging: OpenCV is used in medical imaging for tasks such as image seg mentation, object recognition, and analysis of medical images.", "label": "human"}
{"ID": "00060080", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Surveillance and security: OpenCV is used in surveillance and security systems for tasks such as face detection, motion detection, and object tracking.", "label": "human"}
{"ID": "00060081", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Automotive industry: OpenCV is used in the automotive industry for tasks such as lane detection, traffic sign recognition, and object detection.", "label": "human"}
{"ID": "00060082", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Augmented reality: OpenCV is used in augmented reality applications for tasks such as object tracking, image registration, and marker detection.", "label": "human"}
{"ID": "00060083", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Entertainment industry: OpenCV is used in the entertainment industry for tasks such as face tracking and recognition, special effects, and motion capture.", "label": "human"}
{"ID": "00060084", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "OpenCV is widely used in industry and academia for a variety of applications, including robotics, surveillance, medical imaging, and augmented reality. Its ease of use, real-time processing capabilities, and large community make it a popular choice for developers and researchers in the computer vision field.Depending on the needs and nature of the work or project, you should choose the appropriate language. For example, images can be processed in C++, UX / UI design can be converted to C# for ease of design. The private demo program can be run right away in Python or android. Every language has its pluses and minuses, please consider it accordingly.", "label": "human"}
{"ID": "00060085", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Overall, OpenCV is a versatile and powerful library that can be applied to a wide range of computer vision and machine learning tasks in various fields.", "label": "human"}
{"ID": "00060086", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Tensorflow a, FrameworkTo understand what Tensorflow is, we must first know the concept of Frame work in the software field. Framework is the English term meaning \"framework\".", "label": "human"}
{"ID": "00060087", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "It is the basic functional code pre-written by programmers, creating a set of pro gramming libraries, software libraries, compilers, interpreters, and even APIs that provide basic utilities. version helps programmers more convenient and faster in building application software. Framework was born to help programmers solve a lot of problems from programming in general to web programming, specific apps in particular.", "label": "human"}
{"ID": "00060088", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "In a simpler and easier way, imagine the framework is a pre-made raw frame on a basic and solid foundation, and you are the engineer, the construction and interior designer for the apartment. How home is depends entirely on us.", "label": "human"}
{"ID": "00060089", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Tensorflow With the explosion of the field of Artificial Intelligence – A.I. Over the past decade, machine learning and deep learning have clearly grown along as well. Andat the moment, TensorFlow is the world’s most famous open source machine learning library, developed by researchers from Google. The strong support of math ematical operations for computation in machine learning and deep learning has made approaching problems much simpler, faster and more convenient.", "label": "human"}
{"ID": "00060090", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The built-in functions in the library for each problem allow TensorFlow to buildmultiple neural networks. It also allows you to compute in parallel on many differ ent computers, even on multiple CPUs and GPUs in the same machine, or create dataflow graphs - data flow graphs to build models. If you want to choose a career path in the field of A.I. For this, understanding the basics of TensorFlow is really important.", "label": "human"}
{"ID": "00060091", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "TensorFlow is an open-source machine learning framework developed by the Google Brain team in 2015. It is used for building and training machine learn-ing models, including deep neural networks, for a variety of applications, such as computer vision, natural language processing, and time-series analysis.", "label": "human"}
{"ID": "00060092", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "TensorFlow provides a comprehensive set of tools and libraries for develop ing and deploying machine learning models, including data preprocessing, model building, training, evaluation, and deployment. It also supports distributed training across multiple CPUs and GPUs, as well as deployment on a variety of platforms, such as mobile devices and the cloud.", "label": "human"}
{"ID": "00060093", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Low-level API: TensorFlow also provides a low-level API, which allows users to customize the behavior of the framework for specific use cases.", "label": "human"}
{"ID": "00060094", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "TensorBoard: TensorFlow includes a visualization tool called TensorBoard, which makes it easy to visualize and understand the behavior of machine learning models during training.", "label": "human"}
{"ID": "00060095", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Compatibility: TensorFlow supports a variety of platforms and programming lan guages, including Python, C++, and Java, making it easy to integrate with existing systems and workflows.TensorFlow has become a popular choice for building and deploying machine learning models in industry and academia. Its flexibility, scalability, and ease of use make it an attractive option for developers and researchers alike.", "label": "human"}
{"ID": "00060096", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "No support for windows: There are more users who are comfortable in a windows environment than Linux, and TensorFlow does not satisfy these users. But we don’t need to worry about that if we are windows user, we can also install it through conda or python package library (pip).", "label": "human"}
{"ID": "00060097", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "No GPU support for Nvidia and only language support: Currently, the only sup ported GPUs are NVIDIA and the only full language support is Python, which makes it a drawback because of the increase increase of other languages in deep learning as well as Lau.", "label": "human"}
{"ID": "00060098", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Compute speed: This is an area where TF is lagging behind, but we focus more onproduction environments than performance, which is still the right choice.", "label": "human"}
{"ID": "00060099", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Deep learning libraries are often ’backed’ by big technology companies: Google (Keras, TensorFlow), Facebook (Caffe2, Pytorch), Microsoft (CNTK), Amazon (Mxnet), Microsoft and Amazon are also building. build Gluon (same version as Keras). (These firms all have cloud computing services and want to attract users.) Figure 2.17: What is Keras Here are a few statistics to give everyone an overview of the most used libraries:Figure 2.18: Top deeplearning libraries 2018 Keras is a high-level neural network application programming interface (API)written in Python. It was developed by Franc ¸ois Chollet and is part of the Ten sorFlow project. Keras provides an easy-to-use interface for building and training deep learning models, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and more.", "label": "human"}
{"ID": "00060100", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Keras was designed to be user-friendly and easy to use, with a focus on allowingresearchers and developers to quickly prototype and experiment with different neu ral network architectures. It provides a simple and intuitive interface for defining and training models, allowing users to focus on the modeling task rather than the implementation details.", "label": "human"}
{"ID": "00060101", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Modularity: Keras allows users to build models by stacking layers, each of which can be thought of as a self-contained neural network module.Extensibility: Keras can be easily extended with custom layers and loss functions, making it possible to experiment with new architectures and techniques.", "label": "human"}
{"ID": "00060102", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "GPU acceleration: Keras can be run on GPUs, which allows for faster training times and the ability to work with larger datasets.", "label": "human"}
{"ID": "00060103", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Keras has become a popular choice for building deep learning models in many fields, including computer vision, natural language processing, and robotics. Its simplicity and flexibility make it an attractive option for researchers and developers alike.", "label": "human"}
{"ID": "00060104", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "C#C#(pronounced \"C Sharp\") is a modern, object-oriented programming lan guage developed by Microsoft and used primarily for building applications on the Microsoft .NET framework. C was first released in 2000 and has since become one of the most popular programming languages in the world.", "label": "human"}
{"ID": "00060105", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "C# is designed to be a simple, efficient, and type-safe language that can be used to build a wide range of applications, including desktop applications, web applications, mobile applications, games, and more. C# is often used in conjunction with other technologies such as the .NET Framework, ASP.NET, and Unity.", "label": "human"}
{"ID": "00060106", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "C# is a popular language for enterprise development, particularly for Windowsbased applications. It is also commonly used for game development and web de velopment. C# has a large and active community of developers who contribute toopen-source projects and provide support through forums and on resources.C# with strong support of .NET Framework makes it very easy to create a Windows Forms or WPF (Windows Presentation Foundation) application, game devel opment, Web application, and Mobile application.", "label": "human"}
{"ID": "00060107", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "MVVM separates the user interface (View) from the business logic and data (Model) by introducing a mediator called ViewModel. The ViewModel acts as anintermediary between the View and the Model and handles the communication be tween them. The Model represents the data and business logic, the View represents the user interface, and the ViewModel contains the presentation logic that connects the two.", "label": "human"}
{"ID": "00060108", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Model: The Model is responsible for representing the data and business logic. It is an abstraction of the real-world entity that is being modeled and can be thought of as the application’s data layer.", "label": "human"}
{"ID": "00060109", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "View: The View is responsible for presenting the data to the user and handling user interaction. It can be thought of as the application’s presentation layer.", "label": "human"}
{"ID": "00060110", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "ViewModel: The ViewModel is responsible for connecting the Model and theView. It contains the presentation logic that mediates between the two and ex poses the data and behaviors of the Model to the View through data binding. It also handles user interaction and updates the Model accordingly.The benefits of using the MVVM pattern include:", "label": "human"}
{"ID": "00060111", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Separation of concerns: MVVM separates the business logic and data from the user interface, making the code easier to understand, maintain, and modify.", "label": "human"}
{"ID": "00060112", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Flexibility: MVVM allows for flexibility in the design and implementation of the user interface, making it easier to adapt to changes in requirements or technology.", "label": "human"}
{"ID": "00060113", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Overall, the MVVM pattern is a popular choice for building modern user inter faces that are easy to maintain and test.3.1 Data construction 3.1.1 Overview Data made in this project are actual images of printed circuit boards taken at TAISHODO ELECTRICS VIETNAM.", "label": "human"}
{"ID": "00060114", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "These technologies help display images realistically and clearly, making it easy for users to observe. without increasing bandwidth.Figure 3.2: Camera Hikvision 25mm lens( figure3.3): It helps to adjust the sharpness when combined with the camera.", "label": "human"}
{"ID": "00060115", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Industrial 25mm lenses are designed to be used with machine vision cameras, which are specialized cameras used in industrial and manufacturing settings. Theselenses are typically fixed focal length lenses, which means they have a specific fo cal length that cannot be changed.", "label": "human"}
{"ID": "00060116", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The 25mm focal length is popular in industrial applications because it provides a wide field of view that can capture a large area of the production  or inspection area. This can be useful for applications such as defect detection, where the entire surface of a product needs to be inspected for flaws or defects.", "label": "human"}
{"ID": "00060117", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Overall, 25mm lenses in industrial cameras are an important tool for automation, inspection, and quality control in manufacturing settings.Figure 3.3: Lens 25mm RGB lights, brackets and other( figure3.4) related tools RGB stands for red, green, and blue, which are the primary colors of light. RGBlighting is a type of lighting system that allows you to create a wide range of col ors by mixing these three primary colors. This helps the images to be sharper and clearer, which is convenient in improving the image for model training.Figure 3.4: Some other devices After the process of taking pictures and collecting data, we obtained more than 300 samples of large size images. So we used the image cropping tool (self-developed by the company) to bring back more than 600 image samples of 480x500 pixels for training purposes.", "label": "human"}
{"ID": "00060118", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "After we have enough images, we use PixelAnnotationTool- is a tool to assist in labeling data by color.Next, we put the image data into the python code for training, the environment on Kangle. Of course, before that, the image has gone through processing stages such as noise filtering, angle rotation to enhance and improve the image.", "label": "human"}
{"ID": "00060119", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The above is a summary of the preparation and implementation process to check the quality of solder pins on PCB printed circuit boards.", "label": "human"}
{"ID": "00060120", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Classification of errors This data set includes solder defects and substandard welds. In which, with poor quality welds, there are 3 basic errors: bridge foot, fat bridge and excess solder.", "label": "human"}
{"ID": "00060121", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The component is misaligned, causing the component pins to press on other pins, leading to a tin bridge.•During tin printing, tin is more than the standard, resulting in a tin bridge There are many other reasons as well Solution:", "label": "human"}
{"ID": "00060122", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The AOI in front of the oven can detect the problem (for external components only) and fix it right in front of the oven.", "label": "human"}
{"ID": "00060123", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Use image segmentation combined with computer vision to find errors auto matically.c, Too much tin error Figure 3.7: The too much tin error Concept: Excess tin is a phenomenon where the component pins are redundant when printed, which can lead to a short circuit when the excess points touch each other. Reason:", "label": "human"}
{"ID": "00060124", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "During the printing process, the tin is deflected, leading to a surplus of solder pins when passing through the furnace.", "label": "human"}
{"ID": "00060125", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "During the printing process of tin printing, the tin is more than the standard, leading to an excess of tin There are many other reasons as wellSolution:", "label": "human"}
{"ID": "00060126", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The AOI in front of the oven can detect the problem (for external components only) and fix it right in front of the oven.", "label": "human"}
{"ID": "00060127", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The AOI in front of the oven can detect the problem (for external components only) and fix it right in front of the oven.", "label": "human"}
{"ID": "00060128", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Below is the original image (left side) and the corresponding label sample.Figure 3.9: Image and label of the datasetLooking at the image above, we can see some common errors introduced above and the corresponding color codes.", "label": "human"}
{"ID": "00060129", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "VGG16 refers to the VGG model, also called VGGNet. It is a convolution neural network (CNN) model supporting 16 layers. K. Simonyan and A. Zisserman from Oxford University proposed this model and published it in a paper called Very Deep Convolutional Networks for Large-Scale Image Recognition.", "label": "human"}
{"ID": "00060130", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The VGG16 model can achieve a test accuracy of 92.7% in ImageNet, a dataset containing more than 14 million training images across 1000 object classes. It is one of the top models from the ILSVRC-2014 competition.", "label": "human"}
{"ID": "00060131", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "VGG16 improves on AlexNet and replaces the large filters with sequences of layer and 5 for the second layer. The researchers trained the VGG model for severalweeks using NVIDIA Titan Black GPUs.", "label": "human"}
{"ID": "00060132", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Convolutional layers 2D: he convolutional filters of VGG use the smallest possible LeakyReLU activation: next is the Rectified Linear Unit Activation Function (LeakyReLU)component, AlexNet’s major innovation for reducing training time. Leaky Recti fied Linear Unit, or Leaky ReLU, is a type of activation function based on a ReLU,but it has a small slope for negative values instead of a flat slope. The slope coeffi cient is determined before training, i.e. it is not learnt during training. This type of activation function is popular in tasks where we may suffer from sparse gradients, for example training generative adversarial networks.", "label": "human"}
{"ID": "00060133", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Hidden layers: all the VGG network’s hidden layers use LeakyReLU instead of Lo cal Response Normalization like AlexNet. The latter increases training time and memory consumption with little improvement to overall accuracy.", "label": "human"}
{"ID": "00060134", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Pooling layers: A pooling layer follows several convolutional layers—this helps re duce the dimensionality and the number of parameters of the feature maps created by each convolution step. Pooling is crucial given the rapid growth of the number of available filters from 64 to 128, 256, and eventually 512 in the final layers.", "label": "human"}
{"ID": "00060135", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Fully connected layers: VGGNet includes three fully connected layers. The first two layers each have 4096 channels, and the third layer has 1000 channels, one for every class.", "label": "human"}
{"ID": "00060136", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Before explaining Adam we will describe what a Gradient Descent is?Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates. Until the function is close to or equal to zero, the model will continue to adjust its parameters to yield the smallest possible error. Once machine learning models are optimized for accuracy, they can be powerful tools for artificial intelligence (AI) and computer science applications.", "label": "human"}
{"ID": "00060137", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Starting from an initial value, the Gradient Descent is iteratively run to find the optimal value of the parameters in order to find the smallest possible value of the selected cost function.", "label": "human"}
{"ID": "00060138", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Adaptive Moment Estimation is an algorithm for optimization technique for gradient descent. The method is really efficient when working with large probleminvolving a lot of data or parameters. It requires less memory and is efficient. Intu itively, it is a combination of the ‘gradient descent with momentum’ algorithm and the ‘RMSP’ algorithm.", "label": "human"}
{"ID": "00060139", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Loss function Training artificial neural networks is similar to how humans learn. We feed thedata model, it makes a prediction, and we respond whether the prediction is cor rect or not. Based on the feedback, the model can correct previous mistakes. This process is repeated until the model reaches a certain accuracy.", "label": "human"}
{"ID": "00060140", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "It is very important to show that the model guessed wrong so that it can learn knowledge from the data. And that’s why the loss function was designed. The loss function will show how much the model guessed against the actual value.", "label": "human"}
{"ID": "00060141", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Cross-entropy is a mathematical concept used in information theory and ma chine learning to measure the difference between two probability distributions. Itis commonly used as a loss function in classification tasks, such as image recogni tion and natural language processing.In classification tasks, the goal is to predict the probability distribution of a given input belonging to different classes. The cross-entropy loss measures the difference between the predicted probability distribution and the true probability distribution.", "label": "human"}
{"ID": "00060142", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "L=−ylog (p) + (1 −y)log(1−p) where L is the cross-entropy loss, y is the true label (0 or 1), p is the predicted probability of the positive class (i.e., the probability of the input belonging to the positive class), and log() is the natural logarithm.", "label": "human"}
{"ID": "00060143", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "The cross-entropy loss is a measure of the dissimilarity between the predicted and true probability distributions. It is minimized when the predicted probability distribution matches the true probability distribution, i.e., when the predicted labels are accurate. Thus, minimizing the cross-entropy loss is a common objective in training machine learning models for classification tasks.", "label": "human"}
{"ID": "00060144", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Overall, cross-entropy is a useful mathematical concept for measuring the dif ference between probability distributions and is commonly used as a loss function in classification tasks in machine learning.4.1 Training environmentIn this project we use the training environment Kaggle with along with specifi cations:", "label": "human"}
{"ID": "00060145", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Kaggle offers a wide range of data science competitions that cover various topics, including machine learning, data analysis, natural language processing, com puter vision, and more. The competitions are sponsored by various companies andorganizations and offer cash prizes, job opportunities, and recognition to the win ners.", "label": "human"}
{"ID": "00060146", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "In addition to competitions, Kaggle also provides a platform for data scientists to collaborate on open source projects, share datasets, and discuss data science topics in the community forum. Kaggle also offers various resources for learning data science, including courses, tutorials, and datasets.", "label": "human"}
{"ID": "00060147", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Kaggle has become a popular platform for data scientists to showcase their skills and build their professional reputation. Many companies use Kaggle to recruit toptalent, and winning a Kaggle competition can be a significant boost to a data sci entist’s career.", "label": "human"}
{"ID": "00060148", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Overall, Kaggle is a valuable platform for data scientists to participate in data science competitions, collaborate on open source projects, and learn and share knowledge in the community.4.2 Data training Set quantity Train Test Number of sample 500 110 Table 4.1: The samples of training and testing In this project we train more than 600 samples divided with 500 training images and 110 test images respectively with attached labels.", "label": "human"}
{"ID": "00060149", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Training process with batch size = 16, learning rate = 1e -3, optimizer function is Adam, using loss function is categorical cross entropy loss, epochs = 120 with data set.", "label": "human"}
{"ID": "00060150", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Before learning about AUC, we understand the concept of True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN).", "label": "human"}
{"ID": "00060151", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "FP – False Negative: The amount of data predicted is labeled X but is not actually X (in this case the model predicts wrong).", "label": "human"}
{"ID": "00060152", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "TN – True Negative: Number of predicted data that are not X labels and they are not actually X (in this case the model predicts correct).", "label": "human"}
{"ID": "00060153", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "FN – False Negative: The number of predicted data that are not X but they areactually labeled X (in this case the model predicts wrong).", "label": "human"}
{"ID": "00060154", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Receiver Operating Curve (ROC) is a curve that represents the classification ability of a classification model at threshold thresholds. This curve is based on two indicators:", "label": "human"}
{"ID": "00060155", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "TPR (true positive rate): Also known as recall or sensitivity. Is the ratio of casesthat are correctly classified as positive to the total number of cases that are actu ally positive. This index will evaluate the accuracy of the model’s prediction on positive. The higher its value, the better the model predicts on the positive group.", "label": "human"}
{"ID": "00060156", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "TPR =TP TP +FN(4.1) FPR (false positive rate): The ratio of falsely forecasting negative to positive cases out of the total number of actual negative cases. If the value of FPR = 0.1, the model incorrectly predicted 10% of the total cases to be negative. The lower the FPR of a model, the more accurate the model is because its error on the negative group is lower. The FPR’s complement is the specificity that measures the ratio of correctly predicting negative cases to the total number of actual negative cases.", "label": "human"}
{"ID": "00060157", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Specificity =TN TN +FP(4.2) FPR = 1−Specificity =FP TN +FP(4.3) The ROC (figure 4.4) graph is a convex curve based on TPR and FPR:Figure 4.3: ROC-AUC Graph AUC is an index calculated based on the ROC curve to assess the classification ability of the model. The area under the ROC curve and on the horizontal axis is the AUC with values in the range [0, 1]. When this area is larger, the ROC curve tends to asymptote to the  y=1 and the better the model’s classification ability.", "label": "human"}
{"ID": "00060158", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Main interface: It is initially initialized with the image reader module with the view( figure4.5) belowFigure 4.5: Main interface To load input image we use open file feature in \"Choose Image\" cluster or we can load multiple images using load folder. We have:", "label": "human"}
{"ID": "00060159", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "PASS\" stands for OK and \"FAIL\" stands for NG(Not good).Figure 4.8: Quality soldering feet(OK) Figure 4.9: The tin bridge error(NG)Figure 4.10: Solder weld swelling error(NG)Figure 4.11: The too much tin error(NG)After studying the topic \"Analyze and design software to checking weld qual ity using image processing technology and segmentation deep learning\", with the dedicated help of teacher Dr. Trinh Anh Phuc, I have built a model to check the pin error of the printed circuit board PCB during the production process. As a result, the model achieves high accuracy. My next suggestion for the topic is to build an interface with some necessary features in the process of batch testing to apply to the real model.", "label": "human"}
{"ID": "00060160", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "However, during the implementation of this project, the collection of training and testing data has not been diversified enough to accurately evaluate the model.", "label": "human"}
{"ID": "00060161", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "In the process of researching and completing the project, inevitably shortcomings, I look forward to receiving valuable suggestions from teachers to make the research and development of this application more and more complete.", "label": "human"}
{"ID": "00060162", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "I would like to express my sincere gratitude to the guidance and support of Professor Dr. Trinh Anh Phuc both in terms of knowledge and equipment in the process of making the project.", "label": "human"}
{"ID": "00060163", "file_name": "Analyze and design software to checking weld quality using image processing technology and segmentation deep learning", "content": "Basic machine learning concepts . [On]. Available: studocu . com / vn / document / dai - hoc - thuy- loi / kien truc-may-tinh/supervised-learning-va-unsupervised learning/37603915 (visited on 07/27/2022).", "label": "human"}
{"ID": "00070001", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "People are currently benefiting greatly from the advancement of information technology, especially with the emergence of e-commerce, which allows us to place numerous orders while being at home. With only a few minutes of browsing, you can choose an item, read a thorough description, and decide whether to buy it. In addition, you can read comments and reviews left by previous customers, which helps us gain a different perspective on the product. The convenience of this greatly raises the standard of living. Along with that, some additional issuesoccur because there are numerous models and items available for purchase on e commerce websites, complicating and raising the cost of the customer’s decision.", "label": "human"}
{"ID": "00070002", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Even after spending a lot of effort, the buyer is still not satisfied with the product that has been discovered. Additionally, a significant portion of users either don’t fully and precisely specify their search criteria at the time of purchase or they do so in response to the products that the system displays (or in response to the information produced by the system). The search engines are unable to resolve the issue at that point. Furthermore, the best-selling products only make up a small portion of the whole product, and the long list of products that follow them provides very little revenue. This phenomenon is known as the \"long tail\" in commerce.", "label": "human"}
{"ID": "00070003", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Therefore, showing the most well-liked and best-selling items may boost sales but may not be appropriate for some particular clients and does not emphasize the distinctive individuality of each customer. client. In addition, many consumers don’t precisely and completely decide their search needs at the time of purchase, or they change their requests based on the data the system returns (depending on the products). the system’s display). The search engines are unable to resolve the issue at that point.", "label": "human"}
{"ID": "00070004", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The consumer experience will be significantly impacted, which will make it challenging for business owners to sell. By solving this issue, customers will have more options, save time, have a better overall experience, and be more likely to make purchases. To address this issue, the recommender system was developed, benefiting both customers and business owners.", "label": "human"}
{"ID": "00070005", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Recommender systems can offer customers individualized recommendations based on their historical purchasing patterns, browsing habits, and other pertinent information. Those who might be interested in certain products but have troublefinding them on their own may benefit from this.", "label": "human"}
{"ID": "00070006", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Engagement Boost: Recommender systems can boost user interaction with e commerce platforms by offering tailored and relevant recommendations. More time spent on the platform, higher click-through rates, and eventually higher revenues can result from this.", "label": "human"}
{"ID": "00070007", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Better User Experience: By offering users a well-curated selection of goods that are pertinent to their interests and requirements, recommender systems can improve the overall user experience. This can improve client happiness and loyalty by making purchasing more efficient and pleasurable.", "label": "human"}
{"ID": "00070008", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Cross-Selling and Upselling: Recommender systems can be used to make suggestions to users about related products, which may present opportunities for cross-selling and upselling. For instance, if a customer buys a pair of shoes, the system may recommend matching accessories like socks or a handbag.", "label": "human"}
{"ID": "00070009", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "By delivering individualized recommendations, raising engagement, enhancing the user experience, and fostering cross-selling and upselling opportunities, recommender systems can make it easier for individuals to access e-commerce. Therefore, many e-commerce sites currently use the recommendation system, particularly the major ones like Shopee, Tiki, etc.", "label": "human"}
{"ID": "00070010", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "These systems will keep track of the businesses we visit, the goods we’re interested in, and our past purchases. Then, we will create a list of recommended products, demonstrating how to select the best and related products by category so that we may make better product selections. Additionally, the system can provide supplemental items to help customers complete their purchases.", "label": "human"}
{"ID": "00070011", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "For instance, if we visit Shopee to look for a \"laptop\" Shopee will remember that action and then recommend \"Macbook\" products from numerous merchants, rated according to preference and with associated extras like \"protective cases\" or a few additional \"wireless headphones\" s. However, the system also makes extensive use of the products that we consistently order, learning our purchasing patterns and our preferences for various products so that it may eventually provide better choices that are more in accordance with our demands and after some period of book purchases, the system will have a better understanding of the customer’s interests, improving its capacity to make more correct suggestions.", "label": "human"}
{"ID": "00070012", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Building an on sales website with an integrated recommendation system, I proceed to learn about typical suggestion scenarios from large e-commerce sites.", "label": "human"}
{"ID": "00070013", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "This website will have some key features, including product search; suggestedproduct list; product information, etc. This topic’s key idea is how to include a recommender system into an on store to boost sales effectiveness.", "label": "human"}
{"ID": "00070014", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "I conducted research and developed a system to recommend products that are comparable to those that consumers have already viewed using purchase information from the history of customers of another active website. The technology picks up on the user’s fashion sense. Additionally, based on data from previous purchases, I created a website to sell clothing on and integrated a recommendation system.", "label": "human"}
{"ID": "00070015", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Content-based Filtering: This method recommends items based on their attributesor content, such as the genre of a movie or the ingredients of a recipe. Content based filtering can be effective for longtail items because they may have unique attributes that can be used to make recommendations.", "label": "human"}
{"ID": "00070016", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Collaborative Filtering: This method recommends items based on the user’s past behavior and the behavior of similar users. Collaborative filtering can be effective for longtail items because it can use the behavior of similar users to make recommendations even if the item has few ratings.", "label": "human"}
{"ID": "00070017", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Matrix Factorization: This method decomposes the user-item rating matrix into two low-rank matrices, one representing the user preferences and the other representing the item attributes. Matrix factorization can be effective for longtail items because it can use the attributes of items to make recommendations even if the item has few ratings.", "label": "human"}
{"ID": "00070018", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Hybrid Approaches: These methods combine multiple recommendation techniques to overcome the limitations of individual techniques. For example, a hybrid approach might use content-based filtering for longtail items and collaborative filtering for popular items.", "label": "human"}
{"ID": "00070019", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Deep Learning: This method uses neural networks to learn representations of users and items that can be used to make recommendations. Deep learning can be effective for longtail items because it can learn complex relationships between users and items even if the item has few ratings.", "label": "human"}
{"ID": "00070020", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "My recommendation system includes 3 algorithms: Content-based, Item item-based, and Matrix factorization. By using these methods, recommender systems can provide more accurate and personalized recommendations for both popular and longtail items.1.3 Organization of Thesis In Chapter 2, I am going to give Theoretical Basis including the necessary frameworks that I used, along with a basic understanding of the recommender algorithms that I used to build the recommender system.", "label": "human"}
{"ID": "00070021", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Finding the fundamental and crucial features needed to run an e-commerce website involves evaluating large e-commerce websites, which is what Chapter 3 discusses. Next, provide a thorough explanation of the website’s functional and non-functional needs, which serve as the framework for the system’s design.I describe the system’s design, from use case analysis to thorough website design using the Ionic framework. This chapter serves as the primary guide for describing the features that the website offers and serves as the primary source of information for programming the installation.", "label": "human"}
{"ID": "00070022", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The project’s unique feature, the creation of the recommender system, is presented in Chapter 4. Obtaining data from another database, processing, cleaning, and arranging data, and finally creating three recommended functions: Matrix factorization, collaborative item-item filtering, and content-based Filtering by collaboration and the outcomes.", "label": "human"}
{"ID": "00070023", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Chapter 5, I will present the features of the project and give information about the performance of each used recommender algorithm.", "label": "human"}
{"ID": "00070024", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "In Chapter 6, I’ll wrap up my graduation project and discuss how it will go moving forward. In addition, I offer several enhancements to this suggestion mechanism.", "label": "human"}
{"ID": "00070025", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "At the end of the thesis, a list of the resources you used as references when creating the website and recommender system will be provided.A recommendation system is a machine learning or artificial intelligence (AI) algorithm that makes suggestions or recommends more products to customers using big data. These may be determined using a variety of parameters, such as previous purchases, search history, demographic data, and other elements. In order to help people find products and services they might not have found on their own, recommender systems are really helpful. To visualize how the recommender system works, I built a book recommendation website that can recommend books to users based on user habits and reviews on each product.", "label": "human"}
{"ID": "00070026", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "I used Ionic framework to build the front-end and Asp. NET to build the back end, besides using postgresSQL for data management.", "label": "human"}
{"ID": "00070027", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The Ionic Framework, Asp. NET, PostgreSql data management system, and support libraries for Asp.NET are required technologies for developing job recruitment websites. I’ll describe each technology in this part and explain why it should be used in the system.", "label": "human"}
{"ID": "00070028", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Ionic is a complete open-source SDK for hybrid mobile app development created by Max Lynch, Ben Sperry, and Adam Bradley of Drifty Co. in 2013.", "label": "human"}
{"ID": "00070029", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The original version was released in 2013 and built on top of AngularJS and Apache Cordova. However, the latest release was re-built as a set of Web Components, allowing the user to choose any user interface framework, such as Angular, React or Vue.js. It also allows the use of Ionic components with no user interface framework at all. Ionic provides tools and services for developing hybrid mobile, desktop, and progressive web apps based on modern web development technologies and practices, using Web technologies like CSS, HTML5, and Sass. In particular, mobile apps can be built with these Web technologies and then distributed through native app stores to be installed on devices by utilizing Cordova or Capacitor.", "label": "human"}
{"ID": "00070030", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "ASP.NET is an open-source, server-side web-application framework designed for web development to produce dynamic web pages. It was developed by Microsoft to allow programmers to build dynamic web sites, applications and services. The name stands for Active Server Pages Network Enabled Technologies.", "label": "human"}
{"ID": "00070031", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "It was first released in January 2002 with version 1.0 of the .NET Framework and is the successor to Microsoft’s Active Server Pages (ASP) technology.ASP.NET is built on the Common Language Runtime (CLR), allowing programmers to write ASP.NET code using any supported .NET language. The ASP.NET SOAP extension framework allows ASP.NET components to process SOAP messages.", "label": "human"}
{"ID": "00070032", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "PostgreSQL is an open-source relational database management system (RDBMS) that is widely used for enterprise applications. It is known for its scalability, reliability, and ability to handle complex queries and large datasets.", "label": "human"}
{"ID": "00070033", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Because PostgreSQL complies with ACID standards, its operations are very reliable and consistent. Advanced functionality including transactions, triggers, views, and stored procedures are supported. It also supports a wide range of data types, such as geographical data, XML, and JSON.The community support offered by PostgreSQL is one of its advantages. There is a sizable and vibrant development community that contributes to the project and offers help via forums, mailing lists, and other platforms. Another quality of PostgreSQL is performance. It makes use of an MVCC system, which enables numerous users to access the database at once without interfering with one another. This makes it a fantastic option for popular websites and programs. PostgreSQL is a robust and trustworthy RDBMS that is frequently used in business applications, data analytics, and web development. For developers that need to manage massive datasets and intricate queries, it is a great option.", "label": "human"}
{"ID": "00070034", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Microsoft.AspNetCore.Mvc: This package includes the ASP.NET Core MVC framework, which is used for building web applications.2.2 Matrix Utility A matrix utility is a software tool or program that is designed to perform various operations on matrices, such as matrix multiplication, addition, subtraction, transpose, inversion, and determinant calculation. Matrices are rectangular arrays of numbers that are commonly used in mathematical applications, such as ar algebra, computer graphics, physics, and engineering.", "label": "human"}
{"ID": "00070035", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "A matrix utility may offer a broad range of functions to manipulate matrices in different ways, or it may be tailored to carry out specialized matrix operations. To assist users in visualizing the matrix data, several matrix utilities might additionally offer visualization capabilities. Here are some functions that a matrix utility may offer:", "label": "human"}
{"ID": "00070036", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Matrix visualization: In order to do this, the matrix data must be presented graphically in a variety of ways, such as heatmaps, scatter plots, or network graphs.", "label": "human"}
{"ID": "00070037", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Matrix decomposition: This involves breaking down a matrix into simpler components, such as the LU decomposition or the QR decomposition.", "label": "human"}
{"ID": "00070038", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Determinant calculation: This involves finding the determinant of a matrix, which is a scalar value that can be used to determine various properties of thematrix.", "label": "human"}
{"ID": "00070039", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Content-Based Filtering For each customer, this method will give product recommendations based on the items they buy. Specifically, Content-based will find products that are similar to those that customers have purchased based on the features (features) of the product.", "label": "human"}
{"ID": "00070040", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "In Content-based systems, based on the feature of each product, we need to build a profile for each product, represented as a vector. Product example P(1, 0, 0 ,0, 1, 1, 1, 0) Then, I calculate the customer’s interest in those features based on the products the customer has purchased, specifically the average of all the product feature vectors. Example customer C(0.9, 0.1, 0, 0.2, 0.7, 0.5, 0.9, 0.3) From there, I find products whose feature vector is similar to the user’s interest vector using the cosine similarity formula:", "label": "human"}
{"ID": "00070041", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "cos(u1, u2) =uT 1∗u2 ∥u1∥2∗ ∥u2∥2(2.1) Where u1is the vector representing the customer’s interest in the features, u2 represents the features of a product. If cosu1, u2> threshContent then assume that this product will probably be preferred by customers. The advantage of this approach is that the model building for each customer is independent of other customers, and moreover, the more good features the product has, the more accurate the system will be built.", "label": "human"}
{"ID": "00070042", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Collaborative Based Filtering Collaborative filtering makes recommendations by simultaneously comparingsimilarities between people and items, addressing some of the drawbacks of content based filtering. Serendipitous suggestions are now possible; in other words, collaborative filtering algorithms can suggest an item to user A based on the preferences of a user B who shares those interests. Furthermore, instead of relying on manually designing features, the embeddings can be learned automatically.", "label": "human"}
{"ID": "00070043", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Item-Item In the previous section, I presented the Content-based recommendation method, the main feature of this method is to build a model for each customer without depending on other customers. This has two disadvantages: (i) We do not takeadvantage of information about the buying behavior of our customers, which is useful because the buying behavior of customers can often be grouped into a single category. certain groups, if we know the behavior of some customers in the group, we can infer the behavior of the remaining customers. And (ii), we don’t always have available vectors that show the product’s features in detail.", "label": "human"}
{"ID": "00070044", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The above disadvantages can all be solved by the Neighborhood-based method, specifically in this section, I will present the Item-item collaborative filtering method.", "label": "human"}
{"ID": "00070045", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The next section will present another method called Matrix factorization collaborative filtering that is also in the series of Neighborhood-based methods.", "label": "human"}
{"ID": "00070046", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The basic idea of Neighborhood-based is to determine customer interest in products based on similar customers. So there are two important things here: (i) determining the similarity between customers and (ii) predicting the customer’s interest in a product based on similarity to customers. is different. The determination of similarity between two customers (Similarity matrix) is based on the preferences of two customers for products (through orders), taken from the matrix showing the preferences of the two customers. users to the product (Utility matrix) and calculated according to the cosine similarity formula:", "label": "human"}
{"ID": "00070047", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "sim(u1, u2) =uT 1∗u2 ∥u1∥2∗ ∥u2∥2(2.2) Where u1is the vector representing the customer C1’s interest in the features, u2is the vector representing customer C2’s interest in products. If cosu1, u2> threshContent then assume that 2 users C1, C2have roughly similar interest. Then we will predict customer u’s interest in unknown product iby formula awake :", "label": "human"}
{"ID": "00070048", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "ˆyi,u=P uj∈N(u,i)∗yi,uj∗sim(u, uj)P In which, N(u,)is the set of kcustomers with the highest similarity to u who are interested in the product i.yi,ujis the customer interest ujin the product i. However, in fact, the number of customers is often more than the number of products, so the similarity matrix of users is very large. Moreover, this matrix is usually very sparse (because the number of users who buy many products is small, so for each user,in the product interest vector, there are only a few elements). other than 0). Item item collaborative filtering was born to solve this problem. I evaluate the similarity between products based on the vector showing which products are purchased by customers, and by the formula of cosine similarity. I then recommend the productto users who have purchased similar products with it. This method is similar to the usual Neighborhood-based that I described above, but calculating the similarity matrix between products will become much easier.", "label": "human"}
{"ID": "00070049", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Matrix Factorization For Content-based, Each product is characterized by a vector xthat depicts its features; as this procedure is separate from that of anticipating proposed items, the creation of vector xis crucial. Importantly, creating a model for each unique client will prevent the exploitation of trends in other customers’ behavior.", "label": "human"}
{"ID": "00070050", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "I will discuss matrix factorization collaborative filtering in this section since it will help to mitigate the drawbacks of content-based Assuming that there is no need to pre-build the vector representing the product attributes, we will simultaneously train these vectors against the customer model indicating interest in each product, which will approximate the utility matrix: Y∈RM∗Nis the product of 2 matrices X∈RM∗KandW∈RK∗N.", "label": "human"}
{"ID": "00070051", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "In which Wis the matrix indicating the interest in the features of the entire customer, each column corresponding to a client, and Xis the matrix showing the features of the entire product, each row representing a product. Kis a much smaller number than MandNfor optimal computation, where Mis the number of products and Nis the number of customers.", "label": "human"}
{"ID": "00070052", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The flexibility of the Matrix Factorization approach for Collaborative Filtering in the face of extra constraints, which may be connected to data processing or to particular applications, is one of its advantages. Consider the case where the ratings values are used in the equation without being normalized. Moreover, normalization can be built right into the loss function. As I previously stated, users and/or things are favored in the actual ratings. There are easy-going and meticulous users, and certain goods receive better ratings than others simply because the user notices that other users have previously given them high marks.", "label": "human"}
{"ID": "00070053", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The bias problem can be solved by variables called biases, which depend on each user and item and can be optimized along with XandW. Then the ratings of user n to item m can not only be approximated. equals xmwnbut also depends on the biases of item m and user n. In addition, this value can also depend on the average of all ratings:", "label": "human"}
{"ID": "00070054", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "In which, bm, dn, µis the bias of itemm ,usern . respectively , and the average of allratings (which is constant) At this point, the loss function can be changed to:", "label": "human"}
{"ID": "00070055", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "L(X, W, b, d ) =1 2NX n=1X 2(∥X∥2 F+∥W∥2 F+∥b∥2 2+∥d∥2 2) (2.5)Identifying, evaluating, documenting, and validating the requirements for a software system is the process of performing software requirements analysis. Because it establishes the framework for the whole software development life cycle, this procedure is essential to the success of any software project. By following the key steps below, we can ensure we develop software that meets the needs and expectations of its stakeholders while minimizing the risk of costly errors and delays:", "label": "human"}
{"ID": "00070056", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Elicitation: This entails obtaining details about the needs from key players including clients, business analysts, and end users. To elicit requirements, a variety of techniques can be employed, including interviews, surveys, and brainstorming sessions.", "label": "human"}
{"ID": "00070057", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Analysis and documentation: Following the collection of the requirements,these must be done. For this, the criteria must be divided into smaller, easier to-manage chunks and clearly and succinctly documented.", "label": "human"}
{"ID": "00070058", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Management and tracking: Throughout the software development life cycle, requirements should be monitored and tracked to make sure they are met and that any changes are appropriately recorded and communicated.", "label": "human"}
{"ID": "00070059", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Different requirements have different priorities. The success of the software project depends on the requirements being prioritized according to their significance and viability.", "label": "human"}
{"ID": "00070060", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "For instance, in the context of a banking application, the functional need will be that customers are able to view their most recent account balance when they choose View Balance.\" Software requirements can also be performance-based and non-functional. For instance, a non-functional requirement can be that users should be able to access every page of the system in less than five seconds.", "label": "human"}
{"ID": "00070061", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "I have identified the key operations and procedures for my recommendation system by analyzing the key features and procedures on other e-commerce websites, like Shopee, Tiki, and others.", "label": "human"}
{"ID": "00070062", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Business Process For the product search and selection process, the User can view a list of products in the main screen or display by category. In addition, users can type part of the product name into the search box to search for products. For the process of viewing product details, the user or customer needs to click on the product, the website will display detailed information about the product and some similar products suggested below. Here is activity chart \"Suggest Product\" :", "label": "human"}
{"ID": "00070063", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Usecase Diagram Use case diagram provides a high-level overview of the different functionalities of a system or an application, and it can help stakeholders understand the interactions between the users and the system.", "label": "human"}
{"ID": "00070064", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "In this diagram, there are two main actors: the user, and the admin. Each actor is represented by a stick figure icon. The user can perform various use cases, such as searching products, ing items to the cart, and checking out. The seller can manage the inventory, process orders, and update product information. The payment gateway handles the transaction processing and payment confirmation.Figure 3.2: Usecase Diagram 3.2.4 Decomposition Chart Use case product reviews is performed by User, including small use cases: rating and comment product.", "label": "human"}
{"ID": "00070065", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Rating product : This use case allows a User to rate a product on a scale of 1 to 5. User navigates to the product page of the product they want to rate.", "label": "human"}
{"ID": "00070066", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The option to \"Rate Product\" is chosen by the User. The user can choose their rating on a scale of 1 to 5 using the system. From the scale, the User chooses their rating.", "label": "human"}
{"ID": "00070067", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The \"Add Comment\" option is chosen by the User. For the User to enter their comment, the system displays a form. The User fills up the form with theircomment. The comment is added to the system and shown on the product page. The system adds the rating to the system and displays it on the product page.", "label": "human"}
{"ID": "00070068", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "User Figure 3.3: Usecase Diagram b, Admin Use cases management is performed by Admin, including small use cases: add, modify, delete products or users.", "label": "human"}
{"ID": "00070069", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Admin selects the \"Add Product\" option from the dashboard menu. The system provides a form on which the product’s information, including name, description, price, and image, can be entered.", "label": "human"}
{"ID": "00070070", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Modify product : This use case allows Admin to modify an existing product in the system. Admin selects the \"Manage Products\" option from the dashboard menu. The system displays a list of all the products in the system. The Adminselects the product they want to modify from the list. The system presents editable product information. The administrator updates the product details as necessary. The program verifies the data and changes the product information.", "label": "human"}
{"ID": "00070071", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The admin fills out the form with the necessary product information. The system verifies the input before adding the new product.", "label": "human"}
{"ID": "00070072", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Remove product : This use case allows Admin to delete an existing product from the system. Admin selects the \"Manage Products\" option from the dashboard menu. A list of all the products in the system is displayed by the system. The product the admin wants to remove is chosen from the list. The administrator is asked to confirm the deletion by the system. The deletion is verified by the admin. The product is taken out of the system by the system.", "label": "human"}
{"ID": "00070073", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Use case “View list of suggested products” : In this activity diagram, the user logs in to the system and selects the \"View suggested products\" option. The system then retrieves and analyzes the user’s data to suggest a list of products, which is displayed to the user. The user can browse through the list and select a product to view more details. The system displays the product details, and the user can use the product.Figure 3.6: “View list of suggested products” use case activity diagram 3.4.1 Design overview The package dependency of the application is shown as above, in there:", "label": "human"}
{"ID": "00070074", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Package controller plays the main role of handling web page navigation requests, display the View corresponding to the URL of the page. When the user requests to transfer the change page via URL or system interaction, Controller will find View respectively to display.", "label": "human"}
{"ID": "00070075", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Package API: used to handle requests to manipulate data, provide 3. Service package: contains business handling methods, receives calls from Controllers, processes parameters, and returns results. This package usually calls the methods from the repository package and the utility package to support processing.", "label": "human"}
{"ID": "00070076", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Package repository: contains interfaces that directly manipulate data in the database. This package is responsible for providing the data read and write methods for the service package.", "label": "human"}
{"ID": "00070077", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Entity package: contains classes that map data tables in the database. With this mapping, data manipulation will be done through objects instead of SQL statements.", "label": "human"}
{"ID": "00070078", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Package DTO: contains classes that play the role of data storage, and data transport between packages. With these classes, the data sent and returned is minimized, eliminating unnecessary fields, and increasing the performance ofthe application.", "label": "human"}
{"ID": "00070079", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Histogram of average ratings and ratings count Figure 4.1: Histogram of average ratings and ratings count These 2 charts show the average value of each rating value and the number of ratings for each book. We can see that \"Histogram of average ratings and ratings count\" is quite similar to the normal distribution and \"Histogram of average ratings and ratings count\" has very uneven distribution values, mainly concentrated on one pole of the data set.4.1.2 Histogram of ratings count for each rating value Figure 4.2: Histogram of ratings count for each rating value 4.1.3 Histogram of work ratings count and work text reviews count Figure 4.3: Histogram of work ratings count and work text reviews count 4.1.4 Number of books by language code As we can see from \"Number of books by language code\" histogram most of the books included in the dataset are written in english and variations. About 6,300 volumes are written in English followed by 2070 books written in eng-US.Figure 4.4: Number of books by language code 4.1.5 Number of books over time Figure 4.5: Number of books over time4.1.6 Histogram of rating times by users and books Figure 4.6: Histogram of rating times by users and books This histograms is rating table’s description and from them, we can see that any user can rate from 2 to 200 books and a book can be rated about 100 times. The data visualization helps to somewhat clarify the data set in use.", "label": "human"}
{"ID": "00070080", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Number of times for each rating values Figure 4.7: Number of times for each rating values4.2 Train-Test Split Divide the rating table by each user so that the test data accounts for at least 30% and with the criterion that every user appears in both the train set and the test set, every book appears in the test set. I am able to split the dataset using constraint programming along with the ortools library.", "label": "human"}
{"ID": "00070081", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "x[user_id][book_id] takes value of 1 if rating of user vs user_id for book with book_id in test set, 0 if in train set.", "label": "human"}
{"ID": "00070082", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "For each user_id, call S_user_id the set of book_ids rated by the user then for each user_id: sum of x[user_id][book_id] with book_id belonging to S_user_id must be >= max(1, 0.3 * S_user_id size).", "label": "human"}
{"ID": "00070083", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "For each book_id, T_book_id is the set of user_ids that rate that book then for each book_id, y[book_id] = 1 if and only if the sum of x[user_id][book_id] with user_id of T_book_id must be less than size T_book_id.", "label": "human"}
{"ID": "00070084", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "y[book_id] = 0 if and only if the sum of x[user_id][book_id] and user_id of T_book_id is exactly equal to the size T_book_id.", "label": "human"}
{"ID": "00070085", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "With the above modeling, the problem is solved and the objective function value is exactly equal to 10000 is also the number of books, in the data set or all books appear in the train set.", "label": "human"}
{"ID": "00070086", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The fields used for encoding are : average rating ,work text review count, work rating count, ratings count, ratings 1, ratings 2, ratings 3, ratings 4, ratings 5 ,original publication year ,language code . Where language code uses one-hot-encoding, then apply standard scaler to the above data fields.", "label": "human"}
{"ID": "00070087", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "For each user, build a Ridge Regression problem with the lambda coefficient chosen for the experiment respectively: 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0. (Lambda is often used in loss functions as a regularization term. Regularization is a technique used to prevent overfitting in machine learning models. Overfitting occurs when a model is too complex and fits the training data too closely, resulting in poor performance onnew, unseen data.). The lambda values I mentioned above are used in the following loss function:", "label": "human"}
{"ID": "00070088", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "In item-item collaborative filtering, related things are found based on how similarly users have rated them. The accuracy and effectiveness of the recommendations may vary depending on the number of neighbors or other comparable items that the algorithm takes into account. When the number of neighbors changes in the values 1, 2, 3, 4, 5, the algorithm will consider a different number of similar items for each recommendation. Here is how the number of neighbors can affect the algorithm:", "label": "human"}
{"ID": "00070089", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "If there are only one or fewer neighbors, the algorithm will only take into account the item that is closest to the target item. Personalized recommendations may result from this, but it’s possible that the variety of the user’s preferences won’t be fully reflected.", "label": "human"}
{"ID": "00070090", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "If the number of neighbors is 2 or 3, the algorithm will consider a small set of similar items. This can improve the diversity of the recommendations but may sacrifice accuracy.", "label": "human"}
{"ID": "00070091", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "When there are four or five neighbors, the algorithm will take into account more objects that are comparable. Although it may compromise diversity, this can increase the recommendations’ accuracy.", "label": "human"}
{"ID": "00070092", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "My item-item based collaborative filtering algorithm has the number of neighbors varying in values from 1 to 5. In the user-user algorithm, the number of neighbors varies in 1, 5, 10, 50, 100.", "label": "human"}
{"ID": "00070093", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "With the theoretical basis summarized in the above section, the Matrix Factorization algorithm that I implemented in this section with K being the number of spatial dimensions used to represent users and books whose values change in 50, 100, 150, 200. With a lambda value used of 0.01, the learning-rate is 0.5 I use PyTorch which is a popular open-source machine learning framework that provides efficient tools for matrix factorization. We can perform matrix factorizationwith PyTorch by following steps below :", "label": "human"}
{"ID": "00070094", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Define the model: We need to define a PyTorch model that will perform the matrix factorization. A common model for matrix factorization is the matrix factorization model, which decomposes the input matrix into two lower-dimensional matrices, U and V.", "label": "human"}
{"ID": "00070095", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Define the loss function: The loss function that the model will refine throughout training must be specified. The mean squared error (MSE) loss is a typical loss function for matrix factorization.", "label": "human"}
{"ID": "00070096", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Train the model: To minimize the loss function, we must train the model using stochastic gradient descent (SGD) or another optimizer. To avoid overfitting, we can also employ regularization strategies like L1 or L2 regularization.", "label": "human"}
{"ID": "00070097", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Evaluate the model: After training, we can assess the model’s effectiveness by looking at its holdout test set prediction accuracy. The effectiveness of the model can also be assessed using various measures, such as precision, recall, or F1 score.", "label": "human"}
{"ID": "00070098", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The accuracy of Matrix Factorization algorithm will be shown in the following section when comparing with other algorithms with the same purpose.5.1 User Interface When launching the application, the browser will display the Login UI. User enters required information to access such as email and password.", "label": "human"}
{"ID": "00070099", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "In case the user does not have a login account, the user can access the registration function. Proceed to fill in the necessary information such as nickname, password and email. Each email and nickname can only be used once in each account. Make sure the confirmation password matches the registration password.If you already have an account but forgot your password, you can click the Forget Password\" button to resend the login information via the email you used to register.", "label": "human"}
{"ID": "00070100", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "After logging in, the user can see a list of books that can be read in Search UI. The book search page displays a list of books and detailed information for each book such as reviews, title, year of publication, and book display. Since the number of books is nearly 10,000, pagination is extremely important for ease of search. In addition, users can search for books by entering the name of the book to read in the Find Books\" field.", "label": "human"}
{"ID": "00070101", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Users can view the information of the book when clicking on any book. In the book information screen, users can rate the book by the number of stars the user votes and can read the comments of other customers. User can view book details through Google API.For instance, when clicking the Google Api Button of the Angles book, the system will automatically switch to the screen containing the details of this book through the Google search Next is the most important feature of the project, which is giving a list of suggested books to the user. In this section, the user can choose 1 of 3 algorithms:", "label": "human"}
{"ID": "00070102", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "content-based, item-item based, matrix factorization so that the system gives a list of suggested books.Users can review their personal information in the Profile UI, this screen will contain information such as the customer’s username and email.", "label": "human"}
{"ID": "00070103", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "I use the RMSE value to evaluate the performance of each algorithm and then compare. RMSE stands for Root Mean Squared Error. It is a widely used metric to assess the discrepancy between expected and observed values. The square root of the average of the squared differences between the predicted and actual values is used to calculate RMSE. RMSE is often used in regression analysis to evaluate the accuracy of a model. It provides a single number that summarizes how well the model is performing. The lower the RMSE value, the better the model is atpredicting the target variable.", "label": "human"}
{"ID": "00070104", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "For the item-item algorithm, there is no difference, in other words, the RMSE value is quite large, which means that the performance is still poor.", "label": "human"}
{"ID": "00070105", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "For the user-user algorithm when increasing k (number of neighbors), the RMSE value decreases but is still quite large.6.1 Summary Since the e-commerce website features a highly useful and in-demand built-in recommendation system, the research and development phases have greatly aided my knowledge and practical experience acquisition. Data from another database should first be retrieved, cleaned, and transformed into a form that can be used to create a recommender system. The model should then be built and optimized for the best outcomes. Perhaps you should create a new database that is better suited to holding that data on your website. All of these phases aid in my understanding of and preparation for an AI-integrated software project.", "label": "human"}
{"ID": "00070106", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "About 30 of the volume is made up of the work involved in collecting, processing, and changing the look of data (data must be secure). A little over 40 of the volume is made up of the work involved in researching, creating, analyzing, and optimizing the model. Finally, approximately 30 of the book is devoted to the analysis, design, and construction of websites as well as the learning and application of relevant programming languages.", "label": "human"}
{"ID": "00070107", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The website needs a few additional use cases to be completed, such as I Customers editing personal information, (ii) Customers’ address book, etc. Some features also need to be optimized. Features like I Search and (ii) Get recommended products...", "label": "human"}
{"ID": "00070108", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Add scenarios for session suggestions that are based on customer website access activities (see products, search, add more to the basket, etc.) to appear right after suggested products.", "label": "human"}
{"ID": "00070109", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "By analyzing the data, modifying the user’s scoring method in the train set, and experimenting with different deep learning techniques, the recommender system can be further refined. learning techniques like NeuMF and Deep Matrix Factorization.", "label": "human"}
{"ID": "00070110", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Additionally, my project lacks a set of real test users for the evaluation of the recommender system’s effectiveness, which is another flaw. Collaborative filtering-based Recommendation system,  inelearningcoban.com/2017/05/24/collaborativefiltering  Matrix factorization collaborative filtering -based Recommendation system,  orization  Success of Amazon’s recommendations,  esources/amazon-recommendations-secret-selling-on  PostGresSQL,   Ionic and Asp .Net,  todolist-with-aspnet-core-and-ionic-angular/  Salakhutdinov and Mnih (2007) \"Collaborative Filtering with Restricted Boltzmann Machines\"  Hinton and Salakhutdinov (2006) \"Reducing the Dimensionality of Data with Neural Networks\"  Zhang, Du, and Wang (2016) \"Deep Factorization Machines for Recommender Systems\" Su and Khoshgoftaar \"A Comprehensive Survey on Collaborative Filtering based Recommender Systems\"  Ma et al \"Comparison of Recommendation Algorithms: Experiment on MovieLens Dataset\"  Singh et al \"A Comparative Analysis of Recommendation Algorithms on Yelp Dataset\"Other usecases used in the project. I will describe use case class diagram, activity diagram, etc. They are deployed below A.1 Use Case Login A.1.1 Class diagram In this diagram, there are two main classes: Customer and LoginController. The Customer class represents a user of the system and has properties such as username and password. The LoginController class controls the login process and interacts with the User class and a LoginView class, which represents the database of users and their login information.", "label": "human"}
{"ID": "00070111", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Alternate event streamIf the User has forgotten their password, they can click on the \"Forgot Password\" link, which will prompt them to enter their registered email address.", "label": "human"}
{"ID": "00070112", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "A.2 Use Case Logout A.2.1 Class diagram In this use case, the User actor initiates the logout process by clicking the Logout\" button. The system logs the user out and ends their session, which returns the user to the login screenFigure A.3: Use case class diagram “Logout” A.2.2 Activity Diagram In this activity diagram, the logout process begins with the user clicking on the logout button. The user is then successfully logged out by the system, which also displays a confirmation message. The procedure is then over.Figure A.4: “Logout” use case activity diagram A.2.3 Usecase Specification Usecase UC002-\"Logout\" Usecase codeUC002 Usecase name Logout Intended useUser logout out of the system Actors User Pre-condition User is logged into the system.", "label": "human"}
{"ID": "00070113", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Alternate event streamNoneA.3 Use Case Register A.3.1 Class diagram In this use case, the User actor initiates the registration process by clicking the Register\" button. The user fills out a registration form that is displayed by the system. The system verifies the user’s details once they submit the form, at which point a new user account is created. The system will urge the user to update their information and resubmit the form if there are mistakes in the information they have provided. When a user registers, the system logs them in and directs them to the main application.", "label": "human"}
{"ID": "00070114", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "The system will display an error notice if the data is incorrect or if the registration has already been made. The user then has two options: fix their error and try again, or abort the registration process.Figure A.6: “Register” use case activity diagram A.3.3 Usecase Specification Usecase UC003-\"Register\"Usecase codeUC003 Usecase name Register Intended useUser logout out of the system Actors User Pre-condition User is not currently logged into the system.", "label": "human"}
{"ID": "00070115", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "A.4 Use Case Search Product A.4.1 Class diagram In this use case, the User actor initiates the product search process by entering a search query in the search bar. The user is presented with all products that the system has located and that fit the search criteria. If no matching products are discovered, the system will inform the user that no products were discovered and advise them to narrow down their search.Figure A.7: Use case class diagram \"Search product” A.4.2 Activity Diagram In this activity diagram, the process of searching for a product begins with the user entering a search term. After that, the algorithm looks for items that match the search keyword. The system shows the user the search results if one or more products are discovered. The system displays a notice saying that no matches were discovered if no products are found. The system will display a notification stating that the search term is invalid if it is found to be so. The user then has the option to either continue or end their search.", "label": "human"}
{"ID": "00070116", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "User click on Search bar Activation event Main event stream (success)Ordinal numberPerformed byActivity 1. UserUser enters a search query into the search bar.", "label": "human"}
{"ID": "00070117", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "A.5 Use Case View product information A.5.1 Class diagram In this use case, the User actor views the details page for a selected product.", "label": "human"}
{"ID": "00070118", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "Information about the product, including an image, name, description, price, and availability, is shown by the system. After reading the details, the user may choose to either add the item to their shopping basket or go back to the search results page.", "label": "human"}
{"ID": "00070119", "file_name": "Application of matrix decomposition technique in launching e-book recommendation system", "content": "There aren’t any more flows in this situation. After reading the product details, the customer has the option of either adding the item to their shopping cart or carrying on with their product search.Figure A.9: Use case class diagram \"View product information” A.5.2 Activity Diagram In this activity diagram, the process of viewing product information begins with the user clicking on a product they wish to view. The system then retrieves the information for that product and displays it to the user. The process then ends.Figure A.10: “View product information” use case activity diagram A.5.3 Usecase Specification Usecase UC0005– “View Product Information” Usecase code UC001Usecase nameView product information Intended use For Users to see detailed product information Actors User Pre-condition None Activation event Press choose product Main event stream (success)Ordinal numberPerformed byActivity 1. UserClick on a product to view details 2. SystemGet detailed product information, get information of similar products and display it on the screen. See table below Alternate event streamNoneOrdinal numberData fields Describe Obligatory?Eligibility conditionsExample 1. Product name YesComedy book 2. Price Yes 10$ 3. Mass No 500 g 4. DescribeDetailed product descriptionNo 5. Image Product image link Yes 6. StatusDisplay product information is in stock or notYesOut of stock", "label": "human"}
{"ID": "00080001", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The Relation Extraction (RE) problem is a very important task in Information Extraction. Because of its effectiveness in extracting information from unstructured text, it is the key component of many NLP tasks, such as Information Retrieval , Question Answering  and Knowledge Graph Construction . In particular, a relation extraction system is expected to classify the semantic relation between two entity mentions in the given context. To deal with this problem, many methods have been proposed and achieved remarkable results –. Nevertheless, a majority of previous RE studies only considered the traditional setting where the set of relations is pre-defined and fixed during the training and testing phases. This setting is not practical as new relations of interest might emerge during the deployment time of RE systems in practice, requiring the models to adapt their operation to accommodate new types. Therefore, Continual Relation Extraction was proposed, aiming to learn new relations from new coming data. Recently, CRE has attracted considerable attention in the literature – because of not only its appealing practical applications but also the challenging problems which come from both fields, Continual Learning, and Relation Extraction.", "label": "human"}
{"ID": "00080002", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Compared to conventional RE, CRE has to face the stability-plasticity trade off. Generally speaking, this is a fundamental problem in the continual learning paradigm, where stability relates to maintaining accuracy on the previous tasks, while plasticity relates to learning emerging tasks effectively. Modern deep learning models adapt to new knowledge quickly while lacking stability, this phenomenon is called Catastrophic Forgetting (CF).", "label": "human"}
{"ID": "00080003", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Based on how models mitigate Catastrophic Forgetting, existing approaches can be categorized into one of the following three groups: (1) Regularization-based methods – mitigate catastrophic forgetting by constraining the updates of some network parameters depending on their importance. (2) Dynamic architecture methods ,  adjust network capacity dynamically to learn emerging tasks effectively. (3) Replay-based methods – deploy a memory buffer to save a small number of samples from old tasks for later replay. Among three major approaches, the replay-based method has shown the best results for NLP tasks, including CRE.", "label": "human"}
{"ID": "00080004", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The current state-of-the-art of the CRE task is Contrastive Replay (CRL) which is a replay-based method. Different from previous work, CRL maintains learned knowledge by introducing a contrastive replay mechanism that removes the uses of Softmax classifier and Cross-Entropy loss. It instead proposes to use Supervised Contrastive loss and Nearest Class Mean classifier to make the representation space well-separated. Although CRL outperforms older approaches that use traditional Cross-Entropy loss, it did not learn this pattern in-depth. As a result, it begs the question of why models with Cross-Entropy loss perform so poorly.", "label": "human"}
{"ID": "00080005", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The goal of my research is to investigate the poor performance in the CRE task caused by Cross-Entropy loss. From the investigation, I will propose solutions to improve the performance of the CRE task.", "label": "human"}
{"ID": "00080006", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Existing works in Continual Learning mainly focus on the Catastrophic Forgetting problem, while overlooking other factors. In this thesis, instead of traditional approaches where many methods were proposed to preserve old knowledge, I give a concrete analysis of the transferability of the representations in the CRE setting. Especially, I focus on the bad impact of traditional Cross-Entropy loss on the transferability and how to improve it.", "label": "human"}
{"ID": "00080007", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In an earlier work,  stated an issue in representation learning for image classification, representation bias. First, if the encoder is fixed after learning old tasks, it can preserve the learned representation space but the learned features are only helpful for the old tasks and not for the new tasks to classify. In contrast, if the encoder is updated with new knowledge, the updated representations would be not suitable for previous tasks. For better understanding, I give an example of CRE. First, a classifier is trained to classify between two relations city_of_birth andparents , but I assume that all the cities from city_of_birth samples are located in China. Then the learned feature extractor, by chance, can only classify texts if it mentions China or not. In the next task, it has to classify between capital _ofand siblings , I see that the learned feature cannot help if capital _ofsamples mention cities around the world. This learned feature is considered not transferable. While if the feature extractor can learn a feature that distinguishes between people and places, it can still perform well on classifying between capital _ofandsiblings .", "label": "human"}
{"ID": "00080008", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "This feature is transferable because, without updating the feature extractor, therepresentation space is separated to some extent. If the feature extractor learns non transferable features in the previous task, these features can be changed considerably to adapt to the current task. Consequently, old learned features for previous tasks can be forgotten, leading to the performance reduction on those tasks . Theythen hypothesized that learning transferable and diverse representations is an important requirement for incremental learning. And through a spectral analysis, they found that in representation space, spectral components with large eigenvalues are more transferable and less forgettable.", "label": "human"}
{"ID": "00080009", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Motivated by this work, I conduct a concrete experiment on representation space with spectral decomposition for the CRE task. I found that experimental results in the CRE task show the same pattern, eigenvectors with larger eigenvalues transfer better. Moreover, using the same spectral analysis, I give firm evidence on how the Softmax classifier with CE loss gives worse results compared to the NCM classifier. It is observed that CE loss decreases the eigenvalues of the representation space and hence reduces the transferability of the learned features.", "label": "human"}
{"ID": "00080010", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Based on this experiment, I propose a class-wise regularization that aims to boost the number of eigenvectors with large eigenvalues in the eigenspace of the class-wise data representations. This regularization is inspired by some recent works on dimensional collapse and feature decorrelation , . They try to make the different dimensions of the embedding uncorrelated and intuitively avoid collapse in some dimensions, which at the same time effectively avoids small eigenvalues.", "label": "human"}
{"ID": "00080011", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I conduct a thorough analysis and give an insightful behaviour of representation space in the continual relation extraction setting via the spectral viewpoint.", "label": "human"}
{"ID": "00080012", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Moreover, by using the same spectral analysis, I answer the question of why the NCM classifier gives better performance than the Softmax classifier with CE loss. I find that spectral components with larger eigenvalues have better transferability, and CE loss does decrease the eigenvalues of spectral components, which leads to worse results.", "label": "human"}
{"ID": "00080013", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A simple yet effective class-wise feature decorrelation regularization is proposed with the goal to boost the transferability of the representations. Furthermore, I theoretically show why feature decorrelation helps boost eigenvalues.", "label": "human"}
{"ID": "00080014", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The rest of my thesis is organized as follow.Chapter 2 provides the literature review for my research. First, I show my scope of my research. After that, I will give the overviews for both Relation Extraction and Continual Learning by giving their definitions, some real-life use cases, and the obstacles to the problems. After that, I will give the big picture of the continual relation extraction problem. Moreover, I will introduce existing continual relation extraction methods such as Experience Replay, Contrastive Replay, . . .and their strengths and weaknesses.", "label": "human"}
{"ID": "00080015", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In chapter 3, I will provide the basic background of the techniques and models that I use to propose my method. In the end of the chapter, I will give more details about the current state-of-the-art model in handling the CRE task, Consistent Representation Learning (CRL).", "label": "human"}
{"ID": "00080016", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In chapter 4, I will conduct an experiment on representation space in the continual learning setting through spectral decomposition. In fact, I found the relationship between the transferability of learned features and the eigenvalues of learned features.", "label": "human"}
{"ID": "00080017", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Based on the results from the experiments, I next give proof of the bad impact caused by Cross-Entropy loss with the Softmax classifier on the transferability of features. With the findings from the previous section, I proposed a simple yet effective regularization that tackles the downgrade of the transferability caused by Cross-Entropy loss. In fact, the objective function is motivated by some recent work in dimensional collapse. For the sake of understanding, I will give theoretical proof for my regularizer.", "label": "human"}
{"ID": "00080018", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In chapter 5, extensive experiments on the FewRel and TACRED datasets demonstrate the superior performance of my proposed regularization for the challenging scenario of CRE. My hyper-parameters settings are available at the end of this section for the convenience of reproduction.", "label": "human"}
{"ID": "00080019", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In chapter 6, I give an analysis how my regularizer increases eigenvalues and conduct detailed ablation studies on the effects of it on my model.", "label": "human"}
{"ID": "00080020", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In the final chapter - chapter 7, I will summarize some of the main conclusions, as well as discuss some limitations of this project.2.1 Scope of Research In continual Learning, there are three major scenarios that I will give detailsabout in subsection 2.2.2. However, for the CRE task, I only consider the Class Incremental Learning scenario because it makes a fair comparison with previous works on this problem. Moreover, Class-Incremental Learning is the most practical as well as the most challenging scenario among the three main scenarios. Besides, my thesis focuses only on the replay-based method because it is the dominant and the most effective method in continual NLP problems currently. Finally, because my study aims to investigate the behaviour of the representation space, I will not focus on the architecture of the model. I instead reuse the simple architectures that Iwill give the knowledge base in chapter 3. I also give a brief review of the state-of the-art architecture of Consistent Representation Learning because my experiments on the representation space are based on this model.", "label": "human"}
{"ID": "00080021", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A successful relation extraction system plays a crucial role in exploring unstructured text, and thus is a cornerstone for many other Natural Language Processing tasks, such as Information Retrieval, Question Answering, and Knowledge Graph Construction.", "label": "human"}
{"ID": "00080022", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Generally speaking, relation extraction is a multi-classification problem where learners are trained to predict the relationship between two given entities in a context. For example, given the entity pair [James Cameron, Titanic] in the sentence “Titanic is an epic romance film directed by James Cameron”, the classifier is expected to predict the relation the-director-of .", "label": "human"}
{"ID": "00080023", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Continual Learning Recent advances in Deep Learning have made remarkable progress in building intelligence systems. Many proposed Deep Learning models manage to handle very challenging problems from any field, such as Natural Language Processing, Computer Vision, . . .However, a big drawback in those studies is that they only considered the traditional setting where the task is pre-defined and fixed during the training and testing. Most existing models cannot work well in the real-life context where new tasks might emerge during deployment time. Therefore, the paradigm of Continual Learning is proposed to deal with it. I note that Continual Learning is also referred to as Lifelong Learning, Sequential Learning, or Incremental Learningin some literature.", "label": "human"}
{"ID": "00080024", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Generally speaking, the goal of Continual Learning is to learn from an infinite data stream associated with different tasks and different domains. To give an example, given a classification task, continual learners have to deal with numerous tasks that come consequently, and the number of novel classes grows rapidly. The mission of a continual learner is to perform well on all tasks it has been trained with so far which means it has to perform well on both old datasets and new datasets. This problem of balancing performance on an old and new task is popular in Continual Learning and is called the stability-plasticity trade-off, where stability relates to maintaining accuracy on the previous tasks while plasticity relates to learning emerging tasks effectively. Modern deep learning models adapt to new knowledge quickly while lacking stability, this phenomenon is called Catastrophic Forgetting.", "label": "human"}
{"ID": "00080025", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Catastrophic Forgetting is the fundamental problem in the paradigm of continual learning and most studies in this field are to mitigate it.", "label": "human"}
{"ID": "00080026", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "As mentioned above, the crucial problem in Continual Learning is CatastrophicScenarios Required at test time Task-Incremental Learning Solve tasks so far, task-ID provided Domain-Incremental Learning Solve tasks so far, task-ID not provided Class-Incremental Learning Solve tasks so far and infer task-ID? Table 2.1: Overview of the three continual learning scenarios  Figure 2.1: Split MNIST according to each scenario (Image Source ) Forgetting. Existing continual learning approaches can be categorized into one of the following three groups: (1) Regularization-based methods ,  mitigate catastrophic forgetting by constraining the updates of some network parameters depending on their importance. However, due to the sensitivity of modern neural networks, any changes in network parameters can lead to a big difference in the output. Therefore existing regularization-based methods seem not to solve the continual learning problem effectively. (2) Dynamic architecture methods ,  adjust network capacity dynamically to learn emerging tasks effectively. In detail, the network is extended to handle new tasks while old parameters are kept unchanged with the goal of preserving knowledge on learned tasks so far. In comparison with regularization-based methods, dynamic architecture methods give a better performance but it requires additional capacity for emerging tasks, and thus are not good at scaling. (3) Replay-based methods – deploy a memory buffer to save a small number of samples from old tasks for later replay. Different from the two aforementioned methods, this approach, requires storing samples that are capable of being representatives of old classes. Then to mitigate catastrophic forgettingmodels are trained with data from the current task and stored data.", "label": "human"}
{"ID": "00080027", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Replay-based methods for Continual Relation Extraction Among the three major approaches for mitigating Catastrophic Forgetting, the replay-based method has shown the best results for NLP tasks, including CRE. A number of replay-based CRE models have proven their effectiveness. EA-EMR  proposed a memory replay and embedding alignment technique to mitigate catastrophic forgetting. EMAR  introduced a memory activation and reconsolidation to preserve old knowledge. CML  proposed a curriculum-meta learning method to handle the order-sensitivity and catastrophic forgetting in CRE. RP-CRE  learns a memory network with the goal of refining sample embeddings with relation prototypes, thereby avoiding catastrophic forgetting. ACA  proposed an adversarial class augmentation mechanism to make learned models more robust representations.", "label": "human"}
{"ID": "00080028", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "CRL  maintains learned knowledge by introducing the contrastive replay mechanism and knowledge distillation. KIP-framework  proposed a prompt-based frameworkthat uses the knowledge-injected relation tokens and the relational knowledge infused prototypes to enhance the replay-based model.", "label": "human"}
{"ID": "00080029", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I now give the formulation for the CRE problem. Models were trained on a extraction task and has its own training set Dkand relation set Rk. Formally, each task Tkis a supervised classification task with training set Dkcontaining i=1, where xiis the input sentence and entity pair, and yiis the relation label. As a general goal of continual learning, a CRE system is expected to perform well on both the current task and all previous tasks. Hence models are required to classify each relation into known relation set ˜Rk, where ˜Rk=Sk i=1Ri.", "label": "human"}
{"ID": "00080030", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In addition, in the replay framework, it adapts an episodic memory module to store a few examples of historical tasks. Each relation has its own memory module, i.e., a i=1storing O samples that are capable of being representatives for relation r, where O is the pre-defined number of samples to be stored.3.1 The Transformer architecture and BERT In this section, I give an overview of popular architectures for understanding text data.", "label": "human"}
{"ID": "00080031", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Recurrent Neural Networks and Encoder-Decoder Models To begin with, I introduce the sequence-to-sequence (or seq2seq) problem. Given the following phrase: \"I am going to work today.\" This phrase can be expressed as a sequence of individual words: [I, am, going, to, work, today]. It means \"Tôi sẽ đi làm ngày hôm nay\" in Vietnamese and hence the target sequence would be [Tôi, sẽ, đi làm, ngày, hôm nay]. A successful sequence-to-sequence learner is expected to be able to map the first sequence into the second. In the given example, the model is challenged to perform Translation. There are other problems that can be formulated as sequence-to-sequence learning: Text Summarization, Conversational Modeling, Image Captioning, and more.", "label": "human"}
{"ID": "00080032", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Below are the two primary branches that have been employed for this purpose, but I will cover the main techniques in the next section:", "label": "human"}
{"ID": "00080033", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Classic Recurrent Neural Networks: where the goal is to learn a model that can process the sequence item ( e.g.word, subword, ...) by feeding its representation as input together with the next item from the sequence. In other words, the context for each item will be the words that have already been digested. In a real-life analogy, this resembles a human translator, e.g.one who can translate Vietnamese into English directly.", "label": "human"}
{"ID": "00080034", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Encoder-decoder models: where the goal is to learn an encoder that can process the input sequence into a hidden representation, and a decoder that maps this representation into an output sequence. Continuing the previous analogy, the hidden representation here represents an imaginary language; the encoder is a translator who can translate Vietnamese into this language; the decoder is a translator who converts the imaginary language into English.", "label": "human"}
{"ID": "00080035", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Later in this section, I will demonstrate how Transformers, an exceptional model based on encoder-decoder architecture, utilize recurrent neural networks to learn mappings between sequences.3.1.2 Traditional approaches for Sequence-to-Sequence Learning I will now go into more detail about the definition of Sequence-to-Sequence learning and the ideas behind the two types of models that are generally employed in Seq2seq. I will start by discussing the Recurrent Neural Networks basic design.", "label": "human"}
{"ID": "00080036", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The introduction of Long Short-Term Memory LSTMs and the extremely important mechanism known as attention come next. Finally, I will discuss the Transformer architecture, which is the state-of-the-art and currently the most popular strategy for dealing with Seq2seq.", "label": "human"}
{"ID": "00080037", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Vanilla RNNs: simple Recurrent Neural Networks Previous approaches in Natural Language Processing were sequential in nature. In other words, if we break down the phrase \"I am doing great\" into its component parts [I, am, doing, great ], previous approaches would have to cover each word individually by means of letting the sentence through the entire model in the word by word fashion.", "label": "human"}
{"ID": "00080038", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In detail, inside this recurrent structure, each input is transformed into an output with the help of one cell h. For instance, we know from regular neural networks that the word ikwould become Iif we translated it from Dutch to English. It also connects back to itself, so a better prediction will be made when new input arrives by using the context from previous forward passes. In other words, it makes use of the context that the translation of ik→Iprovides when predicting am.", "label": "human"}
{"ID": "00080039", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "LSTMs: Before the Transformer era, many variants of the classic RNN have been proposed, of which the Long Short-Term Memory (LSTM) is one of the most prominent ones . In these architectures, several gates are used to regulate the flow, i.e.rather than passing the entire hidden state, it partially processes the previous state as well as new inputs.", "label": "human"}
{"ID": "00080040", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "An LSTM network has three extra gates compared to a regular RNN: an input gate, an output gate, and a forget gate. In 3.2, I present the LSTM network visualization.", "label": "human"}
{"ID": "00080041", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "We know that Sigmoid maps each value to the range between 0 and 1. To put it another way, this gate enables the network to learn to forget particular aspects of the cell state based on the current input values and the previous hidden state.", "label": "human"}
{"ID": "00080042", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The second gate is called the input gate, which takes Xtas its input. It is dual in nature, because Xtand the hidden state from the previous cell are passed through here normalizes the data by forcing the input into the [−1,1]range. The Sigmoid function once again maps the combination to [0,1]range, indicating which parts of the input must be retained. After that, what must be maintained and what must be forgotten mix to form the result. This is passed to the third gate, the output gate.", "label": "human"}
{"ID": "00080043", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In this output gate, the hidden state from the previous cell as well as the current input are fed to sigmoid operation to determine what must be maintained dependingon short-term input. This is combined with the short-term input-influenced memory provided by the cell state that has just been altered by the forget and input gates.", "label": "human"}
{"ID": "00080044", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The output is passed to the outer world above and serves as the short-term input for the next cell (providing short-term output context for the next element in the sequence). The memory is also passed to the next cell.", "label": "human"}
{"ID": "00080045", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Attention mechanism By utilizing advantages in backward error computation, LSTMs have outperformed standard, vanilla RNNs in terms of performance. Models built on the RNN architecture so far are still unable to solve the issue of too-long input sequences.", "label": "human"}
{"ID": "00080046", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "This mostly happens because short-term changes are used to update the memory in LSTMs, which adjust the memory depending on short-term ( i.e., current and past input) interrelationships. Longer-term ones can travel through memory, but they eventually fade from memory.", "label": "human"}
{"ID": "00080047", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Scientists  suggested a method called attention as a result. Effectively, this method uses all of the intermediate states—not just the final one—to produce the output prediction. Moreover, by learning weights for various states, it is feasible to instruct the model to focus on different input components based on their relative relevance. In other words, thanks to attention, models no longer face the impact of long-term memory loss.", "label": "human"}
{"ID": "00080048", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "But even so, it was insufficient. Even while memory itself was enhanced by attention, computation was not. This problem affects plain vanilla RNNs and LSTMs alike. Due to the requirement that each token be handled consecutively, the procedure was still sequential. And that is where Transformer came in.", "label": "human"}
{"ID": "00080049", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Attention is all you need: Transformer In a 2017 article, based on the premise that attention is all you need ,  introduce a new architecture. In their work, they described the development of a new model architecture that retains attention but fully eliminates the recurrent aspects of a model. In other words, they made sure that the advantages of attention are still true while drastically lowering the involved computational costs. The specific model architecture is called a Transformer.", "label": "human"}
{"ID": "00080050", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Transformers include both an encoder segment and a decoder segment, similar to LSTMs, which can be utilized as encoder-decoder systems. Figure 3.4 shows the Transformer’s visualization.", "label": "human"}
{"ID": "00080051", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The above figure shows the two basic components of a Transformer: an encoderFigure 3.3: Attention mechanism (Image Source ) segment, which encodes an input into an intermediate representation, and a decoder segment, which decodes the intermediate representation back into readable text.", "label": "human"}
{"ID": "00080052", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "To illustrate, let’s say that our goal is to train a model that can translate English texts into French. In this case, the encoder first converts English into an imagined language, and the decoder, which is also proficient in this language, then converts it back into French.", "label": "human"}
{"ID": "00080053", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I will dive into the encoder in more detail. As can be seen from the visualization, it is composed of the following parts:", "label": "human"}
{"ID": "00080054", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A positional encoding which injects position information into the input embedding, enabling the model to understand the position of certain parts of the input in the input as a whole. Remember that a Transformer no longer has recurrence, therefore positional information must be added in a different way. It is accomplishedFigure 3.4: Transformers Architecture (Image Source ) via positional encoding. In detail, PE(pos,2i) =sin(pos/100002i/dmodel) PE(pos,2i+ 1) = cos(pos/100002i/dmodel)  where posrefers to the position of the “word” in the sequence, iis the dimension index in the input tensor, and dmodel is the dimensionality.", "label": "human"}
{"ID": "00080055", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "An encoder part , which can be identically repeated and stacked up N times, with each repetition enhancing the encoding’s precision. It is made up of a feed-forward section and a multi-head attention segment . Residual connections (i.e.connections that pass the original input to the output, such as the input to the Add Norm aspect, help boost training performance by allowing gradients to flow freely during backpropagation) – The multi-head attention segment allows us to split inputs into queries, keys and values. In fact, the attention mechanism receives three primaryinputs: queries (Q), keys (K), and values (V). All of these inputs can be explained in terms of a \"information retrieval\" system. In general, we send a query for every token in the input sequence. These queries are then compared to a set of keys that characterize the values we are interested in learning more about. How much information from each value to retrieve for a given query depends on how similar the keys are to the provided query. By performing these matches, using self-attention in the certain parts of phrases when encoding certain words. It is multi-headed in that the queries, keys, and values combination can be divided into N parallel chunks, enabling the model to adopt a variety of viewpoints with regard to the mappings being made. The multihead attention blocks are then combined, and layer normalized with the residual input.", "label": "human"}
{"ID": "00080056", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "– The feed forward segment produces the encoding for each individual input. The input is represented in high dimensions by the encoding. A residual connection is available for the free flow of gradients also in this case.", "label": "human"}
{"ID": "00080057", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A (learned) embedding layer allows us to capture the textual data in a way that machines can understand. Like the encoder segment, the embedding is position encoded as well.", "label": "human"}
{"ID": "00080058", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "– A masked multi-head attention segment , when given a specific input word, generates self-attention for the desired outcomes, i.e., which words to focus on. It is masked in the sense that we are unable to predict the future, therefore all words that will appear in a sentence in the future are hidden\" for any given word. Here too, there is a multi-head split followed by a residual adding layer normalization.", "label": "human"}
{"ID": "00080059", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "– A cross multi-head attention segment , where the values from the decoder’s masked multi-head attention block are combined with the keys and values from the encoder outputs. In essence, it enables us to integrate \"key-value mapping\" with real best-matching outcomes (the values). The masked segment’s entire information is then passed as a residual flow.– A feedforward network , with the residual connection allows us to convert the processed input-output combination into a W-dimensional vector, where Wequals the number of words. Finally, using a Softmax function, we can generate the most likely word.", "label": "human"}
{"ID": "00080060", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "We can now better predict the following output token given the encoded input token and the preceding predictions because the predicted outputs have been inserted back into the decoder segment. This approach to working has helped practitioners of natural language processing produce exceptionally impressive text processing outcomes, such as language generation, summarization, translation, and other related tasks. Recurrent neural networks may no longer be the primary choice for developing language models because the Transformers have overcome the problems with long-term memory (by using attention) and computation speed (by getting rid of the recurrent parts).", "label": "human"}
{"ID": "00080061", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Bidirectional encoder representations from transformers - BERT In 2018,  proposed Bidirectional encoder representations from transformers BERT based on Transformer architecture. Note that Transformer model ogirinally contain two key modules, one is an encoder and one is a decoder. However, In BERT, they only take uses of the encoder so BERT is called an encoder-only architecture. In fact, inside a BERT model, they stack a number of encoder blocks up and depending on the number of encoder blocks, they have two versions of BERT:", "label": "human"}
{"ID": "00080062", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "BERT base — 12 layers (transformer blocks), 12 attention heads, 110 million parameters, and has an output size of 768-dimensions.", "label": "human"}
{"ID": "00080063", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "BERT Large — 24 layers (transformer blocks), 16 attention heads, 340 million parameters, and has an output size of 1024-dimensions.", "label": "human"}
{"ID": "00080064", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "BERT is bidirectional as it reads all the input words simultaneously. This actually help BERT to learn a word representation from all of its surrounding words. Researchers pretrained BERT on a large corpus of unlabelled text including the entire Wikipedia (2.500 million words) and book corpus (800 million words) using two strategies called Masked Language Model and Next Sentence Prediction. I give the visualization for both training strategies in figure 3.5.", "label": "human"}
{"ID": "00080065", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Masked Language Model (MLM) : Word sequences are converted into masked words by replacing 15%of each sequence with a [MASK ]token before feeding them into BERT. Based on the context that the non-masked words in the sequence give, the model must then predict the original value of the masked words. TheFigure 3.5: Overall pre-training and fine-tuning procedures for BERT (Image Source ) output words must be predicted as follows:", "label": "human"}
{"ID": "00080066", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Next Sentence Prediction (NSP) : The BERT training process requires feeding pairs of sentences to the model, which then learns to predict whether the second sentence in the pair will come after another in the original text. During training, 50% of the input pairs have a second sentence that is the next sentence in the original text, while in the other 50%, the second sentence is a randomly selected sentence from the corpus. The primary assumption is that the random sentence will not be connected to the first.", "label": "human"}
{"ID": "00080067", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The input is pre-processed in the following way before entering the model to enable in the model’s ability to distinguish between the two sentences in training:", "label": "human"}
{"ID": "00080068", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The first sentence has a [CLS ]token at the start, and each subsequent sentence has a [SEP ]token at the end.", "label": "human"}
{"ID": "00080069", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Each token has a sentence embedding that designates Sentence A or Sentence B. Token embeddings and sentence embeddings have a similar concept.", "label": "human"}
{"ID": "00080070", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "After that, to predict if the second sentences is indeed the subsequent sentence, they perform the following steps:•The entire input sequence is fed into the Transformer model.", "label": "human"}
{"ID": "00080071", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In order to minimize the combined loss function of the two techniques, Masked LM and Next Sentence Prediction are learned jointly when training the BERT model.", "label": "human"}
{"ID": "00080072", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Different from previous works in Relation Extraction,  incorporates the entity-level information into the pre-trained language model, which set the new state-of-the-art for this task. Formally, given a sentence swith two target entities e1ande2. Before feeding to the encoder, four special tokens [E11],[E12],[E21],[E22] are inserted at the start and the end of e1entity and e2entity, respectively. After that, the concatenation of token embeddings [E11]and[E21]is used as the representation for the given sample. It is then feed into a learnable MLP classifier parameterized byWandbas follow:", "label": "human"}
{"ID": "00080073", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "h=LN(W[concat (h11, h21)] +b), where h11, h21are the hidden representations of [E11]and[E21]and LN is a Layer Normalization layer. hserves as the logit for later calculating Cross-Entropy loss.", "label": "human"}
{"ID": "00080074", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The fundamental goal of contrastive learning is to build an embedding space where similar samples stay close together while dissimilar ones are further away.", "label": "human"}
{"ID": "00080075", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The goal of contrastive learning process is visualized in figure 3.6. In recent years, the frame work of contrastive learning has attracted a surge of interest in representationlearning field. Many works were proposed to improve this paradism –.", "label": "human"}
{"ID": "00080076", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Contrastive learning has proven promising performance in many downstream tasks, even competitive to supervised learning , –. This framework can be applied to both supervised and unsupervised settings. On the one hand, if labels are not given , models treat random samples from the same batch of data as negative samples while positive samples are augmented, this setting is also referred to as self-supervised learning . On the other hand, if labels are available, similar samples are those from the same class, and dissimilar samples are those from different classes. Supervised contrastive learning has received extensive attention thanks to its many benefits for representation learning.  verifies that the supervised contrastive loss leads to learned representations more stable to hyperparameter setttings. In one contemporary work,  shows that by combining supervised contrastive loss with cross entropy loss, pre-trained language models are more robust to different level of noise and generalize better to related downstream tasks with limited labeled data. Similar to these works, in my thesis, I combine both objective functions but observe bad results in continual learning setting. Therefore, I conduct an analysis to have a good understanding of this phenomenon.", "label": "human"}
{"ID": "00080077", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Spectral Decomposition Theorem Before delving into PCA, I first give details for Spectral Decomposition (or Eigendecomposition) which is a primary tool to conduct PCA. Given a square matrix A, ifAis symmetric and positive definite, A can always be decomposedas follow:", "label": "human"}
{"ID": "00080078", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "where D is diagonal whose diagonal entries are composed of all eigenvalues of A, and P is orthogonal and has the eigenvectors as its columns.", "label": "human"}
{"ID": "00080079", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "to maximize variance in the representation space. For example, the direction of the first basis vector ( i.e., the first principal component) is chosen to maximize the variation in the predictor space.", "label": "human"}
{"ID": "00080080", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In this thesis, I will not cover the derivation for PCA because it is math-heavy. I instead show the steps to find principal components. Formally, given the output of dimension of the representation space. To conduct PCA, the following steps are performed:", "label": "human"}
{"ID": "00080081", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Identify the principal components: It is trivial that Covis symmetric and positive definite so we apply the spectral decomposition on it.", "label": "human"}
{"ID": "00080082", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "where P is orthogonal and has its columns as principal components and D is diagonal whose diagonal entries are composed of all eigenvalues of Covas well as variances along corresponding principal components.", "label": "human"}
{"ID": "00080083", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "It is clear that PCA find 2 principal components that are orthogonal to one another and maximize variance in the space.Figure 3.8: PCA of a multivariate Gaussian distribution centered at (1,3) with a standard deviation of 3 in roughly the (0.866, 0.5) direction and of 1 in the orthogonal direction.", "label": "human"}
{"ID": "00080084", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The vectors shown are the eigenvectors of the covariance matrix scaled by the square root of the corresponding eigenvalue, and shifted so their tails are at the mean.", "label": "human"}
{"ID": "00080085", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In a recent work, to tackle the continual image classification task,  investigated the transferability of the the learned features by using spectral decomposition on the representation space. The experiment is designed to illustrate the sensitivity of each spectral component in the representation space. In detail, the learner is trained with only two consequence tasks then they monitor how each eigenvalue adjusts after learning the second task. Dataset from the first task is feed into two version of models, the first version is the model trained on only task 1 and the second one is the model after training on both tasks. Therefore, there are two versions of representation space and they apply spectral decomposition on both spaces to get its eigenvalues. If the eigenvectors change significantly after training task 2, these directions are considered as forgettable directions because they cause the change in the shape of the data distribution. In figure 3.9, they compared eigenvalues before and after training with the second task using Corresponding Angles, which will be defined formally in subsection 4.4. One of the most important takeaways is that spectral components with large eigenvalues change insignificantly and thus are transferable. Based on that insight, they proposed a novel augmentation methodcalled Dual Augmentation which can enlarge the spectral components to introduce more diverse and transferable representations for incremental learning.", "label": "human"}
{"ID": "00080086", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In recent years, dimensional collapse ,  has attracted a surge of interest in representation learning field. Dimensional collapse happens when the projected features collapse into a low-dimensional manifold, which has been shown to harm the generalization of learned features.  verifies the connection between dimensional collapse and strong correlation, and shows that feature decorrelation can help mitigate the problem. Many works using feature decorrelation in self-supervised setting ,  has illustrated competitive performance in comparison with conventional contrastive learning methods.", "label": "human"}
{"ID": "00080087", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Meanwhile, in continual learning, the phenomenon of strong correlation is still overlooked. Different from earlier works in continual learning, I conduct an analysis on the correlation between axes in embedding space via spectral analysis and indicate the relationship between the transferability of the learned representation and the strong correlation. Based on that, I propose a feature decorrelation regularization to alleviate the strong correlation and improve the transferability of learned presentations.3.7 Overall Framework of Supervised Contrastive Learning in CRE In order to conduct an experiment which is built on the framework of Supervised Contrastive Learning in CRE, I give a review for this model briefly. For the formulation of the CRE task, I abuse the notations from subsection 2.2.3. In a recent work, to tackle the CRE problem,  introduced a replay-based method, Consistent Representation Learning (CRL), where feature representations are learned using Supervised Contrastive Learning ( SCL) and an Nearest Class Mean (NCM) classifier is used for classification. For the sake of later understanding, in this section, I review the overall framework of CRL briefly. The essential steps of consistent representation learning are depicted in figure 3.10.", "label": "human"}
{"ID": "00080088", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Initial training for new task ( 4 - 11): The parameters of the encoder and projector head are trained on the training sample in Dkwith SCL loss LCL.", "label": "human"}
{"ID": "00080089", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Sample selection ( 12 - 13): For each relation r∈Rk, we retrieve all samples labeled rfrom Dk. Then, the k-means algorithm is used to cluster the samples. The relation representation of the sample closest to the center is selected and stored in memory for each cluster.", "label": "human"}
{"ID": "00080090", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Consistent representation learning ( 16 - 23): In order to keep the embedding of historical relations in space consistent after learning new tasks, we perform SCL loss Contrastive Replay LCRand knowledge distillation constraints on the samples in memory.", "label": "human"}
{"ID": "00080091", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I note that, despite of both being SCL, there are differences between LCLandAlgorithm 1 (CRL) Training procedure for Tk Input: The training set of Dkof the k-th, encoder E, projection head Proj, history memory Mk−1, current relation set Rk, history relation set ˜Rk−1 Output: Encoder fk(·), history memory Mk, history relation set ˜Rk 1:ifTkis not the first then 2: get memory knowledge with EonMk−1; 3:end if 4:Mb←E(Dk); 5:fori←1toepoch 1do 6: foreach x j∈DKdo 7: Sample from Mb; 8: Update EandProj with∇LCL; 9: Update Mb; 10: end for 11:end for 12:Select informative examples from Dkto store into ˜M 13:Mk←Mk−1∪˜M; 14:Rk←˜Rk−1∪Rk; 15:ifTkis not the first then 16: ˜Mb←E(Mk); 17: fori←1toepoch 2do 18: foreach x j∈Mkdo 19: Sample from ˜Mb; 20: Update EandProj with∇LCRandLKL; 21: Update ˜Mb; 22: end for 23: end for 24: Select informative examples from Dkto store into ˜M; 25: Mk←Mk−1∪˜M; 26:end if 27:return E ,Mk,˜Rk LCR. In step 1, initial training for new task, for each batch B,LCLis computed as follows:", "label": "human"}
{"ID": "00080092", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "LCL=X i∈I−1 parameter controling the separation of classes. The slight difference in computingLCRis that it uses the stored sample in the entire memory bank:", "label": "human"}
{"ID": "00080093", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "LCR=X i∈I−1 where ˜SIrepresents the set of indices of all samples in ˜Mb.˜Mbis the memory bank, which stores the normalized representation of all samples in Mk.", "label": "human"}
{"ID": "00080094", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A remarkable point in this approach is that it removes the use of soft-max classifier and cross-entropy loss which is the traditional go-to method for classification.", "label": "human"}
{"ID": "00080095", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "However it still set the state-of-the-art on two CRE dataset benchmarks.4.1 Overview First, I do an analysis to monitor the changes on the representation space using spectral decomposition. Based on the findings from this analysis, I indicate the relationships between the Cross-entropy loss and the transferablity of the learned features. Finally, I propose a simple yet effective regularization to mitigate the bad impact caused by Cross-entropy loss.", "label": "human"}
{"ID": "00080096", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Inspired by , in this section I aim to explore the changes in representation space before and after learning new tasks. Concretely speaking, I monitor how every eigenvector of deep feature space is adjusted after updating new knowledge thanks to spectral decomposition. Formally, I first train a feature extractor on dataset i=1of current task, denoted as Fold. After finetuning Foldon new i=1, I obtain an updated extractor, denoted as Fnew. To measure the sensitivity of learned space, I use old dataset Doldand map it into old space and new space using FoldandFnewrespectively. Let Fold(xi)andFnew(xi)be mapped features of a sample xion old and new spaces, I do spectral decomposition on the correlation matrix as follows:", "label": "human"}
{"ID": "00080097", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "i=1˜F(xi)˜F(xi)T=dX j, where in the L.H.S, ˜Fis the mapped feature Fafter normalizing, while in the order and ujis its corresponding eigenvector. Applying this decomposition on both old representations and new ones, Fold(xi)andFnew(xi), I obtain two set of In order to investigate the transferability of the learned features through spectral components,  introduced the definition of Corresponding Angle : given two angle presents the angle between two eigenvectors corresponding to the same eigenvalue index. The cosine value of the corresponding angle is computed as follows:", "label": "human"}
{"ID": "00080098", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "∥uold,j∥ · ∥unew,j∥(2)=⟨uold,j,unew,j⟩, where uold,jis the j-theigenvectors with the j-thlargest eigenvalue in the old featurespace, and similarly for unew,j. Additionally, because ∥uold,j∥=∥unew,j∥= 1, the (2)=is trivial.", "label": "human"}
{"ID": "00080099", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "For continual learning, if the shape ( i.e.covariance) of the representation distribution of each old class does not change much after learning new tasks, the previous knowledge is well-preserved. Moreover, through the spectral analysis viewpoint, an eigenvector direction that is adjusted slightly after updating will have a small corresponding angle, and vice versa. Therefore, monitoring the corresponding angle can give helpful information about representation shift: eigenvectors that do not change much preserve knowledge well, while ones that significantly change do not carry helpful knowledge in terms of reducing catastrophic forgetting.", "label": "human"}
{"ID": "00080100", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Cosine values of correspoding anglesFewRel Eigenvalue rank indexCosine values of correspoding anglesTACRED Eigenvalue rank index6 Log of eigen valuesFewRel Eigenvalue rank index8 4 0246Log of eigen valuesTACRED scl scl_ce", "label": "human"}
{"ID": "00080101", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I conduct an experiment to explore which part, i.e., which direction of the representation space carries helpful knowledge in CRE setting. For experiment details, I simply use one pretrained language model, i.e., BERT  as a feature extractor, one ar classifier on top of the feature extractor and train on the first two tasks of the FewRel and TACRED datasets using CE loss to examine learned feature space. Figure 4.1 shows the absolute cosine values of the corresponding angles between the old and new eigenvectors. It is clear that, after updating, eigenvectorswith large eigenvalues adjust insignificantly and are therefore good at preserving the shape of the data distribution, while ones with small eigenvalues tend to move towards some different direction and can be considered as forgettable directions.", "label": "human"}
{"ID": "00080102", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Recent works in continual learning has preferred the NCM classifier than the conventional Softmax classifier (trained with CE loss) because of better performance , . Intuitively, the NCM classifier requires the quantity and the quality of vectors that they use to compute class-mean vectors (prototypes) to perform well.", "label": "human"}
{"ID": "00080103", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Despite not suffering from these issues, the Softmax classifier with CE loss usually gives poor results compared to the NCM classifier. However, previous works did not give explanations for this phenomenon in the CRE problem. Different from prior works, I study this pattern in-depth by revisiting the Softmax Classifier with Cross-Entropy Loss via the spectral analysis viewpoint. The experiment is set up similar to CRL  mentioned in subsection 3.7. However, to see how CE loss affects CRE performance, I introduce CE loss LCE:", "label": "human"}
{"ID": "00080104", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "where Dkis the training set of task Tk. To compare with original CRL model, I include CE loss LCEto the overall loss, and train model on two versions, with and without LCE:", "label": "human"}
{"ID": "00080105", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I train the model with the two loss versions on only the first task of FewRel and TACRED datasets. I then investigate the representation space using spectral decomposition. As depicted in Figure 4.1, it is clear that training model with LCL+CEleads to smaller eigenvalues than that with LCE. Therefore, by aforementioned reasonings in subsection 4.2, including LCEwill reduce the transferability of learned representations. Moreover, to give firm evidence that LCEdoes reduce the transferability and hence harm the performance, I train CRL with LCEon two benchmark datasets and compare it with original version in chapter 5. The results are given in Table 5.1.", "label": "human"}
{"ID": "00080106", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "With the previous finding in subsection 4.4, my goal is to boost the number of eigenvector with large eigenvalues of the deep feature space.  indicated the relationship between strong correlation and dimensional collapse, which leads to the idea of feature decorrelation. Based on this finding, I propose a simple technique that enlarges eigenvalues and improves the transferability of representations.Formally, in each batch, for a given label r, the correlation matrix of ris estimated as:", "label": "human"}
{"ID": "00080107", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Is the encoder output representation on the i-thdata point of class r while the mean vector of ris denoted as ¯Zr=1 nPn i=1(Z(r) i). The data representations is explicitly constrained by a class-wise feature decorrelation regularization:", "label": "human"}
{"ID": "00080108", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I give the theoretical proof on how feature decorrelation enlarges the eigenvalues in the next section 4.5. The overall objective function is given by:", "label": "human"}
{"ID": "00080109", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "L′ overall loss. The overall framework 1 therefore remains unchanged, but in ( 8), I update EandProj with∇L′ CLand in (line 20) , I update with ∇L′ CR.", "label": "human"}
{"ID": "00080110", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Without the loss of generality, I give a proof for my loss LFDon a specific class r, denoted as L(r) FD:", "label": "human"}
{"ID": "00080111", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "dX Above equalities hold because the entries on the main diagonal of a correlationmatrix are 1’s. Now, consider my proposed loss L(r) FD, we have:", "label": "human"}
{"ID": "00080112", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "The problem now is to find out which is the eigenvalue of the matrix K(r)−Id. In i=1. Therefore, we have:", "label": "human"}
{"ID": "00080113", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I perform my experiments on two English benchmark datasets: FewRel and TACRED . The training-test-validation split ratio is 3:1:1. FewRel  is a RE dataset that contains 80 relations and 56,000 samples in total. To make it a continual RE dataset, I follow the settings in  and use the original train set and validation set for my experiments. TACRED  is an imbalanced RE dataset that contains 42 relations (including no_relation ) and 106,264 samples. Following the experiment settings by , to reduce the imbalance, I remove the no_relation class and limit the number of training samples of each relation to 320 and the number of testsamples of each relation to 40.", "label": "human"}
{"ID": "00080114", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I use average accuracy on all seen tasks to measure model performance on the CRE task because it shows model performance on previous tasks and thus highlights how well models handle catastrophic forgetting .", "label": "human"}
{"ID": "00080115", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "KIP-framework  proposed a prompt-based framework that uses the knowledge injected relation tokens and the relational knowledge-infused prototypes to enhance the replay-based model.", "label": "human"}
{"ID": "00080116", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Following , I adopted a completely random sampling strategy on relation level in my experiments. In detail, relations are randomly divided into 10 clusters to simulate 10 tasks. In terms of environment and configuration, I train all models on the same task sequence used in ,  by setting exactly the same random seed.", "label": "human"}
{"ID": "00080117", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Moreover, all of my experiments are conducted on the same environment to make a fair comparison among all models. My implementation and hyper-parameters settings are available on released source code for the convenience of reproduction.", "label": "human"}
{"ID": "00080118", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Note that I include 2 versions of CRL, one denoted as CRL is from original workand one denoted as CRL †is trained under the same environment and configuartion with my model. Moreover, I ablate the proposed regularization with two purposes, highlighting the bad impact of CE loss in CRE and showing the effect of my regularization. I give some discussions as follows:", "label": "human"}
{"ID": "00080119", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "First, it is observed that without my proposed regularization, the model is the original CRL combined with CE loss, and its performances are poor compared to the original one, especially on TACRED. In detail, combining CE loss leads to drop 0.1%and 0.6 %on FewRel and TACRED datasets, respectively. It therefore shows the negative impacts of CE loss on continual learning. The reason why there is a large performance gap on TACRED is because the CE loss reduces the eigenvalues significantly. While on FewRel, model still performs well as CE loss does not hurt eigenvalues too much, see Figure 4.1.", "label": "human"}
{"ID": "00080120", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Second, by including my proposed regularization, I set new state-of-the-art performance on two CRE benchmark datasets. My model performs better than current SOTA, CRL by 0.8 %on FewRel and 0.6%on TACRED. It is remarkable that, compared to the version trained without my regularization, it improves the performance from 84.1%to85.0%on FewRel and from 79.4%to80.6%on TACRED. It indicates the effectiveness of my proposed regularizer.", "label": "human"}
{"ID": "00080121", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Description of computing infrastructure used : In this work, I use a single Tesla A100 GPU with 100GB memory operated by Ubuntu Server 18.04.3 LTS for all experiments. PyTorch 1.8.1 and Huggingface-Transformer 4.23.1 (Apache License 2.0) are used to implement the models.", "label": "human"}
{"ID": "00080122", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Average runtime : Training each task on average takes 54 minutes for FewRel dataset and 18 minutes for TACRED dataset. For each task, in both phase 1 (Initial training for new task) and phase 3 (Consistent representation learning) I train the model for 10 epochs following the experiments by . The best epoch is chosen based on F1 score over validation data.", "label": "human"}
{"ID": "00080123", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Number of parameters in the model : There are approximately 110 million parameters in total, including 110 million from the feature extractor and very few parameters, compared to the feature extractor, from the softmax classifier and the projection in the SCL framework.", "label": "human"}
{"ID": "00080124", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Bounds for each hyper-parameter : To tune the proposed objective function, 0.75,1.0,1.25,1.5,2.0,5.0], and µfrom [ 0.1,0.25,0.5,0.75,1.0,1.25,1.5,2.0,5.0].•The method of choosing hyper-parameter values and the criterion used to select among them : We choose the hyper-parameters for the proposed model using manual tuning. All the hyper-parameters are selected based on F1 scores on the validation set.", "label": "human"}
{"ID": "00080125", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Hyperparameter configurations for best-performing models : In my model, I use the following values for the hyper-parameters: 1e-5 for the learning rate with the Adam optimizer; 64 for the mini-batch size; 1 layer softmax classifier.", "label": "human"}
{"ID": "00080126", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Supervised contrastive projection follows the original experiment in  with TACRED.0 100 200 300 400 500 600 700 800 Eigenvalue rank index6 2 024Log of eigen valuesFewRel scl scl_ce our 0 100 200 300 400 500 600 700 800 Eigenvalue rank index8 4 0246Log of eigen valuesTACRED scl scl_ce our Figure 6.1: Distribution of eigenvalues for model trained with Cross-Entropy loss (scl_ce) and one without Cross-Entropy loss (scl) and one with Cross-Entropy loss and my proposed regularization (my model).", "label": "human"}
{"ID": "00080127", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "In this section, I show the effectiveness of my proposed regularization in terms of enlarging eigenvalues. I conduct the same experiment as in subsection 4.2 on three models: CRL, CRL with LCE, CRL with LCEandLFD. The gap in eigenvalues (Figure 6.1) shows that my feature decorrelation regularization actually increases the number of eigenvectors with large eigenvalues.", "label": "human"}
{"ID": "00080128", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I emphasize that, my proposed regularization reduces the number of eigenvectorswith small eigenvalues by penalizing the top eigenvalues and boosting the eigenvalues with lower indices, see section 4.5. Note that reducing top eigenvalues to some extent does not reduce the number of eigenvectors with large eigenvalues, as shown in Figure 6.1, the top eigenvectors trained with my models are slightly smaller than scl and scl_ce, thus giving a good effect in general.7.1 Summary In this work, I conduct a thorough study on the transferability of the representations in the CRE problem through spectral analysis and observe that eigenvectors with larger eigenvalues carry more transferable knowledge. Moreover, I explore the effect of a Softmax classifier with Cross-Entropy loss on the eigenvalues. In fact, it decreases the eigenvalues and thereby leads to worse transferable representations.", "label": "human"}
{"ID": "00080129", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Based on these findings, I introduce a class-wise feature decorrelation regularization with the goal of boosting eigenvalues to get better representations in terms of transferability. With the proposed constraint, I can take advantage of both mechanisms supervised contrastive learning and the Softmax classifier. My theoretical analysis shows the effectiveness of my proposed method in handling the decrease of eigenvalues caused by Cross-Entropy loss. Furthermore, my extensive experiments on two benchmark datasets show the superior performance of my method.", "label": "human"}
{"ID": "00080130", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Although I do an analysis to indicate that eigenvectors with larger eigenvalues carry more helpful features, there is a lack of interpretation in these directions.", "label": "human"}
{"ID": "00080131", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "It would be preferable to provide some examples to demonstrate the superiority of these directions and make them more understandable.", "label": "human"}
{"ID": "00080132", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Like all of prior works about CRE, I only focus on classifying a pair of entities into relation types when given those entities in a context. To aim to a complete solution for CRE, the problem of named entity recognition should be studied in the continual learning scenarios. C. Xiong, R. Power andJ. Callan, “Explicit semantic ranking for academic search via knowledge graph embedding,” inProceedings of the 26th International Conference on World Wide Web jourser WWW ’17, Perth, Australia: International World Wide Web Conferences Steering Committee, 2017, 1271–1279, ISBN:", "label": "human"}
{"ID": "00080133", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "D. Sorokin andI. Gurevych, “Context-aware representations for knowledge base relation extraction,” inProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing Copenhagen, Denmark: Association for Computational Linguistics, september 2017, pages 1784–1789. DOI:", "label": "human"}
{"ID": "00080134", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "L. Baldini Soares, N. FitzGerald, J. Ling andT. Kwiatkowski, “Matching the blanks: Distributional similarity for relation learning,” inProceedings of the 57th Annual Meeting of the Association for Computational Linguistics Florence, Italy: Association for Computational Linguistics, july2019, pages 2895–2905.", "label": "human"}
{"ID": "00080135", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "D. Zeng, K. Liu, S. Lai, G. Zhou andJ. Zhao, “Relation classification via convolutional deep neural network,” inProceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers Dublin, Ireland: Dublin City University andAssociation for Computational Linguistics, august 2014, pages 2335–2344. url:", "label": "human"}
{"ID": "00080136", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "P. Zhou, W. Shi, J. Tian andothers , “Attention-based bidirectional long short term memory networks for relation classification,” inProceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2:", "label": "human"}
{"ID": "00080137", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "R. Zhang, F. Meng, Y. Zhou andB. Liu, “Relation classification via recurrent neural network with attention and tensor layers,” Big Data Mining and Analytics , jourvol 1,number 3,pages 234–244, 2018. DOI:10.26599/BDMA.", "label": "human"}
{"ID": "00080138", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "embedding alignment for lifelong relation extraction,” inProceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) Minneapolis, Minnesota: Association for Computational Linguistics, june 2019, pages 796–806. DOI:10.18653/v1/N19-1086 .url:https:", "label": "human"}
{"ID": "00080139", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "X. Han, Y. Dai, T. Gao andothers , “Continual relation learning via episodic memory activation and reconsolidation,” inProceedings of the 58th Annual Meeting of the Association for Computational Linguistics On: Association for Computational Linguistics, july2020, pages 6429–6440. DOI:10.18653/ v1/2020.acl-main.573 .url:", "label": "human"}
{"ID": "00080140", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "L. Cui, D. Yang, J. Yu andothers , “Refining sample embeddings with relation prototypes to enhance continual relation extraction,” inProceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) On: Association for Computational Linguistics, august 2021, pages 232–243. DOI:10.18653/v1/2021.acl-long.", "label": "human"}
{"ID": "00080141", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "K. Zhao, H. Xu, J. Yang andK. Gao, “Consistent representation learning for continual relation extraction,” inFindings of the Association for Computational Linguistics: ACL 2022 Dublin, Ireland: Association for Computational Linguistics,may 2022, pages 3402–3411. DOI:10.18653/v1/2022.findings acl.268 .url:", "label": "human"}
{"ID": "00080142", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "J. Kirkpatrick, R. Pascanu, N. Rabinowitz andothers , “Overcoming catastrophic forgetting in neural networks,” Proceedings of the National Academy of Sciences , jourvol 114,number 13,pages 3521–3526, 2017. DOI:10.1073/pnas.", "label": "human"}
{"ID": "00080143", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "F. Zenke, B. Poole andS. Ganguli, “Continual learning through synaptic intelligence,” inProceedings of the 34th International Conference on Machine Learning D. Precup andY. W. Teh, editors ,jourser Proceedings of Machine Learning Research, volume 70, PMLR, 2017, pages 3987–3995. url:https:", "label": "human"}
{"ID": "00080144", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Bagdanov, “Rotate your networks: Better weight consolidation and less catastrophic forgetting,” 2018 24th International Conference on Pattern Recognition (ICPR) , pages 2262–2268, 2018.", "label": "human"}
{"ID": "00080145", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "C. Fernando, D. S. Banarse, C. Blundell andothers , “Pathnet: Evolution channels gradient descent in super neural networks,” ArXiv ,jourvol abs/1701.08734, 2017.", "label": "human"}
{"ID": "00080146", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "D. Lopez-Paz andM. Ranzato, “Gradient episodic memory for continual learning,” inProceedings of the 31st International Conference on Neural Information Processing Systems jourser NIPS’17, Long Beach, California, USA: Curran Associates Inc., 2017, 6470–6479, ISBN: 9781510860964.", "label": "human"}
{"ID": "00080147", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "R. Aljundi, F. Babiloni, M. Elhoseiny, M. Rohrbach andT. Tuytelaars, “Memory aware synapses: Learning what (not) to forget,” inEuropean Conference on Computer Vision 2017.", "label": "human"}
{"ID": "00080148", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A. Chaudhry, M. Ranzato, M. Rohrbach andM. Elhoseiny, “Efficient lifelong learning with a-GEM,” inInternational Conference on Learning Representations 2019. url: .", "label": "human"}
{"ID": "00080149", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Revisiting the nearest class mean classifier in on class-incremental continual learning,” 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) ,pages 3584–3594, 2021.", "label": "human"}
{"ID": "00080150", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "F. Zhu, Z. Cheng, X.-y. Zhang andC.-l. Liu, “Class-incremental learning via dual augmentation,” inAdvances in Neural Information Processing Systems M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang andJ. W. Vaughan, editors ,volume 34, Curran Associates, Inc., 2021, pages 14 306–14 318.", "label": "human"}
{"ID": "00080151", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "J. Zbontar, L. Jing, I. Misra, Y. LeCun andS. Deny, “Barlow twins: Self supervised learning via redundancy reduction,” inInternational Conference on Machine Learning 2021.", "label": "human"}
{"ID": "00080152", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A. Bardes, J. Ponce andY. LeCun, “VICReg: Variance-invariance-covariance regularization for self-supervised learning,” inInternational Conference on Learning Representations 2022. url:https : / / openreview. net / forum?id=xm6YD62D1Ub . G. M. Van de Ven andA. S. Tolias, “Three scenarios for continual learning,” arXiv preprint arXiv:1904.07734 , 2019.", "label": "human"}
{"ID": "00080153", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "T. Wu, X. Li, Y.-F. Li andothers , “Curriculum-meta learning for order robust continual relation extraction,” inAAAI Conference on Artificial Intelligence 2021.", "label": "human"}
{"ID": "00080154", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "P. Wang, Y. Song, T. Liu andothers , “Learning robust representations for continual relation extraction via adversarial class augmentation,” inProceedings of the 2022 Conference on Empirical Methods in Natural Language Processing Abu Dhabi, United Arab Emirates: Association for Computational Linguistics, december 2022, pages 6264–6278. url:https : / / aclanthology.", "label": "human"}
{"ID": "00080155", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "H. Zhang, B. Liang, M. Yang, H. Wang andR. Xu, “Prompt-based prototypical framework for continual relation extraction,” IEEE/ACM Transactions on Audio, Speech, and Language Processing ,jourvol 30,pages 2801–2813, 2022. DOI:10.1109/TASLP .2022.3199655 .", "label": "human"}
{"ID": "00080156", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "N. V. Anh, Transformers - \"Người máy biến hình\" biến đổi thế giới NLP ,  hinh-bien-doi-the-gioi-nlp-924lJPOXKPM , [On; accessed 20-February-2023], 2020.", "label": "human"}
{"ID": "00080157", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "T. Luong, H. Pham andC. D. Manning, “Effective approaches to attention based neural machine translation,” inProceedings of the 2015 Conference on Empirical Methods in Natural Language Processing Lisbon, Portugal:", "label": "human"}
{"ID": "00080158", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A. Vaswani, N. Shazeer, N. Parmar andothers , “Attention is all you need,” inAdvances in Neural Information Processing Systems I. Guyon, U. V. Luxburg, S. Bengio andothers ,editors ,volume 30, Curran Associates, Inc., 2017.", "label": "human"}
{"ID": "00080159", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "J. Devlin, M.-W. Chang, K. Lee andK. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” arXiv preprint arXiv:1810.04805 , 2018.", "label": "human"}
{"ID": "00080160", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "S. Wu andY. He, “Enriching pre-trained language model with entity information for relation classification,” inProceedings of the 28th ACM InternationalConference on Information and Knowledge Management jourser CIKM ’19, Beijing, China: Association for Computing Machinery, 2019, 2361–2364, ISBN: 9781450369763. DOI:10.1145/3357384.3358119 .url:https:", "label": "human"}
{"ID": "00080161", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "K. He, H. Fan, Y. Wu, S. Xie andR. Girshick, “Momentum contrast for unsupervised visual representation learning,” in2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020, pages 9726–9735.", "label": "human"}
{"ID": "00080162", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "T. Chen, S. Kornblith, M. Norouzi andG. Hinton, “A simple framework for contrastive learning of visual representations,” inProceedings of the 37th International Conference on Machine Learning H. D. III andA. Singh, editors ,jourser Proceedings of Machine Learning Research, volume 119, PMLR, 2020, pages 1597–1607. url:", "label": "human"}
{"ID": "00080163", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Z. Wu, Y. Xiong, S. X. Yu andD. Lin, “Unsupervised feature learning via non-parametric instance discrimination,” 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition ,pages 3733–3742, 2018.", "label": "human"}
{"ID": "00080164", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "R. D. Hjelm, A. Fedorov, S. Lavoie-Marchildon andothers , “Learning deep representations by mutual information estimation and maximization,” inInternational Conference on Learning Representations 2019. url:", "label": "human"}
{"ID": "00080165", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "P. Bachman, R. D. Hjelm andW. Buchwalter, “Learning representations by maximizing mutual information across views,” inProceedings of the 33rd International Conference on Neural Information Processing Systems Red Hook, NY, USA: Curran Associates Inc., 2019.", "label": "human"}
{"ID": "00080166", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "A. van den Oord, Y. Li andO. Vinyals, “Representation learning with contrastive predictive coding,” CoRR ,jourvol abs/1807.03748, 2018. arXiv: 1807 .", "label": "human"}
{"ID": "00080167", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Y. Tian, D. Krishnan andP. Isola, “Contrastive multiview coding,” inComputer Vision – ECCV 2020 A. Vedaldi, H. Bischof, T. Brox andJ.-M. Frahm, editors , Cham: Springer International Publishing, 2020, pages 776–794, ISBN: 978-3-030-58621-8. O. J. Henaff, A. Srinivas, J. D. Fauw andothers ,Data-efficient image recognition with contrastive predictive coding , 2020. url:", "label": "human"}
{"ID": "00080168", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "R. Hadsell, S. Chopra andY. LeCun, “Dimensionality reduction by learning an invariant mapping,” in2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’06) volume 2, 2006, pages 1735–1742.", "label": "human"}
{"ID": "00080169", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "I. Misra andL. v. d. Maaten, “Self-supervised learning of pretext-invariant representations,” inProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020.", "label": "human"}
{"ID": "00080170", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "X. Chen, H. Fan, R. B. Girshick andK. He, “Improved bases with momentum contrastive learning,” CoRR ,jourvol abs/2003.04297, 2020. arXiv: 2003.", "label": "human"}
{"ID": "00080171", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "M. Caron, I. Misra, J. Mairal, P. Goyal, P. Bojanowski andA. Joulin, “Unsupervised learning of visual features by contrasting cluster assignments,” inAdvances in Neural Information Processing Systems H. Larochelle, M. Ranzato, R.", "label": "human"}
{"ID": "00080172", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "P. Khosla, P. Teterwak, C. Wang andothers , “Supervised contrastive learning,” inAdvances in Neural Information Processing Systems H. Larochelle, M.", "label": "human"}
{"ID": "00080173", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "B. Gunel, J. Du, A. Conneau andV. Stoyanov, “Supervised contrastive learning for pre-trained language model fine-tuning,” inInternational Conference on Learning Representations 2021. url:https : / / openreview. net / forum?id=cu7IUiOhujH .", "label": "human"}
{"ID": "00080174", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "F. Schroff, D. Kalenichenko andJ. Philbin, “Facenet: A unified embedding for face recognition and clustering,” in2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2015, pages 815–823. DOI:10.", "label": "human"}
{"ID": "00080175", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "L. Jing, P. Vincent, Y. LeCun andY. Tian, “Understanding dimensional collapse in contrastive self-supervised learning,” inInternational Conferenceon Learning Representations 2022. url:", "label": "human"}
{"ID": "00080176", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "T. Hua, W. Wang, Z. Xue, Y. Wang, S. Ren andH. Zhao, “On feature decorrelation in self-supervised learning,” arXiv e-prints , arXiv–2105, 2021.", "label": "human"}
{"ID": "00080177", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "X. Han, H. Zhu, P. Yu andothers , “FewRel: A large-scale supervised few shot relation classification dataset with state-of-the-art evaluation,” inProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing Brussels, Belgium: Association for Computational Linguistics, 2018, pages 4803–4809.", "label": "human"}
{"ID": "00080178", "file_name": "Continual Relation Extraction with Feature Decorrelation", "content": "Y. Zhang, V. Zhong, D. Chen, G. Angeli andC. D. Manning, “Position aware attention and supervised data improve slot filling,” inProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing Copenhagen, Denmark: Association for Computational Linguistics, september 2017, pages 35–45. DOI:10 . 18653 / v1 / D17 - 1004 .url:https :", "label": "human"}
{"ID": "00090001", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The motivation behind creating my web application stems from the increasinginterest and popularity of cryptocurrencies. As the cryptocurrency market contin ues to grow, there is a demand for accessible and user-friendly platforms to monitor and visualize the momentum factor in cryptocurrency data.", "label": "human"}
{"ID": "00090002", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "By developing this web application, I aim to provide users with an intuitiveand informative tool to track and analyze the momentum factor for different cryp tocurrencies. The ability to visualize the momentum data can help investors and enthusiasts gain insights into potential price movements and trends.", "label": "human"}
{"ID": "00090003", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The significance of this project lies in its potential to democratize cryptocur rency data analysis. By making momentum factor visualization easily accessible to users, regardless of their technical background, I hope to contribute to a broader understanding of the cryptocurrency market and foster informed decision-making.", "label": "human"}
{"ID": "00090004", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Moreover, the web application’s adaptability allows for potential use cases be yond the crypto domain. The visualization techniques and tools employed in thisproject can be extended to other fields where momentum analysis and data visual ization are relevant.", "label": "human"}
{"ID": "00090005", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In conclusion, my web application’s primary objective is to provide a user friendly platform for visualizing the momentum factor in cryptocurrency data, fostering a better understanding of market trends and contributing to informed decision-making for investors.", "label": "human"}
{"ID": "00090006", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Under the current market conditions, there is a noticeable absence of any ap plication specifically designed to visualize momentum data for cryptocurrencies.", "label": "human"}
{"ID": "00090007", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Despite the growing interest and popularity of cryptocurrencies, there is a lack of user-friendly platforms that provide easy access to visualizing and analyzing the momentum factor for various crypto assets.", "label": "human"}
{"ID": "00090008", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The absence of such applications highlights the significance and urgency of my graduation thesis. By developing a web application to fill this void, I aim to offer users an intuitive and informative tool for monitoring and understanding the momentum trends in the cryptocurrency market.", "label": "human"}
{"ID": "00090009", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The primary objective of my thesis is to bridge this gap and provide investorsand enthusiasts with a dedicated platform that empowers them to make more informed decisions. By democratizing cryptocurrency data analysis and making momentum factor visualization readily accessible, my web application seeks to con tribute to a broader understanding of the cryptocurrency market and foster better decision-making for users with varying technical backgrounds.", "label": "human"}
{"ID": "00090010", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Firstly, I chose to gather cryptocurrency data using the Coingecko API as it pro vides comprehensive and up-to-date information on various cryptocurrencies. This data is then stored on Github, ensuring a secure and easily accessible repository for further analysis.", "label": "human"}
{"ID": "00090011", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Secondly, I implemented a momentum factor calculation algorithm to process the collected data. This algorithm allows me to assess the momentum trends and gauge the strength of price movements for different cryptocurrencies over time.", "label": "human"}
{"ID": "00090012", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Furthermore, to predict future price movements, I utilized an LSTM (Long Short-Term Memory) model, a type of deep learning architecture well-suited forsequential data like cryptocurrency price history. The LSTM model can learn patterns and dependencies from historical data, enabling it to make informed predic tions about future price changes.", "label": "human"}
{"ID": "00090013", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The primary contribution of my project is the development of a web application that showcases the momentum factor for various cryptocurrencies. By presenting this factor visually, the application aims to provide users with valuable insights into market trends, supporting them in making well-informed investment decisions.", "label": "human"}
{"ID": "00090014", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Chapter 2 delves into the comprehensive requirement survey undertaken to dis cern the fundamental needs and functionalities of the application. This processinvolved an exploration of user expectations, market trends, and industry bench marks. By examining these factors, a holistic understanding emerged, guiding the identification and prioritization of essential features for the application. In essence,Chapter 2 serves as a pivotal guidepost that illuminates the path forward by unveil ing the intrinsic features vital to the application’s success. Through an intricate interplay of research, analysis, and interpretation, the requirement survey instilled clarity and purpose, ensuring that the subsequent development stages were both focused and effective.In Chapter 3, I will embark on the decisive task of selecting the technologies andtheories that align seamlessly with the identified functionalities outd in Chapter 2. This discerning process involves a meticulous evaluation of the diverse tech nological landscape, coupled with an in-depth exploration of pertinent theoretical frameworks. By strategically harmonizing these elements, the aim is to cultivate an environment conducive to the development of the application. This chapter serves as a pivotal juncture where the foundation for the application’s evolution is laid.", "label": "human"}
{"ID": "00090015", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Moving forward to Chapter 4, I delve into the intricate architecture of the appli cation, with a particular emphasis on its meticulous design. This chapter serves asa focal point where the structural intricacies of the application are unveiled and ex amined in detail. The spotlight is cast upon the overarching blueprint, highlightingthe thoughtful arrangement of components, modules, and interactions that collectively orchestrate the application’s seamless functionality. Through a comprehensive exploration of its design intricacies, this chapter illuminates the artful orches tration that underpins the application’s cohesive and intuitive user experience.", "label": "human"}
{"ID": "00090016", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In Chapter 5, I delve into the challenges I encountered during the course of this project and the systematic approach I undertook to overcome them. This chapterserves as a candid reflection of the hurdles I confronted and the solutions I de vised to surmount each obstacle. Through a narrative, I unravel the intricate web of complexities and out the steps I took to address them, providing an insightful account of my problem-solving journey. This chapter stands as a testament to the tenacity, adaptability, and resourcefulness that I applied to tackle each challenge.", "label": "human"}
{"ID": "00090017", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Chapter 6 provides a comprehensive overview of the developed application andouts the future trajectory for its growth and enhancement. Within this chap ter, I present a holistic view of the application in its current state Furthermore, I expound upon the strategic roadmap for the application’s continued development.", "label": "human"}
{"ID": "00090018", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "This encompasses a detailed analysis of the envisioned enhancements, additional features, and potential extensions that could enrich the user experience and amplify the application’s utility. In essence, Chapter 6 serves as a pivotal point of reflection and projection, encapsulating the journey from inception to fruition while paving the way for the application’s promising evolution in the times ahead.From the task definition in Chapter 1, Chapter 2 conducts a detailed survey of the current state and requirements of the software.", "label": "human"}
{"ID": "00090019", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "My product is a web application designed to accompany users in tracking and analyzing the affect of momentum factors to return. To develop this product, Iconducted a thorough analysis and evaluation from two sources: The first is anal ysis of existing systems: I researched and evaluated existing applications in the market, such as cryptocurrency market analysis tools and price prediction apps.", "label": "human"}
{"ID": "00090020", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Through comparison, I found that these products lack comprehensive momentumfactor functionalities and cryptocurrency price predictions. The second is explo ration of similar applications: I studied similar applications in the market. However,these apps do not focus on displaying and analyzing the momentum factor of cryp tocurrencies. Instead, they mainly concentrate on features like monitoring exchangerates and price charts. Based on the survey and analysis, I identified important fea tures to be developed in the product, including detailed display of the momentum factor and presenting investment opportunities based on momentum factors. Myproduct aims to provide users with an informative tool to gain an overall under standing of the momentum factor in the cryptocurrency market, empowering them to make informed investment decisions.", "label": "human"}
{"ID": "00090021", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The software can automatically update data on a daily basis, can show users the visualizations of how the momentum factor impacts returns, and users can also view predictions of the next day’s prices for various cryptocurrencies.2.2.1 General use case diagram Figure 2.1: General use case diagram In my use case diagram, there are 2 factors: Github Actions’s Virtual machine and User of the software. Github Actions’ Virtual machine takes on the responsi-bility of updating data on a daily basis. The users can view visualizations and see price predictions.", "label": "human"}
{"ID": "00090022", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Detailed use case diagram Figure 2.2: Daily update cryptocurrencies priceGithub Actions’ Virtual machine will automatically run the code file to update data on various cryptocurrencies at 00:15 UTC+0 every day.", "label": "human"}
{"ID": "00090023", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Daily update cryptocurrencies price: At 00:15 UTC+0 every day, Github Actions’s Virtual machine will run the code to generate the updated data file for cryp tocurrency prices. After generating the file, Github Actions’s Virtual machine will push it to the GitHub repository.", "label": "human"}
{"ID": "00090024", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Daily update data prepared for visualizations: After Github Actions’ Virtual ma chine pushes the data file containing cryptocurrency prices, it will continue to run the code to transform that data for visualization preparation. It will then push the prepared data files for visualization to GitHub. This step is performed after theuse case mentioned above because it requires transforming the updated cryptocur rency price data generated in the previous step, which takes approximately 10-15 minutes. To ensure proper sequencing, I have scheduled this step to run at 01:00 UTC+0 daily View visualizations: The visualizations are displayed directly on the two pages Return and mom20\" and \"Momentum\" of the website. Users can click on these two pages to view the visualizations.", "label": "human"}
{"ID": "00090025", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "See price predictionss: The price prediction model will directly display its re sults on the \"LSTM model\" page of the website. Users can click on this page, choose the cryptocurrency they want to predict, and then view the predicted prices.", "label": "human"}
{"ID": "00090026", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Usability: The user interface should be simple, user-friendly, and logically or ganized to facilitate easy navigation.Maintainability: The system should be easy to maintain and upgrade, with clear codebase and documentation.", "label": "human"}
{"ID": "00090027", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In summary, Chapter 2 has assisted me in identifying the essential functional ities required for the program. To implement these functions, I will need specifictechnologies and theoretical foundations, which will be elaborated on in the upcoming section, Chapter 3.In this chapter, I will introduce the technologies utilized in the project. Addi tionally, I will provide an overview of the momentum concept and delve into the details of the LSTM model.", "label": "human"}
{"ID": "00090028", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Collecting data: To collect cryptocurrency data on a daily basis, I utilized the Pycoingecko library, which is specifically designed to provide a Python API for easy access to CoinGecko data. Pycoingecko simplifies the process of fetching cryptocurrency-related information from CoinGecko’s extensive database through Python. In comparison to other available options like yfinance and Binance API, I chose to use the Pycoingecko library for several reasons.", "label": "human"}
{"ID": "00090029", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Firstly, Pycoingecko is specifically designed to interact with CoinGecko, which is a well-known and reliable platform for cryptocurrency data. While yfinance is a popular library for fetching financial data, it primarily focuses on traditional stock market data and may not provide the same extensive coverage of cryptocurrency data as Pycoingecko does.", "label": "human"}
{"ID": "00090030", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Secondly, Pycoingecko’s API is straightforward and easy to use, making it suit able for developers who prefer a more Pythonic approach to interact with CoinGecko’s data. On the other hand, Binance API is targeted towards cryptocurrency exchange data and trading functionalities, which might not be the primary focus for my web application, which aims to visualize and analyze momentum factors.", "label": "human"}
{"ID": "00090031", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Furthermore, CoinGecko’s API, accessed through Pycoingecko, provides a wide range of cryptocurrency data, including historical prices, market metrics, and other essential information. This comprehensive coverage is beneficial for conductingin-depth analysis and visualization of the momentum factor for various cryptocur rencies.", "label": "human"}
{"ID": "00090032", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Lastly, Pycoingecko ensures real-time data updates, allowing the web applica tion to display the latest and most accurate information to users. This real-time data is crucial for making informed decisions based on the most current market trends.", "label": "human"}
{"ID": "00090033", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Overall, the Pycoingecko library emerged as the most suitable choice for my project due to its ease of use, compatibility with CoinGecko’s comprehensive cryp-tocurrency data, and the ability to provide real-time updates, making it an ideal fit for implementing the momentum factor analysis and visualization functionalities in my web application.", "label": "human"}
{"ID": "00090034", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Automatic update data: For automating the data update process, I employed GitHub Actions, a powerful and flexible automation tool provided by GitHub. By using GitHub Actions, I could set up scheduled tasks to automatically fetch and update cryptocurrency data from CoinGecko at regular intervals.", "label": "human"}
{"ID": "00090035", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The workflow begins by defining a YAML file in the ‘.github/workflows‘ direc tory of the project repository. This YAML file contains the necessary configurationto specify when and how often the data update should occur. I configured the work flow to trigger at specific time intervals or based on specific events, such as code commits or pull requests.", "label": "human"}
{"ID": "00090036", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Within the workflow, I defined the steps to run, which included calling the Python script responsible for fetching data through the Pycoingecko library. ThePython script executed API calls to CoinGecko and retrieved the required cryp tocurrency data.", "label": "human"}
{"ID": "00090037", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "GitHub Actions then executed the workflow automatically based on the definedschedule or events. The data update process would occur without any manual in tervention, ensuring that the web application always displayed the most current cryptocurrency data.", "label": "human"}
{"ID": "00090038", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "By leveraging GitHub Actions for automating data updates, I streamd the process of keeping the data up-to-date, ensuring that users of the web applicationcould access the latest and most accurate information on cryptocurrency momentum factors. This automation feature significantly enhanced the overall functional ity and user experience of the web application. When comparing GitHub Actions with the automation technology offered by AWS (Amazon Web Services), there are several key differences and considerations:", "label": "human"}
{"ID": "00090039", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Platform Specificity: GitHub Actions is tightly integrated with the GitHub plat form and is mainly focused on automating tasks related to code management and development workflows. In contrast, AWS provides a broad range of cloud-based services, including automation tools like AWS Step Functions and AWS Lambda, which can be used for various purposes beyond code management.Scope of Automation: GitHub Actions is primarily designed for automatingworkflows within GitHub repositories. It excels at tasks like continuous integra tion, code testing, and deployment. On the other hand, AWS automation servicesoffer a more extensive scope, encompassing tasks such as infrastructure provision ing, serverless computing, and data processing.", "label": "human"}
{"ID": "00090040", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Cloud Infrastructure: AWS provides a full-fledged cloud infrastructure with aglobal network of data centers, allowing seamless scalability and high availabil ity for automation tasks. This level of infrastructure is not available with GitHub Actions, as it operates within the GitHub ecosystem.", "label": "human"}
{"ID": "00090041", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Flexibility and Customization: While GitHub Actions offers simplicity and easeof use for code-related workflows, AWS automation tools provide greater flexi bility and customization. AWS services can be integrated with various other AWSofferings and third-party services, allowing developers to design complex automa tion workflows tailored to specific use cases.", "label": "human"}
{"ID": "00090042", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Pricing: GitHub Actions offers a certain amount of free usage for public reposi tories, making it cost-effective for open-source projects. AWS automation services, on the other hand, are part of the larger AWS cloud ecosystem, and their pricing is based on consumption, which can vary depending on the scale and complexity of the automation tasks.", "label": "human"}
{"ID": "00090043", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Ecosystem and Community: GitHub Actions benefits from the active GitHub community, which shares and contributes to the available actions and workflows.", "label": "human"}
{"ID": "00090044", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "AWS, being a vast cloud platform, has its own ecosystem and an extensive com munity that provides a wide range of solutions and support.", "label": "human"}
{"ID": "00090045", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Choosing GitHub Actions for this project is a practical and suitable decision. It offers a free tier, making it cost-effective for a small-scale project like mine. WithGitHub Actions, I can automate tasks related to code management, continuous in tegration, and data updates from Coingecko, all within the GitHub platform. Itssimplicity and straightforward setup allow me to focus on developing and improv ing the web application without worrying about infrastructure management.", "label": "human"}
{"ID": "00090046", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Furthermore, GitHub Actions has an active community that contributes to a wide variety of pre-built actions and workflows. This means I can easily find and incorporate existing solutions into my project, saving time and effort.", "label": "human"}
{"ID": "00090047", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "As my project expands and requires more complex automation tasks or cloud in frastructure, I can consider exploring AWS automation services in the future. AWS offers a comprehensive suite of cloud-based solutions that can seamlessly integratewith my existing codebase and provide additional functionalities for scaling, data processing, and deployment.", "label": "human"}
{"ID": "00090048", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In conclusion, starting with GitHub Actions is a pragmatic choice for my small scale web application. It aligns well with the current scope and budget of the project. As the project grows, I can evaluate AWS automation services to address more extensive automation needs and cloud infrastructure requirements.", "label": "human"}
{"ID": "00090049", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Data protection: GitHub Actions run on virtual machines, and they can access the repository using the provided Personal Access Token (PAT) for authentication.", "label": "human"}
{"ID": "00090050", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "By configuring the actions to use the PAT for commits, I can ensure a higher level of security for the data in the repository.", "label": "human"}
{"ID": "00090051", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The use of a PAT for authentication ensures that only authorized actions, such as automated workflows or scripts, can interact with the repository. The PAT acts as a unique identifier for the virtual machine, granting it the necessary permissions to commit changes to the repository.", "label": "human"}
{"ID": "00090052", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Since the PAT is associated with the virtual machine and is not exposed publicly, it reduces the risk of unauthorized access to the repository. Additionally, I can control the scope of the PAT’s permissions, limiting it to specific actions required for the workflows.", "label": "human"}
{"ID": "00090053", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Moreover, GitHub allows me to manage access and revoke tokens at any time,providing further control over the security of the repository. I can also set up two factor authentication for additional protection.", "label": "human"}
{"ID": "00090054", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "By leveraging GitHub Actions with a PAT for commits, I can ensure that the au tomation process remains secure and that only trusted sources are allowed to make changes to the repository, contributing to a safer and more controlled development environment.", "label": "human"}
{"ID": "00090055", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Create web applications: Streamlit is an open-source Python library that al lows users to create web applications for data science and machine learning projectseasily. With Streamlit, developers can build intuitive and interactive data-driven web applications using just a few s of Python code. The API is designed to be straightforward and intuitive, enabling developers to quickly prototype and deploy data visualization tools, dashboards, and machine learning models.", "label": "human"}
{"ID": "00090056", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "One of the key features of Streamlit is its reactive updates, which automaticallyrefresh the visualizations and UI components whenever there is a change in the in put data, ensuring a smooth and responsive user experience. Additionally, Streamlit offers a wide range of components, such as plots, tables, buttons, sliders, and text inputs, making it easy to create dynamic and versatile web applications.", "label": "human"}
{"ID": "00090057", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Streamlit seamlessly integrates with popular Python data science libraries like Pandas, Matplotlib, and Plotly, allowing developers to leverage their existing codeand data analysis skills. Sharing and deploying Streamlit applications are straightforward, and they can be easily shared with others through a simple URL or de ployed to cloud platforms like Heroku, AWS, or Streamlit sharing.", "label": "human"}
{"ID": "00090058", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "While Streamlit is designed for simplicity and ease of use, it still allows for customization and fine-tuning of web applications using custom CSS and HTML.", "label": "human"}
{"ID": "00090059", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Its user-friendly interface and Python-based approach make it an excellent choice for rapid prototyping and building data-centric web apps. Streamlit empowers datascientists and developers to create interactive and impactful web applications, mak ing it a valuable tool for data exploration, visualization, and sharing insights with stakeholders and the broader audience.", "label": "human"}
{"ID": "00090060", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "There are various web development tools in the data visualization field, such asFlask, Dash, Plotly, Shiny (R), Django, Bokeh, and many others. However, com pared to these tools, Streamlit offers several advantages:", "label": "human"}
{"ID": "00090061", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Easy to Learn and Use: Streamlit is designed specifically for Python users and data scientists, making it easy to learn and use, especially for those with Python experience.", "label": "human"}
{"ID": "00090062", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Time-Saving: Streamlit provides a simple and intuitive API, allowing users to create web apps with just a few s of code. This saves time and effort during the development process.", "label": "human"}
{"ID": "00090063", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Reactivity: Streamlit features reactive updates, automatically updating data and the user interface when changes occur. This creates a smooth and interactive user experience.", "label": "human"}
{"ID": "00090064", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Seamless Integration with Python Data Science Libraries: Streamlit integrates well with popular Python libraries like Pandas, Matplotlib, Plotly, and more. Thisallows users to reuse existing code and leverage Python’s powerful computational capabilities.", "label": "human"}
{"ID": "00090065", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Strong Community and Support: Streamlit has a vibrant community and strong support from the Python and data community. Users can easily find documentation, guides, and examples to help address any issues while using the tool.", "label": "human"}
{"ID": "00090066", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In summary, Streamlit is a powerful and efficient tool for creating web appsfor data visualization and project presentation. Its simplicity, seamless Python in tegration, and reactive updates are key advantages that set Streamlit apart from other web development tools. Additionally, one notable advantage of Streamlit is that it can directly run GitHub repositories on the cloud system share.streamlit.io.", "label": "human"}
{"ID": "00090067", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "This seamless integration with GitHub allows for easy deployment and sharing of projects. Streamlit’s robust support for data-focused projects makes it a perfect fit for my project, which is primarily centered around data visualization and analysis.", "label": "human"}
{"ID": "00090068", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "With Streamlit’s capabilities, I can efficiently showcase and share my data-driven web application with others, making it a valuable tool for my project.", "label": "human"}
{"ID": "00090069", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Momentum Investment Investment based on momentum is a strategy in the field of finance, relying on the observation that assets (such as stocks, currencies, or commodities) tend tocontinue moving in the direction shown in the recent short-term past. The funda mental principle of this strategy is to assess the short-term trend of prices or yields of assets and select those assets with strong performance in the recent period for investment.", "label": "human"}
{"ID": "00090070", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Momentum can be measured in various ways, based on the book ’Trading Sys tems and Methods,’ I select the following momentum factors:", "label": "human"}
{"ID": "00090071", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "mom-10, mom-15, mom-20, mom-25: loge(Current price divided by price 10,15,20,25 days ago) psma-15, psma-20, psma-25, psma-30: Current price divided by the average price of 15, 20, 25, and 30 days ago - 1 smaf-2-20, smaf-3-20,smaf-3-25,smaf-5-30: The average price of 2,3,3,5 days ago divided by the average price of 20,20,25,30 days ago - 1 rrp-15, rrp-20, rrp-25, rrp-30: The current price minus the 15-day averageprice divided by the 15-day standard deviationdsh-15, dsh-20,dsh-25,dsh-30: - The number of days since reaching the high est price within the 15-day period Investing based on momentum adheres to the principle of buying into assets with higher momentum and selling assets with lower momentum. The algorithm to determine the relationship between return and momentum factor in momentum investment method is as follows:", "label": "human"}
{"ID": "00090072", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Calling the ranking of the momentum factor for a cryptocurrency in ascending order is \"rank,\" we calculate the weight as follows: weight = rank - the average of all ranks of the cryptocurrencies.", "label": "human"}
{"ID": "00090073", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "scaled return = scaled * returnNote that rank = 1 corresponding to the cryptocurrency with the lowest momen tum factor This algorithm accurately reflects the essence of momentum-based investment strategy, wherein cryptocurrencies with higher momentum values are bought, and those with lower momentum values are sold. This is demonstrated through scaled.", "label": "human"}
{"ID": "00090074", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "LSTM (Long Short-Term Memory) is well-suited for cryptocurrency price pre diction due to its ability to capture sequential dependencies and patterns within time series data. There are several reasons why LSTM is considered a suitable choice for this type of problem:", "label": "human"}
{"ID": "00090075", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Sequential Information: Cryptocurrency prices are inherently time-dependent and exhibit sequential patterns. LSTM is designed to handle sequential data and can effectively capture the temporal relationships and dependencies in the price movements.", "label": "human"}
{"ID": "00090076", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Long-Term Dependencies: LSTM is specifically designed to mitigate the van ishing gradient problem, allowing it to capture long-term dependencies in the data. This is crucial for modeling the complex and often non-ar relation-ships present in cryptocurrency price data.", "label": "human"}
{"ID": "00090077", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Handling Non-Linearity: Cryptocurrency prices are influenced by a multitude of factors, including market sentiment, news, and external events. LSTM’s ability to capture non-ar relationships makes it suitable for handling the intricate and dynamic nature of crypto markets.", "label": "human"}
{"ID": "00090078", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Feature Extraction: LSTM can automatically learn relevant features from the data, reducing the need for manual feature engineering. This is particularlyadvantageous in the context of cryptocurrency price prediction, where identi fying relevant features can be challenging.", "label": "human"}
{"ID": "00090079", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Flexibility: LSTM networks can be designed with multiple layers and neurons, allowing them to capture intricate patterns and relationships in the data. This flexibility makes them adaptable to various complexities in the price data.", "label": "human"}
{"ID": "00090080", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Sending my heartfelt gratitude sumittttttt , for creating an application using Streamlit and LSTM model. I’ve utilized the LSTM model code he provided to enhance a feature within my own application.", "label": "human"}
{"ID": "00090081", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In summary, the conclusions drawn from the above discussions have led to the decision to employ the mentioned technologies and theoretical foundations. The utilization of these technologies and theories has facilitated the development of my application. In the next chapter, I will provide a detailed presentation of the application’s structure and delve into the experiment and evaluation section.4.1 Architecture design 4.1.1 Software architecture selection In Streamlit, developers do not need to explicitly define the Model-View-Controller(MVC) architecture as in traditional frameworks. Instead, the development ap proach is more straightforward and declarative. Python code is written in a single file and executed from top to bottom, incorporating data processing, visualization, and user interface elements all together.", "label": "human"}
{"ID": "00090082", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Streamlit’s reactive programming model enables automatic updates to the user interface whenever there are changes in the data, eliminating the need for explicitcontroller logic. This streamd approach allows developers to focus on writ ing data processing and visualization code directly in Python, without the need to strictly adhere to the MVC pattern.", "label": "human"}
{"ID": "00090083", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Streamlit’s design philosophy simplifies web application development by han dling the reactive updates behind the scenes, making it easier for developers to create interactive applications directly from their Python code.", "label": "human"}
{"ID": "00090084", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Overall design In Streamlit, developers can create a multipage web application by organizing their code into separate files and placing them in a folder Each file in the folder represents a different page of the web application, providing the flexibility to have multiple views for the app.", "label": "human"}
{"ID": "00090085", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "It’s important to note that while Streamlit does not strictly adhere to the tradi tional Model-View-Controller (MVC) architecture, the concept of having separate pages for different views aligns with the \"View\" part of the MVC pattern. In this approach, each page file in Streamlit defines the user interface (UI) elements and logic for a specific view of the application.", "label": "human"}
{"ID": "00090086", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "This organizational strategy allows developers to create a more structured andmodular web application, enhancing the manageability and maintenance of differ ent views. By following this method and organizing code into separate files withinthe folder, developers can efficiently build a multipage web application in Stream lit.4.1.3 Detailed module design I designed 4 modules corresponding to the source code for the 4 pages of the web application:", "label": "human"}
{"ID": "00090087", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "User interface design The default screen resolution of Streamlit is not explicitly limited to a specific value. It is designed to automatically adapt to the user’s screen resolution and thedevices they use to access the web application. This enables Streamlit to be respon sive and compatible with various screen sizes, including desktops, laptops, tablets, and mobile phones.", "label": "human"}
{"ID": "00090088", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Streamlit utilizes a web-based interface, allowing it to dynamically adjust the size and layout of components within the application to fit the current screen size.", "label": "human"}
{"ID": "00090089", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "This ensures that the content of the application is displayed optimally and easily accessible, regardless of the specific screen resolution.", "label": "human"}
{"ID": "00090090", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "As Streamlit is designed to be compatible with a wide range of screen resolutions and devices, you can use your application on various devices without worry ing about adjusting the interface for each specific case. The default screen size of Streamlit is typically determined by the web browser or the device used to access the web application. Streamlit itself does not impose a fixed default screen size, as it is designed to be responsive and adaptive to different screen sizes.", "label": "human"}
{"ID": "00090091", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "When you run a Streamlit app, the content will be displayed within the web browser window. The size of this window is determined by the browser settings or the device’s screen size. Users can resize the browser window, and Streamlit will automatically adjust the layout and content of the app to fit the new size.", "label": "human"}
{"ID": "00090092", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Streamlit’s responsiveness allows it to work well on various devices, such as desktops, laptops, tablets, and mobile phones, providing an optimal user experience across different screen sizes and resolutions. Streamlit supports a large and diverse range of colors. Users can utilize the default colors provided by Streamlit’s built-inlibrary or define custom colors according to their preferences.", "label": "human"}
{"ID": "00090093", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Streamlit supports colors in HEX or RGB format, allowing developers to use almost any color available on the web color palette.", "label": "human"}
{"ID": "00090094", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "For example, the default colors in Streamlit are as follows: Red: \"FF0000\" or red\", Green: \"00FF00\" or \"green\", Blue: \"0000FF\" or \"blue\", White: \"FFFFFF\" or \"white\", Black: \"000000\" or \"black\"Additionally, I can utilize custom HEX or RGB codes to create unique and ap pealing colors that suit my application’s design. Customizing colors in Streamlitenables developers to create an attractive and engaging user interface for their ap plications.", "label": "human"}
{"ID": "00090095", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "I will present a collection of illustrative images showcasing the interface designs for various functionalities.Figure 4.1: Navigation design On the navigation containing the names of the web pages, there are close and open buttons to optimize the interface.Figure 4.2: Zoom in zoom out button design Designing zoom in and zoom out buttons for visualizations.Figure 4.3: Selection bar design Designing a selection bar to input the name of the cryptocurrency for prediction.Figure 4.4: Running notificationWhen the application is processing data, a ’Running’ notification will be dis played.4.3 Application Building 4.3.1 Libraries and Tools In this project, I have utilized the following libraries and tools:", "label": "human"}
{"ID": "00090096", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Purpose Tool URL address Programming IDE Visual Studio Code 1.81.0  API/ Web Scraper Pycoingecko 3.1.0  API/ Web Scraper CryptoCmd 0.6.1  Data Wrangling Pandas 1.3.4  Data Wrangling Numpy 1.21.2  Data Visualisation Matplotlib 3.7.2  Data Modeling Scikit Learn 1.1.1  Data Modeling Tensorflow 2.9.1  Data Modeling Keras 2.9.0  Webapp Streamlit 1.24.1  Table 4.1: List of libraries and tools used 4.3.2 Achievement The achieved results of my project encompass the development of a versatile and flexible web application designed to analyze and visualize the relationship between momentum factor and returns within the cryptocurrency market. This application comprises the following key components:", "label": "human"}
{"ID": "00090097", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Visualizations: The application offers a variety of charts and graphs that depictthe relationship between returns and the momentum factor. These visual represen tations enable users to easily track and analyze the data.", "label": "human"}
{"ID": "00090098", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Momentum Investment Analysis: The application provides an analysis of mo mentum investment strategy, focusing solely on the momentum factor. Users canview the profit charts of this strategy to gain a deeper understanding of its func tioning.", "label": "human"}
{"ID": "00090099", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Price Prediction Using LSTM Model: The application includes the capability to predict cryptocurrency prices using an LSTM model. Users can select a specific cryptocurrency for prediction and view the prediction results.", "label": "human"}
{"ID": "00090100", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The product comprises 1271 s of code, with a file size of 73KB, divided into sections as follows:Component Number of s of code file size Update data 518 40 KB Home 25 2 KB Return and mom20 172 9 KB Momentum 390 17 KB LSTM Modell 166 5KB Table 4.2: Statistical information about the application 4.3.3 Illustration of main functions The following are some of the functionalities that end-users can utilizeFigure 4.5: Home page On the Home page, users can view general information about the application.", "label": "human"}
{"ID": "00090101", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Users also have the option to navigate to other pages by selecting them from the left side of the screen.Figure 4.6: Return and mom20 page On this page, users can view charts illustrating the relationship between return and momentum factor mom20 over time. Adjacent to each visualization, there will be zoom-in buttons. When users click on these buttons, they can view detailedversions of the respective visualizations.", "label": "human"}
{"ID": "00090102", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Mobile Testing: Testing mobile applications on different devices and plat forms.\"Each of these testing approaches contributed to ensuring the functionality, per formance, and security of the application.", "label": "human"}
{"ID": "00090103", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In the context of my project, the application is deployed and hosted using Stream lit’s sharing platform, known as ‘share.streamlit.io‘. This platform allows me toeasily deploy and share my Streamlit app with others without the need for manag ing servers or complex configurations.", "label": "human"}
{"ID": "00090104", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "When I deployed the application on ‘share.streamlit.io‘, Streamlit took care of the deployment process and provided the necessary server infrastructure to host the app. This allowed me to focus solely on developing the application and creating an intuitive user experience.The deployment process was straightforward. After writing the Streamlit app code and ensuring it functioned correctly on my local machine, I simply uploadedthe code to a public GitHub repository. From there, I connected my GitHub reposi tory to the Streamlit sharing platform. Streamlit then automatically detected changes in the repository and deployed the app to its servers, making it accessible through a web browser.", "label": "human"}
{"ID": "00090105", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The choice to use Streamlit’s sharing platform simplified the deployment pro cess significantly. It eliminated the need for me to manage and configure servers,which can be time-consuming and require technical expertise. Additionally, it en sured that the app could be accessed by users worldwide without any geographical restrictions.", "label": "human"}
{"ID": "00090106", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In terms of server configuration, the specifics are managed by Streamlit’s plat form. This includes allocating the necessary resources to ensure the app runs smoothly and efficiently. Users can access the application by simply visiting the provided URL, and Streamlit takes care of the rest.", "label": "human"}
{"ID": "00090107", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Overall, leveraging Streamlit’s sharing platform for deployment allowed me to focus on creating a seamless user experience and showcasing the features of the application without being burdened by server management complexities.", "label": "human"}
{"ID": "00090108", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In summary, this chapter has provided both an overview and detailed insightsinto the application after its development. The development process has encompassed several crucial steps, accompanied by challenges and corresponding solu tions during the construction of the application. These aspects will be thoroughly elucidated in Chapter 5.Having covered the four sections, we now have a comprehensive overview of the application. This section endeavors to unveil an intricate narrative detailing the developmental journey of the application. We will delve into the minutiae of thedevelopment process, offering insight into the challenges, intricacies, and intrica cies that I encountered along the way. Additionally, I will illuminate the strategies I employed to effectively navigate and resolve these challenges. This narrative not only offers a glimpse into the technical facets but also delves into the tenacity and resourcefulness I exercised in addressing and surmounting these hurdles.", "label": "human"}
{"ID": "00090109", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The motivation behind selecting the topic of showcasing momentum effects isrooted in the current landscape of the financial markets, where numerous applica tions offer insights into factors such as volatility and information ratio v.v. Despite this abundance of tools, I noticed a distinct gap – the lack of direct visualizations that illustrate the intrinsic connection between momentum and return. It was this very observation that sparked the creation of the present application.", "label": "human"}
{"ID": "00090110", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In today’s dynamic cryptocurrency market, understanding momentum’s influence on asset price movements has emerged as a crucial aspect of successful trading and investment strategies. While existing platforms provide glimpses into related metrics, the absence of a dedicated platform that directly portrays the inter play between momentum and returns prompted the inception of this project.", "label": "human"}
{"ID": "00090111", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The objective, therefore, is twofold. Firstly, to offer users an intuitive and vi sually informative means of comprehending momentum effects, transcending thelimitations of numerical representations. Secondly, to bridge the gap between theoretical knowledge and practical application by presenting users with real-time vi sualizations that vividly showcase how momentum impacts return. By delving into the nuanced intricacies of this crucial relationship, the project aims to empower users with actionable insights, enabling them to make more informed decisions within the complex realm of cryptocurrency trading and investment.While the intention to visualize the relationship between return and momentum has been established, my aspiration extends beyond mere graphical representations of profit and momentum. I aim to convey this relationship within the context of an investment strategy, providing users with a more comprehensive understanding and a foundation for their investment decisions. Through discussions with my guiding instructor, I was introduced to the concept of the momentum investment approach, which has guided me towards a distinctive path.", "label": "human"}
{"ID": "00090112", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The momentum strategy, rooted in the principle of momentum, becomes a fo cal point of this project’s endeavor. This approach, intriguingly, revolves around asingle dimension momentum where users exclusively emphasize momentum fac tors. By adopting this investment methodology, the application seeks to offer usersa distinct perspective, allowing them to grasp the intricate interplay between mo mentum and return dynamics.", "label": "human"}
{"ID": "00090113", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In a dynamic exchange of ideas with my mentor, the momentum methodologyemerged as a compelling route to portray this intricate relationship. While conven tional wisdom may prompt a focus on returns, this innovative approach sharpensthe focus on momentum, showcasing how its nuances influence returns. By visual izing this investment method, the application bridges the gap between theory and practice, offering users a tangible insight into how a momentum-centric strategy can influence their investment outcomes.", "label": "human"}
{"ID": "00090114", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The algorithm devised to uncover the relationship between the momentum factor and cumulative return was a crucial aspect of this project’s development. Through extensive discussions and guidance from my mentor, I was directed to the algorithm meticulously presented in Chapter 3. Subsequently, I embarked on implementing this algorithm within the Google Colab environment, a pivotal step in bringing the envisioned visualization to life.", "label": "human"}
{"ID": "00090115", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "This phase involved utilizing an available dataset to execute the algorithm. Lever-aging the inherent capabilities of Google Colab, I coded and executed the algo rithm, scrutinizing its outcomes and insights. By immersing myself in this process, I not only gained a practical understanding of the algorithm’s functioning but alsounearthed valuable insights into the intricate relationship between momentum fac tors and cumulative returns.", "label": "human"}
{"ID": "00090116", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "As a result, the algorithm presented in Chapter 3 came to life in a tangible and actionable manner, substantiated by real-world data. This pivotal phase not only validated the algorithm’s efficacy but also paved the way for the subsequent stagesof visualization and application development. By anchoring the project in this algorithmic framework, we ensured that the end product is rooted in a robust foun dation, bolstered by the synergy of theoretical rigor and empirical validation.", "label": "human"}
{"ID": "00090117", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "the extensive runtime and the limited application scope due to a static dataset. Rec ognizing the need for optimization and real-time data integration, I embarked on a comprehensive exploration to address these hurdles.", "label": "human"}
{"ID": "00090118", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The pivotal question that emerged was how to acquire real-time, historical data encompassing an extensive repository of past information for seamless integration into the application. As I delved into this challenge, several avenues were explored, each with its own intricacies and limitations. The quest for a solution led me down paths such as web crawling and API utilization, where the intention was to procure a large volume of historical data. However, these approaches presented their own set of challenges.", "label": "human"}
{"ID": "00090119", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Web crawling, while a viable option, posed difficulties in terms of reliability, scalability, and legality. Additionally, the extraction of comprehensive historical data through web crawling often proved intricate and time-consuming, thus not aligning with the need for real-time updates.", "label": "human"}
{"ID": "00090120", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "APIs, on the other hand, emerged as a promising route. Yet, the landscapeof cryptocurrency APIs revealed constraints, ranging from limited free access tothrottled requests over time. These limitations could hinder the seamless and dy namic flow of real-time data required for the application’s success.", "label": "human"}
{"ID": "00090121", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "After extensive exploration, I arrived at a solution that proved both suitable andpromising: leveraging the CoinGecko API. This API not only provides comprehen sive historical data but also offers a reliable and structured framework for accessing real-time cryptocurrency information. The availability of historical data spanning various timeframes, coupled with the API’s real-time capabilities, fulfilled the dual requirement of historical depth and current relevance.", "label": "human"}
{"ID": "00090122", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In my pursuit to enhance runtime efficiency, I meticulously reviewed the algorithm’s implementation, identifying potential bottlenecks and optimization op portunities. Drawing from my research and comparisons of various technologiesoutd in Chapter 3, I arrived at a strategic decision. Leveraging the capabili ties of Streamlit and GitHub Actions, I charted a course to tackle these challenges head-on.", "label": "human"}
{"ID": "00090123", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Streamlit, a powerful framework for creating interactive and user-friendly ap plications, offered a promising avenue to enhance user experience and streamdata visualization. By harnessing Streamlit’s intuitive interface and dynamic capa bilities, I aimed to transform the algorithm’s outputs into engaging visualizations that provide real-time insights to users. This strategic move not only addressed the runtime challenge but also set the stage for creating a user-centric application that empowers investors and traders alike.", "label": "human"}
{"ID": "00090124", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Complementing Streamlit, GitHub Actions emerged as a potent tool to auto mate data updates and optimize the application’s responsiveness. By configuringGitHub Actions to trigger data updates at specific intervals, I ensured that the ap plication remained in sync with the latest market trends. This integration bestowed the application with the ability to dynamically process incoming data, effectively eliminating the constraint of a static dataset.", "label": "human"}
{"ID": "00090125", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The amalgamation of Streamlit and GitHub Actions signifies a transformative leap from a laborious algorithmic exploration to a versatile, real-time application.", "label": "human"}
{"ID": "00090126", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Through this strategic pairing, the project evolved into an innovative solution that not only overcame the initial challenges but also positioned itself as a valuable asset for investors seeking timely insights in the ever-fluctuating cryptocurrencylandscape. By integrating these technologies, I’ve laid the groundwork for an ap plication that is optimized for both performance and real-world relevance, poised to empower users with dynamic visualizations and actionable insights.Beyond these challenges, I encountered a significant hurdle pertaining to the prolonged execution time of the algorithm from the moment data is fetched from CoinGecko to the eventual generation of visualizations. This extended durationcould potentially disrupt the web application’s smooth functioning, leading to un desirable interruptions during the algorithm’s runtime. To address this concern and maintain the application’s stability, I devised a strategic approach that leveraged GitHub Actions to streamline the entire process.", "label": "human"}
{"ID": "00090127", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "I recognized the potential of GitHub Actions as an integral tool not only for data updates but also for preprocessing tasks and algorithm execution. By orchestrating a series of code segments within GitHub Actions, I optimized the workflow to process input data, execute the algorithm, and generate preliminary results. This strategic design effectively reduced the computational load on the web application and eliminated the risk of disruptions caused by extensive algorithm runtime.", "label": "human"}
{"ID": "00090128", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Through this strategic partitioning of tasks, the web application became moreresilient and responsive. Users could seamlessly interact with the application, un hindered by the algorithm’s computational demands. The resulting data stream, spanning from data acquisition to preliminary insights, ensured a continuous and fluid user experience.", "label": "human"}
{"ID": "00090129", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In essence, this approach leveraged GitHub Actions not only as a data update mechanism but also as a holistic solution for optimizing the overall applicationflow. By judiciously dividing the workload, I ensured that the web application remains steadfast and dependable, offering users a seamless and uninterrupted journey from data ingestion to insightful visualizations. This strategic intervention underscores the project’s commitment to delivering an engaging and user-centric ex perience, unmarred by the computational intricacies that power its backend.When utilizing GitHub Actions to automate data updates, a critical challenge that surfaced was the imperative need for data security. The task at hand was to ensure that only the GitHub Actions virtual machine possessed the authority to modify my GitHub repository. In navigating this security conundrum, a strategic approach was vital to safeguard the integrity of the program.", "label": "human"}
{"ID": "00090130", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Amidst my exploration, I arrived at a solution that seamlessly balanced automa tion and security: the utilization of a personal access token. This token served as a secure authentication mechanism, permitting only authorized entities—such as the GitHub Actions virtual machine—to modify the repository. By incorporating this layer of security, I effectively restricted access to my repository while empowering the automated workflow to execute updates without compromising data integrity.", "label": "human"}
{"ID": "00090131", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The personal access token acts as a digital key that ensures data manipulationis conducted solely by trusted sources. This strategic implementation not only ad dresses the security challenge posed by automated updates but also guarantees therobustness of the program’s execution. By embracing this security measure, I es tablished a secure and efficient data update mechanism, preserving the sanctity of the repository and facilitating the seamless flow of data updates from external sources.", "label": "human"}
{"ID": "00090132", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "After successfully implementing the visualizations, I recognized the potentialto enhance the functionality of the web application further. To address this, I in tegrated a pre-existing Long Short-Term Memory (LSTM) model, adding a new dimension of insight for users. This strategic inclusion not only offers users a more detailed perspective on the upward or downward trends of cryptocurrency data butalso underscores the extensibility and scalability inherent in the project.The incorporation of the LSTM model introduces a dynamic layer of analy sis, enabling users to delve deeper into the intricacies of cryptocurrency trends. By leveraging the LSTM’s predictive capabilities, users can gain valuable insights intopotential future price movements. This augments the application’s utility, cater ing to both novice and seasoned investors seeking informed decisions within the volatile cryptocurrency landscape.", "label": "human"}
{"ID": "00090133", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Furthermore, the integration of the LSTM model serves as a testament to theproject’s expandable nature. It demonstrates the inherent flexibility of the applica tion, showcasing the ease with which additional functionalities can be seamlesslyintegrated. This strategic decision positions the web application as a robust foun dation that can readily accommodate future enhancements, ensuring that users will continue to benefit from new insights and analyses as the cryptocurrency market evolves.", "label": "human"}
{"ID": "00090134", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In essence, the inclusion of the LSTM model not only enriches the user expe rience by providing advanced predictive insights but also reinforces the project’scapacity for growth. This strategic expansion lays the groundwork for potential fu ture additions, solidifying the web application’s role as a dynamic and invaluable tool for users navigating the complex realm of cryptocurrency investments.", "label": "human"}
{"ID": "00090135", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "We have now traversed the entire journey of conceptualization, development, and evolution of the project. In the next chapter, I will present the conclusions drawn from this endeavor and out the future prospects for this project.6.1 Conclusion Comparing my product with similar offerings in the market, we find that while there are numerous applications providing insights into momentum related factors such as volatility and information ratios, there is a distinct gap in the landscape for platforms directly illustrating the relationship between momentum and return. My project addresses this gap by providing visualizations that offer users an in depth understanding of how momentum influences returns. Additionally, the integration of the LSTM model adds a predictive dimension, further distinguishing our product from others in the field.", "label": "human"}
{"ID": "00090136", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Data Integration and Automation: Successful integration of the CoinGecko API for acquiring historical and real-time cryptocurrency data and automating data updates through GitHub Actions. This ensures the application remains up-to-date and provides users with real-time insights.", "label": "human"}
{"ID": "00090137", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Visual Representation of Momentum-Return Relationship: Through meticu lous coding and design, I have effectively visualized the intricate relationshipbetween momentum and return, empowering users to comprehend how mo mentum impacts investment outcomes.", "label": "human"}
{"ID": "00090138", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Predictive Analysis with LSTM Model: By incorporating a Long Short-TermMemory (LSTM) model, I have elevated the application’s capabilities by offering users predictive insights into potential future price movements of cryp tocurrencies.", "label": "human"}
{"ID": "00090139", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Algorithmic Efficiency and Processing Time: The execution time of algorithms remains a challenge, affecting the real-time responsiveness of the ap plication. Further optimization is required to ensure seamless user experience.", "label": "human"}
{"ID": "00090140", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Data Coverage and Diversity: While the application supports a range of cryptocurrencies, expanding data coverage and diversity could enhance its analyt ical capabilities and user appeal.", "label": "human"}
{"ID": "00090141", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Unique Visualization Approach: The development of a user-friendly interfacethat provides visualizations showcasing the momentum-return relationship in cryptocurrencies. This fills a gap in the market by offering a comprehensive visual understanding.", "label": "human"}
{"ID": "00090142", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Practical Predictive Analysis: The integration of an LSTM model for predic tive analysis adds depth to the application, enabling users to make informed decisions based on potential future price movements.", "label": "human"}
{"ID": "00090143", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Interdisciplinary Skill Integration: The project required a blend of programming skills, data analysis, and domain knowledge. This interdisciplinary ap proach is crucial for developing holistic applications.", "label": "human"}
{"ID": "00090144", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Balancing Complexity and Accessibility: Striking the right balance betweencomplex algorithms and user-friendly design is essential for ensuring the ap plication’s usability and practicality.", "label": "human"}
{"ID": "00090145", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Continuous Learning and Adaptation: The everevolving nature of technology and cryptocurrency markets necessitates a commitment to continuous learning and adaptation to remain relevant.", "label": "human"}
{"ID": "00090146", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Importance of Collaboration and Feedback: Engaging with mentors, peers, and experts provided valuable insights, shaping the direction of the project and enhancing its outcomes.", "label": "human"}
{"ID": "00090147", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Algorithmic Optimization: Prioritize the optimization of algorithms to significantly reduce processing time and ensure that the application remains respon sive and user-friendly.", "label": "human"}
{"ID": "00090148", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Data Enrichment: Expand the scope of supported cryptocurrencies and historical data points, enriching the application’s dataset and enhancing its analyti cal capabilities.", "label": "human"}
{"ID": "00090149", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "User Interface Refinement: Continuously refine the user interface to enhanceuser experience and accessibility, making complex data insights more under standable and actionable.", "label": "human"}
{"ID": "00090150", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Advanced Analytical Tools: Introduce advanced analytical tools, such as sen timent analysis or correlation analysis, to provide users with deeper insights into the cryptocurrency market dynamics.", "label": "human"}
{"ID": "00090151", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Interactive Customization: Develop interactive features that allow users to cus tomize parameters and scenarios, enabling them to tailor the analysis to their specific investment preferences.", "label": "human"}
{"ID": "00090152", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Real-Time Alerts: Implement real-time alerts and notifications based on user defined criteria, keeping users informed about significant market changes that align with their investment goals.", "label": "human"}
{"ID": "00090153", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Educational Resources: Integrate educational resources, such as tutorials, ex planations, and case studies, to empower users with a deeper understanding of the concepts and methodologies employed.", "label": "human"}
{"ID": "00090154", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Enhanced Predictive Modeling: Further refine the LSTM model to enhance prediction accuracy and expand its predictive capabilities, enabling users to make more informed investment decisions.", "label": "human"}
{"ID": "00090155", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In conclusion, this project has successfully developed a unique and valuable tool for analyzing and investing in the cryptocurrency market. By focusing on therelationship between momentum and return in the cryptocurrency context, the ap plication has provided users with deep insights and decision-making support for their investments.", "label": "human"}
{"ID": "00090156", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "The journey of this project has underscored the importance of combining knowledge and skills from various discips, spanning from data collection and integra tion, statistical analysis to predictive modeling. It has also encountered challenges, particularly in optimizing algorithm execution time and ensuring the stability of the application.", "label": "human"}
{"ID": "00090157", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "A significant contribution of the project is the creation of an interactive and intuitive tool that enables users not only to comprehend the intricate relationship between momentum and return but also to predict future price trends. The fusion of real-time and historical data has culminated in an application with genuine value in assisting users in making informed investment decisions.", "label": "human"}
{"ID": "00090158", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Looking ahead, the project holds the potential for further development and ex pansion. This could involve algorithm optimization, the enrichment of supportive data sets, and the addition of interactive and social integration features. The fusion of cryptocurrency expertise and information technology will continue to contributeto the sustainable growth of the project, ultimately yielding a valuable asset for the cryptocurrency investment community.", "label": "human"}
{"ID": "00090159", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "In conclusion, this project represents the culmination of extensive research,meticulous design, and dedicated development. Through the integration of vari ous technologies, theoretical frameworks, and methodologies, I have successfully crafted a dynamic and informative cryptocurrency analysis tool. The application not only visualizes the intricate relationship between momentum and returns but also provides users with valuable insights for informed decision-making.", "label": "human"}
{"ID": "00090160", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Throughout the journey of this project, I have navigated challenges and devisedinnovative solutions, ensuring the application’s functionality, usability, and perfor mance. The utilization of Streamlit for interactive visualization, the incorporation of LSTM models for accurate price predictions, and the seamless automation ofdata updates through GitHub Actions have collectively contributed to the realiza tion of a robust and practical tool.", "label": "human"}
{"ID": "00090161", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "As a result, this project serves as a testament to the synergy between theory and technology in creating impactful solutions. It reflects my dedication to honing both technical and analytical skills, as well as my commitment to delivering a valuable resource to cryptocurrency enthusiasts, investors, and researchers alike.", "label": "human"}
{"ID": "00090162", "file_name": "CRYPTOCURRENCY DATA ANALYSIS AND VISUALIZATION", "content": "Looking forward, I believe this project has the potential for further expansion and enhancement. Future iterations could incorporate more advanced analytical models, additional cryptocurrencies, and customizable features, thereby catering to a wider range of user needs. The journey undertaken during this project has not only enriched my knowledge and capabilities but has also sparked my enthusiasm for continued exploration and innovation in the realm of data science, financial analysis, and application development.Perry J. Kaufman, Trading Systems and Methods . 6th edition, John Wiley Sons, 2013.", "label": "human"}
{"ID": "00100001", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Machine translation, commonly known as MT, is an innovative and transformative technology that facilitates the automated conversion of text from one language to another, without human intervention. As a pivotal aspect of natural language processing, machine translation holds immense potential to overcome linguistic barriers and foster seamless cross-lingual communication. Through the utilization of sophisticated algorithms and neural networks, MT systems analyze and interpret the underlying meaning of sentences in the source language, enabling the generation of equivalent and coherent translations in the target language. The evolution of artificial intelligence and deep learning has led to significant advancements in MT’s accuracy and fluency, rendering it an indispensable tool in diverse domains,including international commerce, diplomacy, and cultural exchange. As this techno logy continues to advance, its potential to revolutionize global communication and collaboration becomes increasingly apparent, underscoring its significance as a subject of exploration and analysis within this thesis.", "label": "human"}
{"ID": "00100002", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "A neural machine translation (NMT) model usually has trouble translating sentences that differ in genre or theme from the sentences used for training the model. This is a common limitation of data-driven machine learning methods, whose performance is guaranteed by assuming that the training and testing distributions are identical.", "label": "human"}
{"ID": "00100003", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Therefore, to achieve high performance in a given domain, we must carefully tailor the NMT model to that domain. The problem of tailoring an NMT model to a target domain is referred to as the domain adaptation problem. Two factors make this problem complex, including the scarcity of training data from the target domain and the catastrophic forgetting problem of the deep models. The lack of training data drives me to leverage parallel data from other domains to train our NMT models. The neural network-based models need many data to optimize their parameters.", "label": "human"}
{"ID": "00100004", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Therefore, I usually have to adapt our NMT model to the target domain using lots of out-of-domain data and a small amount of data from the target domain or finding target domain sentences. Second, several approaches to adapting an NMT model by fine-tuning it with the in-domain data only make its performance very brittle to the out-of-domain test. This problem is referred to as catastrophic forgetting in the neural network literature. The neural models tend to perform dramatically worse in previous tasks after being trained to perform their current tasks.", "label": "human"}
{"ID": "00100005", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "This transformative technology allows the system to process and produce accuratetranslations for domains such as legal, medical, technology, and more, without compromising on quality or efficiency. MDMT leverages cutting-edge techniques like domain tagging, domain adaptation, and multi-task learning or knowledge distillation to equip the model with domain awareness and fine-tune its translation capabilities for specific contexts. With the growing need for efficient cross-lingual communication in today’s globalized world, multi-domain machine translation holds great promise, offering a powerful solution to overcome linguistic barriers and facilitate effective communication across various industries and applications.", "label": "human"}
{"ID": "00100006", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Firstly, I will mention several methods for multi-domain machine translation, focusing on data-centric and model-centric. Data-centric adaptation methods are those that focus on selecting or generating appropriate in-domain data. In the absence of a pre-defined in-domain corpus, natural data (produced by a human) may be selected from a larger generic corpus or corpora according to some domain-specific criteria. A special case of natural data selection is filtering an existing in-domain corpus for cleaner or more relevant data. Departing from exclusively natural data, additional source or target sentences can be generated by neural models if only monolingual natural data is available. Semi-synthetic bilingual data can be produced by forward or back translation of existing natural data. Additional in-domain bilingual data can be partially synthesized from a small in-domain natural datasets using noising or simplification. Finally, purely synthetic data can be synthesized for adaptation.In , they propose a framework for training a single, multi-domain neural machine translation (NMT) model that can translate several domains without increasing inference time or memory usage. They show that this model can improve translation on both high and low-resource domains over strong multi-domain bases.", "label": "human"}
{"ID": "00100007", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In addition, their proposed model is effective when domain labels are unknown during training, as well as robust under noisy data conditions. After  released, many problems were solved using large amounts of data and with remarkable results. For multi-domain machine translation problem, the lack of data is also a big difficulty and the poor data quality, directly leads to bad results, incorrect output.", "label": "human"}
{"ID": "00100008", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "One way to solve this problem is to build a domain adapter model ,  that is directed to a specific domain. Their purpose in  is to exploit knowledge about the heterogeneous nature of the data to train a single fixed-capacity model that approaches the quality of the experts across all domains. Achieving high quality on each domain without ambitious quality on other domains and without increasing the model complexity is an goal that matches the setup of many user-facing MT systems. One drawback associated with employing distillation is the requirementfor a qualified teacher model, which, in turn, can result in significant memory resource utilization and a large number of parameters in quality models. Additionally, when using multiple teacher models , the memory usage scales arly with the number of teacher models, further exacerbating the resource demand.", "label": "human"}
{"ID": "00100009", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Beside data-centric methods, model-centric methods focus on adding domain specific parameters to reduce the interference between domains while keeping the total number of parameters small. The simplest approaches use domain tags.", "label": "human"}
{"ID": "00100010", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "For example,  proposed appending a special token to each source sequence indicating its domain such as < Domain = IT > and train the NMT model with this input. However, this method requires the domain tag of a sentence before translating it. Therefore, we have to predict the domain tag of the source sentence if it is from an unknown origin.  originally proposed appending domain tag to the target sequence so that the decoder will predict the domain in which it will generate the translation. Instead of using domain tags,  proposed using domain embeddings to incorporate the domain information into the context of the translation.  concatenated a domain embedding of small size (e.g., 4) to the embedding of each token in the input sequence. Each domain has its own embedding. Instead of using the domain embedding to represent the domain in the representation,  used a sparse word embedding called ”lexicalized domain representation”, in which a number of dimension are reserved for one domain and will be nullified if the model translates in other domains.", "label": "human"}
{"ID": "00100011", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The objective of this project is to develop a multi-domain machine translation system. Notably, contemporary machine translation tools like Google Translate and Bing primarily concentrate on general domains, rendering them less effective in domains with specific or specialized vocabulary. Consequently, the translationsprovided by these tools might yield unfavorable outcomes and potential misunderst andings for users. For examples, input: Cross-entropy is a widely used loss function in applications. It coincides with the logistic loss applied to the outputs of a neural network, when the softmax is used. , output: Entropy chéo là một hàm mất mát được sử dụng rộng rãi trong các ứng dụng. Nó trùng khớp với tổn thất logistic được áp dụng cho các đầu ra của mạng thần kinh, khi softmax được sử dụng. , another example about medical, input Hypertension is a condition characterized by high blood pressure , output Tăng huyết áp là một tình trạng đặc trưng bởi huyết áp cao . Evidently, when dealing with sentences pertaining to specific domains, Google Translate’s translation proficiency falls short.In order to address the issue, my task involves leveraging the existing machine translation resources for English and Vietnamese, filtering the data relevant to the domain of interest, and applying domain tag control techniques during the NMTtraining process. In Vietnam, VietAI - a non-profit organization has studied multi domain machine translation by creating quality datasets for domains, then fine-tune with a pretrained model. Inspired by that, I took advantage of VietAI’s data called Mtet  to apply to my system.", "label": "human"}
{"ID": "00100012", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "I integrated various multi-domain processing techniques, including domain tag control. Subsequently, I conducted rigorous testing and evaluation of the system’s performance.", "label": "human"}
{"ID": "00100013", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In Chapter 2, the literature review is presented, beginning with an core of the research scope pertaining to multi-domain machine translation. Subsequently, I delve into an overview of relevant studies and recent state-of-the-art research on this subject. Furthermore, an in-depth analysis of the merits and limitations of previous works that require attention is also provided.", "label": "human"}
{"ID": "00100014", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In Chapter 3, a brief introduction is provided for several fundamental concepts and techniques utilized in this research. The initial focus is on transformer models, a prevalent architecture extensively employed in various NLP applications in recent times. Subsequently, emphasis is placed on elucidating the latest developments in neural machine translation, along with advanced techniques such as domain tag control and knowledge distillation methods.", "label": "human"}
{"ID": "00100015", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Chapter 4 will provide an in-depth description of my work, elucidating the various components of the multi-domain machine translation system. Particular focus will be on the data acquisition process, where I leverage available data sources to obtain relevant datasets. Furthermore, I will discuss a technique employed to enhance training efficiency. Additionally, the methods utilized to generate machine translation results during inference time will be thoroughly addressed.", "label": "human"}
{"ID": "00100016", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "All experiments and implementation details are described in Chapter 5, including dataset statistics, hyperparameters, evaluation metrics, and comparison with stateof-the-art bases. I also present my observations on my proposed method compared with state-of-the-art baselines.", "label": "human"}
{"ID": "00100017", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Finally, Chapter 6 summarizes my work. I also point out some limitations that could be addressed in future works.2.1 Overview In this chapter, I briefly review related works which is conducting for multi domain machine translation and some basic knowledge of Neural Machine Translation (NMT) which provides the foundation for the experiments of this thesis. Neural Machine Translation was first introduced in 2014 via the work of ; . Since then, NMT has been largely developed and outperformed old approaches, including Rule-based Machine Translation (RBMT) and Statistical Machine Translation (SMT) in high-resource languages such as French-English or English-German. Building a Neural Machine Translation model consists of 3 basic steps, including text tokenization, training NMT model with pairs of tokenized source and target sentences and decoding or translating. In the first step, each sentence is transformed into a sequence of tokens, which can be words, sub-words, or characters. The sequence of tokens will be transformed into a sequence of integers. In the second step, given a choice of neural architecture ; the parameters of the NMT model are optimized according to a training objective . The input of the NMT model during the training consists of a pair of sequences of integers corresponding to a pair of source and target sentences.", "label": "human"}
{"ID": "00100018", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In the final step, when the NMT model is learned, given any sentence in the source language, the NMT model generates a translation via a decoding algorithm such as beam search . In the inference step, the input of the NMT model is only the sequence of integers corresponding to the source sentence.", "label": "human"}
{"ID": "00100019", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The related works section explores previous research and advancements in multi domain machine translation. Various studies have investigated the challenges of translating text across diverse domains and proposed different approaches to address this issue. A simple way is to use light-weight layer for multi-domain machine translation problem. The approach  propose involves the integration of small, task-specific adapter layers into a pre-trained model. These lightweight adapters, constituting only a small fraction of the original model size, facilitate the model’s simultaneous adaptation to multiple individual tasks. Experiments support the flexibility and scalability of light-weight adapters, (i) yielding comparable or better results when compared with the standard full fine-tuning or bilingual bases, (ii) without the need for any hyperparameter tuning across varying adaptation dataset sizes and model capacities. With a large set of globally shared parameters and small interspersed task-specific layers, adapters allow them to train and adapt a singlemodel for a huge number of languages and domains. From , where data isdomain-labelled, the labels themselves can be used to signal domain for a multi domain system. Domain labels may come from a human-created source or from a model trained purely to infer domain. Tags can be applied to either the source or target sentence.  introduce in-domain and generic domain source sentence tags during fine-tuning. They find this improves performance on the target domain, but show improved performance on the generic domain without tags, and suggest that tags discourage the model from taking advantage of any overlap between the generic and target domains. While most of the above work focuses on tagging the source sentence,  instead prepend in domain tags to the target sentence.", "label": "human"}
{"ID": "00100020", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "They suggest that although NMT models may not learn to infer domain without intervention, target tagging can provide that intervention and teach the model to classify the source sentence’s domain. Importantly this does not require the domain to be explicitly determined for new, user-generated source sentences. However, it also complicates the process of controlling the desired domain.", "label": "human"}
{"ID": "00100021", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In the context of multi-domain machine translation, the utilization of knowledge distillation has also garnered attention. Addressing one of the major challenges in multi-domain machine translation for low-resource languages, the ambiguity in distinguishing between domains and the limited availability of resources, knowledge distillation emerges as a chosen method to generate the necessary resources.  propose a framework for training a single multi-domain neural machine translation model that is able to translate several domains without increasing inference time or memory usage. They show that this model can improve translation on both high and low-resource domains over strong multi domain bases. In addition, their proposed model is effective when domain labels are unknown during training, as well as robust under noisy data conditions. Figure 2.1 describes the implementation process by the method of knowledge distillation. Regarding data with attacheddomains, the training process involves using a teacher model to train on all domain related data, encompassing data from all domains, to develop a comprehensive deep teacher model. Subsequently, the deep teacher model is employed to train separately on each domain, where each domain corresponds to an individual teacher model generating distilled data. Lastly, a smaller model is trained using both the original and distilled data. The student model’s reduced size and memory in comparison to the teacher model lead to significant reductions in memory usage during inference.", "label": "human"}
{"ID": "00100022", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The whole model they use is Transformer. They will keep the Transformer configuration and not use hyperparameter search. They implement perplexity-based early stopping on the development set for all models. For teacher models, they use 12 encoderFigure 2.1: Overview of the multi-domain knowledge distillation (MDKD) method. A single multi-domain model is trained on data that is distilled from high performance deep teachers. MDKD trains multiple deep teachers, each an expert in a specific domain.  and 12 decoder layers; for student models and bases, they use 6 encoder and 6 decoder layers. The teacher models have roughly 100M parameters, and the other models have roughly 60M parameters. When generating the distilled training and development data, they use a beam size of 10. They evaluate on BLEU score  and have increased 1.1 points from base. To cluster the training data, they first compute sentence embedding of all the source training sentences using the multilingual variant of BERT (mBERT) , which has 768 dimensions and is trained on Wikipedia data from 104 languages. They then apply k-means clustering  to compute the clusters on the inferred sentence embedding. In terms of advantages, this method is easy to approach and implement in an uncomplicated way, using a smaller model to train on the original data and the data generated from the teacher model has reduced resources. However, on the downside, data quality is highly dependent on the teacher model. In particular, when scaling new domains, it is necessary to train more models with each of those domains to generate distilled data. In addition, they have not mentioned how much the BLEU score will be reduced by using the student model and teacher model.", "label": "human"}
{"ID": "00100023", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Text preprocessing includes two steps, including text normalization and text tokenization. Text normalization aims to transform a text into a single canonical form. Text tokenization transforms a sentence into the input format of the NMTmodel. In practice, text normalization is optional, while text tokenization is obligatory.", "label": "human"}
{"ID": "00100024", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The tokenization process consists of transforming a sentence into sequence of symbols called tokens, which will be transformed into sequences of integers and then be served as the input of the NMT model. Text tokenization is an essential step in NMT and needs to be carefully conducted. I have to tokenize sentences because NMT models only take a sequence of integers as input. In practice, a token can be a word or a part of a word. There are three common types of token: words, subwords, and characters. These tokens are indexed by a predetermined vocabulary so I can map each token to an integer. The sequence of tokens is converted into a sequence of integers IDs∈Vwhere V is the set of indices of the corresponding vocabulary.", "label": "human"}
{"ID": "00100025", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The vocabulary of the NMT model is fixed. Any out of vocabulary (OOV) token is mapped to a special token < UNK > , which stands for unknown. The size of the vocabulary of an NMT model is chosen to balance the coverage over the processed tokens with a practical constraint on the size of the model. The vocabulary of an NMT model is usually limited to 30-40 thousand types. In the following discussion, I denote Σx,Σythe source vocabulary and the target vocabulary, respectively. . The tokenization process needs to be reversible. To get the final translation, I convert the sequence of tokens predicted by the NMT model into a normal sentence.", "label": "human"}
{"ID": "00100026", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Word tokenization Word tokenization identifies all unique words in the respective training sets to construct the source and target language vocabularies. Because of the computational constraints, the vocabulary of an NMT model is typically limited to a few tens of thousands of types. The types found in the training sets will be reordered according to their frequency, and the top V most frequent types are selected to form a vocabulary . This tokenization algorithm has the disadvantage that its coverage is relativelysmall. Consequently, word-based NMT models usually have to scope to out-of vocabulary tokens ; ; .", "label": "human"}
{"ID": "00100027", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Character tokenization Character tokenization segments words into sequences of characters. This tokenization circumvents the problem of finding an optimal sub-word segmentation for multiple languages in multilingual NMT. Furthermore, character tokenization reduces the size of the vocabulary to a small number of written characters. However, the length of the resulting sequence increases significantly as words are extremely split into character units. As a result computational requirements during training and decoding time increase. First studies on the character-based NMT , including the work of; , focused on solving the out-of-vocabulary and softmax bottleneck problemsassociated with word-level models.; ;  proposed variants of character based model.", "label": "human"}
{"ID": "00100028", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Byte-level tokenization Byte-level tokenization is used to segment the byte-level representation of the text. The rationale behind this tokenization is that byte-level representation could handle character rich languages such as Japanese and Chinese. However, for thesame sentence, the byte-level representation is usually much longer than the character level representation. Furthermore, taking a sequence of bytes as the input of the NMT model greatly increases the cost. To reduce the length of the input sequence, byte-level tokenization applies BPE tokenization on sequences of bytes. In practice,showed comparable performance of byte-level BPE-based NMT compared to BPE based NMT 2.3.4 Subword Tokenization Subword tokenization is the process of finding an optimal segmentation of words such that a limited set of word-pieces can segment a large vocabulary. The rationale behind the subword tokenization is that words are usually composed of several morphemes. For example a plural countable noun is composed of its root and the affix ”s”. By separating the root and the affix, I avoid adding both the singular and the plural form of a noun in our vocabulary and reduce the size of it. In practice, subword tokenization largely increases the coverage of the vocabulary and efficiently handles unseen words. The vocabulary can be built by applying the morphological rules of the language or can be learned by heuristic algorithms such as Byte pair encoding (BPE ) . The two more popular subword tokenizations are the BPE tokenization  and Sentence-piece tokenization , which are based on 2 different approaches: frequency-based and sampling-based respectively.", "label": "human"}
{"ID": "00100029", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "BPE tokenization is based on the following algorithm. Given a corpus and an upper bound K of the number of merge operations, BPE tokenization learns a set of at most K merge operations and a set of subwords that allows the formation of any word in that corpus. In principle, words are first segmented into sequences of characters. At each iteration, the BPE algorithm counts the occurrences of each pair of the current types (characters in the beginning), then adds the merge operation of the most frequent pair to its operation set. Next, it redefines the segmentation of every word according to the new operation set and moves to the next iteration.", "label": "human"}
{"ID": "00100030", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The algorithm stops when it reaches the upper bound K. In the end, frequent words remain unsegmented while rare words become sequences of BPE types. Given a set of BPE operations, BPE tokenization segments a word by first segmenting it into asequence of characters and then applying merge operations to the characters. BPE operations can be learned jointly from both the source and the target languages, from multiple languages as in multi-lingual NMT or separately from each language.", "label": "human"}
{"ID": "00100031", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Despite the efficacy in the open-vocabulary NMT, BPE tokenization segments a word into a unique sequence of tokens whereas there exists different segmentation candidates. Because the model only see the sequences of ids, while these sequences encode the same input, NMT handles them as completely different inputs. Therefore, training a NMT model with different segmentation candidates improve the robustness of the model .  proposed BPE-dropout which introduces stochastic corruptions in the segmentation procedure of BPE, which leads to producing multiple segmentation candidates within the same fixed BPE framework.", "label": "human"}
{"ID": "00100032", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In principle, an NMT model consists of 3 parts: 1) a look-up table of word embeddings, 2) an encoder and 3) a decoder. Similar to the SMT approach, an NMT model modelizes the conditional probability of the target sequence given a chain of conditional probabilities which predict a target token given the previous predicted target tokens and the source sequence as I always assume that the target sentence is initialized by a special token named ”begin-of-sentence” < BOS > , hence, y0=< BOS > . The encoder maps the source sequence xto an intermediate representation in a continuous high dimensional vector space. The Decoder takes the representation of the source sequence Enc(x) as input to condition its prediction on the source sequence. At each time step i, the decoder outputs a distribution over the target vocabulary by mapping its ithhidden computed recursively as si=g(si−1, yi−1, ci) (2.3)using the hidden state of the previous time step, the observation of the previous time step (for example, the (i−1)thtoken ) and the context ci, which is computed from the representation of the source sequence Enc(x)andsi−1.", "label": "human"}
{"ID": "00100033", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In order to transform the input sequence of integers into continuous hidden states, Encoder and Decoder have to use a look-up table of word embeddings. A word embedding is a real valued vector in a high dimension space that represents a token in the vocabulary of the NMT model. The motivation of using word embedding is to transform the input sequence of integers to a sequence of vectors in a continuous space which allows the parameters of the NMT model to be trained with gradient embedding space. Word embeddings are not only used in NMT models but also in Neural language models . ;  used NLM for phrase-based statistical machine translation. Moreover, word embedding can be trained alone using the Skip-gram model  or the Continuous Bag of Word model . After training such models, the resulting word embeddings possess semantic properties so that words having similar meanings or close meanings are mapped to similar vectors in terms of cosine similarity . The fine-grained semantic representation of word embeddings significantly improves the performance of AI in text classification, text retrieval, etc., and surprisingly enables unsupervised machine translation and unsupervised word translation . By using word embeddings, the source sequence is mapped to a sequence of real valued vectors.", "label": "human"}
{"ID": "00100034", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The encoder encodes the source sequence of word embeddings to another sequence of real value vectors (hidden states or contextualized embeddings) ;; , in a high dimension space called a latent space. This process aims to mix the representation of each token with ones of the context surrounding that token. Thecontext of a word is the set of words surrounding that word. Combining the representa tion of a word with its context allows the NMT model to condition the translation of that word on its context. The encoder can combine the state of the token with one of its preceding tokens in a Recurrent encoder, with ones of the surrounding windowin a Convolutional encoder, or with ones of the whole sentence in an Attention based encoder. Each encoding paradigm has its advantages and disadvantages. The Recurrent encoder respects the order of tokens because it consumes tokens one by one from left to right. However, it is very slow to encode the input sequence.", "label": "human"}
{"ID": "00100035", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Convolutional encoder and Attention-based encoder encode all input tokens simultan eously that brings a great advantage in speed. But allowing direct connections between states prevents Convolutional encoders and Attention-based encoders fromapprehending the sequence’s order. Therefore they have to use positional embedding to know the position of each token.", "label": "human"}
{"ID": "00100036", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The decoder works similarly to a language model as it predicts one token per time step. However, the decoder conditions its prediction on the source sequence.", "label": "human"}
{"ID": "00100037", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Therefore, the decoder takes the output of the encoder as its inputs. An Auto regressive decoder conditions its prediction on the predictions of previous steps and the source sequence. The decoder usually uses the same neural architecture as the encoder. However, unlike the encoder, the range of context of a token is strictly limited to its preceding tokens. Because the hidden state of the decoder is computed from the previous hidden states and the observation of the previous step, I need to initialize the 0thhidden state s0(optional) and the 0thtoken. That is why I always begin the target sequence by the token < BOS > , and the decoder starts predicting from the second token on. For example, if [a, b, c, d, e ]is predicted by the decoder, the prediction of token a is conditioned by source sequence xand< BOS > ; the prediction of token bis conditioned by source sequence xand[< BOS >, a ]and so on. Besides, the decoder needs a signal to stop its generative prediction. I always end a prediction by ”end-of-sentence” token or < EOS > . Therefore, instead of predicting [a, b, c, d, e ], the decoder predicts [a, b, c, d, e, < EOS > ]. Concerning the construction of hidden states, the Recurrent decoder usually initializes s0by the last hidden state of the encoder followed by a ar transformation.", "label": "human"}
{"ID": "00100038", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "NMT’s architectures are usually a stack of multiple layers. As described above, the input source sequence is mapped to a sequence of word embeddings. This is considered the 0 th layer of the Encoder. The ithlayer is built upon the (i−1)th layer by applying the same encoding mechanism, which can be recurrent layer, convolutional layer or self-attention layer, to the output of the (i−1)th. I illustrated multi-layer RNN in figure 2.2 . Or for example,  stacked 6 Transformer layers in both the encoder and the decoder of their NMT model. Deep NMT models are able to learn from very large-scale of parallel data and continually create new remarkable performances, state-of-the-art model. However, deep NMT models are harder to train because the gradient flow has to back-propagate through many layers. In order to prevent the gradient flow from vanishing, which happens when the value of the output of the ar transformation in some layer jumps outside the domain of the activation function,  proposes using residual connections, which replaces f(x)byf(x) +xwhere xis the output of the lower layer and f(.) is the transformation of the layer, to transit from the lower layers to their following layers. By using residual connections, a fraction of the gradient still reaches the lower layer and continues to propagate until the lowest layer.Figure 2.2: Recurrent Neural Network2.5 Recurrent neural machine translation This section reviews the very first NMT architecture, the Recurrent neural machine translation architecture (RNMT). RNMT is composed of a Recurrent encoder, a Recurrent decoder, and tables of word embeddings. The Recurrent encoder and the Recurrent decoder usually use the same type of Recurrent neural network (RNN) layers, such as Gated recurrent unit (GRU) and Long-short term memory (LSTM), which Iwill explain in the following section. RNMT is strictly auto-regressive as each hidden state in the encoder/decoder has to go through every intermediate state to assess the information of any time step before it. The hidden states of RNMT inherit the ordering information, which is an advantage over Convolutional neural machine translation (CNMT) and Attention based neural machine translation (ANMT).", "label": "human"}
{"ID": "00100039", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "However, a lack of straightforward connections between the positions of the input sequence causes many difficulties in the training of RNMT, for example the vanishing gradient problem in backpropagation through time  2.5.1 GRU, LSTM layers Gated recurrent units (GRU) and Long-short term memory units (LSTM) are the two most popular layers in the group of Recurrent neural networks. They follow the auto-regressive paradigm by constructing the hidden states one by one as follows hl t=f(hl−1 t, hl t−1) (2.4) where hl−1 tis the hidden state at time step tof the (l−1)thlayer, the 0thlayer is the sequence of word embeddings; the mapping f can be GRU cell or LSTM cell, which will be explained below.", "label": "human"}
{"ID": "00100040", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "LSTMs were first introduced by . They use 4 gating functions including input gate i, output gate o, forget gate fand memory cell c. At each time step t, the contextualized embedding ht is computed as follows t+Ufht−1+bf), t+Uiht−1+bi), t+Uoht−1+bo), c˜ t+Ucht−1+bc), ct=ft⊙ct−1+it⊙c˜,the hyperbolic tangent function or the identity function and ⊙is the element-wise multiplication. These functions are applied element-wise to intermediate vectors in the equations.", "label": "human"}
{"ID": "00100041", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The motivation behind this highly complex structure is to stabilize the exploding/dimi nishing gradient flow  induced by back-propagation through time.", "label": "human"}
{"ID": "00100042", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "RNN encoders RNN encoders use LSTM or GRU layers to encode the source sequence. RNNencoders can use more than one layer to capture more fine-grained language represent ations . The 0thlayer is a sequence of word embeddings, which are extracted from the look-up table of the source side using the word ordering provided by the source sequence.", "label": "human"}
{"ID": "00100043", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "RNN decoders RNN decoders predict the target sequence from left to right, one token per time step. It initializes the 0thhidden state by zero vector or a ar transformation of the last hidden state of the last layer of the encoder. The following section will discuss on an important component of the NMT model, which are attention mechanisms.", "label": "human"}
{"ID": "00100044", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "As the hidden representation of the decoder at each step is computed as follows si=g(si, yi−1, ci) (2.5) where ciis the context vector, ciis computed via an attentional mechanism using si and Enc(x). The prediction probability will be computed as follows where yiis an index of the target vocabulary, Dense is dense layer, whose output is 2.5.4 Attention mechanisms An attentional mechanism consists of 3 components: Query vectors, Key vectors, and Value vectors. Given a sequence Qi, i∈[1. . . n]Kj, j∈[1. . . m ]andVj, j∈ [1. . . m ], the resuls of the attentional mechanism composed by those vectors will be as follows Attention (Q, V, K )i= Σm j=1exp(sim(Qi, Kj)) Σm p=1exp(sim(Qi, Kp))∗Vj, i∈[1, . . . , m ](2.7) where the function sim(x, y)can be the standard dot product < x, y > The attention mechanism manages and quantifies the dependences between the input sequence and the output sequence (e.g., source contextualized embeddingsand target contextualized embeddings), or the input sequence itself (e.g., self attention layers in Transformer ). In the RNN MT model, the attentional mechanism is used to capture the dependences of each token in the target sequence on the tokens in the source sequence. For example,  computed a context vector at ith time step in the decoder as follows Σkexp(eik), (2.8) eik=sim(si−1,hk) where hjis the output of the last layer of the encoder, si−1is the hidden state at the (i−1)thtime step of the last layer of the decoder.", "label": "human"}
{"ID": "00100045", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In recent times, pre-trained transformer models  have exhibited their effectiveness across various natural language processing (NLP) tasks, including Neural Machine Translation, Question Answering, Sequence Classification, and Sentiment Analysis.", "label": "human"}
{"ID": "00100046", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The notable achievements of pre-trained transformer models in contemporary NLP, which relies on Deep Learning techniques, can be attributed to two key factors:", "label": "human"}
{"ID": "00100047", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "pre-training and self-attention mechanisms. Unsupervised pre-training empowers the network to generate highly contextualized word and sentence vectors, while self-attention mechanisms establish global dependencies between words, enabling the model to capture the entire input sequence efficiently.", "label": "human"}
{"ID": "00100048", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Apart from their remarkable empirical performance, pre-trained transformer models offer the advantage of faster training when compared to architectures utilizing recurrent or convolutional layers. An overview of the transformer model architecture is provided in 2.6, followed by the introduction of mBart, one of the most popular pre-trained language models based on the transformer architecture.", "label": "human"}
{"ID": "00100049", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Transformer Architecture The transformer architecture consists of two main components: the encoder and the decoder. The encoder is constructed as a sequence of Nidentical blocks,each containing a multi-head self-attention mechanism and a fully connected feed forward sub-layer. This self-attention mechanism allows the encoder to compute a representation of the input, avoiding the need for recurrent or convolutional operations. Similarly, the decoder also follows a comparable architecture but incorporatesFigure 2.3: Transformer architecture from  an extra intermediate masked attention sub-layer that operates over the encoder output. The encoder part of transformer, illustrated in 2.3, embeds the input sequence ofnwords X∈Rn∗dinto context vectors with the attention mechanism. Different parts of the encoder are explained in the following.", "label": "human"}
{"ID": "00100050", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Positional Encoding Due to the absence of recurrence and convolution in the model, it lacks inherent knowledge of the order within a sequence. Since the order of words is crucial for sentence meaning, it becomes necessary to incorporate a method to capture the positional information of tokens or words within the sequence. To achieve this, a positional vector is introduced and added to each input word embedding. Let us denote the embedding of the ithword in the sequence as xi∈R. To represent the position of the ithword in the sequence, I introduce a position vector pi∈R, which can be set as follows:", "label": "human"}
{"ID": "00100051", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "pi(2j+ 1) = cos(i 100002i p) (2.9) pi(2j) = sin(i 100002j p) (2.10)Figure 2.4: Multi-head Attention from  b, Multi-head Attention After positional encoding, data are fed to a multi-head attention module with self-attention. The multi-head attention is illustrated in 2.4. This module applies the attention mechanism for htimes. The reason for multiple repetitions of attention can be elucidated as follows. The first attention pass determines the extent to which each word attends to other words. Subsequently, the second attention pass computes the degree to which each pair of words attends to other pairs of words.", "label": "human"}
{"ID": "00100052", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Similarly, the third attention pass investigates the level at which each set of two pairs of words attends to other pairs of words. In this manner, we employ a total of har layers to generate hsets of queries, values, and keys, which are used in the attention mechanism 2.5.4 Qi=WT Q,iX;Ki=WT K,iX;Vi=WT V,iX (2.11) where 1<=i <=handWQ,i, WK, i, W V,iare query, key, value matrix of layer i.", "label": "human"}
{"ID": "00100053", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "head i=softmax (QT Finally, all of heads will be concatenated and I obtained the multi-head attention through a projection layer as:", "label": "human"}
{"ID": "00100054", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Zt=Concat (head 0, . . . , head n)WO(2.13) To this end, the output multi-head attention goes through a layer normalization andtwo feed-forward layers as:", "label": "human"}
{"ID": "00100055", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Xt+1=FFN (Zt) =max(0, W1Zt+b1)W2+b2 (2.14) 2.6.2 mBart - Multilingual Denoising Pre-training for Neural Machine Translation According to the abstract, MBART is a sequence-to-sequence denoising auto encoder pretrained on large-scale monolingual corpora in many languages using the BART  objective. mBART  is one of the first methods for pretraining a complete sequence-to-sequence model by denoising full texts in multiple languages, while previous approaches have focused only on the encoder, decoder, or reconstructing parts of the text. MBart use a standard sequence-to-sequence Transformer architecture , with 12 layers of encoder and 12 layers of decoder with model dimension of 1024 on 16 heads (680M parameters). MBart include an additional layer-normalization layer on top of both the encoder and decoder, which MBart found stabilized training at FP16 precision. In their work, following , the researchers utilize two types of noise in the generation process. Firstly, they remove sections of text and substitute them with a mask token. This involves masking approximately 35% of the words in each instance, with the span length randomly sampled based on a Poisson distribution each instance. The decoder input is the original text, but with a one-position offset.", "label": "human"}
{"ID": "00100056", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "To initiate the sentence prediction, they introduce a special language ID symbol denoted as < LID > . While other noise types, like those mentioned in , are possible options, they defer the exploration of the most optimal noising strategy to future research. Specifically, Mbart has demonstrated favorable outcomes in handling the Vietnamese language and certain languages with limited available resources.", "label": "human"}
{"ID": "00100057", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The evaluation of MT systems can be done automatically by comparing n-grams of generated translations and n-grams of gold references. The most popular MT metric is BLEU . Recently,  proposed standardizing hypotheses of MT systems before calculating the BLEU score. BLEU is computed at the corpus-level, i.e., it compares a corpus of hypotheses and the corpus of references. BLEU score is the geometric average of n-gram precisions, including 1-gram, 2-grams, 3-gramsand 4-grams weighted by brevity penalty (BP) 44X i=1log(pi)! (2.15) The n-gram precision pnis computed as follow pn=P hyp∈hypsP n-gram ∈n-gramsmin( Count (Ref,n-gram ),Count (hyp,n-gram ))P hyp∈hypP n-gram ∈-gramsCount( Ref,n-gram ), (2.16) where Count (C, g)is the number of occurrences of the n-gram g in the corpus C.", "label": "human"}
{"ID": "00100058", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The Brevity penalty computed as follows BP=  exp\u0010 otherwise.(2.17) where cis the total length of the hypothesis corpus, ris the total length of the reference corpus. The Brevity penalty assures that a high-scoring candidate translation must also match the reference translations in length.", "label": "human"}
{"ID": "00100059", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In this section, I provide an overview of the datasets employed in the context of the Multi-Domain Machine Translation (MDMT) problem. For domain classification, I utilize the opus dataset , which encompasses data from three distinct domains:", "label": "human"}
{"ID": "00100060", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "However, for the classification problem, only the English data is utilized. One limitation of this dataset is its high prevalence of duplicates, which I address by removing duplicate entries. Additionally, I filter out sentences with lengths less than 50 and eliminate sentences containing hyperlinks, phone numbers, and other extraneous information to enhance the dataset’s quality and applicability for domain classification. At 2.1, I describe the number of sentences in each domains .After IT Medical Law 347,817 1,108,752 719,372 Table 2.1: Opus dataset ’s statistic filtering the datasets, I got new datasets by removing duplicating sentences, removing the sentences that thier lengths is less than 50, hyperlink, phone numbers, ...IT Medical Law 13,645 9,597 8,540 Table 2.2: A new dataset ’s statistic Figure 2.5: Description of Mtet datasets  Subsequently, I will elucidate the utilization of the Mtet dataset , which is employed for addressing the multi-domain machine translation problem. Mtet is a widely used benchmark dataset in the context of multi-domain machine translation (MDMT) research. It is specifically designed to evaluate the performance of machine translation systems in handling translations across diverse domains. The availabilityof the Mtet dataset has significantly contributed to advancing the field of multi domain machine translation for EN-VN and has become a crucial resource for researchers aiming to develop and evaluate state-of-the-art translation systems.", "label": "human"}
{"ID": "00100061", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In 2.5, Legal Document own 27.3%, Medical Publications is 0.3% and Software acquire 1.9%, all of domains I am considering which is contained in Mtet datasets.In this exposition, I shall provide a comprehensive account of the multi-domain machine translation system 3.1 I have developed, including two principal components:", "label": "human"}
{"ID": "00100062", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "the domain classifier (ds)and the Neural Machine Translation (NMT) module. The primary function of the domain classifier (ds) is to categorize sentences within an extensive dataset of unlabeled domains, identifying sentences belonging to the three specific domains targeted, namely medical, technology, and law. Once the data from these domains is obtained, I proceeded to fine-tune the mBart model using the domain-oriented dataset.", "label": "human"}
{"ID": "00100063", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Indeed, the utilization of domain tags has been a prevalent topic in numerous studies, particularly in the domain of multilingual machine translation. Domain tags are an effective technique employed to indicate the specific domain or topic of a given sentence or text, adding in the training and adaptation of machine translation models to diverse domains. In multilingual machine translation, domain tags are instrumental in distinguishing between various domains, thereby enabling the model to generate contextually appropriate translations for each domain.", "label": "human"}
{"ID": "00100064", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "By incorporating domain tags during the training process, the model becomesmore domain-aware and proficient in handling domain-specific language. The app lication of domain tags in multilingual machine translation has shown promising results in improving translation quality across different domains, ensuring more accurate and domain-specific translations. Researchers and developers continue to explore and refine the use of domain tags as a valuable technique to enhance the performance and adaptability of machine translation systems in multilingual and Figure 3.1: Multi domain machine translation systemFigure 3.2: Knowledge distillation multi-domain settings.", "label": "human"}
{"ID": "00100065", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In constructing the domain classification component 3.3, I employ a variant of BERT known as DistillBERT . DistillBERT is a condensed version of theoriginal BERT model, designed to be smaller, faster, more cost-effective, and light weight while still retaining a substantial portion of BERT’s performance capabilities.", "label": "human"}
{"ID": "00100066", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "By utilizing DistillBERT, I aim to reduce the computational and memory resources required for domain classification tasks, making it more efficient and practical for real-world applications. Despite its smaller size, DistillBERT maintains a consider able level of performance, making it a suitable choice for domain classification in the multi-domain machine translation system. Knowledge distillation  is primary technique used for training DistilBERT, as 3.2, hence the name \"distilBert.\" During the training process, distilBert, or the student model, benefits from the guidance of the teacher model to enhance its performance. When trained conventionally, the student model applies the cross-entropy loss function, which is defined as follows:", "label": "human"}
{"ID": "00100067", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Loss ce=−CX i=0qi∗log(pi) (3.1) where C are all of sentences in corpus, p is the prediction probability, q is the ground-truth, the goal of minimizing the loss function is to make the prediction probability distribution and the ground-truth most similar. To enhance the student’s predictions, the loss function employs the teacher’s predictions instead of relying on the ground-truth. In this manner, the training process aims to ensure that the student’s predicted probability distribution closely aligns with that of the teacher.Figure 3.3: Domain classification diagram An analogy can be drawn to a scenario where a teacher provides answers to a multiple-choice test; in this case, a student’s performance is optimized when their chosen answer aligns closely with the teacher’s provided answer. Similarly, knowledge distillation seeks to train the student model to approximate the teacher’s predictions, enabling the student to benefit from the teacher’s knowledge and achieve improved performance. Thus, the distillation loss at xithe observation will have the formulas:", "label": "human"}
{"ID": "00100068", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Loss distill (xi, W) =H(qit, qis) (3.2) where His cross entropy function, qitis the prediction probability of teacher model atxiandqisis the prediction probability of student model at xi.", "label": "human"}
{"ID": "00100069", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Throughout the domain classification training, I maintained the configuration of distilBert, no conducting hyperparameters search, and for the dataset, I solely utilized the English data from the opus dataset, as previously mentioned. Additionally, I incorporated data from the PhoMT datasets , containing four distinct labels:", "label": "human"}
{"ID": "00100070", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "IT,medical ,law, and other . I employ libraries within the Huggingface ecosystem, such as transformers which refers to a popular open-source library developed by Hugging Face, a company specializing in natural language processing (NLP) anddeep learning. The library is designed to provide easy access to a wide range of pre trained models for NLP tasks, with a particular focus on transformer-based models.", "label": "human"}
{"ID": "00100071", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Transformers in Hugging Face allows researchers, developers, and NLP enthusiasts to quickly and efficiently leverage state-of-the-art transformer architectures such as BERT, GPT, RoBERTa, and more. These models have achieved remarkable success in various NLP tasks, including text classification, question-answering, language translation, and sentiment analysis. The library offers a unified and consistent API, making it straightforward to use and switch between different transformer models and architectures seamlessly. Users can easily fine-tune these pre-trained modelsFigure 3.4: HuggingFace ecosystem  on their specific NLP tasks or use them directly for downstream applications.", "label": "human"}
{"ID": "00100072", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In addition, datasets library in Hugging Face is an essential component of the ecosystem, designed to stream data management and access for natural language processing (NLP) tasks. It provides a wide range of high-quality and preprocessed datasets that are commonly used in NLP research and applications. The datasets library in Hugging Face is an essential component of the ecosystem, designed to stream data management and access for natural language processing (NLP) tasks. It provides a wide range of high-quality and preprocessed datasets that are commonly used in NLP research and applications.", "label": "human"}
{"ID": "00100073", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "This section provides a comprehensive account of the NMT construction process 3.6. Building upon the achievements of transfer learning, I employ mBart , a state-of-the-art model renowned for its excellence in machine translation tasks.", "label": "human"}
{"ID": "00100074", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "mBART (multilingual BART) is a state-of-the-art multilingual sequence-to-sequence pre-trained model developed by Facebook AI. It is an extension of BART  (Bidirectional and Auto-Regressive Transformers), which is a powerful denoising autoencoder pre-trained on a large corpus of monolingual text. mBART extends BART’s capabilities to support multiple languages, making it a highly versatile and effective model for a wide range of multilingual natural language processing (NLP) tasks. It is capable of handling tasks such as text generation, text summarization, machine translation, and more, across multiple languages. One of the key features of mBART is its ability to handle zero-shot translation, which means it can performtranslation between language pairs that were not explicitly included during pre training. This makes it a valuable tool for low-resource languages and enables transfer learning between different language pairs. mBART has achieved impressive performance on various benchmark datasets and has been widely adopted in the NLP research community. With its multilingual capabilities, mBART continues to play a significant role in advancing multilingual NLP and enabling effective cross-lingual transfer learning in various language-related tasks. Acquiring datasetsFigure 3.6: Neural machine translation diagram for machine translation across diverse domains can be prohibitively expensive, especially for low-resource languages. Utilizing automatic models for data generation introduces errors, and the model’s knowledge distillation is limited to the data which has learned. In Vietnam, VietAI has built a dataset including various domains by leveraging domain-specific data from reputable websites available in Vietnam named Mtet . MTet dataset is a large-scale, multi-domain English-Vietnamese translation dataset. It contains roughly 4.2 million English-Vietnamese pairs of texts, ranging across multiple different domains such as medical publications, religious texts, engineering articles, literature, news, and poems. The MTet dataset is a valuable resource for researchers and developers working on English-Vietnamese machine translation. It is a large and diverse dataset, which means that it can be used to train machine translation models that are capable of translating text in a variety of different contexts. The MTet dataset is also a high-quality dataset.", "label": "human"}
{"ID": "00100075", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The sentences in the dataset have been carefully curated to ensure that they are grammatically correct and semantically meaningful. This makes the MTet dataset an ideal resource for training machine translation models that produce high-quality translations.", "label": "human"}
{"ID": "00100076", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "However, the dataset lacks domain-tags categorization, necessitating a filtering process. As previously mentioned, domain classification has been mentioned in the preceding section, and the subsequent task involves filtering the Mtet dataset, which comprises IT,law, and medical domains. The mBart model will be utilized in this process. To accommodate the entire training process, the Kaggle platform’s single P100 GPU, which allows free access for 30 hours every week, will be employed.", "label": "human"}
{"ID": "00100077", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In this section, I out two training scenarios. In the first scenario, the training will solely involve the domains of IT, medical, and law, and the evaluation willbe conducted on both the test set of Mtet  and the test set of PhoMT .", "label": "human"}
{"ID": "00100078", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Subsequently, in the second scenario, additional pairs from the PhoMT sets will be incorporated for training, focusing on specific domains. The evaluation will again be performed on the 2 test sets, as in the first scenario.", "label": "human"}
{"ID": "00100079", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "For the model configuration, I maintained the model’s parameters unaltered and utilized the pretrained model \"mbart-large-50-many-to-many-mmt,\" comprising 12 encoder blocks and 12 decoder blocks. During preprocessing, each input sentence is added with a special token corresponding to its domain. For instance, a sentence in the law domain would be represented as < law > +sentence i. Subsequently, all sentences underwent encryption using the BPE algorithm, ensuring uniformity in sentence lengths with a maximum length of max_length = 128 . Padding and truncation techniques were employed to achieve sentences of equal length. The computational model was then fed with the processed inputs, and the parameters were updated following normal neural machine translation practices.In this chapter, I will provide a more comprehensive presentation of the base and experimental evaluation results compared to the two experiments previously discussed in the preceding chapter 3.2.", "label": "human"}
{"ID": "00100080", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The English and Vietnamese machine translation task involves the assessment of two datasets, namely PhoMT and IWSLT15. To evaluate the models’ performance, I will obtain the results from the website Vietnamese Machine Translation , which will serve as the base for comparison. In 4.1, I have mentioned 2 models which Model Fine-tuned En-Vi BLEU score EnViT5 PhoMT + Mtet 45.47 mBart PhoMT 43.46 Table 4.1: Baseline for machine translation are state of the art in translating English to Vietnamese. A limitation in these two models is that they only evaluate on the PhoMT dataset, not across domains. A limitation in these two models is that they only evaluate on the PhoMT dataset, not across domains.", "label": "human"}
{"ID": "00100081", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In 4.2 table, I have mentioned the result of scenarios 1 which only employs data filtered in Mtet datasets. One point that can be observed is that my model Model Test set En-Vi BLEU score ours Mtet with 3 domains 40.25 PhoMT 37.56 Table 4.2: Result of scenarios 1 is experiencing the phenomenon of catastrophic forgetting . The model is only trained on certain domains, resulting in an evaluation score that is 3 points higher compared to the data from the PhoMT dataset. This is one of the frequently encountered phenomena in deep learning models.", "label": "human"}
{"ID": "00100082", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "I tested the evaluation on some pairs of sentences as follows Sentence 1 : \" Machine learning is a field of computer science that explores the development of algorithms and models, enabling computer systems to automatically learn from data, identify patterns, make predictions, and perform tasks without explicit programming, revolutionizing various domains such as image recognition, natural language processing, recommendation systems, and autonomous vehicles. \" ours : \" Máy học là một lĩnh vực của khoa học máy tính khám phá sự phát triển của các thuật toán và mô hình, cho phép các hệ thống máy tính học tự động từ dữ liệu, xác định các mô hình , đưa ra các dự đoán, và thực hiện các nhiệm vụ mà không cần lập trình cụ thể, cách mạng hóa các lĩnh vực khác nhau như nhận diện hình ảnh, xử lý ngôn ngữ tự nhiên, các hệ thống khuyến cáo, và các phương tiện tự động. \" Google Translate: \" Học máy là một lĩnh vực khoa học máy tính khám phá sự phát triển của các thuật toán và mô hình, cho phép các hệ thống máy tính tự động học hỏi từ dữ liệu, xác định các mẫu, đưa ra dự đoán và thực hiện các tác vụ mà không cần lập trình rõ ràng, cách mạng hóa các lĩnh vực khác nhau như nhận dạng hình ảnh, xử lý ngôn ngữ tự nhiên , hệ thống khuyến nghị và xe tự hành. \" Sentence 2: \" Supervised learning is a type of machine learning where the model is trained on labeled examples, enabling it to make predictions or classify new, unseen data based on the patterns learned from the training data. \" ours : \" Học theo giám sát là một loại học máy trong đó mô hình được huấn luyện trên các ví dụ được dán nhãn, cho phép nó có thể dự đoán hoặc phân loại dữ liệu mới, chưa thấy được dựa trên các mô hình học từ dữ liệu huấn luyện. ’, Google Translate: \" Học có giám sát là một loại máy học trong đó mô hình đượcđào tạo trên các ví dụ được gắn nhãn, cho phép nó đưa ra dự đoán hoặc phân loại dữ liệu mới, chưa nhìn thấy dựa trên các mẫu đã học được từ dữ liệu đào tạo. \" Sentence 3: \" Hypertension is a condition characterized by high blood pressure \" ours : \" Tăng huyết áp là một tình trạng đặc trưng của huyết áp cao. \" Google Translate : \" Tăng huyết áp là một tình trạng đặc trưng bởi huyết áp cao \" Sentence 4 : \" Cross-entropy is a widely used loss function in applications. It coincides with the logistic loss applied to the outputs of a neural network, when the softmax is used. \" ours : \" Cross-entropy là một chức năng mất mát được sử dụng rộng rãi trong các ứng dụng. Nó trùng với mất mát logistic áp dụng cho các đầu ra của một mạng thần kinh, khi softmax được sử dụng. \" Google Translate : \" Entropy chéo là một hàm mất mát được sử dụng rộng rãi trong các ứng dụng. Nó trùng khớp với tổn thất logistic được áp dụng cho các đầu ra của mạng thần kinh, khi softmax được sử dụng. \" Sentence 5 : \" Approval for national planning for development of infrastructure for reserve and supply of petrol, oil and gas products for the period of 2021-2030, with a vision to 2050 with the following contents \" ours : \" Phê duyệt quy hoạch phát triển hạ tầng dự trữ, cung ứng xăng dầu, khí thải giai đoạn 2021-2030, có tầm nhìn đến năm 2050 với các nội dung sau \" Google Translate : \" Phê duyệt Quy hoạch phát triển hạ tầng dự trữ và cung cấp sản phẩm xăng, dầu và khí quốc gia giai đoạn 2021-2030, có xét đến năm 2050 với các nội dung sau: \" Sentence 6 : \" Prior to Harvey, blood was supposed to be consumed by the body and produced anew rather than continually circulated. It had also been suggested that the blood flowed through pores between the two halves of the heart and that the heart produced a vital heat, which was tempered by the air from the lungs. \" ours : \" Trước Harvey, máu được cho là được hấp thụ bởi cơ thể và tạo ra một loại máu mới thay vì được lưu thông liên tục. Cũng đã được gợi ý rằng máu chảy qua các khe giữa hai bán cầu của tim và tim tạo ra một nhiệt chủ yếu, được điều hòa bởi không khí từ phổi \" Google Translate : \" Trước Harvey, máu được cơ thể tiêu thụ và tạo ra một lần nữa thay vì lưu thông liên tục. Người ta cũng cho rằng máu chảy qua các lỗ chân lông giữa hai nửa của tim và tim tạo ra nhiệt lượng cần thiết, được làm dịu bởi không khí từ phổi. \"Based on the six examples provided, my model demonstrates a high level of translation accuracy, closely matching the performance of Google Translate. Notably, when translating sentences within the domain, the model exhibits remarkable results.", "label": "human"}
{"ID": "00100083", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "However, in the case of IT-domain sentences, the model occasionally produces minor discrepancies, such as translating \"patterns\" to \"mô hình,\". In machine learning, mẫu\" is prefered. Despite these occasional discrepancies, the overall performance of the model remains promising, showcasing its capability to handle various domains effectively. Despite using significantly less training time and data compared to EnViT5, my model achieves results that are comparable to EnViT5 and particularly close to Google Translate. The efficient performance of my model demonstrates its potential to deliver high-quality translations even with limited resources, making it a promising solution for various translation tasks.5.1 Summary In conclusion, the aim of this thesis was to construct a multi-domain machine translation system. Notably, conventional machine translation tools such as Google Translate and Bing focus predominantly on general domains, which can result in less accurate translations for domains featuring specific or specialized vocabulary.", "label": "human"}
{"ID": "00100084", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Consequently, these translations might lead to undesirable outcomes and potential misunderstandings for users. The development of a multi-domain machine translation system addresses this limitation, offering more contextually appropriate and accurate translations across various domains, and ultimately enhancing the user experience.", "label": "human"}
{"ID": "00100085", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "The establishment of domain-specific machine translation systems plays a crucial role in specialized fields, such as translating legal documents or enriching data for different domains. In this thesis, I have successfully accomplished the development of a multi-domain machine translation system comprising two main components:", "label": "human"}
{"ID": "00100086", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "In my work though, the modeling results I achieved are remarkable and my classification model has also improved a lot in terms of memory and speed. In the future, notable directions for the multi-domain machine translation problem may encompass various promising aspects. One of them involves data augmentation using effective techniques to enhance the domain adaptation across different domains.", "label": "human"}
{"ID": "00100087", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "This may involve leveraging transfer learning, unsupervised learning, or artificial data synthesis methods to generate diverse data for domains with limited resources.", "label": "human"}
{"ID": "00100088", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Another direction is to extend the multi-domain machine translation system to support multilingual capabilities and facilitate translation between various language pairs. This will ensure the integration of domain-specific knowledge and enhance translation performance for multiple language pairs, expanding the system’s scopeof application. The next development direction involves incorporating domainspecific knowledge from external sources, such as specialized dictionaries, domain specific datasets, or expert knowledge from professionals in relevant fields. This can aid in improving the accuracy and contextuality of translations, ensuring their alignment with specific domain contexts.", "label": "human"}
{"ID": "00100089", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "For me, the next direction for the multi-domain machine translation problem is model optimization. This will ensure achieving the best translation performance in the shortest possible time, meeting the demands of real-time applications anddevices with limited resources. In addition, techniques for training large language models are also worth noting to speed up training such as DeepSpeed, mixed precision training, etc. In contemporary GPUs, data types such as bfloat16 are already supported, and they have been extensively utilized in mixed-precision training.", "label": "human"}
{"ID": "00100090", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "This approach significantly accelerates the training process while maintaining acceptable levels of accuracy. Furthermore, parallel computing mechanisms play a crucial role in training deep learning models and are widely employed to further enhance training efficiency. A. Currey, P. Mathur andG. Dinu, “Distilling multiple domains for neural machine translation,” inProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) On: Association for Computational Linguistics, november 2020, pages 4500–4511. DOI:10.", "label": "human"}
{"ID": "00100091", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "A. Vaswani, N. Shazeer, N. Parmar andothers , “Attention is all you need,” inAdvances in Neural Information Processing Systems 2017, pages 5998–6008.", "label": "human"}
{"ID": "00100092", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "C. Chu andR. Wang, “A survey of domain adaptation for neural machine translation,” inProceedings of the 27th International Conference on Computational Linguistics Santa Fe, New Mexico, USA: Association for Computational Linguistics, august 2018, pages 1304–1319. url:", "label": "human"}
{"ID": "00100093", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "C. Kobus, J. M. Crego andJ. Senellart, “Domain control for neural machine translation.,” inRANLP R. Mitkov andG. Angelova, editors , INCOMA Ltd., 2017, pages 372–378, ISBN: 978-954-452-049-6. url:", "label": "human"}
{"ID": "00100094", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "D. Britz, Q. V. Le and R. Pryzant, “Effective domain mixing for neural machine translation.,” inWMT O. Bojar, C. Buck, R. Chatterjee andothers , editors , Association for Computational Linguistics, 2017, pages 118–126, ISBN: 978-1-945626-96-8. url:", "label": "human"}
{"ID": "00100095", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "M. Pham, J. Crego, F. Yvon andJ. Senellart, “Generic and specialized word embeddings for multi-domain machine translation,” inProceedings of the 16th International Conference on Spoken Language Translation Hong Kong:", "label": "human"}
{"ID": "00100096", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "K. Cho, B. van Merri ¨enboer, D. Bahdanau andY. Bengio, “On the properties of neural machine translation: Encoder–decoder approaches,” inProceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in StatisticalTranslation Doha, Qatar: Association for Computational Linguistics, october 2014, pages 103–111. DOI:10.3115/v1/W14- 4012 .url:https:", "label": "human"}
{"ID": "00100097", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "D. Bahdanau, K. Cho andY. Bengio, Neural machine translation by jointly learning to align and translate , cite arxiv:1409.0473Comment: Accepted at ICLR 2015 as oral presentation, 2014. url:", "label": "human"}
{"ID": "00100098", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "P. Koehn, “Pharaoh: A beam search decoder for phrase-based statistical machine translation models.,” inAMTA R. E. Frederking andK. Taylor, editors ,jourser Lecture Notes in Computer Science, volume 3265, Springer, 2004, pages 115–124, ISBN: 3-540-23300-8. url:", "label": "human"}
{"ID": "00100099", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "A. Bapna and O. Firat, “Simple, scalable adaptation for neural machine translation.,” inEMNLP/IJCNLP (1) K. Inui, J. Jiang, V. Ng andX. Wan, editors , Association for Computational Linguistics, 2019, pages 1538–1548, ISBN: 978-1-950737-90-1. url:", "label": "human"}
{"ID": "00100100", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "C. Chu, R. Dabre andS. Kurohashi, “An empirical comparison of domain adaptation methods for neural machine translation.,” inACL (2) R. Barzilay andM.-Y. Kan, editors , Association for Computational Linguistics, 2017, pages 385–391, ISBN: 978-1-945626-76-0. url:", "label": "human"}
{"ID": "00100101", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "A. Currey, P. Mathur andG. Dinu, “Distilling multiple domains for neural machine translation.,” inEMNLP (1) B. Webber, T. Cohn, Y. He andY. Liu, editors , Association for Computational Linguistics, 2020, pages 4500–4511, ISBN: 978-1-952148-60-6. url:", "label": "human"}
{"ID": "00100102", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "K. Papineni, S. Roukos, T. Ward and W.-J. Zhu, “B LEU: A Method for Automatic Evaluation of Machine Translation,” inACL ’02 Philadelphia, Pennsylvania:", "label": "human"}
{"ID": "00100103", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "J. Devlin, M.-W. Chang, K. Lee andK. Toutanova, “BERT: Pre-training of deep bidirectional transformers for language understanding,” inProceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) Minneapolis, Minnesota: Association for ComputationalLinguistics, june 2019, pages 4171–4186. DOI:10.18653/v1/N19 1423 .url: . J. MacQueen, “Some methods for classification and analysis of multivariate observations,” inProceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability - Vol. 1 L. M. Le Cam andJ. Neyman, editors , University of California Press, Berkeley, CA, USA, 1967, pages 281–297.", "label": "human"}
{"ID": "00100104", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "S. Jean, K. Cho, R. Memisevic andY. Bengio, “On using very large target vocabulary for neural machine translation,” inProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) Beijing, China: Association for Computational Linguistics, july2015, pages 1–10.", "label": "human"}
{"ID": "00100105", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "T. Luong, I. Sutskever, Q. Le, O. Vinyals andW. Zaremba, “Addressing the rare word problem in neural machine translation,” inProceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) Beijing, China: Association for Computational Linguistics, july2015, pages 11–19. DOI:10.3115/v1/P15-1002 .url:https:", "label": "human"}
{"ID": "00100106", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "X. Li, J. Zhang andC. Zong, “Towards zero unknown word in neural machine translation.,” inIJCAI S. Kambhampati, editor , IJCAI/AAAI Press, 2016, pages 2852–2858, ISBN: 978-1-57735-771-1. url:", "label": "human"}
{"ID": "00100107", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "W. Ling, I. Trancoso, C. Dyer andA. W. Black, “Character-based neural machine translation.,” CoRR ,jourvol abs/1511.04586, 2015. url:http:// dblp.uni-trier.de/db/journals/corr/corr1511.html# LingTDB15 .", "label": "human"}
{"ID": "00100108", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "M.-T. Luong andC. D. Manning, “Achieving open vocabulary neural machine translation with hybrid word-character models.,” CoRR ,jourvol abs/1604.00788, 2016. url:", "label": "human"}
{"ID": "00100109", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "M. R. Costa jussà andJ. A. R. Fonollosa, “Character-based neural machine translation.,” inACL (2) The Association for Computer Linguistics, 2016, ISBN: 978-1-945626-01-2. url:", "label": "human"}
{"ID": "00100110", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "J. Chung, K. Cho andY. Bengio, “A character-level decoder without explicit segmentation for neural machine translation.,” CoRR ,jourvol abs/1603.06147,2016. url:", "label": "human"}
{"ID": "00100111", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "J. Lee, K. Cho andT. Hofmann, “Fully character-level neural machine translation without explicit segmentation.,” Trans. Assoc. Comput. Linguistics ,jourvol 5, pages 365–378, 2017. url:http : / / dblp . uni - trier. de / db / journals/tacl/tacl5.html#LeeCH17 .", "label": "human"}
{"ID": "00100112", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "C. Wang, K. Cho andJ. Gu, “Neural machine translation with byte-levelsubwords.,” inAAAI AAAI Press, 2020, pages 9154–9160, ISBN: 978-1 57735-823-7. url:", "label": "human"}
{"ID": "00100113", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "I. M. A. D. Suarjaya, “A new algorithm for data compression optimization,” International Journal of Advanced Computer Science and Applications ,jourvol 3, september 2012. DOI:10.14569/IJACSA.2012.030803 .", "label": "human"}
{"ID": "00100114", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "T. Kudo, “Subword regularization: Improving neural network translation models with multiple subword candidates.,” inACL (1) I. Gurevych andY. Miyao, editors , Association for Computational Linguistics, 2018, pages 66–75, ISBN:", "label": "human"}
{"ID": "00100115", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "I. Provilkov, D. Emelianenko andE. Voita, “Bpe-dropout: Simple and effective subword regularization.,” inACL D. Jurafsky, J. Chai, N. Schluter andJ. R.", "label": "human"}
{"ID": "00100116", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Y. Bengio, R. Ducharme, P. Vincent andC. Jauvin, “A Neural Probabilistic Language Model,” en, Journal of Machine Learning Research ,jourvol 3, number 2,pages 1137–1155, 2003.", "label": "human"}
{"ID": "00100117", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "H. S. Le, A. Allauzen andF. Yvon, “Continuous space translation models with neural networks.,” inHLT-NAACL The Association for Computational Linguistics, 2012, pages 39–48, ISBN: 978-1-937284-20-6. url:http:// dblp.uni- trier.de/db/conf/naacl/naacl2012.html# LeAY12 .", "label": "human"}
{"ID": "00100118", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "H. Schwenk, “Continuous space translation models for phrase-based statistical machine translation.,” inCOLING (Posters) M. Kay andC. Boitet, editors , Indian Institute of Technology Bombay, 2012, pages 1071–1080. url:http:", "label": "human"}
{"ID": "00100119", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "html#Schwenk12 . T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado andJ. Dean, “Distributed representations of words and phrases and their compositionality,” inAdvances in Neural Information Processing Systems 26 C. Burges, L. Bottou, M. Welling, Z. Ghahramani andK. Weinberger, editors , 2013, pages 3111–3119. url:", "label": "human"}
{"ID": "00100120", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado andJ. Dean, “Distributed representations of words and phrases and their compositionality,” ArXiv , jourvol abs/1310.4546, 2013.", "label": "human"}
{"ID": "00100121", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "K. Cho, B. van Merrienboer, D. Bahdanau andY. Bengio, “On the properties of neural machine translation: Encoder-decoder approaches.,” CoRR ,jourvol abs/1409.1259, 2014. url:", "label": "human"}
{"ID": "00100122", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "K. He, X. Zhang, S. Ren and J. Sun, Deep residual learning for image recognition , cite arxiv:1512.03385Comment: Tech report, 2015. url:http:", "label": "human"}
{"ID": "00100123", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "R. Pascanu, T. Mikolov andY. Bengio, On the difficulty of training recurrent neural networks , cite arxiv:1211.5063Comment: Improved description of the exploding gradient problem and description and analysis of the vanishing gradient problem, 2012. url: .", "label": "human"}
{"ID": "00100124", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "M. Lewis, Y. Liu, N. Goyal andothers ,Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension , cite arxiv:1910.13461, 2019. url:", "label": "human"}
{"ID": "00100125", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "Y. Liu, J. Gu, N. Goyal andothers , “Multilingual denoising pre-training for neural machine translation.,” CoRR ,jourvol abs/2001.08210, 2020. url:", "label": "human"}
{"ID": "00100126", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "html#abs-2001-08210 . G. Lample, M. Ott, A. Conneau, L. Denoyer andM. Ranzato, “Phrase-based neural unsupervised machine translation.,” CoRR ,jourvol abs/1804.07755, 2018. url:", "label": "human"}
{"ID": "00100127", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "V. Sanh, L. Debut, J. Chaumond andT. Wolf, “Distilbert, a distilled version of bert: Smaller, faster, cheaper and lighter,” arXiv preprint arXiv:1910.01108 , 2019.", "label": "human"}
{"ID": "00100128", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "G. Hinton, O. Vinyals andJ. Dean, Distilling the knowledge in a neural network , cite arxiv:1503.02531Comment: NIPS 2014 Deep Learning Workshop, 2015. url: .", "label": "human"}
{"ID": "00100129", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "A high-quality and large-scale benchmark dataset for Vietnamese-English machine translation,” inProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing On andPunta Cana, Dominican Republic: Association for Computational Linguistics, november 2021, pages 4495–4503.", "label": "human"}
{"ID": "00100130", "file_name": "Research on domain-oriented machine translation English-Vietnamese", "content": "L. Tunstall, L. von Werra andT. Wolf, Natural Language Processing with Transformers: Building Language Applications with Hugging Face . O’Reilly Media, Incorporated, 2022, ISBN: 1098103246. url:", "label": "human"}
{"ID": "00110001", "file_name": "Designing and developing sales staff management system", "content": "Compared to the era of human resources, machines are now an indispensable part of modern life. With the use of machines, many difficult jobs that requireaccuracy and speed are completed perfectly without errors. Realizing that, large scale enterprises always focus on using technology applied to all work processes to ensure the fastest progress. Especially telesales - the service of calling customers, directly affecting the revenue of the business. And that is the purpose for me to carry out this topic: Designing a website to manage Telesales employees.", "label": "human"}
{"ID": "00110002", "file_name": "Designing and developing sales staff management system", "content": "Many businesses with traditional telesales teams will work through the paper work. Customer information will be printed on paper for employees to use. Call reports or customer classification will be recorded directly on the paper given by the manager to the staff. Staff will sit and call each customer, classify needs, and then make notes directly on the page. At the end of the working time, the employeesends back to the manager a report of the work done during the day. Some employ ees have new customers that will be aggregated on excel sheets, printed out, or sent the excel file back to the manager to save in the warehouse to check for duplicate customers and then send them back to the staff.", "label": "human"}
{"ID": "00110003", "file_name": "Designing and developing sales staff management system", "content": "Younger businesses will use google’s on software such as google Sheets, google docs, and google drive to facilitate information communication faster than traditional. When managed by customers, they will directly see what employees are doing in real-time, communicate using on messaging software, or make direct calls.", "label": "human"}
{"ID": "00110004", "file_name": "Designing and developing sales staff management system", "content": "When it is a traditional business, with the use of paper to work, it is easy to make mistakes when all actions at work are human. It is easy for people to makemistakes or make mistakes when recording customer information, product infor mation, call information, etc. In addition, when using documents, it is also very difficult for managers to manage employees in their work. Allocate customers to each employee.", "label": "human"}
{"ID": "00110005", "file_name": "Designing and developing sales staff management system", "content": "When taking care of old customers, employees also cannot recognize old care visits because paper notes cannot show all the content that has been exchangedbefore. That leads to annoying customers having to repeat the same old care ques tions. With the use of on support software, all information stored on it will notbe assigned to each employee, leading to ambiguity in job assignments.", "label": "human"}
{"ID": "00110006", "file_name": "Designing and developing sales staff management system", "content": "The user interface is built in java to provide users with an efficient working environment and speed with high accuracy. Support the team leader to effectively manage, and help employees have the fastest customer information suitable for customer care.", "label": "human"}
{"ID": "00110007", "file_name": "Designing and developing sales staff management system", "content": "To develop applications with the features mentioned above, I choose to build web-based applications that are easy to maintain and use. The system is separatedinto three components: a website for administrators, group managers, and employ ees to use in management and editing according to specific functions. For example, they can add new products, update or delete existing products, categories, etc. And a website for employees and product managers where they can find products, order, and order for customers.", "label": "human"}
{"ID": "00110008", "file_name": "Designing and developing sales staff management system", "content": "The database used for the system is MySql, a free and open-source relational database management system emphasizing scalability and SQL compliance.", "label": "human"}
{"ID": "00110009", "file_name": "Designing and developing sales staff management system", "content": "Server is built on Java which is a fast, secure, reliable programming language for coding anything. This language has been a popular choice among developers for more than two decades. There are millions of Java applications in use today. Java is a cross-platform, object-oriented, network-centric language that can be used as a platform.", "label": "human"}
{"ID": "00110010", "file_name": "Designing and developing sales staff management system", "content": "Chapter 2 presents the requirements analysis of the projects, looking at a num ber of current products that have similar objectives to this project. Based on these products, define an overview of use cases and features for this project that describes some of the important use cases of the system, and the non-functional requirements of the system.", "label": "human"}
{"ID": "00110011", "file_name": "Designing and developing sales staff management system", "content": "Chapter 4 presents the content of application analysis and application design including architectural design, package design, interface design, and applicationbuilding.Chapter 5 introduces the application development processes including the libraries and tools used in the project, application testing, and application deploy ment.", "label": "human"}
{"ID": "00110012", "file_name": "Designing and developing sales staff management system", "content": "Chapter 7 presents the conclusion of the thesis, looks back at the results, knowledge, experience, and orientation for future development solutions, and draws ex perience after completing the system building.2.1 State of the art For this part, I will look at an existing product with similar goals to this project, Bizfly - a product with a telesales staff management function.", "label": "human"}
{"ID": "00110013", "file_name": "Designing and developing sales staff management system", "content": "Employees call customers. When working, the employee logged in to his account to start the work. After logging in, the staff will see the customer file. Re ceive customers to take care of by viewing customer information including phone numbers, and information on previous care to propose customer care strategies.", "label": "human"}
{"ID": "00110014", "file_name": "Designing and developing sales staff management system", "content": "When customers agree to buy, employees are responsible for making invoices for customers. Staff will save product information, customers with payment meth-ods, and payment status. Then can only edit the payment status of the order When there is a new customer, the staff enters the customer information and saves it.", "label": "human"}
{"ID": "00110015", "file_name": "Designing and developing sales staff management system", "content": "Staff changing personal information including Name, phone number, and ad dress. Also can change the password when needed. Staff can see everyone in their group.", "label": "human"}
{"ID": "00110016", "file_name": "Designing and developing sales staff management system", "content": "The staff can see the summary information including total orders, total sales,total customers, total customer care, sales chart this year, statistical statistics of or ders in the month At, the list of employees with the highest revenue of the previous month, and the list of products was the most sold in the previous month.", "label": "human"}
{"ID": "00110017", "file_name": "Designing and developing sales staff management system", "content": "In addition, administrators have the right to change the right to use the features of every other user and change the rights of each employee and leader.", "label": "human"}
{"ID": "00110018", "file_name": "Designing and developing sales staff management system", "content": "The full right to correct the employee information includes which website, which website is accessible, is the leader or member.", "label": "human"}
{"ID": "00110019", "file_name": "Designing and developing sales staff management system", "content": "Turn on the operation or turn off the accounts created.2.2.2 The decomposition use case diagram for employee management users Figure 2.8: Employee manager use case diagram Actor: Administrators.", "label": "human"}
{"ID": "00110020", "file_name": "Designing and developing sales staff management system", "content": "Description: In Figure 2.2.2, the administrator can view, add, edit, and delete employee information. In addition, it is possible to change account permissions, and groups and reset passwords in case employees forget their passwords2.2.3 The decomposition use case diagram for customer management Figure 2.9: Customer manager use case diagram Actor: Administrators, leaders, employees.", "label": "human"}
{"ID": "00110021", "file_name": "Designing and developing sales staff management system", "content": "While the team leader can only manage the customers that his team creates. Users can change customer information. Employees can only change the customer service person.", "label": "human"}
{"ID": "00110022", "file_name": "Designing and developing sales staff management system", "content": "Description: In Figure 2.2.4, the admin edits site access rights one by one andattaches them to users in user management.", "label": "human"}
{"ID": "00110023", "file_name": "Designing and developing sales staff management system", "content": "Description: In Figure 2.2.5, the admin will be the one to add and change prod uct information. Other users will view information for sales and select products to save in the transaction when customers have a need to buy.", "label": "human"}
{"ID": "00110024", "file_name": "Designing and developing sales staff management system", "content": "The decomposition use case diagram for transaction management Figure 2.12: Transaction manager use case diagram Actor: Administrators, leaders, employees.Description: In Figure 2.2.6, the user can create a transaction for the customer, but only change the status and note of the order.", "label": "human"}
{"ID": "00110025", "file_name": "Designing and developing sales staff management system", "content": "The decomposition use case diagram for view summary informa tion Figure 2.13: Synthesize information use case diagramActor: Administrators, leaders, employees.", "label": "human"}
{"ID": "00110026", "file_name": "Designing and developing sales staff management system", "content": "Specification use case login Use case name Login Actor Administrator, Team Leader, Employee Description User login to operate the system Condition The user is created an account by the administrator in the system Event stream 1. The user visits the website 2. The system displays the login form 3. User enters username and password 4. Account checking system The wrong account displays the wrong username or password message.", "label": "human"}
{"ID": "00110027", "file_name": "Designing and developing sales staff management system", "content": "Correct account, check account permissions, activity status, and check tokens. Correctly create and save the token to the session and save the cookie, to the home page.", "label": "human"}
{"ID": "00110028", "file_name": "Designing and developing sales staff management system", "content": "E0qArf33f2rVn3oQ-rDR 5vaD-5Gnoc78cVt1KBlv 4Lp9eK4wN9EghJigJ0is jDaqzkZikmUnLn5LjRF IfP6A9g Table 2.4: Logout information2.3.3 Specification use case creates user Use case name Create user Actor Administrator, Leader Description Admin add users Condition Created by an administrator Event stream 1. Admin access staff page 2. The system displays the ’List of employees’ page 3. Admin selects ’Add’ 4. The system displays the employee information input form 5. Administrator enters information and presses add:", "label": "human"}
{"ID": "00110029", "file_name": "Designing and developing sales staff management system", "content": "In the correct form of information, the system displays a successful save message and displays it on the employee table.", "label": "human"}
{"ID": "00110030", "file_name": "Designing and developing sales staff management system", "content": "team1 5 Type Yes Choose team leader or staff Leader 6 Role Yes Select role Role name : agent 7 Phone numberYes Correct phone number format0987654321 8 Address Yes Can not be left blank Ha Noi Table 2.6: Create user information2.3.4 Specification use case edit information user Use case name Edit employee information Actor Administrator, Leader Description Admin edit user information Condition Created by an administrator Event stream 1. Admin access staff page 2. The system displays the ’List of employees’ page 3. The administrator selects the pen icon in the employee line to edit 4. The system displays the employee information input form 5. The administrator enters the information and presses edit:", "label": "human"}
{"ID": "00110031", "file_name": "Designing and developing sales staff management system", "content": "In the correct form of information, the system displays a successful save message and displays it on the employee table.", "label": "human"}
{"ID": "00110032", "file_name": "Designing and developing sales staff management system", "content": "team1 3 Type Yes Choose team leader or staff Leader 4 Role Yes Select role Role name : agent 5 Phone numberYes Correct phone number format0987654321 6 Address Yes Can not be left blank Ha Noi Table 2.8: Edit user information2.3.5 Specification use case customer care Use case name Customer care Actor Administrator, Leader, Employee Description Users take care of customers Condition User has logged into the system Event stream 1. User visits customer page 2. The system displays the ’List of customers’ page 3. The user selects the information icon in the  of customers to take care of 4. The system displays the page ’Personal customer care history’ 5. User adds care session and notes when taking care of this customer.", "label": "human"}
{"ID": "00110033", "file_name": "Designing and developing sales staff management system", "content": "In the correct form of information, the system displays a successful save message and displays it on the employee table.", "label": "human"}
{"ID": "00110034", "file_name": "Designing and developing sales staff management system", "content": "In the correct form of information, the system displays a successful save message and displays it on the employee table.", "label": "human"}
{"ID": "00110035", "file_name": "Designing and developing sales staff management system", "content": "Ha Noi 2 Product Yes Can not be left blank Full-stacks JS 3 Status Yes Can not be left blank Wait for pay 4 Notes No Called theapplica tion Table 2.24: Transaction information2.3.13 Specification use case edit a transaction Use case name Create transaction Actor Administrator, Leader, Employee Description Users update payment status and transaction notes Condition Users have logged in to the system Event stream 1. Users access the ’transaction management page 2. The system shows ’transaction details 3. Users to choose transactions to be repaired 4. Transaction repair system display system 5. Users choose the status of transactions and add notes and then press ‘fix’ to save 6. Information inspection system True sent to the database, successfully displayed, and displayed the product just added in the product table.", "label": "human"}
{"ID": "00110036", "file_name": "Designing and developing sales staff management system", "content": "February billion 2 Time Yes Showing the current year over timeRevenue data calculated by 2022 Table 2.36: Specification use case the total number of customer care visits 2.3.19 Summary of the sales chart information Use case name Summary of order charts Actor Administrator, Leader, Employee Description Users see the summary of orders in the current month Condition Users have logged in to the system Event stream 1. Users successfully logged in 2. System display homepage summarizes the total number of customers Table 2.37: Summary of the sales chart information No. Name Required Condition Example 1 Percentage of orders statusYes Payment:", "label": "human"}
{"ID": "00110037", "file_name": "Designing and developing sales staff management system", "content": "percent Cancel: 10 percent 2 Time Yes Showing the current month over timeIn August Table 2.38: Summary of order status information2.3.20 Specification use case summary of employees with the highest sales Use case name Summary of employees with the highest sales Actor Administrator, Leader, Employee Description Users view employees with the highest sales in the previous month Condition Users have logged in to the system Event stream 1. Users successfully logged in 2. System display homepage summarizes the total number of customers Table 2.39: Specification use case summary of employees with the highest sales No. Name Required Condition Example 1 Name employeeYes Nguyễn Thành A 2 Sales Yes 20000000 VND 3 Time Yes Showing the current month over timeIn August Table 2.40: Summary of employees with the highest sales information 2.3.21 Specification use case summary of best-selling products Use case name Summary of the most sold products Actor Administrator, Leader, Employee Description Users view the number of products that run best in the month before the present month Condition Users have logged in to the system Event stream 1. Users successfully logged in 2. System display homepage summarizes the total number of customers Table 2.41: Specification use case summary of best-selling productsNo. Name Required Condition Example 1 Product Yes Full-stack Java 2 Quantity Yes 100 3 Time Yes Showing the current month over timeIn August Table 2.42: Summary of best-selling products information 2.3.22 Specification use case edit personal information Use case name Edit personal information Actor Administrator, Leader, Employee Description Users change personal information Condition Users have logged in to the system Event stream 1 User access the ‘personal page’ 2 ‘Personal page’ display system 3 Users change personal information and seal 4 Information testing systems The proper search system saved and sent a successful notice.", "label": "human"}
{"ID": "00110038", "file_name": "Designing and developing sales staff management system", "content": "No. Requirement Evaluation Description 1 Security Pretty goodWhen the user forgets the password, the link to create a new password is sent to the first registered email address only After registering, the actors need to verify the email used to create an account Hashed user password with MB5 encrypt Validate form request Using JWT token when sending request 2Performance Good Fast processing speed in most cases, but it will be slower when computing complex data and interacting with external systems Fast response with user action 3 Usability Good Friendly interface and easy to use Give the correct name that corresponds to the functions it performs The consistency of UX/UI in the application 4 Integrity Good The return data with accuracy is 96 Percent Table 2.47: Non-functional requirement3.1 JWT JSON Web Token (JWT - Figure 3.2) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA or ECDSA.", "label": "human"}
{"ID": "00110039", "file_name": "Designing and developing sales staff management system", "content": "JSON Web Tokens consist of three parts separated by dots (.), which are: header, payload, and signature. The header typically consists of two parts: the type of the token, which is JWT, and the signing algorithm being used. The payload contains the claims. Claims are statements about an entity (typically, the user) and additional data. To create the signature part, you have to take the encoded header, the encoded payload, a secret, and the algorithm specified in the header, and sign that.", "label": "human"}
{"ID": "00110040", "file_name": "Designing and developing sales staff management system", "content": "Authorization: This is the most common scenario for using JWT. Once the user is logged in, each subsequent request will include the JWT, allowing the user to access routes, services, and resources that are permitted with that token. Single Sign On is a feature that widely uses JWT nowadays, because of its small overhead and its ability to be easily used across different domains.", "label": "human"}
{"ID": "00110041", "file_name": "Designing and developing sales staff management system", "content": "Information Exchange: JSON Web Tokens are a good way of securely trans mitting information between parties. Because JWTs can be signed—for example, using public/private key pairs—you can be sure the senders are who they say theyare. Additionally, as the signature is calculated using the header and the payload, you can also verify that the content hasn’t been tampered with.", "label": "human"}
{"ID": "00110042", "file_name": "Designing and developing sales staff management system", "content": "In this scope of application, I used JWT in authorization User and Admin in the system. When the user successfully logs in using their credentials, a JSON Web Token will be returned. Whenever the user wants to access a protected route or resource, the user sends the JWT, in the Authorization header.", "label": "human"}
{"ID": "00110043", "file_name": "Designing and developing sales staff management system", "content": "Java Spring Framework (Spring Framework) is a popular, open-source, enterprise level framework for creating standalone, production-grade applications that run on the Java Virtual Machine (JVM).", "label": "human"}
{"ID": "00110044", "file_name": "Designing and developing sales staff management system", "content": "Java Spring Boot (Spring Boot) is a tool that makes developing web applica tions and microservices with Spring Framework faster and easier through three core capabilities:", "label": "human"}
{"ID": "00110045", "file_name": "Designing and developing sales staff management system", "content": "Autoconfiguration An opinionated approach to configuration The ability to create standalone applications These features work together to provide you with a tool that allows you to set up a Spring-based application with minimal configuration and setup.", "label": "human"}
{"ID": "00110046", "file_name": "Designing and developing sales staff management system", "content": "MySQL is an open-source relational database management system that is widely used for storing and managing data in web applications. It was developed by Oracle Corporation and is available under the GNU General Public License.", "label": "human"}
{"ID": "00110047", "file_name": "Designing and developing sales staff management system", "content": "MySQL is known for its speed, reliability, and scalability, and it can handlelarge amounts of data efficiently. It supports various data types, including inte gers, decimals, dates, and times, and offers advanced features such as transactions, replication, and security.", "label": "human"}
{"ID": "00110048", "file_name": "Designing and developing sales staff management system", "content": "One of the key advantages of MySQL is its ease of use. It comes with a user friendly interface that allows developers to easily create, modify, and query databases.", "label": "human"}
{"ID": "00110049", "file_name": "Designing and developing sales staff management system", "content": "Moreover, it supports various programming languages, including Java, Python, and PHP, which makes it an ideal choice for building web applications.", "label": "human"}
{"ID": "00110050", "file_name": "Designing and developing sales staff management system", "content": "MySQL can be installed on various operating systems, including Windows, Linux, and macOS. It also integrates well with other web development tools, such as Apache and PHPMyAdmin, which makes it even more convenient to use.", "label": "human"}
{"ID": "00110051", "file_name": "Designing and developing sales staff management system", "content": "However, like any technology, MySQL has some limitations. For instance, itmay not be suitable for very large-scale enterprise applications that require ad vanced security and scalability features. Additionally, users need to ensure that they have the appropriate resources and knowledge to use it effectively.", "label": "human"}
{"ID": "00110052", "file_name": "Designing and developing sales staff management system", "content": "In conclusion, MySQL is a powerful and flexible database management sys tem that offers many benefits to developers and administrators. Its ease of use, reliability, and scalability make it a popular choice for building web applications.", "label": "human"}
{"ID": "00110053", "file_name": "Designing and developing sales staff management system", "content": "However, users should also be aware of its limitations and ensure that they have the appropriate resources and knowledge to use it effectively.", "label": "human"}
{"ID": "00110054", "file_name": "Designing and developing sales staff management system", "content": "Tomcat is an open-source web server and servlet container developed by the Apache Software Foundation. It is widely used to run Java-based web applicationsand is known for its stability, scalability, and security.", "label": "human"}
{"ID": "00110055", "file_name": "Designing and developing sales staff management system", "content": "Tomcat supports the Java Servlet, JavaServer Pages (JSP), and WebSocket tech nologies, making it an ideal choice for developers who want to build dynamic web applications. It can be configured to work with various databases and frameworks,such as Spring and Struts, and supports multiple programming languages, includ ing Java, PHP, and Python.", "label": "human"}
{"ID": "00110056", "file_name": "Designing and developing sales staff management system", "content": "Tomcat is easy to install and can be used on various operating systems, including Windows, Linux, and macOS. It comes with a built-in web-based management interface that allows administrators to monitor and configure the server settings.", "label": "human"}
{"ID": "00110057", "file_name": "Designing and developing sales staff management system", "content": "Despite its many advantages, Tomcat has some limitations that users should be aware of. For instance, it may not be suitable for high-traffic websites that requireadvanced load balancing and failover capabilities. Additionally, users need to en sure that their web applications are compatible with the version of Tomcat they are using.", "label": "human"}
{"ID": "00110058", "file_name": "Designing and developing sales staff management system", "content": "In conclusion, Tomcat is a robust and versatile web server that offers many benefits to developers and administrators alike. Its ease of use, flexibility and compat ibility with various technologies make it a popular choice for building Java-based web applications. However, users should also be aware of its limitations and ensure that they have the appropriate resources and knowledge to use it effectively.", "label": "human"}
{"ID": "00110059", "file_name": "Designing and developing sales staff management system", "content": "jQuery is a popular open-source JavaScript library that simplifies the process of interacting with HTML documents, handling events, creating animations, and making asynchronous HTTP requests. It was created by John Resig in 2006 and has since become one of the most widely used JavaScript libraries on the web.", "label": "human"}
{"ID": "00110060", "file_name": "Designing and developing sales staff management system", "content": "One of the key advantages of jQuery is its simplicity. It provides a concise and easy-to-use syntax for manipulating HTML documents and responding to user events, which can help stream the development process and make it easier to create dynamic web applications. Moreover, jQuery provides a consistent interface across different web browsers, which can help avoid cross-browser compatibility issues.", "label": "human"}
{"ID": "00110061", "file_name": "Designing and developing sales staff management system", "content": "Another advantage of jQuery is its extensibility. It provides a wide range of plugins and extensions that can be used to add new features and functionality to web applications. These plugins can be easily integrated into existing projects andcan help save development time and effort.", "label": "human"}
{"ID": "00110062", "file_name": "Designing and developing sales staff management system", "content": "jQuery also provides comprehensive documentation and an active communityof developers, which can help beginners learn the library quickly and easily. Moreover, there are many resources and tutorials available on that can help develop ers take advantage of the full range of jQuery features and capabilities.", "label": "human"}
{"ID": "00110063", "file_name": "Designing and developing sales staff management system", "content": "However, like any technology, jQuery also has its limitations. For instance, itmay not be suitable for large-scale enterprise applications that require more ad vanced features and capabilities. Additionally, jQuery may not be necessary for simple web pages or projects that do not require much interactivity.", "label": "human"}
{"ID": "00110064", "file_name": "Designing and developing sales staff management system", "content": "In conclusion, jQuery is a powerful and versatile JavaScript library that can help simplify the process of developing dynamic web applications. Its simplicity, extensibility, and active community make it a popular choice for web developers.", "label": "human"}
{"ID": "00110065", "file_name": "Designing and developing sales staff management system", "content": "However, developers should also be aware of its limitations and use it judiciously.4.1 Architecture design 4.1.1 Software architecture selection The Spring Web MVC framework provides Model-View-Controller (MVC) architecture and ready components that can be used to develop flexible and looselycoupled web applications. The MVC pattern results in separating the different as pects of the application (input logic, business logic, and UI logic) while providing a loose coupling between these elements.", "label": "human"}
{"ID": "00110066", "file_name": "Designing and developing sales staff management system", "content": "The View is responsible for rendering the model data and in general it generates HTML output that the client’s browser can interpret.", "label": "human"}
{"ID": "00110067", "file_name": "Designing and developing sales staff management system", "content": "The Controller is responsible for processing user requests and building an ap propriate model and passing it to the view for rendering.", "label": "human"}
{"ID": "00110068", "file_name": "Designing and developing sales staff management system", "content": "The DispatcherServlet The Spring Web model-view-controller (MVC) framework is designed around a DispatcherServlet that handles all the HTTP requests and responses. The request processing workflow of the Spring Web MVC DispatcherServlet is illustrated in the following diagram Figure 4.1: Example about Spring bootFollowing is the sequence of events corresponding to an incoming HTTP request to DispatcherServletAfter receiving an HTTP request, DispatcherServlet consults the HandlerMap ping to call the appropriate Controller.", "label": "human"}
{"ID": "00110069", "file_name": "Designing and developing sales staff management system", "content": "The Controller takes the request and calls the appropriate service methods based on the used GET or POST method. The service method will set model data based on defined business logic and return the view name to DispatcherServlet.", "label": "human"}
{"ID": "00110070", "file_name": "Designing and developing sales staff management system", "content": "Once the view is finalized, The DispatcherServlet passes the model data to the picture which is finally rendered on the browser.", "label": "human"}
{"ID": "00110071", "file_name": "Designing and developing sales staff management system", "content": "All the above-mentioned components, i.e. HandlerMapping, Controller, and ViewResolver are parts of WebApplicationContext which is an extension of the plainAp plicationContext with some extra features necessary for web applications.", "label": "human"}
{"ID": "00110072", "file_name": "Designing and developing sales staff management system", "content": "Overall designFigure 4.2 illustrates the UML package diagram of the application, the appli cation using three-tier architecture adds a new middle layer - called the logic tier, presentation tier, and data tier.Figure 4.2: UML package diagram The presentation layer contains the components that implement and display the user interface and manage user interaction. A set of user interface components such as the dashboard, notification pages, and reports are designed to provide a way for users to interact with the application. The user interface can make use of controllers to communicate with the back end and to navigate or process the interface components.", "label": "human"}
{"ID": "00110073", "file_name": "Designing and developing sales staff management system", "content": "The business logic layer is a set of class libraries (or just classes and functions)containing domain models and other knowledge around the business, expressed in the current programming language. It contains all the processing logic of the application.", "label": "human"}
{"ID": "00110074", "file_name": "Designing and developing sales staff management system", "content": "Data layer is where we persist data for the application or system. This contains the functionality for creating, transforming, updating, and deleting items into the database.", "label": "human"}
{"ID": "00110075", "file_name": "Designing and developing sales staff management system", "content": "Detailed package design Figure 4.3: Detail package design4.2 Detailed design 4.2.1 User interface design No Element Description 1Screen size The resolution preferred is 1920px of horizontal 2Theme color Body background: ffffff, color: 333333, 53d1b0 Box shadow: 0 0.5rem 1rem RGB(0 0 0 / 15%) 3Button Flat design, rectangle shape with border-radius of 5px or 10px 4Text Font-family: Roboto The main font size for normal text is 16px, 18px, and 35px 5Language Vietnamese 6Notification The message pops up after the operation is done Table 4.1: Database design table User Figure 4.4: Dashboard pageFigure 4.5: List product page Figure 4.6: Dialog add a transaction in transaction pageFigure 4.7: List transaction page Figure 4.8: Edit transaction in transaction pageFigure 4.9: History care in customer page 4.2.2 Class design Figure 4.10: Class designa. Details for class design a.1. Login:", "label": "human"}
{"ID": "00110076", "file_name": "Designing and developing sales staff management system", "content": "Objective Tools/Libs URL IDE Intellij Ultimate a64 bit  Language Java  Language Javascript  Javascript library Jquery  Testing APIs Postman  User authentication JWT  Resource management Github  Database Mysql server  Table 5.1: Libraries and tools 5.1.2 Achievement After surveying and developing the system, I created the website with the main functions:", "label": "human"}
{"ID": "00110077", "file_name": "Designing and developing sales staff management system", "content": "The first website is a function for the institute administrator, including viewing products, adding products, and creating and editing user access rights. Also, the admin has all user rights.", "label": "human"}
{"ID": "00110078", "file_name": "Designing and developing sales staff management system", "content": "Furthermore, there are websites where employees can log in to the system tomanage their transactions, and customers, and assign users to take care of cus tomers.", "label": "human"}
{"ID": "00110079", "file_name": "Designing and developing sales staff management system", "content": "Illustration of main functions First, there are pictures to illustrate the result of the main features of the website for users:Figure 5.1: Login page Figure 5.2: Dashboard page Figures 5.1 and 5.2 show the user login and home pages. Upon successful login,the user will be taken to the dashboard. There will be aggregates of sales-related data.", "label": "human"}
{"ID": "00110080", "file_name": "Designing and developing sales staff management system", "content": "Function Scenario Expected Result Login 1. Input username and password1. If the input is correct, the home page is shown to the user.", "label": "human"}
{"ID": "00110081", "file_name": "Designing and developing sales staff management system", "content": "Click the “Log in” button2. If the input is incorrect, an error message will appear, requesting the user to try again.", "label": "human"}
{"ID": "00110082", "file_name": "Designing and developing sales staff management system", "content": "Add new user 1. Click \"Add\" from page user1. If the input is correct, the dialog success is shown to the user, and close the dialog 2. Input information of user2. If the input is incorrect, an error message will appear, requesting the user to try again.", "label": "human"}
{"ID": "00110083", "file_name": "Designing and developing sales staff management system", "content": "Edit customer 1. Click the button edit from the customer’s page1. If the input is correct, the home page is shown to the user.", "label": "human"}
{"ID": "00110084", "file_name": "Designing and developing sales staff management system", "content": "Input information of user2. If the input is incorrect, an error message will appear, requesting the user to try again.", "label": "human"}
{"ID": "00110085", "file_name": "Designing and developing sales staff management system", "content": "Get detailed transaction for editingClick the button edit from the transaction’s pageIf the response data is correct and the form gets data from the response, the form with data of the transaction is full display to the user.", "label": "human"}
{"ID": "00110086", "file_name": "Designing and developing sales staff management system", "content": "Get all data calculator for dashboardLogin or click home pages buttonIf the data returns successfully and the data merges into the tables then all the summary tables should now be complete Table 5.2: Table testing scenarios5.2.2 Testing results Table 5.3 gives the results of when testing scenarios in table 5.2:", "label": "human"}
{"ID": "00110087", "file_name": "Designing and developing sales staff management system", "content": "Deployment environment The system for both users and administrators and the server for the backend site is developed on the web platform by using Jquery with its libraries, tested on a local host environment.", "label": "human"}
{"ID": "00110088", "file_name": "Designing and developing sales staff management system", "content": "Parameter type Local Google cloud vps CPU Intel core I5-4210H 2.9 MhzIntel(R) Xeon(R) CPU @ 2.20GHz RAM 8GB 2GB ROM 128GB SSD , 500GB HDD20GB HDD OS Windows 10 Pro 64-bit Linux 11 Graphic VGA GTX 850m (4GB) No Table 5.4: Environment parameter implementation5.3.2 Implementation results Below is a picture of ten accounts working at the same time to test the product’s performance:", "label": "human"}
{"ID": "00110089", "file_name": "Designing and developing sales staff management system", "content": "Time CPU Memory 11:35 between 2.18% to 3.75% total CPUstable at 57.35% and 1.147GiB 11:40 between 2.35% to 5.11% total CPUbetween 57.33% to 57.57% and between 1.146GiB to 1.151GiB 11:45 between 2.22% to 5.59% total CPUbetween 57.48% to 59.73% and between 1.149GiB to 1.194GiB 11:50 between 2.04% to 4.63% total CPUbetween 59.64% to 59.73% and between 1.193GiB to 1.194GiB Table 5.5: The test times on the virtual machineIn this chapter, I will present my problems and contribution throughout the process of my graduation project, what did I do to solve the problems and some achievements.", "label": "human"}
{"ID": "00110090", "file_name": "Designing and developing sales staff management system", "content": "Lack of clarity in architecture: If data is transferred directly between layers,changing the data structure or adding new properties can affect the entire applica tion and make maintenance and development difficult.", "label": "human"}
{"ID": "00110091", "file_name": "Designing and developing sales staff management system", "content": "Poor performance: When transferring data between layers, especially when transmitting data over the network, directly passing large objects or data structures can lead to poor performance and reduce application speed.", "label": "human"}
{"ID": "00110092", "file_name": "Designing and developing sales staff management system", "content": "Difficulty in error handling: If there is an error when transferring data, error handling can become more complex when not using DTO. If data is transferred directly, errors can affect many layers of the application, making it more difficult to fix them.", "label": "human"}
{"ID": "00110093", "file_name": "Designing and developing sales staff management system", "content": "Complexity in maintenance: When objects are passed directly between layers, fixing errors or maintenance can have unintended consequences on other layers, making maintenance more difficult.", "label": "human"}
{"ID": "00110094", "file_name": "Designing and developing sales staff management system", "content": "Problem solvingImproving clarity in architecture: DTO provides an intermediate layer for trans ferring data between layers. Using DTO helps clearly separate the different parts of the application, improving the architecture of the application and reducing issues related to the data structure.", "label": "human"}
{"ID": "00110095", "file_name": "Designing and developing sales staff management system", "content": "Increasing performance: DTO allows for selective transmission of necessary data, optimizing performance and reducing the amount of data transmitted over the network.", "label": "human"}
{"ID": "00110096", "file_name": "Designing and developing sales staff management system", "content": "Ease of error handling: DTO helps simplify error handling by clearly specifying how data is transferred between layers. This facilitates quick and simple detection and resolution of errors.", "label": "human"}
{"ID": "00110097", "file_name": "Designing and developing sales staff management system", "content": "Increasing flexibility and maintainability: Using DTO reduces the dependence between layers, improving code reusability and the maintainability of the applica-tion.", "label": "human"}
{"ID": "00110098", "file_name": "Designing and developing sales staff management system", "content": "Improving clarity in architecture: Using DTO helps clearly separate the different layers in the application architecture, such as separating the business layer and the user interface layer. A DTO can be used to transfer data between these layers.", "label": "human"}
{"ID": "00110099", "file_name": "Designing and developing sales staff management system", "content": "Increased performance: By transmitting only the necessary data, DTO can help optimize performance by reducing network traffic and minimizing the processingtime of the application.", "label": "human"}
{"ID": "00110100", "file_name": "Designing and developing sales staff management system", "content": "Simplified error handling: With DTO, error handling can be simplified, making it easier to identify and fix issues that may arise when transferring data between different layers.", "label": "human"}
{"ID": "00110101", "file_name": "Designing and developing sales staff management system", "content": "Improved maintainability and flexibility: Using DTO can help make an appli cation more flexible and maintainable by reducing dependencies between different layers, making it easier to update and modify the application. This also allows for greater code reusability, which can save time and effort in the long run.", "label": "human"}
{"ID": "00110102", "file_name": "Designing and developing sales staff management system", "content": "Problem description In traditional authentication methods using sessions, a session is created and stored on the server each time a user logs in successfully. Each request from the user will contain the session ID, and the server will check the session to ensure that the user is authenticated and has access to the requested resource. However, session management can lead to security issues such as session hijacking, session tracking attacks, and other issues.", "label": "human"}
{"ID": "00110103", "file_name": "Designing and developing sales staff management system", "content": "Additionally, in traditional authentication methods using sessions, logging in on a different browser will no longer have the active session, and the user will have to log in again, losing the active session on the old browser.", "label": "human"}
{"ID": "00110104", "file_name": "Designing and developing sales staff management system", "content": "Problem solving Using JWTs can address these issues by not storing sessions on the server, with each request from the user containing authentication information within the JWT.", "label": "human"}
{"ID": "00110105", "file_name": "Designing and developing sales staff management system", "content": "This ensures higher security, minimizes session management issues, and also al lows users to log in on multiple browsers and devices without losing the active session on the old browser.", "label": "human"}
{"ID": "00110106", "file_name": "Designing and developing sales staff management system", "content": "Scalability: Since JWTs are self-contained, they can be easily distributed andused across different systems and services. This makes them ideal for use in dis tributed systems and microservices architectures.", "label": "human"}
{"ID": "00110107", "file_name": "Designing and developing sales staff management system", "content": "Flexibility: JWTs can be used for a variety of purposes, including authentica tion, authorization, and information exchange. This makes them a versatile tool forimplementing secure communication between different components of an applica tion.", "label": "human"}
{"ID": "00110108", "file_name": "Designing and developing sales staff management system", "content": "Interoperability: JWTs are a widely adopted standard, which means they can be used with a variety of programming languages, platforms, and frameworks. This makes it easy to integrate different components of an application or share data between different systems.", "label": "human"}
{"ID": "00110109", "file_name": "Designing and developing sales staff management system", "content": "Easy deployment and integration: JWT is a widely used standard, making it easy to deploy and integrate with different technologies.", "label": "human"}
{"ID": "00110110", "file_name": "Designing and developing sales staff management system", "content": "Scalability: JWT makes it easier to distribute and use across different systems and services, increasing the scalability of the application.", "label": "human"}
{"ID": "00110111", "file_name": "Designing and developing sales staff management system", "content": "Flexibility: JWT can be used for various purposes, including authentication, au thorization, and information exchange, increasing the flexibility of the application.", "label": "human"}
{"ID": "00110112", "file_name": "Designing and developing sales staff management system", "content": "Reduced session management issues: JWT does not require storing session in formation on the server, reducing session management issues for the application.", "label": "human"}
{"ID": "00110113", "file_name": "Designing and developing sales staff management system", "content": "Support for login on multiple browsers and devices: JWT allows users to log in on different browsers and devices without losing the login session on the old browser.6.3 Clean code 6.3.1 Problem description Placing queries in a loop can cause performance problems, especially when there is a large number of iterations. For each iteration, the system will have to perform a new question, which consumes resources and prolongs processing time.", "label": "human"}
{"ID": "00110114", "file_name": "Designing and developing sales staff management system", "content": "Besides, when you don’t make the variable names final or enum, the code can become confusing and difficult to maintain. When the value of a variable can change, especially in different methods or in iterations, this can lead to undetectable bugs or unexpected behaviors.", "label": "human"}
{"ID": "00110115", "file_name": "Designing and developing sales staff management system", "content": "Problem solving A better approach is to execute a single query to get all the required data, and then use this data in the for loop. This will help reduce the load on the database and improve system performance.", "label": "human"}
{"ID": "00110116", "file_name": "Designing and developing sales staff management system", "content": "In addition, it is also necessary to pay attention to optimizing queries to reduce resources and processing time. Using indexes and temporary tables is also one of the ways to improve query performance.", "label": "human"}
{"ID": "00110117", "file_name": "Designing and developing sales staff management system", "content": "In addition, naming variables that are easy to understand and clear is also part of writing clean code. This makes the code easier to read and makes it easier to maintain and develop later.", "label": "human"}
{"ID": "00110118", "file_name": "Designing and developing sales staff management system", "content": "In addition, as the code becomes more readable, it is easier to maintain and develop later. People who are new to the project can also easily understand the code without difficulty.", "label": "human"}
{"ID": "00110119", "file_name": "Designing and developing sales staff management system", "content": "Therefore, using clean code techniques like removing the query from the for loop and using final or enum variables improves the performance and makes the application more maintainable.", "label": "human"}
{"ID": "00110120", "file_name": "Designing and developing sales staff management system", "content": "Problem description The issue with not using pagination is that it can lead to slower page load times and potentially overload the server with too much data to process at once. This is especially problematic when dealing with large datasets or high-traffic websites.", "label": "human"}
{"ID": "00110121", "file_name": "Designing and developing sales staff management system", "content": "Additionally, users may become frustrated with having to scroll through numerous pages of results to find what they are looking for, leading to a poor user experience.", "label": "human"}
{"ID": "00110122", "file_name": "Designing and developing sales staff management system", "content": "Problem solvingTo solve the paging problem in Spring Boot, we can use the PagingAndSortin gRepository library, one of the features of Spring Data JPA. This library providesmethods that help us perform page analysis and sort data query results.First, we need to create an interface that inherits from PagingAndSortingRepos itory, with the type of the entity and the type of the main keyword as generic type parameters. Then in this interface, we can define methods like findAll(Pageable pageable) to get a list of elements based on the pagination and sorting parameters.", "label": "human"}
{"ID": "00110123", "file_name": "Designing and developing sales staff management system", "content": "For example, the website may experience slow loading times due to limited server resources, making it difficult for users to access the site. Additionally, the website may be more vulnerable to security threats, as it may not have access to the latest security updates and patches. Moreover, if the website experiences a sudden spike in traffic, it may crash or become unavailable, leading to a poor user experience and potential revenue loss for the business. By deploying a website to the cloud, these issues can be addressed, as cloud platforms typically offer scalability, security, and high availability.", "label": "human"}
{"ID": "00110124", "file_name": "Designing and developing sales staff management system", "content": "Problem solving Deploying a Java Spring Boot backend server on Google Cloud Platform(GCP) offers several benefits. It can solve issues such as scalability, reliability, se curity, resource management, flexible costs, and service integration. GCP allows for infrastructure to scale independently, provides tools for managing resources and monitoring performance, and has in-built security features. Additionally, GCP’sflexible cost structure allows for cost-effective resource management. Overall, de ploying a Java Spring Boot backend server on GCP can help businesses operate more efficiently, securely, and cost-effectively.", "label": "human"}
{"ID": "00110125", "file_name": "Designing and developing sales staff management system", "content": "After a while of researching, I chose the google cloud platform as a server to set up the backend server:Figure 6.11: Virtual machine on google cloud platform Figure 6.12: Run server backend success The image above shows that the server has successfully run with port 8080 in a virtual machine with external IP: 34.125.12.154.", "label": "human"}
{"ID": "00110126", "file_name": "Designing and developing sales staff management system", "content": "Achievement After using GCP, I was able to successfully deploy my Java Spring Boot backend server to the network. In order for my project to run on the virtual machine, I needed to use a database to fetch data, Gradle to build the project, and open ports to access through the firewall. Through this process, I learned a great deal about optimizing server performance and making it more efficient.", "label": "human"}
{"ID": "00110127", "file_name": "Designing and developing sales staff management system", "content": "One of the major benefits of using GCP is the ability to access the server fromanywhere, which is incredibly convenient. Moreover, the security and safety features of GCP made me feel secure about hosting my server on their platform. Overall, GCP has been very user-friendly and easy to use, which has made my develop ment process much smoother.", "label": "human"}
{"ID": "00110128", "file_name": "Designing and developing sales staff management system", "content": "Problem description Transferring information via URLs is inherently risky. If user information is notencrypted to be secure, hackers can access the server directly without authentica tion, requiring operations that only users or administrators can perform.6.6.2 Problem solving With each request from the client to the server, security information will be attached in the header. The server will check the access of that API, then validate the security information attached in the header, and then allow the operation to be performed. The solution is to use JWT to store and transmit security information to the server.", "label": "human"}
{"ID": "00110129", "file_name": "Designing and developing sales staff management system", "content": "When the user logs in successfully, the server will return the JWT which is an encrypted string from three parts: header, payload, and signature. In it, the header is the type of the JWT token and the SH512 signing algorithm. The payload contains user authentication information, including login email, login method, authorities, and expiration date. The end of the JWT is the signature, encrypted from a private string of characters using the HMAC512 algorithm .", "label": "human"}
{"ID": "00110130", "file_name": "Designing and developing sales staff management system", "content": "When the JWT string is received from the server, the client stores this informa tion in the browser. From here, every time the user wants to make a request to the server, the JWT is invoked and attached to the header of the sending request. The JWT will be decrypted with a secret string only available on the server side, then the decrypted string will be used to authenticate the account, check the account’s authorization, and check the expiration date. If all the information in the JWT is valid, the server will process the client’s request and return the result. Otherwise, API access to the server will be blocked. The Figure below is an example of a JWT string.", "label": "human"}
{"ID": "00110131", "file_name": "Designing and developing sales staff management system", "content": "The system has been developed and deployed on a web platform using Jquery as the user interface and the Spring Boot framework with Java as the main platformfor the server. It offers a range of functions to users, such as the ability to aggre gate product, transaction, and customer information to enhance sales performance.", "label": "human"}
{"ID": "00110132", "file_name": "Designing and developing sales staff management system", "content": "Meanwhile, system owners can manage employees, products, customers, and user permissions, as well as track and manage on orders. Furthermore, the system generates detailed reports on total revenue, new customers, orders, sales trends, and top-performing employees and products. All of these features aim to increase revenue for managers.", "label": "human"}
{"ID": "00110133", "file_name": "Designing and developing sales staff management system", "content": "Throughout the project, I learned various new technologies, including how todefine a project, select system functions, test the system, and connect it to a net work. Additionally, I honed my analytical, problem-solving, and report-writing skills.", "label": "human"}
{"ID": "00110134", "file_name": "Designing and developing sales staff management system", "content": "Although the system is operational and has basic user functions, it has somelimitations that need to be improved due to time and resource constraints. For ex ample, the system currently lacks a payment function. However, I plan to continue refining the system to address these shortcomings in the future.", "label": "human"}
{"ID": "00110135", "file_name": "Designing and developing sales staff management system", "content": "As part of my graduation project, I have developed the basic functions of an employee management system. However, to improve user experience and ease the workload of administrators, I plan to upgrade the system further. Specifically, I will focus on enhancing user interaction features such as product warranty, bill payment, and a mobile application version for more accessibility.", "label": "human"}
{"ID": "00110136", "file_name": "Designing and developing sales staff management system", "content": "Furthermore, I recognize the need to improve existing functions to better serve user needs, particularly in delivery management. To achieve this, I will implement a feature that allows users to track the status of their orders more easily. My ultimate goal is to create a user-friendly and intuitive system that meets the needs of all users. Getfly business management . [On]. Available:  com/ (visited on 01/15/2023).", "label": "human"}
{"ID": "00120001", "file_name": "A Top-down action game for learning English with Unity", "content": "From the heyday of arcade machines to the rise of home consoles, the gaming industry has grown exponentially over the past few decades. We can divide the development of the game industry into several different stages.", "label": "human"}
{"ID": "00120002", "file_name": "A Top-down action game for learning English with Unity", "content": "0–1983: Pre-crisis era Atari is a name that should be mentioned in the his tory of the game industry. Early prototypes of video games were developed in a lab in the 1960s, but it was Atari’s release of Pong in 1972 that helped kickstartthe industry. The arcade version of table tennis is a attractive game, attracting cus tomers eager to play and companies began to produce their clones. Likewise, Atari himself sold a version of the game for Pong’s console in 1975 and finally the Atari 2600-branded console in 1977, which would be the first console to sell more thana single console million units. In a short time, the arcade market began to stabi lize. After the game market decd due to too many copies of Pong, the releaseof Space Invaders in 1978 revived the market. Arcade machines began to be in stalled everywhere and new series of games like Pac-Man and Donkey Kong have promoted the further development of this type of entertainment. By 1982, arcade games were generating more money than both the pop industry and the box office.", "label": "human"}
{"ID": "00120003", "file_name": "A Top-down action game for learning English with Unity", "content": "5–2000: The race for technological progress. Unfortunately, the pace of de velopment of the gaming industry is too fast to sustain. Eager to profit from theburgeoning (household) console game market, Atari licensed the ultra-budget Pac Man docking stations and an adaptation of the E.T. the Extra-Terrestrial. They hit the market in a hurry. As a result, the poor quality of the game cost the company millions of dollars in profits and brand damage. As other companies also sought to capitalize on the market, many poor-quality console and game products caused an industry-wide downturn. At the same time, the personal computer became the newest gaming machine, especially with the release of the Commodore 64 in 1982.", "label": "human"}
{"ID": "00120004", "file_name": "A Top-down action game for learning English with Unity", "content": "It was a defining sign of the historical era of the gaming industry: a run technol ogy race. In the years that followed, Nintendo released the Nintendo Entertainment System (NES) console in 1985 (released in Japan as the Famicom), prioritizing high-quality games and consistent marketing to recapture The market is feeling cautious. Thanks to games like Duck Hunt, Excitebike, and the introduction of Mario in Super Mario Bros, the NES’ huge success revived the console market.", "label": "human"}
{"ID": "00120005", "file_name": "A Top-down action game for learning English with Unity", "content": "Nintendo wanted to continue its dominance in the field with the release of the Game Boy handheld and the Super Nintendo entertainment system. In 1988, theSega arcade company entered the fray with the Sega Mega Drive console (released as the Sega Mega Drive console called Genesis in North America) and later theGame Gear handheld, placing a marketing emphasis on processing power. Elec tronic manufacturer Sony released the PlayStation in 1994, using CD-ROM discsinstead of electronic tapes to increase storage capacity for individual games. It be came the first console in history to sell over 100 million units, and the focus on the software format continued with the next generation of consoles: PlayStation 2 (DVD) and PlayStation 3 (Blu-ray). Even Microsoft recognized the importance of PC gaming and developed the DirectX API to aid in game programming. That X\" brand later helped the company break into the console market with the Xbox product.", "label": "human"}
{"ID": "00120006", "file_name": "A Top-down action game for learning English with Unity", "content": "1–now: The on boom. However, it is the rise of the Internet and mo bile phones that has taken the gaming industry from tens of billions to hundreds of billions of dollars in revenue. The main reason is thanks to the appearance of subscription services (subscriptions) and freemium services. The company witha freemium model, a combination of “free” and “premium”, provides basic ser vices initially for free to users but to use more premium services or extra features,customers need to pay. In 2001, Microsoft launched the Xbox Live on gam ing platform with a monthly subscription, giving players access to voice chat andmultiplayer connectivity services. It quickly became a must-have feature for con sumers. Meanwhile, on PC, Blizzard tapped into the massively multiplayer on (MMO) subscription market with the 2004 release of World of Warcraft, whichpeaked at over 14 million monthly paying subscribers. At the same time, the com panies saw a bright future for mobile games, but they encountered many difficulties in the exploitation process. Nintendo continued to dominate the handheld market with updated Game Boy releases, and Nokia and BlackBerry tried integrating gameapps into their phones. But it was Apple’s iPhone that underpinned the game’s tran sition to mobile platforms. The company’s release of its App Store for smartphones(followed by Google’s store for Android devices) paved the way for app develop ers to create free, paid games. and pay-per-feature to serve the mass market. Now, everyone’s eyes are on that burgeoning 85 billion dollars mobile gaming market,and game companies are beginning to solidify their positions in this segment. Con sole makers like Microsoft and Sony are rolling out cloud subscription services while they continue to develop new consoles. Meanwhile, Amazon and Google arerolling out their services that work across multiple devices, including mobile de vices. After seeing the success that games like Pokemon Go have on smartphones, the title hit over 1 billion dollars in annual sales and broke Grand Theft Auto V’s 1billion dollar sales record in just over a year and three days, companies are tryingto capture as much share of the mobile gaming market as possible. With the prolif eration of smartphones, social gaming and streaming services, they’re on the right track. There are over 2.7 billion people playing games worldwide in 2020, and how they choose to spend their money will continue to shape the history of the gaming industry.", "label": "human"}
{"ID": "00120007", "file_name": "A Top-down action game for learning English with Unity", "content": "From the above information, we can see that the game industry is a potential market which will grow a lot in the future, and also has a great attraction to the young generation.", "label": "human"}
{"ID": "00120008", "file_name": "A Top-down action game for learning English with Unity", "content": "As mentioned above, this project has the main purpose of helping players learn English. This game will focus on helping players learn vocabulary. The reason is that vocabulary is the \"root source\" of all problems. To communicate coherently and capture the necessary information with the other party, vocabulary is what you need to be sure of. Only when possessing a rich and rich vocabulary can yourspeech become natural and fluent. In the process of communication, readers or lis teners almost only pay attention to the content that the speaker wants to expressrather than grammar and sentences. Because, even if you firmly grasp the gram matical structures, the vocabulary is limited, it is still impossible to properly convey the content that you want to convey to the listener. Rich and abundant vocabulary will greatly assist you in developing and perfecting other skills more effectively.", "label": "human"}
{"ID": "00120009", "file_name": "A Top-down action game for learning English with Unity", "content": "With a wide range of vocabulary, you can easily understand the conveyed content even if your grammar is not too strong. And when you understand quickly and getit right, you will be able to respond quickly. The process of listening, understand ing and speaking the word will also become more and more fluent. To help players learn vocabulary systematically from easy to difficult and acquire knowledge more quality and effective, this project did classify the difficulty of vocabulary and apply it to the gameplay. The difficulty scale this essay decided to apply as a standard is called CEFR. CEFR stands for ’Common European Framework of Reference for languages, which describes the language abilities of students at different levels oflearning. CEFR can be used to compare standards in language learning and to cre ate instructional programs. It ranks language skills at six levels. A1 and A2 indicate elementary and elementary levels of ability, B1 and B2 indicate lower and upper intermediate, C1 indicates advanced level, C2 indicates complete proficiency in the language.", "label": "human"}
{"ID": "00120010", "file_name": "A Top-down action game for learning English with Unity", "content": "Based on the above reference scale, the game is divided into 5 levels with diffi-culty levels ranging from A1 to C1. To complete the game, an important factor is that the player must continuously learn the vocabulary at each level to a sufficient level of proficiency, which will stimulate the player to absorb new knowledge in the process of experiencing. Due to a large number of English words, to avoid the loss of knowledge, the vocabulary data set has been selected the most important words(words with a lot of frequency) at each level of vocabulary to optimize learning ef ficiency. This dataset is based on two main books, Oxford 3000 and Oxford 5000.", "label": "human"}
{"ID": "00120011", "file_name": "A Top-down action game for learning English with Unity", "content": "As for the gameplay, to increase the attractiveness and continuity of the players, I decided to choose action-oriented game development. The viewing angle of the game is a Top-down view so that players do not have vestibular problems such as dizziness, and headaches when playing games for a long time. The goal of the project is that players can enjoy the feeling of playing the game and learn a large number of vocabularies.", "label": "human"}
{"ID": "00120012", "file_name": "A Top-down action game for learning English with Unity", "content": "The plot is the \"backbone\", creating the \"soul\" for a game, helping to push the emotions when experiencing and contributing to the rationalization of gameplay.", "label": "human"}
{"ID": "00120013", "file_name": "A Top-down action game for learning English with Unity", "content": "The following is the plot for this game product. This is the story of continent A, an isolated region that has never been explored. This world is a place where magic is supreme and is ruled by two empires B and C. To explain the origin of these two empires, one must dive into the deepest depths of the river of history here.", "label": "human"}
{"ID": "00120014", "file_name": "A Top-down action game for learning English with Unity", "content": "At that time, the methods of survival were very instinctive and minimalist while nature was extremely harsh. Thus, this was a very dark period in human history that is later often referred to as the \"Age of Illiteracy\". Humans continued to live in disarray until one day, on dry soil in Continent A’s eastern half, there was a boy who was suffering the most painful moments of his life since he was born. His family had just been slaughtered by a swarm of insects while trying to find food to survive the meteorite season. He is the last surviving member of the family but is also surrounded by a huge swarm of cockroaches. Realizing that he no longer had a chance to survive, the memory of his family becoming food for the insects that suddenly appeared, pushed his mind to the brink of collapse. He raised his face to the sky and shouted to release all his resentment towards life, but due to the pain and exhaustion, he couldn’t scream like a normal person. His mouth was constantly deformed, his breathing was also constantly interrupted, which inadvertently made his screams become a strange sound that had never appeared before. He shouted until his throat was torn, his strength and strength exhausted and he gave up hope of living, suddenly his body felt indescribable as if he was connected to this continent.", "label": "human"}
{"ID": "00120015", "file_name": "A Top-down action game for learning English with Unity", "content": "This strange feeling pulled him out of the pit of despair, made him look around andthis scene was forever imprinted in his mind until the last days of his life. The story of the boy in a desperate scream for extermination who unleashed the power to destroy the cockroaches has quickly spread throughout the A continent. Some believe the boy has special powers, others say that the boy’s scream had touched a higher-level existence, some just considered it a coincidence, etc. But whatever the conclusion, countless people tried to research its usage. That power is based on rumors, they believe that as long as they control this power, they will become the hegemony of the continent. It has been proven that this power is indeed attainable when in the following years it has begun to appear that some people can create phenomena beyond human understanding when trying to understand them. making strange sounds with the mouth. This reinforced the belief that there was a power beyond human ability and from this point on, the entire A continent was immersed in trying to control this power. Over the years, the research and application of this mysterious power have come a long way. The sound that the boy made this yearis known as an ancient language by humans, this is also the reason why the qual ity of life in Continent A has grown to a height beyond all imagination. Ancient languages occupy absolute importance in life here, appearing in all fields such as military, mining, education, economy, etc. Through countless years of research and development, the world has only discovered 2 types of ancient languages, calledEnglish and Vietnamese. Each type has its characteristics but all bring great ben efits in all aspects of life. A special feature is that each person can only use one type of ancient language - that is the first type of ancient language they use in their life. This has inadvertently created two opposing factions in Continent A whenevery user of the ancient language believes that the language they use is the origi nal strength of this continent. This ideological conflict over time splits the peopleliving here into two main factions, empire B and C. At first, political conflicts be tween B and C took place extremely tensely when the two empires were very tense.", "label": "human"}
{"ID": "00120016", "file_name": "A Top-down action game for learning English with Unity", "content": "This nation competes on all fronts to prove its rune superior. However, over time, this conflict gradually cooled down when neither side can take a clear advantageand the power of the two empires is always in balance. People also gradually be lieve that the power of the two ancient languages is equivalent and the contempt forthose who use the other languages gradually disappears, the people of the two em pires live in peace, and the people of the mainland live together in peace. Land A gradually became prosperous and developed. It was thought this peace would last forever, but an event that took place some 200 years ago developed the seeds that threatened to destroy them all. A genius researcher discovered a way to combinetwo ancient languages, English and Vietnamese, when he accidentally discoveredthat these two ancient languages had words with the same meaning. He also real ized when combining these two words, he will gain an unsurpassed supreme power.", "label": "human"}
{"ID": "00120017", "file_name": "A Top-down action game for learning English with Unity", "content": "Excited by this discovery but also aware of the huge impact it would have on him, he spent the rest of his life searching for all the words with the same meaning in English and Vietnamese alone, then record all that knowledge in a book. This book was named \"English-Vietnamese Dictionary\" by him, then he hid this book in a very secret place and intended never to publish this research. However, because he regretted his efforts, he told this to his son and warned that this was a family secret not to be revealed to anyone before he die. This secret was kept hidden only by a single member of the family until D’s lifetime. In a world where ancient languages were so essential, one’s social status was determined by one’s ability to use ancient languages. D is a poor student who always struggles with the most basic words despite trying hard to learn, leading to D being bullied and despised by his friends.", "label": "human"}
{"ID": "00120018", "file_name": "A Top-down action game for learning English with Unity", "content": "This took place and built up in D an ideal that wanted to change the world where no one had to learn a language by creating a new language that people could stilluse without having to learn. He decided to find the dictionary revealed by his fa ther in the last days of his life. After an arduous journey, D successfully finds the dictionary and tries to use it to change the rules of the world. However, due to a lack of basic knowledge of grammar, he accidentally combined the incantation into extremely strange and hybrid sounds between the two ancient languages. This spell overturned all the principles of English and Vietnamese, causing these two ancient languages to become chaotic and completely disable all their power. This caused an unprecedented crisis on the A continent when it threatened to bring it back to the Age of Illiteracy. Mankind’s only hope is to collect all the words that have become chaotic in the English-Vietnamese dictionary. Regretting his behavior, D decides to go back and collect the lost word pairs in the dictionary. Please use your English knowledge to help D redeem his mistake!2.1 Survey As stated in the abstract, there is currently a very high demand for English instruction in Vietnam. Although the English training market has recently been heavily mined, there is still a ton of untapped potential, particularly in the area of English learning software development. Applications for learning English like Duolingo, LingoDeer, Cake, and others have proven to be quite popular and useful for users. There are a few applications that have integrated games to increase the fun and excitement in the learning process. However, it can be said that the target audience of most applications containing games is children who have just started learning foreign languages when the gameplay is very simple and easy to play.", "label": "human"}
{"ID": "00120019", "file_name": "A Top-down action game for learning English with Unity", "content": "This is very suitable for young children but will not be very effective for those of an older age when the monotonous gameplay will quickly become boring.", "label": "human"}
{"ID": "00120020", "file_name": "A Top-down action game for learning English with Unity", "content": "Based on the fact that the market is lacking in English learning games forteenagers, this will be the main user group that this project is aimed at. Game play will be designed quickly and with dramatic elements, causing high difficulty and requiring that in addition to the player having English knowledge, they must also be able to control the character skillfully to complete the game.", "label": "human"}
{"ID": "00120021", "file_name": "A Top-down action game for learning English with Unity", "content": "Class diagramClass diagram Figure 2.1 shows the relationship between objects in the pro cess of building the system of this project. Some important classes that have a lot of influence are GameManager, PlayerManager, DataManager, EnemyManager, etc. As soon as the game starts, the DataManager class will be called to reloadthe data from the player’s last session. After the player selects the screen in Can vasChooseMap, the system will load the map data in LoadingManager. Once the loading is complete, the GameManager will receive the signal and trigger all the necessary classes to start performing their tasks to start the gameplay. Triggeredclasses include SpawnerManager, BuffManager, PlayerManager, and GameMan ager also calls CanvasGameplay to appear. When the GameManager receives the signal to end the game when the player wins or loses, the GameManager willcall the DataManager to save the necessary information and return the UI to Can vasChooseMap.<<Interface>> IBuff +Setup(Integer):void HealthBuff OnT riggerEnter():void +Setup(Interger):void Update():voidSpeedBuff OnT riggerEnter():void +Setup(Interger):void Update():void Projectile speed:Float +chosenChar:Char Move():void DestroyBullet():IEnumerator OnT riggerEnter():void CameraFollow +player:T ransform +smoothness:Float cameraOf ffset:V ector3 Start():void Update():void CameraMinimap +player:T ransform Start():void Update():void CameraScroll +cam:Camera +zoomSpeed:Float camFOV :Float mouseScrollInput:Float Start():void Update():voidEnemyBaseState(abstract) +EnterState(EnemyStateManager):void +EnterState(EnemyStateManager):void +EnterState(EnemyStateManager ,Float):void ) +UpdateState(EnemyStateManager):void OnT riggerEnter(EnemyStateManager ,Collider):void EnemyCharUI +charHolder:T ransform +panelPrefab:T ransform +floatingT extEng:T extMesh +floatingT extViet:TextMesh +hiddenCharList:Dictionary<Integer ,TextMeshUGUI> panelDistance:Float leftMargin:Float charCount:Integer Update():voidEnemyChasingState chasingT imeKeeper:Float maxSenseChaseRange:Float +EnterState(EnemyStateManager):void +UpdateState(EnemyStateManager):voidEnemyDyingState deadT imeKeeper:Float +EnterState(EnemyStateManager):void +UpdateState(EnemyStateManager):voidEnemyPatrollingState frontSightRange:Float backSightRange:Float walkPointRange:Float maxSearchRange:Float walkT imeKeeper:Float searchT imeKeeper:Float +EnterState(EnemyStateManager):void +UpdateState(EnemyStateManager):void OnT riggerEnter(EnemyStateManager ,Collider):void SearchW alkPoint(EnemyStateManager):void CheckPlayerAround(EnemyStateManager):voidEnemyPushBackState +EnterState(EnemyStateManager):void +UpdateState(EnemyStateManager):void EnemyStateManager +currentState:EnemyBaseState +ChasingState:EnemyChasingState +PatrollingState:EnemyPatrollingState +PushBackState:EnemyPushBackState +DyingState:EnemyDyingState +StunState:EnemyStunState +enemyCharUI:EnemyCharUI +player:T ransform Start():void Update():void OnT riggerEnter(Collider):void SwitchState(EnemyBaseState):void +Die():void +LoadCharHolder():voidEnemyStunState stunT ime:Float +EnterState(EnemyStateManager):void +EnterState(EnemyStateManager ,Float):void +UpdateState(EnemyStateManager):voidSimplePool TagUtilityMathUtilityBuffManager +healthPotionPrefab:T ransform +speedPotionPrefab:T ransform +houseList:List<T ransform> +spawnDuration:Float +StartSpawnBuf f():void +StopAll():void DataManager +playerData:PlayerData +LoadData():void +SaveData():voidPlayerData +health:Integer +mapLevel:Integer +gold:Integer +upgradeAtkLevel:Integer +upgradeHealthLevel:Integer +upgradeSpeedLevel:Integer +upgradeCooldownLevel:Integer +rankData:Dictionary<string,List<Float>> EnemyManager +enemyList:List<EnemyStateManager> +deadEnemyCount:int +maxEnemyDead:int Update():void +OverlapEnemy():List<EnemyStateManager> +GetEnemyFoward():List<EnemyStateManager> +ResetAll():voidGameManager +startGameplayT rigger:bool +stopGameplayT rigger:bool +isWin:bool +currentLevel:string Update():void StopGameplay():void HandleWin():voidLoadingManager +dictionary:Dictionary<string,string> +LoadDictionary():void LoadSlowly():IEnumerator SoundManager +backgroundSound:AudioSource +soundOne:AudioSource +currentBgClip:AudioClip +soundV olume:Float +musicV olume:Float +(multiple sound data):SoundInfor +PlayBackgroundSound():void +PlaySoundOneShot():void +StopBgMusic():voidSoundInfor +clip:AudioClip +volume:Float SpawnerManager +enemyPool:T ransform +enemyPrefab:GameObject +spawnPlaces:List<T ransform> +enemyCount:Integer spawnOf fset:Float enemyMax:Integer +StartSpawnEnemy() +StopAll()PlayerManager +playerConfig:PlayerScriptable +player:PlayerController +health:Integer +bulletSpeed:Float +speed:Float +cooldown1:Float +cooldown2:Float +cooldown3:Float +cooldown4:Float +chosenChar:Char +isDead:bool +isStartGame:bool +goldCollected:Integer +ResetParam():void +InitPlayerStat():void PlayerController +bulletPrefab:T ransform rotateV elocity:Float +isCasting:bool clickPosBuf fer:Vector3 Start():void Update():void HandleKeyboardInput():void ChangeW ord():void NormalAttack():void DoRotation():void +GetHit():void +HandleDeath():void +Shoot():void +HandleCooldown():void +Blink():void +CastSkill1():void +CastSkill2():void +CastSkill3():void +GetHealth():void +GetStat():void PlayerAnimator +stopCastingEvent:UnityEvent +shootEvent:UnityEvent +shootEvent:UnityEvent +castSkill1Event:UnityEvent +castSkill2Event:UnityEvent +CastSkill1Anim():void +CastSkill2Anim():void +CastSkill3Anim():void +AttackAnim():void +FinishCasting():void +Shoot():void CanvasInventoryScreen +goldTxt:T ext +canvasPlayoptionScreen:CanvasPlayoptionScreen +upgradeConfig:UpgradeScriptable +OnOpen():void +OnClose():void +OnBack():void +OnUpgradeClick():voidCanvasHighscoreScreen +rankItemList:List<RankItem> +scoreList:List<Float> +playoptionScreen:CanvasPlayoptionScreen +UpdateRank():void +OnOpen():void +OnBack():void ResetUI():void BookItem +word:T extCanvasBookScreen +wordPrefab:BookItem +scrollV iew:List<GameObject> +contentHolder:List<GameObject> +LoadBook():void +OnClose():void +OnOpen():void +OpenBook(Integer):voidCanvasChooseMap +canvasLoadingScreen:CanvasLoadingScreen +playoptionScreen:CanvasPlayoptionScreen +bookScreen:CanvasBookScreen +lockerList:List<GameObject> +swiper:Swiper +OnOpen():void +OnPlayClick():void +OnReadClick():void +OnBack():void +Setup():voidCanvasDieScreen +canvasChooseMapScreen:CanvasChooseMap +OnOpen():void +OnClose():void +OnBack():voidCanvasGameplay +canvasDieScreen:CanvasDieScreen +canvasWinScreen:CanvasWinScreen +timerClock:T imerClock +playerHealthSlider:Slider +chosenCharUI:T ransform +abilityImage:Image Update():void +Setup():void CanvasLoadingScreen +timerClock:T imerClock +loadingSlider:Slider +UpgradeV alue():void +OnOpen():void +OnClose():voidCanvasPlayoptionScreen +canvasHighscoreScreen:CanvasHighscoreScreen +canvasStartScreen:CanvasStartScreen +canvasChooseMapScreen:CanvasChooseMapScreen +canvasInventoryScreen:CcanvasInventoryScreen +OnOpen():void +OnClose():void +OnMainModeClick():void +OnHighscoreClick():void +OnInventoryClick():void +OnBackClick():voidCanvasStartScreen +canvasPlayoptionScreen:CanvasPlayoptionScreen +popup_Quit:Popup_Quit +popup_Setting:Popup_Setting +OnOpen():void +OnClose():void +OnStartClick():void +OnQuitClick():void +OnSettingClick():void CanvasW inScreen +canvasChooseMapScreen:CanvasChooseMap +OnOpen():void +OnClose():void +OnNext():voidPopup_Setting +musicSlider:Slider +soundSlider:Slider +OnOpen():void +OnClose():void +OnApply():void Swiper +currentPage:Integer +scrollbar:GameObject Update():voidTimerClock +currentT ime:Float startT ime:Float isStopT ime:bool +Setup():void Update():void +OnClose():void +OnOpen():voidPopup_Quit +OnOpen():void +OnClose():void +OnY es():void RankItem +rankTxt:T ext +scoreTxt:T ext +Setup(string,string):void UpgradeScriptable +word:T extHelper 1 0...* 10...*1 1Text0...*1 10...* 0...* Figure 2.1: Class diagram2.2.2 Sequence diagramSequence diagram is a diagram used to identify the sequence of events of a cer tain group of objects. It describes in detail the messages sent and received between objects and also focuses on the timing of sending and receiving those messages.", "label": "human"}
{"ID": "00120022", "file_name": "A Top-down action game for learning English with Unity", "content": "Setting Figure 2.2 is the sequence diagram of the Setting feature. The flow starts when the player clicks the Setting button in the Canvas Start Screen. After the adjustment is complete, the game’s volume will be updated again in Sound Manager.", "label": "human"}
{"ID": "00120023", "file_name": "A Top-down action game for learning English with Unity", "content": "User updateUICanvasStartScreen Setting and Applyclick Setting buttonPopup_Setting OnSettingClick()SoundManager OnApply() updateUI Figure 2.2: Sequence diagram of Setting b, Highscore Figure 2.3 is the sequence diagram of Highscore feature. The stream will start when the player clicks on the High score button in the Canvas Play option Screen.", "label": "human"}
{"ID": "00120024", "file_name": "A Top-down action game for learning English with Unity", "content": "The system will access the Data Manager to get the data of the gameplay comple tion time and display it back to the Canvas High Score Screen.", "label": "human"}
{"ID": "00120025", "file_name": "A Top-down action game for learning English with Unity", "content": "Start Figure 2.4 is the sequence diagram of Start gameplay feature. After the playerpresses Play on the Canvas Choose Map and the Loading Manager finishes load ing the data, the GameManager will trigger a few other classes to start the main gameplay.", "label": "human"}
{"ID": "00120026", "file_name": "A Top-down action game for learning English with Unity", "content": "Upgrade Figure 2.5 is the sequence diagram of Upgrade feature. The flow of this diagram revolves around the DataManager so that it can check if the player has enough resources to upgrade.User CanvasPlayoptionScreen updateUIclick Highscore buttonCanvasHighscoreScreen OnHighscoreClick() updateUIDataManager check data exist check data existGetRankT ype() updateUIalt click rank T ype GetRankT ype() return rank dataupdateUI return rank data altopt Figure 2.3: Sequence diagram of Highscore User CanvasChooseMap click Play buttonLoadingManager LoadDictionary()GameManager send trigger StartGameplay()OnPlayClick()SpawnerManager BuffManager Setup()PlayerManager CanavsGameplay StartSpawnEnemy() StartSpawnBuf f InitPlayerStat() updateUI Figure 2.4: Sequence diagram of Start gameplay User CanvasPlayoptionScreen updateUI click Upgrade updateUIclick Inventory buttonInventoryScreen DataManager OnUpgradeClick() Check enough gold SaveData()click Inventory button return if not enough return new dataalt Figure 2.5: Sequence diagram of Upgradee, Game loop Figure 2.6 is the sequence diagram of handle gameloop. After the player loses, the data will be updated and the main UI will switch to Canvas Choose Map.", "label": "human"}
{"ID": "00120027", "file_name": "A Top-down action game for learning English with Unity", "content": "User updateUI health if player alivePlayerController check player Death HandleDeath()player Get HitGameManager StopGameplay()CanvasFail trigger if player deathDataManager SaveData OnOpen()CanvasChooseMap OnOpen() trigger end game click back Figure 2.6: Sequence diagram of handle gameloop 2.2.3 Activity diagramAn activity diagram is a diagram that describes the execution steps, actions, de cision nodes, and branching conditions to control the execution flow of the system.", "label": "human"}
{"ID": "00120028", "file_name": "A Top-down action game for learning English with Unity", "content": "Game loop Figure 2.11 is the activity diagram of handle gameloop.Click Setting Display Setting UI Click close buttonYes No Close Setting UIApply Setting Click ApplyEditSettingClick close button YesNo Figure 2.7: Activity diagram of Setting feature Click Highscore Get highscore data Click close button YesNo Close Highscore UIClick dif ferent rank typeDisplay highscore UI Figure 2.8: Activity diagram of Highscore featureClick Play Load Dictionary Start gameplay trigger Start Spawn Enemy Start Spawn Buf f Init Player Stat Setup gameplay UI Play game Figure 2.9: Activity diagram of Start gameplay feature Click Inventory Display inventory UI Close Inventory UIClick button backYes No Click upgrade Check enough coinNo Update DataYes Figure 2.10: Activity diagram of Upgrade featureControl Player Is Get HitNo Yes Is DeathNo Handle DeathYes Save Data Back to canvas choose mapClick next on fail UIIs Win Click next on win UIYes No Figure 2.11: Activity diagram of handle gameloop feature3.1 Game technology At the moment, due to the growing gaming industry, there is also a multitude of different development tools for game developers to choose from. Some typical names can be mentioned such as Unity Engine, Cocos Creator, Unreal Engine, Godot, etc. This project decided to choose Unity Engine as development tool. Unity has some great advantages such as free, large community, cross-platform, etc. Here is the basic information about Unity Engine.", "label": "human"}
{"ID": "00120029", "file_name": "A Top-down action game for learning English with Unity", "content": "Unity is a cross-platform game engine developed by Unity Technologies, firstannounced and released in June 2005 at the Apple Worldwide Developers Confer ence as a game engine. play Mac OS X. This tool has been gradually expandedto support a variety of desktops, mobile devices, consoles, and virtual reality plat forms. It is especially popular for iOS and Android mobile game development andis considered easy to use for beginner developers and popular for indie game de velopment. Unity gives users the ability to create games and experiences in both 2D and 3d, and it provides the main scripting API in C #using Mono, for both theUnity editor in plugin form and the game itself, as well as drag and drops func tionality. Before C #was the main programming language used for the engine, it formerly supported Boo, the language was removed with the release of Unity 5 and a Boo-based implementation of Javascript called UnityScript, was deprecated in August 2017, following the release of Unity 2017.1, in favor of C #.", "label": "human"}
{"ID": "00120030", "file_name": "A Top-down action game for learning English with Unity", "content": "Unity history: Unity 2.0 (2007) In 2007, Unity 2.0 was released with about 50 new features. The update came with a terrain engine that was geared for complex 3D scenes, as well as video playback, dynamic shadows that changed in real time, and other features. The update also included new tools that made it simpler forprogrammers to work together. It had a networking layer that offered Network Ad dress Translation, State Synchronization, and Remote Procedure Calls, allowing programmers to create multiplayer games based on the User Datagram Protocol.", "label": "human"}
{"ID": "00120031", "file_name": "A Top-down action game for learning English with Unity", "content": "Unity swiftly introduced support for the iPhone after Apple opened its App Storein 2008. The engine dominated the iPhone market for many years and gained pop ularity among iOS game creators.", "label": "human"}
{"ID": "00120032", "file_name": "A Top-down action game for learning English with Unity", "content": "Unity 3.0 (2010) In September 2010, Unity 3.0 was released, increasing the en gine’s graphical capabilities for desktop computers and gaming consoles. Alongwith Android support, Unity 3 included delayed rendering, a built-in tree edi tor, native font rendering, automatic UV mapping, audio filters, and the BeastLightmap tool from Illuminate Labs. VentureBeat noted in 2012, \"Few businesseshave helped the flow of independently developed games as much as Unity Tech nologies. Its tools are used by more than 1.3 million game creators to produce cutting-edge graphics for their iOS, Android, console, PC, and web-based games.", "label": "human"}
{"ID": "00120033", "file_name": "A Top-down action game for learning English with Unity", "content": "Simply put, Unity wants to be the platform-agnostic game engine.\" According to a Game Developer magazine survey conducted in May 2012, Unity is the best game engine for mobile devices.", "label": "human"}
{"ID": "00120034", "file_name": "A Top-down action game for learning English with Unity", "content": "Unity 4.0 (2012) Unity 4.0 was released by Unity Technologies in November 2012. This version provided access to the Linux preview, support for DirectX 11and Adobe Flash, as well as new animation tools dubbed Mecanim. In 2013, Facebook added a software development kit for games built using the Unity game en gine. This included capabilities for tracking advertising efforts, deep linking-whereusers could jump straight from social media posts to particular game areas-and simple in-game image sharing. With Unity, Facebook created a brand-new PC gam ing platform in 2016. Facebook’s gaming platforms were supported by Unity, and Unity creators could export and publish games to Facebook more quickly.", "label": "human"}
{"ID": "00120035", "file_name": "A Top-down action game for learning English with Unity", "content": "Unity 5 (2015) The Verge said of 2015’s Unity 5 release: \"Unity started with the goal of making game development universally accessible. Unity 5 is a long-awaitedstep towards that future.\" With Unity 5, the engine improved its lighting and au dio. Through WebGL, Unity developers could add their games to compatible Web browsers with no plug-ins required for players. Unity 5.0 offered real-time global illumination, light mapping previews, Unity Cloud, a new audio system, and the Nvidia PhysX 3.3 physics engine. The fifth generation of the Unity engine also introduced Cinematic Image Effects to help make Unity games look less generic.", "label": "human"}
{"ID": "00120036", "file_name": "A Top-down action game for learning English with Unity", "content": "Unity 5.6 added new lighting and particle effects, updated the engine’s overall per formance, and added native support for Nintendo Switch, Facebook Gameroom, Google Daydream, and the Vulkan graphics API. It introduced a 4K video player capable of running 360-degree videos for virtual reality.", "label": "human"}
{"ID": "00120037", "file_name": "A Top-down action game for learning English with Unity", "content": "Monobehaviour: MonoBehaviour is the base class that every Unity script de rives from. It provides several lifecycle functions that make it easier to develop your apps and games.", "label": "human"}
{"ID": "00120038", "file_name": "A Top-down action game for learning English with Unity", "content": "GameObject: Unity defines GameObjec as an object that represents the Assets in the game such as characters, plants, tools, props, cameras, effects... GameObject all contain a basic property called Transform, used to set GameObject’s position,orientation and size.Components: Components are properties added to GameObject such as Anima tion, sound, 3D models, effects, ... to build, combine different elements to define morphologies, behaviors,... of the desired object in the game.", "label": "human"}
{"ID": "00120039", "file_name": "A Top-down action game for learning English with Unity", "content": "Scenes: In Unity, a Scene is a game scene, the game space where the layout of GameObject is set, or a part containing interface settings such as in-game menus.", "label": "human"}
{"ID": "00120040", "file_name": "A Top-down action game for learning English with Unity", "content": "Scripts: Script are a Component in Unity. This is an essential component used to interact with player actions, or manage events to change the direction of the game in accordance with the game scenario. Unity gives programmers the ability to write script in C #language.", "label": "human"}
{"ID": "00120041", "file_name": "A Top-down action game for learning English with Unity", "content": "Prefabs: Prefab is a finished GameObject after adding properties and stored again for reuse. GameObject cloned from a prefab will be exactly the same. To create a prefab, simply drag a GameObject from the Hierarchy window onto the Project window Camera: The camera in Unity is used to show the frame, the perspective that the player can see in the game. In a game, it is possible to set up multiple cameras to split the player screen, create effects, or customize such as view from the back, miniature map, ...", "label": "human"}
{"ID": "00120042", "file_name": "A Top-down action game for learning English with Unity", "content": "Navmesh: Navmesh is a specified grid in the Unity scene that specifies navi gable areas in the environment, including areas where characters can walk, as wellas obstacles. This is useful for situations where a combination of Pathfinding navi gation and AI control is required. The Navmesh agent component helps characters avoid each other, move around the scene toward a common goal, or any other type of scenario involving spatial reasoning or navigation.", "label": "human"}
{"ID": "00120043", "file_name": "A Top-down action game for learning English with Unity", "content": "Core gameplay lettThis project is a 3D top-down shooter built for Windows computers based on the context following the main character in the journey to atone for mistakes andsave civilization for the world. The main character moves in the 3D coordinate sys tem and hunts for monsters and survives until enough points pass the level. Player view from the top down, control the main character to move with the right mouse and shoot with the left mouse. The bullet of the main character fired will come with 1 letter, that letter will be selected by the player by pressing the character you want to shoot on the keyboard before firing. If the player shoots the letter correctly,he will kill the monster and get extra points. A monster will represent a 1-word meaning in English but missing some characters, monster will be killed when the missing characters are shot enough at the person. The killed monster will display the Vietnamese meaning of the English word that the monster carries. On the map, there will be some points where beneficial buffs will appear for the player such as increased health, and increased speed, ... Over time when the player reaches thefollowing levels, the difficulty of the vocabulary representing the monster will in crease. Players can also upgrade the character’s strength (speed, health, skills, ...) with the amount of gold accumulated when finish a level. Every time player wins a level, adding to the next UI will be opened, the system will save the time the player used to pass the level to create a high score table. The high score system will motivate the player to complete the level many more times. During the game, the player will be exposed to English words and see their meanings continuously, whilealso trying to remember and guess the hidden English characters. This will simul taneously use 2 methods of learning English, passive learning and active learning, which greatly increases learning efficiency.", "label": "human"}
{"ID": "00120044", "file_name": "A Top-down action game for learning English with Unity", "content": "Game loop The Gameflow chart (Figure 3.1) visually represents the loop of stages players go through while experiencing the game. The gameflow of this project consists of 5 main states.", "label": "human"}
{"ID": "00120045", "file_name": "A Top-down action game for learning English with Unity", "content": "NEW MAPWIN GAMEBATTLE VS ENEMYCOLLECT GOLD UPGRADE Figure 3.1: Player’s skill 1 3.2.3 Game Unit a, Player Player (Figure 3.2) can move and shoot the selected character to destroy the monster, player can also use skills. Player will lose health if touched monsters andFigure 3.2: Playerwill die when out of health point. Player has 3 skills:", "label": "human"}
{"ID": "00120046", "file_name": "A Top-down action game for learning English with Unity", "content": "The first skill (Figure 3.3): Character will summon a sword and slash at the enemy in front, all hit monsters will show their hidden word.", "label": "human"}
{"ID": "00120047", "file_name": "A Top-down action game for learning English with Unity", "content": "The 3rd skill (Figure 3.5): Character will swing his shield in front of him, all monsthit monsters will be knocked back.", "label": "human"}
{"ID": "00120048", "file_name": "A Top-down action game for learning English with Unity", "content": "MonsterMonster (Figure 3.7) will patrol around and will rush at the player when it de tects the player. Monster will die if get shot all hidden character or hit the player.Figure 3.4: Player’s skill 2Figure 3.5: Player’s skill 3Figure 3.6: Player’s skill 4Figure 3.7: Monsterc, House House (Figure 3.8) is the place where buffs are generated, the house can block the player’s bullets. Neither monster nor the player can enter the house.", "label": "human"}
{"ID": "00120049", "file_name": "A Top-down action game for learning English with Unity", "content": "Buff Buffs (Figure 3.11) are appeared around the house, if the player touches a buff, there will be some beneficial effects such as increased health, increased movement speed,...Figure 3.9: WellFigure 3.10: FenceFigure 3.11: Buff3.2.4 Enemy AI The game’s enemy is controlled by the state machine (Figure 3.12). When the monster spawns, it will be in the patrolling state, when it detects a player nearby (monsters will have a longer range to detect the player in front than the player behind) the monster will switch to the chasing state and increase its movement speed while chasing the player. If the monster is hit by the player’s skill 2, it will be put into the stunning state, when the stun time expires, it will go to the patrolling state. If the monster is hit by the player’s skill 3, its state will change to push back state, after being pushed back the monster will switch to the chasing state. When a monster is hit by all weak characters, it will enter the dying state and die. While in dying state monsters cannot be changed to another state.", "label": "human"}
{"ID": "00120050", "file_name": "A Top-down action game for learning English with Unity", "content": "Chasing State Patrolling State Stun State Push Back State Dying StatePlayer close enough Player far enough Any StateGet shot all weak pointsGet hit by player skill 3Get hit by player skill 2 Figure 3.12: Enemy state machine 3.2.5 Vocabulary system The Vietnamese meanings of words in this project have been refined to be ascomprehensive as possible, helping players understand the most important meanings of an English word in Vietnamese. Monsters in each level will contain a ran dom vocabulary in the list of words of that level. Before starting each level, the player can choose to see all the words that can appear in that level and learn it first.", "label": "human"}
{"ID": "00120051", "file_name": "A Top-down action game for learning English with Unity", "content": "This makes it easier for players to win that level and also helps players learn more vocabulary. Once the monster has selected a word from the set, it will mask some random characters. The number of characters to be masked depends on the number of characters in that vocabulary, which will help the game be more balanced and also stimulate the player’s vocabulary memorization.3.2.6 UI Flow The diagram 3.13 shows the transitions between the game’s UI.", "label": "human"}
{"ID": "00120052", "file_name": "A Top-down action game for learning English with Unity", "content": "Start Screen Play Option Screen Popup Setting Popup Quit Highscore Screen Inventory Screen Choose Map Screen Book Screen Loading Screen Gameplay ScreenWin/Lose Screen Figure 3.13: UI flow 3.2.7 A few main UI a, Start screen This is the first screen the player encounters when starting the game. The Start screen (Figure 3.14) has 4 options for the player: Quit, Play option screen, Setting and Tutorial screen.", "label": "human"}
{"ID": "00120053", "file_name": "A Top-down action game for learning English with Unity", "content": "The player can press Play to jump into the main gameplay or press Read to read the words the monsters at this level may contain. The stages the player cannot open will have a lock icon and in these stages, the player cannot interact.", "label": "human"}
{"ID": "00120054", "file_name": "A Top-down action game for learning English with Unity", "content": "Gameplay screenThe gameplay screen (Figure 3.18) is the UI when the player enters the game play. This screen includes the time from the start of the stage in the upper left corner of the screen, the minimap in the lower right corner, the money collected located in the upper right corner, the progress bar at the top, the skill and health bar at the bottom of the screen.Figure 3.16: Inventory screen Figure 3.17: Choose map screenFigure 3.18: Gameplay screen4.1 Test caseSoftware testing is the method of checking whether the software product con forms to the stated requirements, and ensuring that there are no bugs or defects. It includes the examination, analysis, observation and evaluation of various aspects of the product.", "label": "human"}
{"ID": "00120055", "file_name": "A Top-down action game for learning English with Unity", "content": "Control character movement This test case is to test the player’s ability when using the right mouse button for moving the character (Figure 4.1).", "label": "human"}
{"ID": "00120056", "file_name": "A Top-down action game for learning English with Unity", "content": "Control character shoot This test case is to test the player’s ability when using the left mouse button for controlling the character to shoot (Figure 4.2).", "label": "human"}
{"ID": "00120057", "file_name": "A Top-down action game for learning English with Unity", "content": "Cast character skill 1 This test case is to check the character’s ability to use the first skill (Figure 4.3).Figure 4.3: Test case for cast character skill 1 4.1.4 Cast character skill 2This test case is to check the character’s ability to use the second skill (Fig ure 4.4).", "label": "human"}
{"ID": "00120058", "file_name": "A Top-down action game for learning English with Unity", "content": "Cast character skill 3 This test case is to check the character’s ability to use the third skill (Figure 4.5).", "label": "human"}
{"ID": "00120059", "file_name": "A Top-down action game for learning English with Unity", "content": "Cast character skill 4This test case is to check the character’s ability to use the fourth skill (Fig ure 4.6).Figure 4.6: Test case for cast character skill 4 4.1.7 Check character and enemy collision This test case is to check the collision between the character and the enemy (Figure 4.7).", "label": "human"}
{"ID": "00120060", "file_name": "A Top-down action game for learning English with Unity", "content": "Check character die This test case is to check whether the character dies when runs out of health point (Figure 4.8).", "label": "human"}
{"ID": "00120061", "file_name": "A Top-down action game for learning English with Unity", "content": "Check enemy and bullet collision This test case is to check the collision between the character and the enemy (Figure 4.9).", "label": "human"}
{"ID": "00120062", "file_name": "A Top-down action game for learning English with Unity", "content": "The selection of assets in this project encountered some difficulties. The first is that although there are a lot of resources on, it is also very time-consuming to search because you have to try many different asset sets. Next, due to the target audience of the game, the game’s graphics are not required to be too heavy and run smoothly on popular computers. In addition, the assets between the model, UI, and sound must have a good combination to increase the feeling of the player.", "label": "human"}
{"ID": "00120063", "file_name": "A Top-down action game for learning English with Unity", "content": "Solution To choose the right asset, the first thing we need to do is to build a plot for the game. Then all the resources to find will be based on that topic. A few key keywords will be selected and attached to each search order for all different asset types. The next thing is to build a system that must be flexible and modular to make it easy to change assets but still keep the game flow running as it was. This requires some knowledge of object classification and design patterns. In the process of making, small details also need to be paid attention and meticulously completed because this is a very important factor to increase the \"game feel\" for the player. The last thing is to constantly search and change assets until a satisfactory set of assets is found.", "label": "human"}
{"ID": "00120064", "file_name": "A Top-down action game for learning English with Unity", "content": "Scalability a, Problem Since there are many ideas yet to be implemented, the system needs to be able to be easily modified and developed. The initial version of the system may runsmoothly, but further development will result in very large code files and overlap ping game logic.", "label": "human"}
{"ID": "00120065", "file_name": "A Top-down action game for learning English with Unity", "content": "Solution Several designs have been made to keep the system open. The first change is to use a state machine for the enemy, the state machine will help to split a large code file into small independent code files that are easy to track and expand. It also helps to slightly improve performance when not having to check too many conditions in 1 frame. Next is the rational use of Singleton. Singleton is a veryefficient way to access data between classes, but as the system gets bigger, having too many singleton classes will cause the logic to be linked together and lead to changing one logic file which will affect to other files.", "label": "human"}
{"ID": "00120066", "file_name": "A Top-down action game for learning English with Unity", "content": "Performance Game performance is how well a computer can handle and display games and is one of the crucial elements of a game. This project has had good performance when running, but in order to ensure that computers with weaker configurations achieve good performance when executing the game, some changes and solutions need to be made.", "label": "human"}
{"ID": "00120067", "file_name": "A Top-down action game for learning English with Unity", "content": "Problem Since there are many ideas yet to be implemented, the system needs to be able to be easily modified and developed. The initial version of the system may runsmoothly, but further development will result in very large code files and overlap ping game logic.", "label": "human"}
{"ID": "00120068", "file_name": "A Top-down action game for learning English with Unity", "content": "Solution In Unity there are 2 main reasons that can affect game performance, maybe dueto errors in the code or because the graphics are too heavy for the processing ca pabilities of the machine. To improve game performance, the first thing the projectdoes is implement a pooling system. Because the Instantiate() and Destroy() func tions are quite heavy when done in large numbers, it will easily cause lag in weakly configured computers. There are two groups of objects in the game that need to be destroyed and initialized continuously, Enemy and Bullet, so these two groups of objects have been applied with a pooling system to improve performance. Caching is also used a lot to reduce the frequency of using Unity’s get component functions and C#’s garbage collections.", "label": "human"}
{"ID": "00120069", "file_name": "A Top-down action game for learning English with Unity", "content": "The game’s rendering capabilities need to be improved next. The system has implemented a few strategies to decrease the quantity of draw calls sent to the GPU in order to solve this issue. A protracted frame and fps loss will result from an excessive amount of draw calls because each one requires CPU processing time to gather information, so when the number of draw calls is too large, it will lead to a prolonged frame and fps drop. The game used the static batching method - this method will make all meshes that share the same material (shaders, textures, ...) will be able to be pooled into one draw call.5.2 Conclusion and Future WorkThis project is a Top-down action game with purpose to help players learn English while playing. The game has completed essential functions such as control ling the player and using the player’s skills to interact with the enemy, deploying anAI system for the enemy based on the State machine, combining logic and anima tion for the player and enemy to bring smooth and realistic interaction for players,build data saving and loading system. From this system, the project has imple mented other functions such as the upgrade system for the player and the high score system for the player to help the player save the times of all fastest wins.", "label": "human"}
{"ID": "00120070", "file_name": "A Top-down action game for learning English with Unity", "content": "In addition to optimizing game performance, this project has integrated a poolingsystem for spawning monsters and bullets. All user interface (UI) such as Start, In ventory, Rank, etc. have also been completed. However, this project still has some shortcomings. The first is that the game’s graphics and sound system are not good enough to brings emotions to the player. The reason for this is the lack of suitable assets with affordable price. Next, due to the limited game design experience, the UI layout is still basic and lacking in creativity, the map in the game is small, so it is easy to be boring for players. Finally, some initial ideas have not been implemented in the project yet such as custom game mode and difficulty adjustment feature of the game.", "label": "human"}
{"ID": "00120071", "file_name": "A Top-down action game for learning English with Unity", "content": "The first is to add the difficulty of the game, I plan to add other states to the en emy’s state machine so that when the player adjusts the difficulty of the game, in addition to changing the parameters, the enemy will also appear other behaviors corresponds to the difficulty the player chooses. For example, when at a higher difficulty level, the monster may have some additional abilities such as stealth and a more complex movement trajectory to dodge the player’s bullets, .... Next is the custom mode in the game, this mode will help players create their word boards and when starting the gameplay, the monsters will contain words that are the words that the player has created. This mode will help players learn the words they want.", "label": "human"}
{"ID": "00120072", "file_name": "A Top-down action game for learning English with Unity", "content": "Another feature I want to add is to create more maps or the program will have an automatic map creation feature, aiming to prevent players from getting bored when playing the same map over and over again. Finally, it is to improve the graphics and sound of the game to increase the emotions of the players.", "label": "human"}
{"ID": "00120073", "file_name": "A Top-down action game for learning English with Unity", "content": "During the project, I also learned many things. Starting from recognizing theproblems when the scale of the project increases, there have a deeper understand ing and experience in choosing the design pattern that best suits each part of the project. Next is understanding the importance of clean code as well as applyingappropriate data structures and algorithms to optimize performance. I also have more experience in handling the animation and particles in unity in the process of making player skills. Finally, I would like to once again thank my teachers, family and friends for always helping me during the completion of the project, I hope my product will be well received and have positive contributions for society.", "label": "human"}
{"ID": "00130001", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "In recent years, deep learning techniques have demonstrated excellent results and have had considerable success across numerous visual applications. However,in order to obtain accurate outcomes, they frequently require a large amount of la bel data, and the process of data gathering, and annotation can be time-consumingand expensive. For instance, it can take hours to annotate only one image for se mantic segmentation tasks. Because of this, the option to use a model trained onassociated samples from a separate task would be highly helpful. They are espe cially important for semantic segmentation as the learning networks need a lot of manually labeled data that is very hard and expensive to acquire.", "label": "human"}
{"ID": "00130002", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The majority of machine learning models, including neural networks (NNs)commonly assume that training and test samples from the same distribution. How ever, there are several instances in real-world issues when distribution of training and test data are different. When doing inference on a target domain, network may perform less well since they are trained using data from source domain. DomainAdaptation (DA) focuses on agile methodologies that use data from a source domain to produce models with excellent performance on a target domain. In this dis sertation, I focus on unsupervised domain adaptation (UDA) method, which uses labeled samples from source domain and unlabeled samples from target domain.", "label": "human"}
{"ID": "00130003", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "UDA has many potentials with the task required of having a lot of labeled images, which is hard to collect. In this work, we research UDA for Semantic Seg mentation because the task usually requires large datasets of pixel-wise annotation, while synthetic images are available and easy to obtain. To be specified, images of urban scenes from Grand Theft Auto V’s realistically generated computer game are collected and utilized as training domain source data. The project’s ultimate objective is for model M to perform well on the real dataset Cityscapes, which isa dataset of actual urban settings that were photographed in 50 cities around Ger many and its bordering nations. The cityscapes dataset’s labels are inaccessible with the UDA configuration.", "label": "human"}
{"ID": "00130004", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Semantic Segmentation is a computer vision task in which the goal is to cate gorize each pixel in an image into a class or object. The goal is to produce a dense pixel-wise segmentation map of an image, where each pixel is assigned to a specific class or object. In recent years, semantic segmentation has advanced significantlythanks to the development of deep neural networks (DNN). However, because of various environmental changes, networks often suffer from dramatic performance drop when performing inference on testing data. Meanwhile, the process of data annotation is often time-consuming and expensive. Thus, Unsupervised Domain Adaptation (UDA) is a potential approach to deal with such a challenge.", "label": "human"}
{"ID": "00130005", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Because of the domain shift phenomenon between source and target datasets, anintuitive way is to bridge the gap between source and target distributions. Thus, sev eral works using adversarial training-based methods for matching the distribution of these distributions have obtained great success. This is achieved by minimizing a domain adversarial loss to dec both the global discrepancy between sourceand target distributions, while retraining models with source domain by minimiz ing specific losses. Specifically, a domain discriminator is trained to separate thesource samples from the target samples, and the feature network attempts to mis lead the discriminator by producing features that are domain-invariant. However, because trying to align global features distributions, these methods don’t pay muchattention to the underlying structures among classes. The alignment of class conditional distributions is as important as the alignment of global distributions. Al though some recent research tries to solve this issue, there is no guarantee that the target domain’s pixels are well-separated by semantic category.", "label": "human"}
{"ID": "00130006", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Self-training, a recent innovation in the UDA job, has replaced explicitly matching the distributions of the source and target domains as the most prevalent alterna tives. This is accomplished by repeatedly creating a set of pseudo labels, and then using these pseudo labels to retrain the network. The network eventually builds upthe adaptation during the self-paced curriculum learning in this way. The pseudo labels can be generated either on or off. Because of the difference between source and target distributions, the generated pseudo-labels tend to be noisy andneed to be selected carefully. Common practice recommends choosing pseudo la bels based on a stringent confidence threshold, although high scores are not alwaysaccurate, preventing the network from learning trustworthy information in the tar get domain. However, it’s possible that certain pixels won’t ever be learned duringthe entire training process if you just employ solid predictions. For instance, it be comes challenging to accurately assign pseudo labels to the pixels belong to a given class if the model is unable to satisfactorily forecast that class, which may result in inadequate and categorically unbalanced training data.", "label": "human"}
{"ID": "00130007", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "In conclusion, self-learning has received a lot of attention recently, but it has nu merous drawbacks, most notably the omission of explicit domain alignment, which leads to noisy labels. Due to the negative transfer, pixel features from separate do-mains but belonging to the same semantic class may be transferred farther away.", "label": "human"}
{"ID": "00130008", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Additionally, because datasets are frequently have a long tail distribution that favors common classes, unusual classes perform significantly worse than other classes.", "label": "human"}
{"ID": "00130009", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Although off UDA has proven to be crucial when it comes to transferring to new domains, it is incredibly practical to be able to deploy a model and have it automatically adapt to new conditions. Thus, the project’s objective is to developa one-stage adaptation framework that emphasizes the semantic concepts of indi vidual pixels in order to encourage learning of class-discriminative. In addition, our method tries to solve the imbalance problem in the dataset and improve the performance of hard classes, which is very low with previous methods.", "label": "human"}
{"ID": "00130010", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "I propose semantic-guided representation learning in the embedding space toaddress the problem of traditional self-learning neglecting explicit domain align ment, which may result in noise in pseudo labels. The approach is to immediately adopt global category prototypes computed on the source domain to direct thealignment between the source, mixed and target domains. Additionally, I devel oped a novel mixing approach that often pastes pixels from rare classes from the source images to the target images in order to address the imbalance problem in the dataset. As a result, the help model learned more data on these classes and improved their performance.", "label": "human"}
{"ID": "00130011", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "To preserve the underlying structures among classes, I propose using Con trastive Learning by applying constraints on features of different categories.", "label": "human"}
{"ID": "00130012", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Thus, it is expected that the same category will have a high degree of repre sentational similarity across multiple domains.", "label": "human"}
{"ID": "00130013", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "To solve the class imbalance problem in domain adaptation, I propose a novel mixing strategy. The proposed utilizes frequent scores normalized classwise to select pixels and generate mixed images with balanced class distribution.", "label": "human"}
{"ID": "00130014", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The first part of Chapter 2 discusses earlier studies on UDA, contrastive learn ing, and mixing techniques. It lays a strong basis for UDA and explains the key difficulties encountered during self-learning. Chapter 3 presents a novel methodcombining self-learning, contrastive learning, and a mixing strategy. I out keyresults in Chapter 4 and show experiments. The work is summarized, and signifi cant issues are outd in Chapter 5.2.1 Semantic SegmentationSemantic Segmentation is a computer vision task in which the goal is to catego rize each pixel in an image into a class or object. The Intersection over Union (IoU), which has the following definition, is the most widely used metric for assessing amodel’s performance on such tasks. Semantic segmentation has advanced signif icantly with convolution neural networks. FCN  created interest in using deeplearning for this task. Many follow-up methods are proposed to expand the recep tive fields to include more context information. In all of these works, the family ofDeeplab ,  attracts the most attention and is frequently used due to its useful ness and simplicity. These techniques typically require large datasets of pixel-wise annotations, such as Cityscapes and PASCAL VOC.", "label": "human"}
{"ID": "00130015", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Unsupervised Domain Adaptation (UDA), a relatively new area of machine learning, emerged as a result of the increasing amount of data and the limited and expensive resources needed for annotation. Any labels for the target domain data are completely absent in unsupervised domain adaptation (UDA). A model that was trained on data from the source domain must independently adapt to the target domain. Style transfer, feature alignment and self-training are the three main categories of the existing methodologies for UDA of semantic segmentation.", "label": "human"}
{"ID": "00130016", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Early UDA methods generate a domain invariant feature representation by uti lizing the neural network’s early layers. Adversarial learning makes it simple to dothis by reducing the difference in domains between the two domains. To produce domain-invariant features, earlier feature alignment research aims to reduce the difference between the source and target domains. For the first time, Hoffman  included DA into segmentation, considering feature alignment with extra category limitations. The learning of domain-invariant features is proposed to use enormous adversarial learning variations, which may be divided into input, feature, output, or patch space adaptations. To mention a few, segmentation is thought of by Tsai et al.  as organized outputs, where images from many domains exhibit striking semantic similarity. For the discriminator to align features at a finer level, Wang et al.  include class information.", "label": "human"}
{"ID": "00130017", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Other UDA techniques concentrate on transferring the source’s style across to the target domain. These methods try to close the domain gap between the sourceand target domains, by translating the source images to mimic images from the tar get domain. According to Yang and Soatto, the Fourier transform makes it simple to retrieve comparable information. In their Fourier Domain Adaptation (FDA)  method, the low frequencies from the source picture are swapped out for those from the target image after computing the frequency responses of both the source and target images. After that, it practices with the stylised visuals. The FDA technique beats earlier style-based approaches, and when combined with self-supervision adaptation is further improved. CyCADA  was among the earliest methods toadd style directly to the photos. Style and antagonistic domain adaptation are com-bined in the method. The styling procedure uses the adversarial image transla tion model CycleGAN  to translate images from source to target and target to source. The models are trained by a GANs loss using a discriminator, a cycle loss,a semantic consistency loss, and a loss that enforces cycle consistency. The dis criminator’s goal is to distinguish between actual target images and source images that have been styled as targets.", "label": "human"}
{"ID": "00130018", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The UDA problem, however, was attempted to be seen as a semi-supervised work due to the recent success of semi-supervised learning research. The goal of self-training is to gradually increase the number of labelled examples in a dataset by using previously labelled examples to train a classifier, which is then applied to unlabeled instances to predict pseudo-labels. First,  iterative learning approach with class balance and spatial prior in the target domain is suggested. Later, toclose the domain gap, Wang et al.  improve self-training by utilizing the sup plemental supervision from depth estimation. Additionally, ProDA  recently bases on category centroids to produces pseudo labels, in order to achieve higher performance. They all, however, rely on a strong start and a challenging process of fine-tuning.", "label": "human"}
{"ID": "00130019", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Modern state-of-the-art methods , ,  concentrate on building a domain invariant representation using adversarial learning first, followed by self-training.2.2.1 Self supervision Self-training is a strategy to incrementally grow a set of labelled examples bytraining a classifier using existing labelled instances and then using the trained clas sifier to predict pseudo-labels for untouched instances. The current labelled dataset is then supplemented with high confident predictions, increasing the total number of tagged occurrences. Until no further instances of pseudo-labelled data can be located, the process is repeated. The lack of labelled data in the target domain in UDA is directly addressed by self-training. Self-training techniques are a typical semi-supervised learning approach that can improve decision boundary learningfor source and target data. Recent semi-supervised research has demonstrated per formance levels that are nearly identical to those of fully supervised research with only a few numbers of labeled examples. On the other hand, domain adaptationmay considerably improve the model’s accuracy, but it still falls short of super vised performance levels.", "label": "human"}
{"ID": "00130020", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The methodology for pseudo-label approaches may be broken down into two parts: first, creating pseudo-labels from the unlabeled data, and second, fine-tuning the model using these pseudo-labels. Self-training is a potent domain adaptationtechnique that can find a feature space with matching source and target distributions in addition to learning superior decision boundaries. In essence, class wise feature alignment and global closeness of source and target features are bothencouraged by feature learning in self-training that is directed by softmax crossentropy loss. The global and class-wise feature alignment approaches based on ad versarial training have the same objective as the CNN-based self-training methods,but they attempt to address domain adaptation in a more straightforward and ele gant manner. Early approaches were mostly off iterative processes. As a result,these techniques frequently involve several levels of training and are quite time consuming. Recently, some works using on pseudo-label technique because of its less difficult setup with one stage training. For example, DACS  suggests creating a mixed domain by copying picture patches from the source domain to the target domain and using a teacher model to teach a student model. Some works , combine on and off pseudo-label techniques. Although self-learning technique has received much attention and significantly improved the adaptation performance, it is still below the level of supervised performance.", "label": "human"}
{"ID": "00130021", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "If models use incorrect pseudo labels, performance will drop significantly. Someworks design thresholds to generate pseudo labels according to the confidenceFigure 2.4: An illustration of the proposed iterative self-training architecture for unsuper vised domain adaption .", "label": "human"}
{"ID": "00130022", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "scores. Recent works ,  suggested manually setting the threshold for ig noring the low-confidence pseudo labels, it is still difficult in a number of ways.", "label": "human"}
{"ID": "00130023", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "First, it can be challenging to determine the threshold’s value for various target do mains. It depends on how similar the source domain and target domain are, which is difficult to predict beforehand. Second, it can be challenging to determine thethreshold’s value for various categories. As an illustration, the objectives, like traf fic signs, have infrequently been observed in the source domain. The rare category has a relatively low overall confidence score. The information of rare categories may be ignored if the threshold is high. Third, the pixel’s location also affects thethreshold. For instance, the pixel in the middle of an objective, like a car, is typically fairly simple to predict, whereas the pixel on the edge of the objective typi cally faces ambiguous predictions. Thus, it is difficult for the demand to match the fixed threshold. To solve the issues, CBST  suggested dynamic thresholds for each category while  uses an auxiliary loss to determine which pseudo labels may be noisy.  use a Gaussian Mixture Mode (GMM) to fit the predictions to certainty and uncertainty modes, then chooses trustworthy pseudo labels. Pseudo labels are assigned to pixels in the certainty mode.", "label": "human"}
{"ID": "00130024", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Contrastive Learning Contrastive representation learning’s objective is to develop an embedding space where like sample pairs remain nearby while unlike sample pairs are spread away.", "label": "human"}
{"ID": "00130025", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Contrastive learning is typically used as a self-supervised by applying different transformations to the input and anticipating the same outcome and have recentlydemonstrated tremendous promise for representation learning in classification tasks.", "label": "human"}
{"ID": "00130026", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Feature contrast learning (FCL) was firstly introduced, which normalized features before the classifier are used to compute the contrastive loss. In FCL, a pair of features from the same picture that have been transformed differently is seen aspositive and would be driven closer, whereas all feature pairs from different im ages are regarded as negative and are predicted to be pushed away. Contrastive learning also has been recently studied to improve semantic segmentation, with a number of different design strategies. These works ,  aim to distinguish different class features in the feature space while aligning the same class features.", "label": "human"}
{"ID": "00130027", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "In some recent efforts, UDA semantic segmentation incorporates contrastive learning. Through the use of Cutmix between the target domain and the source domain, RCCR  creates several contexts for a portion of the target domain.", "label": "human"}
{"ID": "00130028", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Then, they employ pixel-to-pixel contrastive learning to increase the difference between inter-region pixels and decrease the consistency of pixels inside an area.", "label": "human"}
{"ID": "00130029", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "MixingBoth classification and semantic segmentation have been effectively accom plished using the type of augmentation approach known as mixing. Pixels from two training images are combined to create a new, significantly disturbed sample. As suggested by Zhang et al  in their mixup algorithm, this may be accomplished by interpolating between the pixel values of the two images. Another method is to use a set of pixels from one image and a different set from a different image. The latter technique allows for the quantification of the pixel selection through the use of a binary mask, where the mask is one for pixels chosen from the first image and zero for those chosen from the second. The segmentation maps are mixed similarly for the semantic segmentation scenario.", "label": "human"}
{"ID": "00130030", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Mixing has been successful in SSL for semantic segmentation when applyingstrong augmentations on unlabeled images for consistency regularization. The bi nary mixing technique CutMix , from one image, random rectangular areas are cut off and put onto another. A binary mask the same size as the images is used in this method, which is based on mask-based mixing, to combine two images. The ClassMix algorithm  took this idea a step further by replacing the mask usedfor mixing with one generated dynamically based on network predictions. The aug mentation technique takes half of the predicted classes for a given image and pastes the associated pixels onto a second image to create a significantly affected imagewhere the semantic bounds of objects are always closely followed.", "label": "human"}
{"ID": "00130031", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Although selecting source objects could help to reduce the unbalanced distribu tions of classes, it is not the best option because the network would still be trained to recognize shapes and details specific to the source domain that are different from those found at inference time for the target images. Instead, some works ,  employ fictitious labels to copy and paste elements from the target scenes into the source or target pictures, causing the network to scan both domains for these patterns. It is also necessary to filter out noisy predictions due to the noise that pseudo-labels inherently include.3.1 DACS: a base with teacher-student architectureFirst, I formally introduce the domain adaptive semantic segmentation prob lem. Unsupervised domain adaptive (UDA) semantic segmentation contains two The objective of UDA semantic segmentation is to train a semantic segmentation model Mwith DSandDTso that Mcan accurately predict the class of each pixel in the target domain image. The model M=G◦Eas a combination of a feature extractor Eand a classifier G. We can directly train a segmentation model using the source data to address this issue. The segmentation loss on the source domain can be described as follows given a source image xsand its matching label ys:", "label": "human"}
{"ID": "00130032", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "L(i) j=1CX c=1y(i,j,c) s logp(i,j,c) s where p(i,j) sis predicted probability of pixel x(i,j) s. Because of domain shift problem, performance will drop significantly when deploying on the target dataset.", "label": "human"}
{"ID": "00130033", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "To solve the domain gap problem, several approaches that can be divided into adversarial training and self-training (ST). In this work, I chose DACS  as the base method for the self-training approach. It uses teacher-student architecture, which makes models more stable and pseudo labels less noisy. In addition, because DACS  is a one-stage method, it is easy to set up.", "label": "human"}
{"ID": "00130034", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "ST approaches use a teacher network M′=G′◦E′to create pseudo-labels for the target domain data in order to more effectively transfer knowledge from the source to the target domain.", "label": "human"}
{"ID": "00130035", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "ˆy(i,j,c) t = [c=c′p′(i,j,c′) T] where p′(i,j) Tis predicted probability obtained by teacher M′of pixel x(i,j) Tand[·] denotes the Iverson bracket. Follow DACS strategy, we use the ratio of pixels that q(i) j=1[max c′p′eaxample:", "label": "human"}
{"ID": "00130036", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "We can optimize the cross-entropy loss of the target image xtwith the pseudo label ˆytto make the model more closely match the target data. In order to further enhance the performance of the model on the target domain, we will create a mixed image xmand a mixed label ym. To create the mixed images from the source image and the target image, we specifically create a random mask called Mand use Mas follow:", "label": "human"}
{"ID": "00130037", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The framework includes a student network ( M), a teacher network ( M′), studentand teacher projection head ( HandH′respectively). The teacher-student archi tecture based DACS method , and teacher model’s weights were updated as exponential moving average of student’s weights during training. First, we use a mixing method and create a mixed image xmfrom a source xsand target xtimage.", "label": "human"}
{"ID": "00130038", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The mixing strategy tries to solve imbalance problem by frequently pasting pix els belong rare classes from source to target images. We calculate a cross-entropy lossLsfor supervising the student model with source labels, and a consistencylossLmbetween the mixed prediction pmand the mixed label ˆym. Second, we em ploy global category prototypes to direct the alignment of the source and target domains. We obtain source embedding, mixed embedding and target embedding features by passing source images ( xs), mixed images ( xm) and target images ( xt) through student projection head, respectively . Given these embedding features, weFigure 3.1: Architecture of the proposed method.", "label": "human"}
{"ID": "00130039", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "perform contrastive learning by maximizing similarity between features and proto types having same category. Similarly, we also perform contrastive learning in the label space, the output of the classifier. To update prototypes, we use embedding features which were extracted by passing source images and target images through teacher projection head H′.", "label": "human"}
{"ID": "00130040", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Traditional self-training ,  techniques have an important weakness: the majority of them ignore explicit domain alignment. Due to the negative transfer, pixel features from distinct domains but belonging to the same semantic class may be transferred farther away even when target samples have perfect pseudo-labeling.", "label": "human"}
{"ID": "00130041", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "In addition, the target domain features are not sufficiently discriminative sincethere are no explicit supervision signals in the target domain data. Because con trastive learning ,  can increase the distinguishability of unlabeled data, we use it to solve these problems. The plan is to use global category prototypes effectively to guide the alignment of source and target domains . I create a multi-level contrastive learning loss in particular to explicit domain alignment andenhance feature distinguishability from both prototype-level and pixel-level data.Prototypes Initialization . The initialized class-aware prototypes can be com puted as pfeat c=PnS j=1F′ s(i,j)[y(i,j) s=c] PnS j=1[y(i,j) s=c] where source feature F′ s(i,j)from the teacher model of pixel y(i,j) s. Prototypes could be interpreted as the approximately correct representational centroid for multiple categories.", "label": "human"}
{"ID": "00130042", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Contrast Adaptation . Images from the source and target domains xs, xt∈ student network. We compute the similarity between source features and each of prototypes. Each pixel has a vector P(i,j) s→p= [P(i,j,1) s→p, P(i,j,2) s→p, ..., P(i,j,C ) s→p]representing similarity scores between its feature and prototypes:", "label": "human"}
{"ID": "00130043", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "P(i,j,c) s→p=exp(pfeat c·F(i,j) PC c′=1exp(pfeat c′·F(i,j) The purpose of this objective is to enforce the requirement that pixels from the same category have a high degree of representational similarity. We employ source contrastive loss Ls L(i) j=1CX c=1yslogP(i,j,c) s→p In order to perform domain alignment, we also need to apply contrastive loss with target and mixed images. Because mixed images contain the information of the source domain and the target domain, perform the loss on its much valuable.", "label": "human"}
{"ID": "00130044", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "But we need create pseudo labels for target images due to the lack of labels, I suggest two ways to generate pseudo labels. One way is only using pseudo labels with high confidence scores.", "label": "human"}
{"ID": "00130045", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "˜y(i,j,c) t =( 1,ifc=c′p′ T(i,j,c′)andp′ 0,otherwise L(i) j=1CX c=1˜ytlogP(i,j,c) t→p The another, we use all pseudo labels created by maxing confidence score each pixel. But, we multiple contrastive loss with qscore, which is the ratio of pixels thatexceed a certain threshold of the maximum softmax probability to adapt gradually during training. At the beginning, qis usually small and increases slowly when model becomes better.", "label": "human"}
{"ID": "00130046", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "L(i) j=1CX c=1q(i) TˆytlogP(i,j,c) t→p ˆy(i,j,c) t = [c=c′p′ T(i,j,c′)] q(i) j=1[max c′p′ The contrastive loss L(i) m→pon a mixed image x(i) mwas calculated similarly. The final contrastive loss on feature level for pixel prototypes is LCFeat=nsX i=1L(i) s→p+ntX i=1L(i) t→p+nmX i=1L(i) m→p Update Prototypes . During training, prototype calculation requires a lot of computing power. In addition, when initializing prototypes, source features areonly involved in computing, so in order to improve the domain-invariant represen tational capability of prototypes, I suggest two prototype update strategies together with training to incorporate target-related information into prototypes.", "label": "human"}
{"ID": "00130047", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "When updating prototypes, I use only features of pixels on target images with a high confidence score to ensure prototypes represent the correct centroids as much as possible. Specifically, I generate pseudo labels to update prototypes as:", "label": "human"}
{"ID": "00130048", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "˜pfeats c =P˜ns j=1F′(i,j) s[y(i,j) s=c] P˜ns j=1[y(i,j) s=c] ˜pfeatt c =P˜nt j=1F′(i,j) t[˜y(i,j) t=c] P˜nt j=1[˜y(i,j) t=c]where feature F′(i,j)from the teacher model of pixel x(i,j),˜nsand ˜ntis number of images on a batch. To be simply, ˜pfeat crepresents the category cestimated online prototypes ˜pfeatc cand˜pfeatt c.", "label": "human"}
{"ID": "00130049", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "pfeat c←−pfeat cnfeat c+ ˜pfeat c˜nfeat c nfeat c+ ˜nfeat c where nfeat crepresents the total number of category c-related pixels since the last update, ˜nfeatcrepresents the total number of category cpixels from a training mini batch that was just added.", "label": "human"}
{"ID": "00130050", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The other way is estimating the prototypes as the moving average of the pro totypes in mini-batches, to track the slowly moving prototypes. The prototype is estimated to be in each iteration as:", "label": "human"}
{"ID": "00130051", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "pfeat c←−mpfeat c+ (1−m)˜pfeat c where mis a hyper-parameter, which specifies an ongoing update rate for the source and target prototypes while training Label Space Adaptation It is not enough to increase the discriminativeness of features in domain adaptation tasks; we also need to reduce the gap betweenfeatures and classifier weights. In accordance with PCL , we compute the con trastive loss using the probabilities rather than the features. Thus, we might use the suggested prototype contrast adaptation in the label space. The primary distinction is that now the number of categories, not the hidden channels in the feature space,determines the size of prototypes. Apart from this, prototypes initialization, con trast adaptation and update prototypes are the same. The overall losses for contrast adaptation is:", "label": "human"}
{"ID": "00130052", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "There is a significant class imbalance in the semantic segmentation datasets, as illustrated in Figure 3.2. For example, \"traffic light\" and \"sign\" have extremely few pixels, whereas \"motorcycle\" and \"train\" are classes that only appear in a small number of photographs. Especially for those long-tailed classes, such a problemwill make it challenging to train a segmentation model. A navie way is to in crease pixels belong rare classes. According this, I proposed a novel Copy-Paste resampling strategy. The main concept is to repeatedly copy pixels from uncom-Figure 3.2: The class distribution of the Cityscapes dataset .", "label": "human"}
{"ID": "00130053", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Class-balance Sampling . In order to select pixels from rare classes, we must first determine which images include those pixels. First, we need to determine which classes are rare based the frequency fcof each class cin the source dataset.", "label": "human"}
{"ID": "00130054", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "fc=Pns j=1[y(i,j) s=c] ns·H·WAccording DAFormer , based on the frequency fcof a certain class cthe sam pling probability P(c)of that class is calculated as follow:", "label": "human"}
{"ID": "00130055", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "The distribution’s smoothness is determined by the temperature T. A lower Tre sults in a heavier emphasis on rare classes with a small fcand a higher Tin a more uniform distribution. Therefore, with reasonable T, we have balanced class distribution in a batch.", "label": "human"}
{"ID": "00130056", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Rare classes Mixing . Large domain gaps, or significant discrepancies in datadistributions, are a typical cause of UDA difficulties and result in false pseudo labels. One of the problems is a target domain bias toward initially transferableclasses that are easy to combine, which results in some classes never being pre-dicted. To solve the problem, DACS  add new data through cross-domain mix ing, and because the labels for these new images partially come from the source domain, they won’t be for conflated all of the images. Additionally, the pixels that have ground-truth labels (source-domain labels) and those that have pseudo-labels(target-domain labels) may now be neighbors in an image, making the implicit dis tinction of domains unlikely. However, while recent mixing techniques assist thenetwork in more successfully bridging the domain gap and resolving the class con flation issue, it is hard to prevent network bias toward common classes. I proposed two novel mixing strategies that focus on solving the conflation problem. The core idea is to frequently paste uncommon classes from source images to target images.", "label": "human"}
{"ID": "00130057", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "RClassMix . One way is based on ClassMix , instead of selecting half of the classes in a source domain image randomly, we select classes according fc calculating before. Thus, the corresponding pixels are cut out and pasted onto an image from the target domain. As a result, classes with a lower frequency will have a larger chance of pasting. Specifically, a labeled images xAare sampled from source dataset based on Class-balanced Sampling and an unlabeled images xBare sampled from target data. A binary mask Mis generated by selecting half of the classes present in images xAaccording probability function fc, and the pixels from those classes are set to have value 1 in M, while all other pixels are set to value 0. The augmented image xmis created by combining images xAandxBusing this mask.", "label": "human"}
{"ID": "00130058", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "RCutMix . Another method is based on CutMix , which randomly cutting and pasting a region from the target image onto the source image. In our method, we cut a region so that more pixels belong to class cthan 50% of the total number of pixels belong to class cin the source image. Formally, we randomly select class cwith probability function fcand then choose a image xAcontain this class. Wesample the bounding box coordinates B= (rx, ry, rw, rh)indicating the cropping regions on xA. The region needs to satisfy the condition:", "label": "human"}
{"ID": "00130059", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "rw−1X i=0rh−1X j=0[y(rx+i,ry+j) i=0H−1X j=0[y(i,j) A=c] where yAis the ground-truth label of the image xA,[·]denotes the Iverson bracket, WandHare the width and height of image xA, respectively. A binary mask M was generated by assigning 1 to pixels in the region; the others were set to 0.", "label": "human"}
{"ID": "00130060", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "L=Ls+Lm+LC By optimizing the equation, clusters of pixels belonging to the same category aresimultaneously pushed away from other categories and pulled together in the fea ture space, creating a discriminative embedding space. Thus, our approach canconcurrently improve intra-class compactness and inter-class separability in a uni fied framework while minimizing the gap across domains. While this is goingon, it helps with the creation of trustworthy pseudo-labels, which helps with self training.Algorithm 1: MCLDA algorithm Input: Input data xs, ys, xt, maximum/ warm-up iteration L/L m.", "label": "human"}
{"ID": "00130061", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "c=1 ifiter < L m.then end else end end .4.1 Experimental Setups 4.1.1 Datasets Cityscapes is a dataset of actual urban settings that were photographed in 50 cities around Germany and its bordering nations. The resolution is 2048 x 1024, and there are 2,975 training images, 500 validation images, and 1,525 test images in all. Each of these photographs has been meticulously annotated with pixel-level semantic labels, and each pixel is separated into 19 different categories. Since the test set of the synthetic-to-real adaptation does not contain ground truth labeling, evaluations of the validation set are performed.", "label": "human"}
{"ID": "00130062", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "GTAV is a composite picture collection that shares 19 semantic categories with Cityscapes. Grand Theft Auto V’s physically rendered computer game has 24,966 urban scene photos that are retrieved and used as training domain source data.", "label": "human"}
{"ID": "00130063", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Evaluation Protocols The Intersection over Union (IoU), which has the following definition, is the most widely used metric for assessing a model’s performance on such tasks:", "label": "human"}
{"ID": "00130064", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "IOU =TP TP+FP+FN where TP,FPandFNare the number of true positive, false positive and false negative predictions of the model respectively. After calculating IoU for 19 classes, we compute the mean IoU of all these classes (mIoU).", "label": "human"}
{"ID": "00130065", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "the segmentation head, which exports the prediction, and the feature extractor, which offers a feature representation. ResNet101-DeepLabv2 is typically used as afeature extractor segmentation head pair, or a variation of it, in segmentation adap tation techniques. The more cutting-edge DeepLabv3+ head is used in very fewnew methods. The ResNet50-DeepLabv2 was chosen to use a somewhat less com plex model (ResNet50) to speed up training. All models are pre-trained on COCOdataset. In the training phase, I chose RestNet101 as a feature extractor head. Af ter the final encoder layer, Atrous Spatial Pyramid Pooling (ASPP) is added withdilation rates of [6,12,18,24]. The projection head His constructed by two succes sive convolutions (2048 hidden layer channels and 128 output channels) with oneintermediate ReLU layer.", "label": "human"}
{"ID": "00130066", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Training details . The method is implemented with the PyTorch library on NVIDIA GeForce RTX 4090. We utilize the stochastic gradient descent as our optimizer to train the segmentation network, where the momentum is 0.9and the weight decay is10−4. We use polynomial learning rate scheduling with a power of 0.9, with the iterations.", "label": "human"}
{"ID": "00130067", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Testing . At the test step, we resize the validation photos to 1024 x 512 for the input image. The teacher’s network M′and projection head Hare all immediately eliminated from the basic segmentation model, with no additional inference step added. We use per-class intersection-over-union (IoU), a widely used evaluation metric in semantic segmentation, as well as mean IoU across all classes.", "label": "human"}
{"ID": "00130068", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "First, to verify the effectiveness of mixing strategies, we sequentially perform them with the base model DACS. With the RCutMix method, we cut a region on source images, which have an area equal to 40 %the area of an image. Then, we conduct some investigations to check the success of 2 ways to update prototypes:", "label": "human"}
{"ID": "00130069", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "ema update and averaging update, 2 ways to use pseudo labels: Use all pseudo labels and only use confident pseudo labels. Later, we want to see how mixingstrategies improve MCLDA by combining the mixing methods with MCLDA us ing only confident pseudo labels, which has a confidence score greater than 0.9, tocompute Lcand update prototypes. Finally, we conduct ablation studies to deter prototypes was set 0.9999. Pixel contrast starts from Lm(default 3k) iteration.", "label": "human"}
{"ID": "00130070", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Results on GTAV to CityscapesThe table 4.1 illustrates our results, and for all of our comparisons, we have cho sen to include their best performance. In the table, DACS (with ClassMix mixing method) serves as our base, and RCutMix and RClassMix refer to the results of our proposed mixing strategies.", "label": "human"}
{"ID": "00130071", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "RClassMix . The table 4.1 demonstrates how our RClassMix outperforms DACSby a small margin (+0.02 %mIoU from 52.32 %to 52.34 %mIoU). Specifi cally, performance of the mortocycle and bicycle classes rise considerably (14.42Figure 4.1: Class sampling probability P(c)withT= 0.01 Figure 4.2: Confusion Matrix of RClassMix strategyMixing methodRoad S.Walk Build. Wall Fence Pole T. Light T. Sign Veget. Terrain Sky Person Rider Car Truck Bus Train M.Bike Bike mIoU ClassMix 92.09 44.17 87.54 29.37 35.73 38.94 44.67 53.43 87.88 42.55 89.6 67.34 38.95 88.33 52.33 51.02 0 14.42 35.79 52.32 RCutMix 93.30 57.34 86.3 31.47 29.26 32.56 43.90 52.06 82.62 26.15 88.86 66.07 43.05 88.39 59.63 51.89 5.38 44.98 57.63 54.78 RClassMix 88.84 35.43 86.68 37.74 34.75 33.15 42.05 50.76 89.19 35.61 89.08 65.18 37.91 86.79 59.59 54.87 0.25 28.38 41.12 52.34 RCutMix + RClassMix 93.68 58.56 86.74 32.96 34.29 33.74 42.79 53.96 86.3 43.34 88.36 66.57 41.72 88.73 56.83 52.02 0.27 31.85 52.86 55.03 Table 4.1: Comparison results with different mixing strategies from GTAV to Cityscapes.", "label": "human"}
{"ID": "00130072", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "rarely pasted from source to target images. The difference between the two methodsis that RClassMix selects classes with a probability P(c)while DACS randomly se lects half of the classes in the source images. The blue bars of Fig. 4.1 show that more pixels of the source images belong to the unusual classes are chosen and also pixels belong to common classes (road, sidewalk) are almost never selected with an extremely small probability. This led to confusion between road and sidewalk classes because of the lack of supervision signals on mixed images.", "label": "human"}
{"ID": "00130073", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "RCutMix . Table 4.1 demonstrates that when compared to the approach DACS, RCutMix provides notable gains for the majority of classes. The sidewalk, rider, train, bicycle, and motorcycle classes benefit from RCutMix the most. In particular, the performance of the train class increased by 5.38 %IoU, while other methods frequently only saw a 0 %IoU. We also see that performance of the mortocycle and bicycle classes rise considerably (14.42 %to 44.98 %IoU, 35.79 %to 57.63 %IoU, resspectively). This demonstrates how RCutMix greatly benefits some rare classes. In a few particular cases, the performance of single classes decreases such as fence, terrain. These are rare classes, probably because the RCutMix mixing play a smaller role for them. As a result, we think that when compared to DACS mixing, our RCutMix method has made some advancements. RCutMix focuses on context rather than just pasting a group of pixels from the same class to the target domain image and only using their inherent qualities. The source and target images frequently have semantic contexts that are similar, such as a rider over a bike or motorcycle or a sidewalk next to a road. Due to the frequent appearance of riders on motorcycles and bicycles, and RCutMix’s ability to preserve these characteristics on mixed images, so performance of these classes significantly increases. Howver, some classes, such as terrain and fence, must maintain their shape rather than theenvironment surrounding them, and RCutMix becomes worse with these classes.Figure 4.3: Cityscapes feature space visualization using UMAP before to the categoriza tion layer. RClassMix (above) and RCutMix (under) 4.3.2 Feature visualizationWe use UMAP to show the target feature representations prior to the final clas sification layer on the GTA →Cityscapes benchmark of some classes in order to more clearly understand the underlying principles of the proposed strategy. In RClassMix, the feature representation within each class is more compressed thanin RCutMix because greater emphasis is placed on the object’s inherent proper ties. However, there is a significant amount of overlap between the motorcycle and bicycle representations in RClassMix. The model trained on RCutMix tends toemploy contextual information to distinguish between classes that are often con fused, leading to representations of ’motorcycle’ and ’bicycle’ that are more easily distinguishable. Additionally, class ’rider’ is distinct from class ’person’ because it frequently appears with classes ’motorcycle’ and ’bicycle’. In addition, modelsare difficult to categorize because of the extreme overlap between features of the classes \"train\" and \"bus\" in two techniques. This implies that there are still hard to solve the ’train’ class problem.", "label": "human"}
{"ID": "00130074", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Combination of RCutMix and RClassMix methodWe want to integrate RCutMix and RClassMix because they both have advan tages. Specifically, We randomly choose one of two methods to perform the mixing procedure with the source and target images. The table show that two strategies promote each other. The performance outperforms two methods elements (55.03 %mIou compared with 54.78 %mIoU and 52.34 %mIoU). Both RCutMix and RClassMix methods have their own advantages and drawbacks. While RClassMix performs poorly with classes (train, bus, motorcycle, bicycle) that must be placed in a specific context in order to avoid misunderstanding, and RCutMix performs poorly with classes that must be pasted completely from source images to target images, the Combination of RCutMix and RClassMix method solve all problems which two methods elements faced.", "label": "human"}
{"ID": "00130075", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Results on GTAV to Cityscapes Pseudo labels Update prototypesmIoUOnly Confident pseudo labelsAll generated pseudo labelsEMA Averaging ✓ ✓ 53.44 ✓ ✓ 53.62 ✓ ✓ 53.20 Table 4.2: Comparison of different methods for updating prototypes and choosing pseudo labels.", "label": "human"}
{"ID": "00130076", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "In Chapter 3, we proposed two different formulas to update prototypes: usingthe computation of the strict statistical mean of all data, or estimating as the mov ing average of the prototypes in mini-batches. Table 4.2 demonstrates that EMAmethod outperform averaging all data to update prototypes(53.62 %mIoU compared with 53.44 %mIoU). This might be due to the model being frequently unadaptable at the start of the training period. Features in the start are therefore worth less when the model improves because they prevent the construction of accurate prototypes. While estimating prototypes as the moving average of the prototypes in mini-batches gives more attention to latest features, which is more value than features at the beginning. In addition, Table 4.2 shows that utilizing just confident pseudo labels outperforms using all produced pseudo labels (53.62 %mIoU com-pared with 53.20 %mIoU). Thus, only confident pseudo labels should be used to compute contrastive loss and protect a model from noisy labels,4.4.2 Combination of Multi-Level Contrastive Adaptation with Mixing strate gies UDA Method Contrastive loss RClassMix RCutMix mIoU DACS✓ 52.32 ✓ 54.78 ✓ ✓ 55.03 MCLDA✓ ✓ 52.83 ✓ ✓ 53.55 ✓ ✓ ✓ 56.76 Table 4.3: Combination of mixing and multi-level contrastive adaptation techniques.", "label": "human"}
{"ID": "00130077", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "By integrating mixing techniques with MCLDA and employing only confident pseudo labels with a confidence score larger than 0.9 to compute Lcand update prototypes, we aim to examine how mixing strategies enhance MCLDA. Table 1 shows that using our technique with the RClassMix strategy slightly improves performance (52.32 %to 52.34 %), however using the RCutmix strategy causesa performance dec (54.78 %to 53.55 %). Specially, we achieve the best per formance (56.76 %mIoU) when integrate both RCutMix and RClassMix with our method MCLDA.", "label": "human"}
{"ID": "00130078", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Feature level and Multi-Level Contrastive Adaptation Comparison UDA Method Feature level Multi-level mIoU DACS 52.32 MCLDA (RCutMix+RClassMix) ✓ 55.91 MCLDA (RCutMix+RClassMix) ✓ 56.76 Table 4.4: Comparison of Contrastive Adaptation at the Feature Level and Multiple Levels.", "label": "human"}
{"ID": "00130079", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "and it is 56.76 %, proving the superiority of multi-level adaptation. In addition to minimizing the effects of overfitting to the source domain, multi-level contrastiveadaptation additionally exploits and leverages multi-granular pixel-wise correla tions. Both of the multi-level adaptations help mitigate the domain shift since they are mutually supportive of one another.4.4.4 Visualization of Feature Space Figure 4.4: Visualization of features extracted with DACS (left) and MCLDA (right)On the GTA →Cityscapes benchmark of all classes, we employ UMAP to dis play the target feature representations prior to the final classification layer. From the UMAP analysis, the DACS alignment methods could yield separated features,but since the boundaries between various category features are not clear, dense pre diction may be challenging. Features from several categories may be more clearlydistinguished when we use multi-level contrastive adaptation, proving that the se mantic prototypes can effectively supervise the target data. When compared to DACS method, the embedded representations of our MCLDA show the clearestclusters, demonstrating the discriminative capabilities of the contrastive adapta tion.5.1 SummaryIn this work, I propose a novel one-stage adaptation framework called Multi level Contrastive Learning for Domain Adaptive Semantic Segmentation (MCLDA),which emphasizes the semantic concepts of individual pixels to promote learn ing of class-discriminative and ultimately enhance the performance of self-training methods. The technique begins by generating a pixel-wise contrastive loss while considering advantage of the connections between pixel-wise representations from the two domains. In essence, pixel representations from the same category should cluster together, and pixel representations from other categories should disperse.", "label": "human"}
{"ID": "00130080", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Prototypes at the output level are also used, in addition to feature-level adaptation, to improve the performance of adaptation. In this thesis, we describe two methods for updating prototypes as well as two techniques for computing contrastive loss utilizing produced pseudo labels. Additionally, I suggest a unique mixing techniquethat overcomes the issue of dataset imbalance. Instead of copying and pasting pix els at random as in the previous technique, our method chooses locations wherethere are pixels from uncommon classes. Furthermore, because the model has ac cess to more information about difficult classes, their performance has improved significantly. However, the performance of class \"train\" is still poor, suggesting that adding more information to the class is not a good way to solve the issue. J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in Proceedings of the IEEE conference on computer vision and pattern recognition , 2015, pp. 3431–3440.", "label": "human"}
{"ID": "00130081", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, “Se mantic image segmentation with deep convolutional nets and fully connected crfs,” arXiv preprint arXiv:1412.7062 , 2014.", "label": "human"}
{"ID": "00130082", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam, “Rethinking atrous convolution for semantic image segmentation,” arXiv preprint arXiv:1706.05587 , 2017.", "label": "human"}
{"ID": "00130083", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "J. Hoffman, D. Wang, F. Yu, and T. Darrell, “Fcns in the wild: Pixel-level ad versarial and constraint-based adaptation,” arXiv preprint arXiv:1612.02649 , 2016.", "label": "human"}
{"ID": "00130084", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Y.-H. Tsai, K. Sohn, S. Schulter, and M. Chandraker, “Domain adaptationfor structured output via discriminative patch representations,” in Proceed ings of the IEEE/CVF International Conference on Computer Vision , 2019, pp. 1456–1465.", "label": "human"}
{"ID": "00130085", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "H. Wang, T. Shen, W. Zhang, L.-Y. Duan, and T. Mei, “Classes matter: A fine-grained adversarial approach to cross-domain semantic segmentation,” inEuropean conference on computer vision , Springer, 2020, pp. 642–659.", "label": "human"}
{"ID": "00130086", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Y. Ganin, E. Ustinova, H. Ajakan, et al. , “Domain-adversarial training of neural networks,” The journal of machine learning research , vol. 17, no. 1, pp. 2096–2030, 2016.", "label": "human"}
{"ID": "00130087", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Y. Yang and S. Soatto, “Fda: Fourier domain adaptation for semantic seg mentation,” in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2020, pp. 4085–4095.", "label": "human"}
{"ID": "00130088", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "J. Hoffman, E. Tzeng, T. Park, et al., “Cycada: Cycle-consistent adversarial domain adaptation,” in International conference on machine learning , Pmlr, 2018, pp. 1989–1998.", "label": "human"}
{"ID": "00130089", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, “Unpaired image-to-image trans lation using cycle-consistent adversarial networks,” in Proceedings of the IEEE international conference on computer vision , 2017, pp. 2223–2232.", "label": "human"}
{"ID": "00130090", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Y. Zou, Z. Yu, B. Kumar, and J. Wang, “Unsupervised domain adaptation for semantic segmentation via class-balanced self-training,” in Proceedings of the European conference on computer vision (ECCV) , 2018, pp. 289–305. Q. Wang, D. Dai, L. Hoyer, L. Van Gool, and O. Fink, “Domain adaptivesemantic segmentation with self-supervised depth estimation,” in Proceed ings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. 8515–8525.", "label": "human"}
{"ID": "00130091", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "P. Zhang, B. Zhang, T. Zhang, D. Chen, Y. Wang, and F. Wen, “Prototypical pseudo label denoising and target structure learning for domain adap tive semantic segmentation,” in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 12 414–12 424.", "label": "human"}
{"ID": "00130092", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Y. Wang, J. Peng, and Z. Zhang, “Uncertainty-aware pseudo label refinery for domain adaptive semantic segmentation,” in Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. 9092–9101.", "label": "human"}
{"ID": "00130093", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Y. Lu, Y. Luo, L. Zhang, Z. Li, Y. Yang, and J. Xiao, “Bidirectional self training with multiple anisotropic prototypes for domain adaptive semantic segmentation,” in Proceedings of the 30th ACM International Conference on Multimedia , 2022, pp. 1405–1415.", "label": "human"}
{"ID": "00130094", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "W. Tranheden, V. Olsson, J. Pinto, and L. Svensson, “Dacs: Domain adap tation via cross-domain mixed sampling,” 2021 IEEE Winter Conference on Applications of Computer Vision (WACV) , pp. 1378–1388, 2020. [On].", "label": "human"}
{"ID": "00130095", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "B. Xie, M. Li, and S. Li, “Spcl: A new framework for domain adaptive semantic segmentation via semantic prototype-based contrastive learning,” arXiv preprint arXiv:2111.12358 , 2021.", "label": "human"}
{"ID": "00130096", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Z. Zheng and Y. Yang, “Rectifying pseudo label learning via uncertainty es timation for domain adaptive semantic segmentation,” International Journal of Computer Vision , vol. 129, no. 4, pp. 1106–1120, 2021.", "label": "human"}
{"ID": "00130097", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "T. Pissas, C. S. Ravasio, L. D. Cruz, and C. Bergeles, “Multi-scale and crossscale contrastive learning for semantic segmentation,” in European Confer ence on Computer Vision , Springer, 2022, pp. 413–429.", "label": "human"}
{"ID": "00130098", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "X. Zhao, R. Vemulapalli, P. A. Mansfield, et al. , “Contrastive learning forlabel efficient semantic segmentation,” in Proceedings of the IEEE/CVF In ternational Conference on Computer Vision , 2021, pp. 10 623–10 633.", "label": "human"}
{"ID": "00130099", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Q. Zhou, C. Zhuang, R. Yi, X. Lu, and L. Ma, “Domain adaptive semantic segmentation via regional contrastive consistency regularization,” in 2022IEEE International Conference on Multimedia and Expo (ICME) , IEEE, 2022, pp. 01–06.", "label": "human"}
{"ID": "00130100", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, “Mixup: Beyond empirical risk minimization,” arXiv preprint arXiv:1710.09412 , 2017.", "label": "human"}
{"ID": "00130101", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "S. Yun, D. Han, S. J. Oh, S. Chun, J. Choe, and Y. Yoo, “Cutmix: Reg ularization strategy to train strong classifiers with localizable features,” in Proceedings of the IEEE/CVF international conference on computer vision , 2019, pp. 6023–6032.", "label": "human"}
{"ID": "00130102", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "V. Olsson, W. Tranheden, J. Pinto, and L. Svensson, “Classmix: Segmentation based data augmentation for semi-supervised learning,” in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision , 2021, pp. 1369–1378.", "label": "human"}
{"ID": "00130103", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "A. Cardace, P. Z. Ramirez, S. Salti, and L. Di Stefano, “Shallow features guide unsupervised domain adaptation for semantic segmentation at classboundaries,” in Proceedings of the IEEE/CVF Winter Conference on Appli cations of Computer Vision , 2022, pp. 1160–1170.", "label": "human"}
{"ID": "00130104", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "J. Li, Z. Wang, Y. Gao, and X. Hu, “Exploring high-quality target domain information for unsupervised domain adaptive semantic segmentation,” in Pro ceedings of the 30th ACM International Conference on Multimedia , 2022, pp. 5237–5245.", "label": "human"}
{"ID": "00130105", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "Z. Jiang, Y. Li, C. Yang, et al., “Prototypical contrast adaptation for domainadaptive semantic segmentation,” in European Conference on Computer Vi sion, Springer, 2022, pp. 36–54.", "label": "human"}
{"ID": "00130106", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "J. Li, Y. Zhang, Z. Wang, and K. Tu, “Probabilistic contrastive learning for domain adaptation,” arXiv preprint arXiv:2111.06021 , 2021.", "label": "human"}
{"ID": "00130107", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "R. Li, S. Li, C. He, Y. Zhang, X. Jia, and L. Zhang, “Class-balanced pixellevel self-labeling for domain adaptive semantic segmentation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni tion, 2022, pp. 11 593–11 603.", "label": "human"}
{"ID": "00130108", "file_name": "MCLDA: Multi-level Contrastive Learning for Domain Adaptive Semantic Segmentation", "content": "L. Hoyer, D. Dai, and L. Van Gool, “Daformer: Improving network architec tures and training strategies for domain-adaptive semantic segmentation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2022, pp. 9924–9935.", "label": "human"}
{"ID": "00140001", "file_name": "Design a system to manage and support sales of technology products", "content": "In today’s technology-driven world, the sales and management of technology products have become increasingly crucial. The lack of a robust on presence for many traditional retail stores poses a significant challenge, hindering their ability to effectively promote their products and reach a broader customer base. This creates a pressing need for a specialized system designed to manage and support the sales of technology products.", "label": "human"}
{"ID": "00140002", "file_name": "Design a system to manage and support sales of technology products", "content": "By addressing this issue, businesses can unlock numerous benefits. Firstly, adedicated system will enable retailers to establish a strong on presence, allowing them to showcase their complete product range and enhance their brand iden tity. This increased visibility can lead to higher sales, expanded market reach, and improved business growth.", "label": "human"}
{"ID": "00140003", "file_name": "Design a system to manage and support sales of technology products", "content": "Moreover, an integrated sales management system will facilitate accurate inven tory management, ensuring real-time updates on product availability. This reduces the risk of overselling or stockouts, streams the sales process, and ultimately enhances customer satisfaction.", "label": "human"}
{"ID": "00140004", "file_name": "Design a system to manage and support sales of technology products", "content": "The objective of the project is to develop a sales process management system for a technology retail store. The system is designed to provide features for both buyers and sellers, ensuring an efficient purchasing process.", "label": "human"}
{"ID": "00140005", "file_name": "Design a system to manage and support sales of technology products", "content": "For buyers, the system aims to provide a user-friendly shopping interface, enabling users to easily search for products and access product information. Along side this, ordering and purchasing functions are implemented, complemented by pages that facilitate tracking of their own orders.", "label": "human"}
{"ID": "00140006", "file_name": "Design a system to manage and support sales of technology products", "content": "For sellers, the system offers an interface designed to assist administrators inmonitoring store sales performance, managing inventory, and tracking placed orders. Additionally, it encompasses functions related to customer management, enabling sellers to access customer information and deactivate accounts when neces sary.", "label": "human"}
{"ID": "00140007", "file_name": "Design a system to manage and support sales of technology products", "content": "To accomplish the objectives set forth in section 1.2, this thesis involves con structing a responsive website that fulfills functional requirements for inventory management, order tracking, and provides a user-friendly interface for seamlessshopping experiences.", "label": "human"}
{"ID": "00140008", "file_name": "Design a system to manage and support sales of technology products", "content": "Using Angular to build the user interface. Angular utilizes the MVC (Model View-Controller) pattern, which helps to clearly separate the application logic anduser interface. It is written in TypeScript, a clear and understandable program ming language that provides static typing, clear definition, and compile-time error checking.", "label": "human"}
{"ID": "00140009", "file_name": "Design a system to manage and support sales of technology products", "content": "Using ExpressJS to build the backend API. ExpressJS is a web framework for Node.js with strengths such as fast processing speed, flexibility, and ease of use. ExpressJS provides powerful middleware for handling requests and responses, allowing the development of both simple and complex web applications.", "label": "human"}
{"ID": "00140010", "file_name": "Design a system to manage and support sales of technology products", "content": "Using MongoDB as the database. MongoDB is a non-relational (NoSQL) database management system that has many advantages. It offers flexible data structures and integrates well with programming languages such as Java, Python, and Node.js. It also provides flexible query support, allowing complex queries and flexible data searches.", "label": "human"}
{"ID": "00140011", "file_name": "Design a system to manage and support sales of technology products", "content": "With the technologies mentioned above, I have designed and completed a web site that meets the basic features of an e-commerce website. Buyers can register anaccount, search for products, place orders, and review products after purchase. Sell ers can post products for sale, edit product information, track and process orders, as well as monitor sales and receive alerts for out-of-stock products.", "label": "human"}
{"ID": "00140012", "file_name": "Design a system to manage and support sales of technology products", "content": "Chapter 2 presents the survey and analysis of requirements and the scope of the topic. In this chapter, the advantages and disadvantages of the surveyed programs are discussed. Based on that, the necessary functions for the application and the user objects are determined. Furthermore, an overview and analysis are provided to clarify the business processes, detailed specifications for important tasks, and non-functional requirements.", "label": "human"}
{"ID": "00140013", "file_name": "Design a system to manage and support sales of technology products", "content": "Chapter 3 will cover the technologies and theoretical foundations of those tech nologies, including their advantages and disadvantages and how they are applied to the system.", "label": "human"}
{"ID": "00140014", "file_name": "Design a system to manage and support sales of technology products", "content": "Chapter 4 presents the software architecture of the application, describing into the detailed design of each module, class design, database design, as well as the tools and libraries used during the application development process.", "label": "human"}
{"ID": "00140015", "file_name": "Design a system to manage and support sales of technology products", "content": "Chapter 5 discusses the achievements of the project, the knowledge acquired, aswell as the strengths and weaknesses of the application. Additionally, it outs the future development direction of the system.After chapter 1, which introduces motivation, objectives, and the scope of the topic, as well as the tentative solution, chapter 2 will carry out the practical survey.", "label": "human"}
{"ID": "00140016", "file_name": "Design a system to manage and support sales of technology products", "content": "Currently, in Vietnam, there are various websites that support on sales forbusinesses. After conducting some research, I focused on three platforms: Hoang hamobile, hacom.vn and mac8.vn as these websites specifically cater to the sale of technology products.", "label": "human"}
{"ID": "00140017", "file_name": "Design a system to manage and support sales of technology products", "content": "Hoanghamobile Hoanghamobile is a platform that supports selling technology products for achain of stores (figure 2.1). The website includes many advantages such as a modern and clear system of links to various types of products, detailed product de scriptions with corresponding segmented specifications, a convenient system for comparing different items, and a user-friendly product search filter. However, the website also has some disadvantages. For instance, the product rating system does not require users to have made a purchase, certain uncommon product types lack corresponding specifications (e.g., keyboards), orders can be placed without an account, leading to difficulties in controlling and handling spam-related issues.", "label": "human"}
{"ID": "00140018", "file_name": "Design a system to manage and support sales of technology products", "content": "A user interface consists of information about products, product search, pur chasing, managing personal accounts, viewing individual orders, and product reviews.", "label": "human"}
{"ID": "00140019", "file_name": "Design a system to manage and support sales of technology products", "content": "The products must display detailed descriptive information, specific techni cal specifications for each item, product reviews, and relevant data such aspurchase counts and rating scores A system interface supports sellers in posting products, managing products, handling orders, and managing system users.", "label": "human"}
{"ID": "00140020", "file_name": "Design a system to manage and support sales of technology products", "content": "The charts display sales revenue and sales statistics that the admin can adjust by time and product type they want to view.", "label": "human"}
{"ID": "00140021", "file_name": "Design a system to manage and support sales of technology products", "content": "General use case diagram Base on figure 2.4, the system consists of three agents : Guest, User and Admin Figure 2.4: General use case diagram Guest will have the following features :", "label": "human"}
{"ID": "00140022", "file_name": "Design a system to manage and support sales of technology products", "content": "Decomposition of the \"inventory management\" use case The figure 2.5 illustrates that admin can search for products, check product data, modify product information, and restock products. This functionality allows the admin to control and customize the product information of the store.Figure 2.5: Decomposition of the use case \"inventory management\" 2.2.3 Decomposition of the \"user account management\" use case Base on figure 2.6, this feature enables the admin to search for users within the system, view user information such as username, email, along with their placed orders. Additionally, this feature also provides the admin with a function to disable user accounts in certain exceptional cases.", "label": "human"}
{"ID": "00140023", "file_name": "Design a system to manage and support sales of technology products", "content": "System Create an order with status ’Open’ and save it to database 7 System Navigate user to Home page Alternative FlowStep Actor Action 2a System If in cart didn’t store any product, disable button checkout 2b System If user did not log in ,navigate user to Login pagePost conditionCreate Order Successfully2.3.3 Description of use case \"evaluate order\" Table 2.4: Detail for use case \"evaluate order\" Usecase ID UC03 Name Evaluate Order Role UserPre conditionHaving an account, signed in, created an order Basic FlowStep Actor Action 1 User Click to Line Order History at the sidebar 2 System Navigate User to Order History Page 3 User Click to an Order 4 System Navigate User Order Detail Page 5 User Click button add Review 6 System Open an Review Form 7 User Fill in Review Form and click button Verify 8 System Create Review and save it to data base 9 System Redirect user to Order History Page Alternative FlowStep Actor Action 4a System If order status is not Done, hide button add Review 4b System If order status is Done and User already review, hide button add reviewPost conditionAdd review successfully 2.3.4 Description of use case \"add product for sale\" Table 2.5: Detail for use case \"add product for sale\" Usecase ID UC04 Name Add product for sale Role Admin Pre-condition Have account, signed in Basic FlowStep Actor Action Continued on next pageTable 2.5: Detail for use case \"add product for sale\" (Continued) 1 Admin Click button Add Product on sidebar 2 System Navigate user to page Add Product 3 Admin Choose product type 4 System Display a product addition form with required fields and specific technical specifications for each type of item.", "label": "human"}
{"ID": "00140024", "file_name": "Design a system to manage and support sales of technology products", "content": "In the design and development of the system, apart from the core functionalities, non-functional requirements also hold significant importance. The following are the criteria for non-functional requirements that have been established.", "label": "human"}
{"ID": "00140025", "file_name": "Design a system to manage and support sales of technology products", "content": "SecurityThe server must have robust password encryption mechanisms, user authentica tion for their actions, and prevent unauthorized access to functionalities that users are not authorized to access.", "label": "human"}
{"ID": "00140026", "file_name": "Design a system to manage and support sales of technology products", "content": "Maintainability The system should be designed with clear and organized components, dividedinto smaller modules to facilitate effective management. By adopting a standard ized approach to coding, developers can ensure that the codebase is consistent and easy to maintain. Such an architecture allows teams to work on specific modules independently, making updates and changes more straightforward.", "label": "human"}
{"ID": "00140027", "file_name": "Design a system to manage and support sales of technology products", "content": "It should respond promptly to user actions or requests, providing seamless interac tions. Moreover, the system must consistently deliver accurate results and function as expected without any unexpected errors or crashes. Efficient data retrieval is equally important, ensuring that database queries return results within acceptable time limits, enabling quick access to the required information. By meeting theseperformance requirements, the system can deliver reliable and efficient service toits users.After chapter 2, which conducts the survey and analyzes the project’s require ments, as well as provides an overview of the system’s functionalities, chapter 3 will enumerate the technologies used to accomplish the objectives.", "label": "human"}
{"ID": "00140028", "file_name": "Design a system to manage and support sales of technology products", "content": "JavaScript is a versatile programming language that can be used for both front-end and back-end development. It empowers developers to create interactive and dynamic web pages, enhancing user experience and adding functionality to websites (Figure 3.1).", "label": "human"}
{"ID": "00140029", "file_name": "Design a system to manage and support sales of technology products", "content": "With a vast and thriving developer community, JavaScript has fostered the creation of numerous frameworks, libraries, and tools. These valuable resources sig nificantly stream the development of intricate web applications, fostering higher levels of productivity and efficiency in the development process.", "label": "human"}
{"ID": "00140030", "file_name": "Design a system to manage and support sales of technology products", "content": "By seamlessly integrating with HTML and CSS, the foundational technologies of web development, JavaScript empowers developers to manipulate the Document Object Model and facilitate dynamic alterations to the structure and content of web pages. These modifications can be triggered by user interactions or other events, enhancing the interactivity and responsiveness of websites.", "label": "human"}
{"ID": "00140031", "file_name": "Design a system to manage and support sales of technology products", "content": "Moreover, JavaScript’s relatively easy-to-learn syntax enables rapid develop ment, prototyping, and iteration. This is particularly beneficial for small-scale projectsor when working in agile development environments, promoting quicker turnaround times and increased productivity.", "label": "human"}
{"ID": "00140032", "file_name": "Design a system to manage and support sales of technology products", "content": "In conclusion, JavaScript’s versatility, wide adoption, rich ecosystem, integration with HTML and CSS and rapid development capabilities make it a com pelling choice for building websites.", "label": "human"}
{"ID": "00140033", "file_name": "Design a system to manage and support sales of technology products", "content": "Angular is a popular and powerful front-end framework for building web applications. It utilizes TypeScript, a statically typed superset of JavaScript, and follows the component-based architecture.", "label": "human"}
{"ID": "00140034", "file_name": "Design a system to manage and support sales of technology products", "content": "Angular offers an extensive array of tools, libraries, and features that foster accelerated development and heightened productivity (Figure 3.2). Its repertoire en compasses two-way data binding, dependency injection, and a component-based architecture, all of which stream the development workflow and minimize code verbosity.", "label": "human"}
{"ID": "00140035", "file_name": "Design a system to manage and support sales of technology products", "content": "With its robust two-way data binding capability, Angular empowers seamlesssynchronization between the data model and the user interface (UI). This bidirec tional linkage ensures that any changes made in the model automatically propagate to the view, and vice versa. As a result, manual manipulation is minimized, leadingto a highly responsive and interactive user experience.", "label": "human"}
{"ID": "00140036", "file_name": "Design a system to manage and support sales of technology products", "content": "Being developed and maintained by Google, Angular benefits from continuousimprovement and ongoing support. Moreover, Angular boasts a vibrant and engaged community of developers who actively contribute to its growth. This community collaborates through various channels such as forums, blogs, and open source projects, fostering knowledge sharing and providing valuable assistance to developers.", "label": "human"}
{"ID": "00140037", "file_name": "Design a system to manage and support sales of technology products", "content": "TypeScript is a statically typed superset of JavaScript that brings additional features and advantages to web development (Figure 3.3). Its main benefits includeenhanced code maintainability and readability through the use of static types, improved code quality with early error detection during development, and better tooling support for code navigation and refactoring, resulting in more robust and scal able applications.", "label": "human"}
{"ID": "00140038", "file_name": "Design a system to manage and support sales of technology products", "content": "Scalability is another significant advantage of TypeScript. With its static typingand comprehensive language features, TypeScript facilitates code organization andpromotes scalability, making it an ideal choice for developing complex and maintainable applications. The ability to define types for variables, function parame ters, and return values allows developers to establish clear interfaces and contracts within the codebase.", "label": "human"}
{"ID": "00140039", "file_name": "Design a system to manage and support sales of technology products", "content": "TypeScript benefits from a robust tooling ecosystem and an active and thrivingcommunity. It has excellent support from modern Integrated Development Environments such as Visual Studio Code, WebStorm, and others. These Integrated De velopment Environments offer advanced features like intelligent code completion, refactoring tools, and real-time error detection, enhancing developer productivity and enabling a smoother development experience.", "label": "human"}
{"ID": "00140040", "file_name": "Design a system to manage and support sales of technology products", "content": "ExpressJs is a server-side web framework based on NodeJs, used to build powerful and flexible web applications. It provides a set of features and tools forhandling HTTP requests, managing routing, and creating complex web applica tions (Figure 3.4).", "label": "human"}
{"ID": "00140041", "file_name": "Design a system to manage and support sales of technology products", "content": "By offering a clear and intuitive approach, ExpressJs simplifies the process of defining routes and handling various HTTP methods (GET, POST, PUT, DELETE,etc.). This framework enables you to efficiently organize your application’s end points and logic, streamlining maintenance and facilitating scalability for your web application.", "label": "human"}
{"ID": "00140042", "file_name": "Design a system to manage and support sales of technology products", "content": "MongoDB is an open-source, non-relational database management system (NoSQL) developed with a document-oriented architecture. It is designed to storeand retrieve data in JSON-like documents, providing a flexible and scalable ap proach for handling unstructured data (Figure 3.5).", "label": "human"}
{"ID": "00140043", "file_name": "Design a system to manage and support sales of technology products", "content": "MongoDB excels in horizontal scalability, empowering it to distribute data across multiple servers for seamlessly managing significant traffic and large data volumes.Furthermore, MongoDB incorporates efficient indexing and query optimizationtechniques, ensuring high-performance data retrieval. These features make Mon goDB an ideal choice for web development projects that anticipate rapid growth and demand robust scalability and performance.", "label": "human"}
{"ID": "00140044", "file_name": "Design a system to manage and support sales of technology products", "content": "MongoDB’s distributed architecture and automatic sharding support enable hor izontal scalability, allowing web applications to handle increased traffic and data volume without sacrificing performance. This makes MongoDB well-suited for websites that anticipate future growth and need to accommodate expanding user bases and data requirements while maintaining optimal efficiency.", "label": "human"}
{"ID": "00140045", "file_name": "Design a system to manage and support sales of technology products", "content": "Angular Highcharts is a powerful library that integrates Highcharts, a popular JavaScript charting library, with Angular, a widely-used web application framework. It provides developers with a seamless and convenient way to create interac tive and visually appealing charts and graphs within Angular applications.", "label": "human"}
{"ID": "00140046", "file_name": "Design a system to manage and support sales of technology products", "content": "Angular Highcharts facilitates dynamic and interactive data visualization, of fering a diverse array of chart types such as  charts, bar charts, pie charts, and more (Figure 3.6). These charts can be extensively customized with styling options, tooltips, drill-down functionalities, and animation effects, resulting in an enriched user experience.", "label": "human"}
{"ID": "00140047", "file_name": "Design a system to manage and support sales of technology products", "content": "Angular Highcharts empowers the binding of chart data to Angular compo nents, facilitating automatic updates and synchronization with your application’s data model. This functionality proves invaluable when working with real-time dataor scenarios where data changes dynamically, guaranteeing that your charts con sistently reflect the most current information available.", "label": "human"}
{"ID": "00140048", "file_name": "Design a system to manage and support sales of technology products", "content": "JSON Web Token (JWT) is a method of transmitting information between two parties in the form of a JSON object that is securely encoded (Figure 3.7). It is commonly used for authentication and authorization purposes in web applications and APIs.", "label": "human"}
{"ID": "00140049", "file_name": "Design a system to manage and support sales of technology products", "content": "JWTs are stateless, meaning that they do not rely on the server to store any ses sion data or user information. Instead, all the necessary information is securely contained within the token itself. This statelessness makes JWTs highly scalable and reduces the burden on the server, resulting in better performance and improvedefficiency. As a result, JWTs have become a preferred method for handling authen tication and authorization in modern web applications and APIs.Figure 3.6: Examples of Angular Highcharts application By digitally signing JWTs using either a secret key or a public/private key pair, their authenticity and integrity are ensured. This cryptographic process guarantees that the information contained within the token remains secure during transmission between parties. As a result, JWTs have become a trusted and secure method for exchanging data, providing a reliable solution for authentication and authorization in web applications and APIs.", "label": "human"}
{"ID": "00140050", "file_name": "Design a system to manage and support sales of technology products", "content": "Due to their compact nature and inclusion of only essential information, JWTs have a significantly smaller payload compared to other authentication mechanisms like sessions. As a result, they contribute to improved performance and reduced overhead in network communication. This streamd approach makes JWTs anefficient choice for handling authentication and authorization, particularly in mod ern web applications and APIs where network efficiency is crucial for delivering aseamless user experience.Figure 3.7: How JSON Web Token worksWith the technologies and theoretical foundations discussed in chapter 3, chap ter 4 will focus on providing a detailed description of the system, including the software architecture of the application, detailed design of classes, modules, and images of the developed system.", "label": "human"}
{"ID": "00140051", "file_name": "Design a system to manage and support sales of technology products", "content": "Software architecture selection The client-server architecture has been chosen as the software architecture forthe thesis project. The client-server architecture is a widely used software archi tectural model in which the functionality of a software application is divided into two main components: the client and the server. The client is the front-end part of the application that directly interacts with users. It is responsible for presenting the user interface and handling user interactions. On the other hand, the server is the back-end part of the application that processes and manages data, implements business logic, and responds to client requests.", "label": "human"}
{"ID": "00140052", "file_name": "Design a system to manage and support sales of technology products", "content": "Firstly, the client-server architecture offers a clear separation of responsibilities between the client and the server components. The client is responsible for handling the user interface and presentation logic, while the server focuses on processing data, implementing business logic, and managing resources. This separation allows for modular development, making it easier to design, implement, and maintain each component independently.", "label": "human"}
{"ID": "00140053", "file_name": "Design a system to manage and support sales of technology products", "content": "Additionally, the client-server architecture provides flexibility in choosing thetechnology stack for different parts of the website. The client-side can be developed using web technologies like HTML, CSS, and JavaScript, which are well suited for creating interactive user interfaces. On the server-side, developers have the freedom to select programming languages and frameworks that best suit theproject’s requirements, performance considerations, and their expertise. This flexi bility empowers developers to leverage the most suitable tools for each component, resulting in a more optimized and efficient system.", "label": "human"}
{"ID": "00140054", "file_name": "Design a system to manage and support sales of technology products", "content": "For this thesis, the Model-View-Controller (MVC) pattern has been selected as the preferred architectural design . MVC is a widely adopted pattern renownedfor its capability to effectively separate concerns, promoting modularity, maintain ability, and reusability throughout the development process.Figure 4.1: MVC design pattern On the figure 4.1, the Model represents the data and data-related logic in theapplication. In the context of this thesis website project, ExpressJS can be uti lized to build the backend API (Application Programming Interface) responsible for managing the data. ExpressJS enables handling of HTTP requests, accessing the database, and executing data-related operations. Modules like Mongoose can be employed to interact with a MongoDB database. The Model layer handles tasks such as data retrieval, manipulation, and storage.", "label": "human"}
{"ID": "00140055", "file_name": "Design a system to manage and support sales of technology products", "content": "The View is responsible for rendering the user interface and interacting with users. In this project, Angular components are employed to create user interfaces.", "label": "human"}
{"ID": "00140056", "file_name": "Design a system to manage and support sales of technology products", "content": "These components can display data from the Model and also send requests to theController to handle user events. Angular provides powerful HTML syntax to cre ate flexible and reliable interfaces. The View layer focuses on presenting data to the user, providing an intuitive and interactive user experience.", "label": "human"}
{"ID": "00140057", "file_name": "Design a system to manage and support sales of technology products", "content": "The Controller acts as an intermediary between the Model and the View. Its role is to handle user requests and interact with the Model to retrieve data. It then provides the data to the View for display. In Angular, components can be used to define Controller logic. These components handle user events, make API calls to the Model (using the HTTP client), and supply data to the View through variables or data-binding mechanisms. The Controller layer encapsulates the application’s business logic, coordinating between the Model and the View.", "label": "human"}
{"ID": "00140058", "file_name": "Design a system to manage and support sales of technology products", "content": "Overall design The system is divided into two main parts: Front-end and Back-end.Figure 4.2: Overall package design Base on figure 4.2, the front-end layer comprises packages organized as follows:", "label": "human"}
{"ID": "00140059", "file_name": "Design a system to manage and support sales of technology products", "content": "Common package: houses shared items of the website, such as the search bar, models, and directives Component package: houses reusable components used across various parts of the project, such as the header, footer, paging, and more.", "label": "human"}
{"ID": "00140060", "file_name": "Design a system to manage and support sales of technology products", "content": "Guard package:Contains classes that can be used to check and determine whether a specific page or functionality can be accessed or not.", "label": "human"}
{"ID": "00140061", "file_name": "Design a system to manage and support sales of technology products", "content": "Interceptor package: Contains mechanism that allows user to intercept, handle, and transform HTTP requests before they are sent or after receiving responses from the server.•Service package: contains the utility functions that handle logic required in multiple places throughout the project.", "label": "human"}
{"ID": "00140062", "file_name": "Design a system to manage and support sales of technology products", "content": "Routers package: the place where requests are directed to controllersAuth package: contains the functions for checking and authenticating user re quests before processing the logic Controller package: the place where requests from users are received, logic is processed, and responses are sent back to display in the application for users.", "label": "human"}
{"ID": "00140063", "file_name": "Design a system to manage and support sales of technology products", "content": "Detailed package design a, Front-end detail package design The detailed package design for the front-end is described in figure 4.3:", "label": "human"}
{"ID": "00140064", "file_name": "Design a system to manage and support sales of technology products", "content": "Auth: contains user identification properties and functions to modify those properties.In the Store package represent on figure 4.5,it housing global states that require access from multiple components throughout the project. This approach allows for efficient management of shared application state and facilitates the implementation of related logic associated with the stored data.", "label": "human"}
{"ID": "00140065", "file_name": "Design a system to manage and support sales of technology products", "content": "On the figure 4.7, the Component package encapsulates individual elements that compose a page, with each component assigned to a specific section of the page.", "label": "human"}
{"ID": "00140066", "file_name": "Design a system to manage and support sales of technology products", "content": "User: contains pages that require customers to have an account within the system and be logged in to access them. Only authenticated users with valid credentials can access these pages.", "label": "human"}
{"ID": "00140067", "file_name": "Design a system to manage and support sales of technology products", "content": "Auth: acts as a dedicated container for all API-related logic concerning userauthentication and registration within the system. It encompasses functionali ties for handling user login, registration, and related authentication processes.", "label": "human"}
{"ID": "00140068", "file_name": "Design a system to manage and support sales of technology products", "content": "Product: serves as a dedicated container for all API-related logic concerning product management within the system. It encapsulates functionalities relatedto handling product-related operations, such as adding new products, updat ing inventory, searching for products, and any other actions associated with product entities.", "label": "human"}
{"ID": "00140069", "file_name": "Design a system to manage and support sales of technology products", "content": "User: serves as a dedicated container for all API-related logic concerning usermanagement within the system. It encapsulates functionalities related to han dling user-related operations, such as searching for users, retrieving user lists, and disabling user accounts.", "label": "human"}
{"ID": "00140070", "file_name": "Design a system to manage and support sales of technology products", "content": "Review: serves as a dedicated container for all API-related logic concerning reviews within the system. It encompasses functionalities related to handlingreview-related operations, such as adding reviews after purchasing a product and searching for reviews corresponding to specific items.", "label": "human"}
{"ID": "00140071", "file_name": "Design a system to manage and support sales of technology products", "content": "Category: serves as a dedicated container for all API-related logic concerning product categories within the system. It encompasses functionalities related to handling category-related operations, such as adding new product categories, managing their technical specifications, and searching for specifications when creating products.", "label": "human"}
{"ID": "00140072", "file_name": "Design a system to manage and support sales of technology products", "content": "Review : Defining the database structure of a review Import : Defining the database structure of an import receipt SoldItem : Defining the database structure of an item sold receipt4.2 Detailed design 4.2.1 User interface design The user interface design in this project aims to ensure a smooth user experience and clear communication of information. The focus is on creating a seamless and intuitive interface that allows users to interact with the application effortlessly.", "label": "human"}
{"ID": "00140073", "file_name": "Design a system to manage and support sales of technology products", "content": "Database design The entity-relationship diagram is represented on figure 4.17 as follows:Figure 4.17: Entity-relationship diagram The thesis identifies the main entities as Product, User, and Order based on the entity-relationship diagram.", "label": "human"}
{"ID": "00140074", "file_name": "Design a system to manage and support sales of technology products", "content": "The entity \"Product\" have a many-to-many relationship with entity \"Order\", meaning that a product can belong to multiple order and an order can have more than one product The entity \"Product\" have a one-to-many relationship with entity \"Import\", meaning that a Product can have more than one Import Product receipt.", "label": "human"}
{"ID": "00140075", "file_name": "Design a system to manage and support sales of technology products", "content": "The entity \"Product\" have a one-to-many relationship with entity \"SoldItem Record\", meaning that a Product can have more than one Sold item record.", "label": "human"}
{"ID": "00140076", "file_name": "Design a system to manage and support sales of technology products", "content": "The entity \"User\" have a one-to-many relationship with entity \"SoldItemRecord\", meaning that an User can have multiple records of purchasing ac tivities.", "label": "human"}
{"ID": "00140077", "file_name": "Design a system to manage and support sales of technology products", "content": "The relationships of the entity \"Order\" can be described as follows:•The entity \"Order\" have a many-to-one relationship with entity \"User\", mean ing that a purchase order can only belong to one buyer.", "label": "human"}
{"ID": "00140078", "file_name": "Design a system to manage and support sales of technology products", "content": "The entity \"Order\" have a one-to-one relationship with entity \"Review\", mean ing that an Order can only have one review.", "label": "human"}
{"ID": "00140079", "file_name": "Design a system to manage and support sales of technology products", "content": "Libraries and tools Table 4.6: List of libraries and tools Purpose Tool Version Coding IDE Visual Studio Code 1.8 Programing Language TypeScript 4.9.4 Database GUI MongoDB Compass 1.36.0 API development tool Postman 10 Server-side scripting NodeJS 18.16 Control source code Git 2.37.0 API Access Control Cors 2.8.5 Hashing Password Crypto-js 4.1.1 Enviroment setup dotenv 16.0.3 Web application framework Express 4.18.2 Ensuring the authenticity jsonwebtoken 9.0.0 Object Data Modeling mongoose 7.0.0 Automatically restarting application Nodemon 2.0.21 Front-end App framework Angular 15 State management ngrx 15.4.0 Store Image firebase 9.22.1 Continued on next pageTable 4.6: List of libraries and tools (Continued) Parsing and Formatting Date moment 2.29.4 Reactive programming libery rxjs 7.8.0 Creating Reactive Chart angular-highcharts 15.0.1 Code formatting prettier 9.19.0 Count Line of Code VS Code Counter 3.2.1 Check the server’s load capacity Artillery 2.0.0 4.3.2 Achievement The system has achieved its main objectives effectively. It consists of three core components running on a website platform: a server back-end, a user interface for buyers, and an interface for administrators. The system’s notable features include inventory management, order management, user management for administrators, product search, and order placement for buyers.", "label": "human"}
{"ID": "00140080", "file_name": "Design a system to manage and support sales of technology products", "content": "This thoughtfully constructed system offers a seamless user experience. The inventory management module enables businesses to keep track of products and update stock levels. The order management feature ensures smooth processing andtracking of customer orders. Administrators have complete control over user accounts and permissions. The product search function allows easy product discovery, and the user interface for buyers is intuitive, making the buying process hassle free. Overall, the system sets a high standard for e-commerce platforms, benefiting businesses and enhancing customer satisfaction.", "label": "human"}
{"ID": "00140081", "file_name": "Design a system to manage and support sales of technology products", "content": "Additionally, there is a search filter with options to search by product name, manu facturer, and product category, allowing the admin to easily find desired products.Figure 4.23: Interface of the admin’s product listing page Figure 4.24 displays the user list page in the system, along with their respective order statistics. The admin can click on an account name to navigate to the detailed user information page. Moreover, the admin can search for users by account name using the search bar.", "label": "human"}
{"ID": "00140082", "file_name": "Design a system to manage and support sales of technology products", "content": "Testing is a critical phase in the software development process, ensuring thatthe system functions as intended and meets the initial design requirements. Byconducting comprehensive functional , developers can identify and address po tential issues, ensuring a reliable and user-friendly product. The validation of key functionalities will be presented in the following sections.", "label": "human"}
{"ID": "00140083", "file_name": "Design a system to manage and support sales of technology products", "content": "The system is deployed using a Platform as a Service architecture, consisting of one server back-end deployed on Render and two clients deployed on Netlify.", "label": "human"}
{"ID": "00140084", "file_name": "Design a system to manage and support sales of technology products", "content": "The source code of the project is pushed to Git and then connected to third party services Render and Netlify for deployment on the internet. Each part of the project has a corresponding Git repository with separate environment setups,such as domain names, build commands, and publish directories. For the front end, additional environment variables need to be set up for Firebase configuration, including apiKey, authDomain, and projectId. These variables are essential for the client application to interact with Firebase services correctly.", "label": "human"}
{"ID": "00140085", "file_name": "Design a system to manage and support sales of technology products", "content": "The successfully deployed projects include: 1 client for administrators, 1 client for buyers, and 1 back-end server with the following URLs:•URL for administrators:  lify.app/ URL for customers:  URL for Back-end server:  The test cases listed and executed in the testing section have been retested to ensure consistency with the version deployed on the internet. The server’s load capacity testing has been performed using the artillery tool, as indicated in the table below.", "label": "human"}
{"ID": "00140086", "file_name": "Design a system to manage and support sales of technology products", "content": "Shortest response time 0.055s Longest response time. 0.082s Average response time 0.0597s Number of successful requests 100 50 users simultaneously accessing within 10 seconds.", "label": "human"}
{"ID": "00140087", "file_name": "Design a system to manage and support sales of technology products", "content": "Shortest response time 0.054s Longest response time. 0.077s Average response time 0.061s Number of successful requests 500 100 users simultaneously accessing within 10 seconds.", "label": "human"}
{"ID": "00140088", "file_name": "Design a system to manage and support sales of technology products", "content": "Shortest response time 0.055s Longest response time. 0.47s Average response time 0.067sNumber of successful requests 724Chapter 5 will discuss the achievements of the system, its strengths, and weak nesses . Additionally, it will provide insights into the system’s potential growth and improvements for the future.", "label": "human"}
{"ID": "00140089", "file_name": "Design a system to manage and support sales of technology products", "content": "The graduation thesis has successfully fulfilled the stated objectives. Specifi cally, the project has developed a sales support system for a store with two maininterfaces catering to buyers and sellers. The buyer interface facilitates easy prod uct search, ordering, and order tracking for users. On the other hand, the seller interface serves as a system for managing items, processing orders, and handling user management.", "label": "human"}
{"ID": "00140090", "file_name": "Design a system to manage and support sales of technology products", "content": "One of the prominent features of the system is the inclusion of various charts and graphs to support administrators in tracking sales and order numbers. Moreover, these customizable charts allow admins to easily review the desired data they are interested in.", "label": "human"}
{"ID": "00140091", "file_name": "Design a system to manage and support sales of technology products", "content": "The system is constructed using Angular for the frontend interface and user in terface logic, while ExpressJS is employed to build the logic for connecting to thedatabase and providing data to the frontend. MongoDB serves as the data repos itory, and JWT is utilized for user authentication whenever they connect to the system’s data.", "label": "human"}
{"ID": "00140092", "file_name": "Design a system to manage and support sales of technology products", "content": "After successful development, the system was deployed on the network. Its func tions were tested and are now operating according to the original design, providingbuyers with a comprehensive interface and convenient and fast inventory manage ment and order processing capabilities.", "label": "human"}
{"ID": "00140093", "file_name": "Design a system to manage and support sales of technology products", "content": "However, the system still has some limitations. The UI, UX design lacks pro fessionalism and modernization, leading to some unappealing layouts for website users. The website is only designed and optimized for laptop use, and it is not yetresponsive on different platforms such as phones and tablets. Additionally, the sys tem does not have on payment functionality due to the requirement in Vietnam that on payment platforms like Momo can only be used by officially registered businesses.", "label": "human"}
{"ID": "00140094", "file_name": "Design a system to manage and support sales of technology products", "content": "The near-future direction for the product is to complete the on payment functionalities and enhance the user interface to be more professional and modern.Moreover, the project plans to revise and upgrade the interface to ensure compati bility across various platforms, such as tablets, mobile devices, and different screen resolutions for PCs. This will enable a seamless user experience regardless of the device used.", "label": "human"}
{"ID": "00140095", "file_name": "Design a system to manage and support sales of technology products", "content": "Furthermore, the long-term vision is to build a product comparison system that assists users in comparing similar items before making a purchase. Additionally, an on communication system will be developed to facilitate seamless interactions between customers and the store, making it easier for customers to connect with the business.", "label": "human"}
{"ID": "00140096", "file_name": "Design a system to manage and support sales of technology products", "content": "Integrating a delivery system into the current system can indeed provide valu able support for the business in managing orders more efficiently, especially in thescenario where the store’s scale increases significantly in the future. This integra tion would stream the order fulfillment process, enabling smoother logisticsand ensuring timely deliveries. By automating the delivery management, the busi ness can handle a higher volume of orders without compromising on the quality of service. C. T. G. D. E. Angular, Angular100day . [On]. Available: https://github.com/angular-vietnam/100-days-of-angular (vis ited on 07/22/2023).", "label": "human"}
{"ID": "00140097", "file_name": "Design a system to manage and support sales of technology products", "content": "M. Kumar, Highcharts with angular custom directive and web api . [On line]. Available: highcharts-with-angular-custom-directive-and-web api/ (visited on 2017). E. jwt, Express jwt . [On]. Available:  package/express-jwt (visited on 02/23/2023).", "label": "human"}
{"ID": "00140098", "file_name": "Design a system to manage and support sales of technology products", "content": "[On]. Available: https : / / www. vaadata . com / blog / jwt tokens - and - security- working - principles - and - use  cases/ (visited on 2016).", "label": "human"}
{"ID": "00150001", "file_name": "Violence Detection in Surveillance Camera", "content": "Violence is a global phenomenon that has caused lots of damage to people and property. It results in the deaths of more than 1.6 million people each year, making it one of the leading causes of death worldwide. While no country is untouchedby violence, the vast majority of its resultant deaths occur in low- to middle income countries, many of which are stricken with internal conflicts. However, it should be kept in mind that violent deaths cannot simply be attributed to war, and more than 80% of such deaths occur outside of armed conflicts. Violence has also shown to be an incredibly costly issue, and in 2015 alone the total impact of violence on the world economy was estimated at 13.6 trillion USD – a figure which is equivalent to 13.3% of world GDP. High levels of violence and crime in regions such as Southern Africa are often the symptoms of underlying social, economic, and political challenges such as social inequality, rapid urbanization, poverty, unemployment, and institutional shortcomings. The adverse effects of violence on a country are harmful not only to its citizens but to the well-being of the community and country as a whole. In many countries, the impact of violence has significantly and directly reduced economic growth and poses an obstacle to reducing poverty, while violence also causes profound psychological and physical trauma, reducing the quality of life for all of the society .", "label": "human"}
{"ID": "00150002", "file_name": "Violence Detection in Surveillance Camera", "content": "Nowadays, to contribute to the prevention of acts of violence, surveillance cameras are widely used. However, it is impossible to spend human resources to check captured videos 24/7, hence, this led to a problem: Automated violence detection system on surveillance cameras.", "label": "human"}
{"ID": "00150003", "file_name": "Violence Detection in Surveillance Camera", "content": "Surveillance and anomaly detection have become more important as the quantity of video data has grown rapidly . When compared to regular activity, such aberrant occurrences are uncommon. As a result, creating automated video surveillance systems for anomaly detection has become a need to reduce labour and time waste.", "label": "human"}
{"ID": "00150004", "file_name": "Violence Detection in Surveillance Camera", "content": "Detecting abnormalities in videos is a difficult job since the term “anomaly” is often imprecise and poorly defined . They differ greatly depending on the conditions and circumstances in which they occur. Bicycling on a standard route, for example, is a typical activity, but doing so in a walk-only lane should be noted as unusual. The uneven internal occlusion is a noteworthy, yet difficult to explain characteristic of the abnormal behaviour. Furthermore, owing to its largedimensionality, resolution, noise, and rapidly changing events and interactions, video data encoding and modelling are more challenging. Other difficulties include lighting changes, perspective shifts, camera movements, and so on .", "label": "human"}
{"ID": "00150005", "file_name": "Violence Detection in Surveillance Camera", "content": "Violence detection is one of the most crucial elements of video-based anomaly detection (Khan et al., 2019). The usage of video cameras to monitor individuals has become essential due to the rise in security concerns across the globe, and early detection of these violent actions may significantly minimize the dangers.", "label": "human"}
{"ID": "00150006", "file_name": "Violence Detection in Surveillance Camera", "content": "A violence detection system’s primary goal is to identify some kind of aberrant behaviour that fits under the category of ’violence’ . If an event’s conduct differs from what one anticipates, it is considered violent. A person striking, kicking, lifting the other person, and so on are examples of such anomalies . Since human monitoring of the complete video stream is impractical owing to the repetitive nature of the work and the length of time required, automated identification of violent events in real-time is required to prevent such incidents .", "label": "human"}
{"ID": "00150007", "file_name": "Violence Detection in Surveillance Camera", "content": "Given the similarities, there seem to be confusion between the terms ‘Action recognition’ and ‘Violence detection’. Action recognition is, simply put, a technology that can identify human actions. Human activities are categorized into four groups based on the intricacy of the acts and the number of bodily parts engaged in the action: Gestures, actions, interactions, and group activities. A gesture is a series of motions performed with the hands, head, or other body parts to convey a certain message. A single person’s actions are a compilation of numerous gestures.", "label": "human"}
{"ID": "00150008", "file_name": "Violence Detection in Surveillance Camera", "content": "Interactions are a set of human activities involving at least two people. When there are two actors are involved, one should be a human and the other may be a human or an object. When there are more than two participants and one or more interacting objects, group activities involve a mix of gestures, actions, or interactions .", "label": "human"}
{"ID": "00150009", "file_name": "Violence Detection in Surveillance Camera", "content": "On the other hand, violence detection is a specific issue within the larger topic of ‘action recognition’. The goal of violence detection is to identify whether or not violence happens in a short amount of time automatically and efficiently. The usage of video cameras to monitor individuals has become essential due to the rise in security concerns across the globe, and early detection of these violent actions may significantly minimize the dangers. A violence detection system’s primary goal is to identify some kind of aberrant behaviour that fits under the category of ‘violence ‘. If an event’s conduct differs from what one anticipates, it is considered violent. A person striking, kicking, lifting the other person, and so on are examples of such anomalies . Since human monitoring of the complete video stream is impractical owing to the repetitive nature of the work and the length of time required, automated identification of violent events in real-time is requiredto prevent such incidents .", "label": "human"}
{"ID": "00150010", "file_name": "Violence Detection in Surveillance Camera", "content": "However, it should be noted that detecting abnormalities in videos is a difficult job since the term “anomaly” is often imprecise and poorly defined . They differ greatly depending on the conditions and circumstances in which they occur.", "label": "human"}
{"ID": "00150011", "file_name": "Violence Detection in Surveillance Camera", "content": "Bicycling on a standard route, for example, is a typical activity, but doing so in a walk-only lane should be noted as unusual. The uneven internal occlusion is a noteworthy, yet difficult to explain characteristic of the abnormal behaviour.", "label": "human"}
{"ID": "00150012", "file_name": "Violence Detection in Surveillance Camera", "content": "Furthermore, owing to its large dimensionality, resolution, noise, and rapidly changing events and interactions, video data encoding and modelling are more challenging.", "label": "human"}
{"ID": "00150013", "file_name": "Violence Detection in Surveillance Camera", "content": "Other difficulties include lighting changes, perspective shifts, camera movements, and so on . Even so, despite the difficulties, creating automated video surveillance systems for anomaly detection has become a need to reduce labour and time waste.", "label": "human"}
{"ID": "00150014", "file_name": "Violence Detection in Surveillance Camera", "content": "From our survey to automatically detect violence in general, based on features extraction methods, there are 2 main approaches: handcrafted and deep learning.", "label": "human"}
{"ID": "00150015", "file_name": "Violence Detection in Surveillance Camera", "content": "The main purpose of this thesis is to develop an end-to-end system for automatically detecting violent behaviors from videos captured by surveillance cameras. Based on our survey from 1.2, we selected the deep learning approach because of its high accuracy and flexibility.", "label": "human"}
{"ID": "00150016", "file_name": "Violence Detection in Surveillance Camera", "content": "Chapter 4 presents evaluation results of SOTA on violence detection as well as our proposed method on the AICS - violence and a standard benchmark dataset.", "label": "human"}
{"ID": "00150017", "file_name": "Violence Detection in Surveillance Camera", "content": "Finally, in chapter 5, we concludes the results of our work and suggest futureresearch directions.DIVISION OF WORK ID Work Assignee 1Survey handcrafted and machine learning methods for violence detectionThuy 2 Survey deep learning methods for violence detection Hung 3Collected more samples for test sets of the AICS - violence datasetHung, Thuy 4 Implement candidate box extraction Hung 5 Implement and evaluate the thesis’s proposed fusion method Hung, Thuy 6 Evaluate base methods on the AICS - violence dataset Hung, Thuy 7 Evaluate the thesis’s proposed method on a standard dataset Thuy2.1 Problem context As a result of violence being such a complex phenomenon, there is no clear definition for it. Therefore, it is often understood differently by different people in different contexts - such as those from different countries, cultures, or belief systems.", "label": "human"}
{"ID": "00150018", "file_name": "Violence Detection in Surveillance Camera", "content": "The World Health Organization (WHO) defines violence as “The intentional use of physical force or power, threatened or actual, against oneself, another person, or against a group or community, that either results in or has a high likelihood of resulting in injury, death, psychological harm, maldevelopment or deprivation” .", "label": "human"}
{"ID": "00150019", "file_name": "Violence Detection in Surveillance Camera", "content": "On the basis of the WHO’s definition of violence, an elaborate “typology of violence” (as shown in Figure 2.1) has been developed that characterizes different categories and types of violence, as well as the links between them (allowing for a holistic approach to intervention).", "label": "human"}
{"ID": "00150020", "file_name": "Violence Detection in Surveillance Camera", "content": "Self-Directed violence: Self-directed violence refers to violent acts a person inflicts upon him- or herself, and includes self-abuse (such as self-mutilation) and suicidal behaviour (including suicidal thoughts, as well as attempted and completed suicide).", "label": "human"}
{"ID": "00150021", "file_name": "Violence Detection in Surveillance Camera", "content": "Interpersonal violence: Interpersonal violence refers to violence inflicted by another individual or by a small group of individuals. It can be further divided into two subcategories: Family and intimate partner violence and Communityviolence.", "label": "human"}
{"ID": "00150022", "file_name": "Violence Detection in Surveillance Camera", "content": "Collective violence: Collective violence can be defined as the instrumental use of violence by people who identify themselves as members of a group – whether this group is transitory or has a more permanent identity – against another group or set of individuals, in order to achieve political, economic or social objectives. This can manifest in a number of forms, such as genocide, repression, terrorism and organised violent crime.", "label": "human"}
{"ID": "00150023", "file_name": "Violence Detection in Surveillance Camera", "content": "By looking more closely at the nature of acts of violence, these three categories can be further divided into four, more specific, types of violence:", "label": "human"}
{"ID": "00150024", "file_name": "Violence Detection in Surveillance Camera", "content": "Physical violence: Physical violence is the intentional use of physical force, used with the potential for causing harm, injury, disability or death. This includes, but is not limited to: scratching, pushing, shoving, grabbing, biting, choking, shaking, slapping, punching, hitting, burning, use of a weapon, and use of restraint or one’s body against another person. This type of violence does not only lead to physical harm, but can also have severe negative psychological effects – for example, if a child is frequently a victim of physical violence at home, he or she can suffer from mental health problems and be traumatised as a consequence of this victimisation.", "label": "human"}
{"ID": "00150025", "file_name": "Violence Detection in Surveillance Camera", "content": "Sexual violence: Sexual violence involves a sexual act being committed or attempted against a victim who has not freely given consent, or who is unableto consent or refuse. This includes, but is not limited to: forced, alcohol/drug facilitated or unwanted penetration, sexual touching, or non-contact acts of a sexual nature. A perpetrator forcing or coercing a victim to engage in sexual acts with a third party also qualifies as sexual violence. This type of violence can also lead to physical harm, and in most cases has severe negative psychological effects too.", "label": "human"}
{"ID": "00150026", "file_name": "Violence Detection in Surveillance Camera", "content": "Psychological violence: Psychological violence (also referred to as emotional or mental abuse) includes verbal and non-verbal communication used with the intent to harm another person mentally or emotionally, or to exert control over another person. The impact of psychological violence can be just as significant as that of other, more physical forms of violence, as the perpetrator subjects the victim to behaviour which may result in some form of psychological trauma, such as anxiety, depression or post-traumatic stress disorder. This includes, but is not limited to: expressive aggression (e.g., humiliating and degrading), coercive control (e.g., limiting access to things or people, and excessive monitoring of a person’s whereabouts or communications), threatsof physical or sexual violence, control of reproductive or sexual health, and exploitation of a person’s vulnerability (e.g., immigration status or disability).", "label": "human"}
{"ID": "00150027", "file_name": "Violence Detection in Surveillance Camera", "content": "Neglect: Neglect, or deprivation, is a type of abuse which occurs when someone has the responsibility to provide care for an individual who is unable to care for him- or herself, but fails to do so, therefore depriving them of adequate care. Neglect may include the failure to provide sufficient supervision, nourishment, or medical care, or the failure to fulfil other needs for which the victim cannot provide themselves. Neglect can lead to many long-term side effects such as: physical injuries, low self-esteem, attention disorders, violent behaviour, physical and psychological illness, and can even result death.", "label": "human"}
{"ID": "00150028", "file_name": "Violence Detection in Surveillance Camera", "content": "These four types of violence can occur in each of the previously mentioned broad categories, and their subcategories (except for self-directed violence). The Figure 2.1 illustrates these links between types of violence and the nature of violent acts. Horizontally the graphic shows who is affected, while vertically it describes how they are potentially affected.", "label": "human"}
{"ID": "00150029", "file_name": "Violence Detection in Surveillance Camera", "content": "Our thesis is solely directed towards detecting ‘Physical violence’, hence, from here onward, the word ‘violence’ indicates the phenomena of ‘Physical violence’ specifically.", "label": "human"}
{"ID": "00150030", "file_name": "Violence Detection in Surveillance Camera", "content": "In this section, methods of violence detection are analysed to completely disassemble the present condition and anticipate the emerging trends of violence discovery research by providing a comprehensive assessment of the video violence detection methods that have been described in state-of-the-art researches. Current techniques, state-of-the-art violence detection techniques which were published between approximately from 2015 to 2021, into three categories based on their methodologies: conventional methods, end-to-end deep learning-based methods, and machine learning-based methods.", "label": "human"}
{"ID": "00150031", "file_name": "Violence Detection in Surveillance Camera", "content": "Scientists have presented various approaches and methods for detecting violent or unusual occurrences, citing the fast rise in crime rates as an example of the need for more efficient identification. Various methods for detecting violence have been developed in past few years. Based on the classifier employed, violence detection methods are divided into three categories: violence detection using machine learning, violence detection using SVM, and violence detection using deep learning . A methodology for detecting objects and a method for extracting features are also discussed.2.2.1 Overview of feature extractions This section goes through the feature descriptors that violence detection papers utilized in their research as well as other recent state-of-the-art descriptors.", "label": "human"}
{"ID": "00150032", "file_name": "Violence Detection in Surveillance Camera", "content": "The fundamental components for detecting activity from the video are video features. The dataset and characteristics collected from video to evaluate the pattern of activity have a direct impact on the methodology’s accuracy. For example, in combat situations, the movement of various objects increases faster. The movement of objects in a typical setting is normal and not too rapid. The direction of item movement in relation to time and space is also utilized to investigate unusual occurrences. Such features can be divided in to two main categories based on how they are collected:", "label": "human"}
{"ID": "00150033", "file_name": "Violence Detection in Surveillance Camera", "content": "Handcrafted features: Manually engineered by the data scientist Learning features: Automatically obtained from a machine or deep learning algorithm Suppose, for an image classification task, where the target is to classify cats from dogs, the developer is faced with a dilemma on how to input the data to the classifier. There are two options:", "label": "human"}
{"ID": "00150034", "file_name": "Violence Detection in Surveillance Camera", "content": "The raw pixel data (The issue with this approach is that the feature space is vast, which makes it hard for models to generalize) 2. Attempt to extract features from the image so that the feature space can be reduced. If the second option is chosen, two methods are available for implementation:", "label": "human"}
{"ID": "00150035", "file_name": "Violence Detection in Surveillance Camera", "content": "Manually define a set of features and extract them. Some examples include edge detection as in Figure 2.2, corner detection, histograms, etc. The problem with this approach is that nothing guarantees that the number of corners is a good descriptor for classifying cat and dog images.", "label": "human"}
{"ID": "00150036", "file_name": "Violence Detection in Surveillance Camera", "content": "In a nutshell, since ‘learned features’ are extracted automatically to solve a specific task, they are extremely effective at it. In fact, deep learning models that perform feature extraction and classification outperform models that classify manually extracted features by a large margin. This is one of the reasons why deep learning is so popular. On the other hand, we have no control on what features the model will extract from the data. In many cases these features are only good for classifying the data and have no real-world interpretation. They are only good for the task that they were trained for.", "label": "human"}
{"ID": "00150037", "file_name": "Violence Detection in Surveillance Camera", "content": "A feature descriptor is an algorithm which takes an image and outputs feature descriptors/feature vectors. Feature descriptors encode interesting information into a series of numbers and act as a sort of numerical “fingerprint” that can be used to differentiate one feature from another. Following are a few well-recognized feature descriptors a, Histogram of oriented gradients (HOG) HOGs are feature descriptors for object identification and localization that can compete with DNN’s performance . The gradient direction distribution is utilized as a feature in HOG. Because the brightness of corners and edges vary greatly, calculating the gradient together with the directions may assist in the detection of this knowledge from the images.b, Histogram of optical flow (HOF) A pattern of apparent motion of objects, surfaces, and edges is produced as a result of the relative motion between an observer and a scene. This process is called Optical Flow. The histogram of oriented optical flow (HOF)  is an optical flowcharacteristic that depicts the series of events at each point in time. It is scale invariant and unaffected by motion direction.", "label": "human"}
{"ID": "00150038", "file_name": "Violence Detection in Surveillance Camera", "content": "SPACE –time interest points Laptev and Lindeberg and Laptev proposed the space–temporal interest point detector by expanding the Harris detector. A second-moment matrix is generated for each spatiotemporal interest point after removing points with high gradient magnitude using a 3D Harris corner detector , . This descriptor’s characteristics are used to describe the spatiotemporal, local motion, and appearance information in volumes.", "label": "human"}
{"ID": "00150039", "file_name": "Violence Detection in Surveillance Camera", "content": "MoSIFT MoSIFT  is an extension of the popular SIFT  image descriptor for video. The standard SIFT extracts histograms of oriented gradients in the image.", "label": "human"}
{"ID": "00150040", "file_name": "Violence Detection in Surveillance Camera", "content": "The 256-dimensional MoSIFT descriptor consists of two portions: a standard SIFT image descriptor and an analogous HOF, which represents local motion. These descriptors are extracted only from regions of the image with sufficient motion.", "label": "human"}
{"ID": "00150041", "file_name": "Violence Detection in Surveillance Camera", "content": "The MoSIFT descriptor has shown better performance in recognition accuracy than other state-of-the-art descriptors  but the approach is significantly more computationally expensive than STIP.", "label": "human"}
{"ID": "00150042", "file_name": "Violence Detection in Surveillance Camera", "content": "Violence flow descriptor The violence flow, which utilizes the frequencies of discrete values in a vectorized form, is an essential feature descriptor. This is different from other descriptors in that instead of assessing magnitudes of temporal information, the magnitudes are compared for each, resulting in much more meaningful measurements in terms of the previous frame . Instead of looking at local appearances, the similarities between flow-magnitudes in terms of time are investigated.", "label": "human"}
{"ID": "00150043", "file_name": "Violence Detection in Surveillance Camera", "content": "Bag-of-Words (BoW) The Bag-of-Words (BoW) method, which originated in the text retrieval community  has lately gained popularity for a picture  and video comprehension .", "label": "human"}
{"ID": "00150044", "file_name": "Violence Detection in Surveillance Camera", "content": "Each video sequence is represented as a histogram over a collection of visual words in this method, which results in a fixed-dimensional encoding that can be analysed with a conventional classifier. The cluster centres produced via k-means clusteringacross a large collection of sample low-level descriptors are usually described as the lexicon of visual words in a learning phase .", "label": "human"}
{"ID": "00150045", "file_name": "Violence Detection in Surveillance Camera", "content": "Motion boundary histograms (MBH) By measuring derivatives independently for the horizontal and vertical components of the optical flow, Dalal et al. developed the MBH descriptor  for human detection. The relative motion between pixels is encoded by the descriptor. Because MBH depicts the gradient of the optical flow, information regarding changes in the flow field (i.e., motion boundaries) is preserved while locally constant camera motion is eliminated. MBH is more resistant to camera motion than optical flow, making it better at action detection.", "label": "human"}
{"ID": "00150046", "file_name": "Violence Detection in Surveillance Camera", "content": "Violence detection using hand-crafted and machine learning techniques a, Fast Fight Detection In the field of computer vision, action recognition has now become a relevant research area. However, the identification of particular events with immediate practical application, such as fighting or general violent conduct, has received much less attention. In certain situations, such as prisons, mental institutions, or even camera phones, video surveillance may be very helpful . Given the circumstances, a new technique for detecting violent sequences was suggested by Gracia et al in the article ‘Fast Fight Detection’ . To distinguish between fighting and non-fighting episodes, features derived from motion blobs are utilized.", "label": "human"}
{"ID": "00150047", "file_name": "Violence Detection in Surveillance Camera", "content": "As illustrated in Figure 2.4, Fast Fight Detection model  uses motion blobs for extracting features. The proposed method was assessed using three different datasets as ‘Movies’ dataset with 200 video clips , the ‘Hockey fight’ dataset that consists of 1000 video clips , and the ‘UCF-101’ dataset of realistic action videos collected from YouTube . The proposed method was compared with other five related methods as Bag of Words (BoW)  using scale-invariant feature transform (MoSIFT)  and STIP  features, Violent Flows (ViF) method , Local Motion method , also variant v-1 and variant v-2 methods that applied KNN, AdaBoost, and Random Forest classifiers. Although the proposed technique falls short from a perspective of performance, it has a much quicker calculation time, making it suitable for practical uses , .", "label": "human"}
{"ID": "00150048", "file_name": "Violence Detection in Surveillance Camera", "content": "RIMOC (Rotation-Invariant Feature Modelling Motion Coherence) Jerky and unstructured motion are often present in film with violent human behaviours due to the fact that aggressive occurrences are difficult to quantify owing to their unpredictability and sometimes need high-level interpretation. In order to capture its structure and distinguish the unstructured movements, a newFigure 2.4: Fast Fight Detection architecture  problem-specific ‘Rotation-Invariant feature modelling Motion Coherence’ (RIMOC) was suggested in 2016 .Figure 2.5: RIMOC architecture  As shown in Figure 2.5, RIMOC is based on eigenvalues calculated locally and densely from second-order statistics of Histograms of Optical Flow vectors from successive temporal instants, then embedded into a spheric Riemannian manifold.", "label": "human"}
{"ID": "00150049", "file_name": "Violence Detection in Surveillance Camera", "content": "In a poorly supervised way, the proposed RIMOC feature is utilized to develop statistical models of normal coherent movements. Events with irregular mobility may be identified in space and time using a multi-scale approach combined with an inference-based method, making them ideal candidates for aggressive events.", "label": "human"}
{"ID": "00150050", "file_name": "Violence Detection in Surveillance Camera", "content": "A big dataset is produced for this goal, which comprises of sequences from twodistinct sites: an in-lab fake train and a genuine underground railway , real train, and then four datasets are formed: fake train, real train, real train station, and real-life settings. These datasets are used in the trials, and the findings indicate that the suggested approach outperforms all state-of-the-art methods in terms of ROC per frame and false-positive rate , .", "label": "human"}
{"ID": "00150051", "file_name": "Violence Detection in Surveillance Camera", "content": "Motion Direction Inconsistency-Based Fight Detection for Multi view Surveillance Videos Yao et al. present a multiview fight detection technique based on optical flow statistical features and random forest . This technique may provide fast and reliable information to cyber-physical monitoring systems. Motion Direction Inconsistency (MoDI) and Weighted Motion Direction Inconsistency (WMoDI), two new descriptors, are developed to enhance the performance of current techniques for films with various filming perspectives and to address misjudgement on nonfighting activities like jogging and chatting.", "label": "human"}
{"ID": "00150052", "file_name": "Violence Detection in Surveillance Camera", "content": "Recognizing violent activity without decoding video streams Most conventional activity identification techniques’ motion target detection and tracking procedures are often complex, and their applicability is limited. To solve this problem, a fast method of violent activity recognition is introduced which is based on motion vectors .", "label": "human"}
{"ID": "00150053", "file_name": "Violence Detection in Surveillance Camera", "content": "First and foremost, the motion vectors were directly retrieved from compressed video segments. The motion vectors’ characteristics in each frame and between frames were then evaluated, and the Region Motion Vectors (RMV) descriptor was produced. To classify the RMV to identify aggressive situations in movies, a SVM classifier with radial basis kernel function was used in the final step. In order to evaluate the proposed method, the authors created VV AR10 dataset that consistsof 296 positive samples and 277 negative samples by sorting video clips from UCF sports , UCF50 , HMDB51  datasets. Experiments have shown that the proposed method can detect violent scenes with 96.1% accuracy in a short amount of time. That is why the proposed method can be used in embedded systems.", "label": "human"}
{"ID": "00150054", "file_name": "Violence Detection in Surveillance Camera", "content": "MoBSIFT Local spatiotemporal feature extractors have been explored in previous studies; nevertheless, they come with the overhead of complicated optical flow estimates.", "label": "human"}
{"ID": "00150055", "file_name": "Violence Detection in Surveillance Camera", "content": "Despite the fact that the temporal derivative is a faster alternative to optical flow, it produces a low-accuracy and scale-dependent result when used alone. As a result, a cascaded approach of violence detection was suggested, based on motion boundary SIFT (MoBSIFT) and a movement filtering method .", "label": "human"}
{"ID": "00150056", "file_name": "Violence Detection in Surveillance Camera", "content": "Crowd Violence Detection In computer vision, Lagrangian theory  offers a comprehensive set of tools for evaluating non-local, long-term motion information. Authors propose a specialized Lagrangian method for the automatic identification of violent situations in video footage based on this theory . The authors propose a new feature based on a spatiotemporal model that utilizes appearance, background motion correction, and long-term motion information and leverages Lagrangian direction fields as shown at 2.9. They use an expanded bag-of-words method in a late-fusion way as a classification strategy on a per-video basis to guarantee suitable spatial and temporal feature sizes.", "label": "human"}
{"ID": "00150057", "file_name": "Violence Detection in Surveillance Camera", "content": "A Video-Based DT–SVM School Violence Detecting Algorithm Figure 2.10: Video-based DT-SVM architecture  A new method for identifying school violence was proposed by Ye et al. in 2020 . As depicted in Figure 2.10, this technique uses the KNN algorithm to identify foreground moving objects and then uses morphological processing methods to pre-process the identified targets. Then, to optimize the circumscribed rectangular frame of moving objects, a circumscribed rectangular frame integrating technique was proposed. To explain the distinctions between school violence and everyday activities, rectangular frame characteristics and optical-flow featureswere retrieved. To decrease the feature dimension, the Relief-F and Wrapper algorithms were applied. SVM is used as a classifier, and a 5-fold cross-validation was conducted. The results show 94.4 percent precision and 89.6 percent accuracy.", "label": "human"}
{"ID": "00150058", "file_name": "Violence Detection in Surveillance Camera", "content": "In order to improve recognition performance, a DT–SVM two-layer classifier is created. Authors utilized boxplots to identify certain DT layer characteristics that can differentiate between everyday activities and physical violence. The SVM layer conducted categorization for the remaining activities. The accuracy of this DT–SVM classifier was 97.6 percent, while the precision was 97.2 percent, indicating a considerable increase , .", "label": "human"}
{"ID": "00150059", "file_name": "Violence Detection in Surveillance Camera", "content": "Gaussian Model of Optical Flow (GMOF) At the time existing vision-based techniques focus mostly on detecting violence and make very little attempt to pinpoint its location. To tackle this problem, Zhange et al. presented a quick and robust method for identifying and localizing violence in surveillance situations to address this issue .", "label": "human"}
{"ID": "00150060", "file_name": "Violence Detection in Surveillance Camera", "content": "Spatiotemporal Autocorrelation of Gradients (STACOG) One of the most important stages in the development of machine learning applications is data representation. Data representation that is efficient aids in better classification across classes. Deepak et al. investigate Spatiotemporal Autocorrelation of Gradients (STACOG) as a handmade feature for extracting violent activity characteristics from surveillance camera videos  as described in Figure 2.13.Figure 2.13: STACOG architecture  The proposed strategy is divided into two stages:", "label": "human"}
{"ID": "00150061", "file_name": "Violence Detection in Surveillance Camera", "content": "Extraction of STACOG based Features 2. Discriminative learning of violent/non-violent behaviour’s using an SVM Classifier Two well-known datasets were used to test the proposed approach: ‘Hockey fight’ dataset  that contains 1000 video clips and the ‘Crowd Violence’ Dataset. The proposed ‘STACOG features + SVM’ model shown 91.38% accuracy in violence detection overcoming state-of-the-art methods like HOF+BoW, HNF+BoF, ViF+SVM, BiLSTM, GMOF, and others.", "label": "human"}
{"ID": "00150062", "file_name": "Violence Detection in Surveillance Camera", "content": "Automatic real-time video-based surveillance system In video processing, aggression detection is critical, and a surveillance system that can operate reliably in an academic environment has become a pressing requirement.", "label": "human"}
{"ID": "00150063", "file_name": "Violence Detection in Surveillance Camera", "content": "To solve this problem, a novel framework for an automatic real-time video-based surveillance system is proposed .Figure 2.14: Automatic real-time video-based surveillance system architecture  As depicted in Figure 2.14, the proposed system is divided into three phases during the development process. The first stage is pre-processing stage that includes abnormal human activity detection and content-based image retrieval (CBIR) in the event that the system identifies unusual student behavior. In the first stage, students are registered by entering their personal data including first name, second name, birthday, course, student id card, and photos. The entered data is stored in a central database for conducting a search when abnormal actions are detected. The video is then turned into frames in the second step. Motion objects are detected using a temporal-differencing method, and motion areas are identified using the Gaussian function. Furthermore, a form model based on the OMEGA equation is employed as a filter for identified items, whether human or non-human. SVM is used to classify human behaviours into normal and abnormal categories. When a person engages in abnormal behaviour, the system issues an automated warning. It also adds a method to get the identified item from the database using CBIR for object detection and verification. Finally, a software-based simulation using MATLAB is performed, and experimental findings indicate that the system performs simultaneous tracking, semantic scene learning, and abnormality detection in an academic setting without the need of humans.", "label": "human"}
{"ID": "00150064", "file_name": "Violence Detection in Surveillance Camera", "content": "Framework for high-level activity analysis Song, Kim Park, in 2018, proposed a new framework for high-level activity analysis based on late fusion and multi-independent temporal perception layers,which is based on late fusion . It is possible to manage the temporal variety of high-level activities using this approach. Multi-temporal analysis, multi-temporal perception layers, and late fusion are all part of the framework.", "label": "human"}
{"ID": "00150065", "file_name": "Violence Detection in Surveillance Camera", "content": "Violence detection using deep learning techniques a, Violence detection using 3D CNN To build complicated handmade characteristics from inputs, most techniques require domain expertise. Deep learning methods, on the other hand, may operate directly on raw inputs and extract necessary features automatically. As a result, Ding et al. created a new 3D ConvNets approach for video violence detection, which does not need any previous information in 2014 .Figure 2.16: 3D CNN architecture  As depicted in Figure 2.16, the convolution on the collection of video frames is computed using a 3D CNN, and therefore motion information is retrieved from the input data. The back-propagation technique is used to obtain gradients and the model has been trained to apply supervised learning. Experimental validation was carried out in the context of the ‘Hockey fights’  dataset to assess the approach. The findings indicate that the approach outperforms manual features in terms of performance.", "label": "human"}
{"ID": "00150066", "file_name": "Violence Detection in Surveillance Camera", "content": "Real time violence detection using bidirectional LSTM (BDLSTM) A real-time violence detection system is presented, which analyses large amounts of streaming data and recognizes aggression using a human intelligence simulation .", "label": "human"}
{"ID": "00150067", "file_name": "Violence Detection in Surveillance Camera", "content": "Violent scene detection using CNN Deep Audio Features Violent scene detection system is proposed that uses CNN built on acoustic information from video clips . CNN is applied in two ways: a as a classifier directly or as a deep acoustic feature extractor.", "label": "human"}
{"ID": "00150068", "file_name": "Violence Detection in Surveillance Camera", "content": "CNN-based features are used to build SVM classifiers. Then the detection of violent scene is performed on each chunk of video. Then the detection is produced by max or min pooling on the segment-level detections. Experiments are performed via ‘MediaEval’ dataset  and results show that the proposed method performs better than the base methods: audio only, visual only and audio learned fusion and visual in terms of average precision.", "label": "human"}
{"ID": "00150069", "file_name": "Violence Detection in Surveillance Camera", "content": "Detect violent videos using Convolutional Long Short-term Memory (ConvLSTM) Sudhakaran Lanz (2017) proposed a deep neural network for detecting violent scenes in videos .Figure 2.19: ConvLSTM architecture  As described in Figure 2.19, to extract frame-level characteristics from a video, a CNN is applied. The frame-level characteristics are then accumulated using LSTM that uses a convolutional gate. The CNN, in combination with the ConvLSTM, can capture localized spatiotemporal characteristics, allowing for the analysis of local motion in the video. The paper also proposed feeding the model neighbouring frame differences as input, pushing it to encode the changes in the video. In terms of recognition accuracy, the presented feature extraction process is tested on three common benchmark datasets as ‘Hockey Fight’ , ‘Movie Fight’ ,and ‘Violent-Flows’ . Findings were compared to those produced using state of-the-art methods. It was discovered that the suggested method had a promising capacity for identifying violent films prevailing state-of-the-art methods as three streams + LSTM, ViF, and ViF+OViF .", "label": "human"}
{"ID": "00150070", "file_name": "Violence Detection in Surveillance Camera", "content": "Mask RCNN + LSTM To identify violent behaviours of a single person, an ensemble model of the Mask RCNN and LSTM was proposed . Initially, human key points and masks were extracted, and then temporal information was captured. Experiments have been performed on datasets such as, ‘Weizmann’ , ‘KTH’ . The results demonstrated that the proposed model outperforms individual models showing a violence detection accuracy rate of 93.4% in its best result. The proposed approach is more relevant to the industry, which is beneficial to society in terms of security.", "label": "human"}
{"ID": "00150071", "file_name": "Violence Detection in Surveillance Camera", "content": "Detecting human violent behaviour by integrating trajectory and deep CNN Typical violence detection approaches depend on hand-crafted features, which may be insufficiently discriminative for the job of recognizing violent actions.", "label": "human"}
{"ID": "00150072", "file_name": "Violence Detection in Surveillance Camera", "content": "Inspired by the performance of deep models for the recognition of human action, an innovative method for the detection of human violent behaviour by combining the trajectory and deep CNN is proposed that takes advantage of both handcrafted features and deep-learned features .Figure 2.20: Integrating trajectory and deep CNN architecture  To assess the proposed method, tests on two distinct violence datasets are performed:", "label": "human"}
{"ID": "00150073", "file_name": "Violence Detection in Surveillance Camera", "content": "‘Hockey Fights’  and ‘Crowd Violence’ dataset. On these datasets, the findings show that the proposed approach outperforms state-of-the-art methods like HOG, HOF, ViF, and others.", "label": "human"}
{"ID": "00150074", "file_name": "Violence Detection in Surveillance Camera", "content": "Violence detection using spatiotemporal features with 3D CNN In smart cities, schools, hospitals, and other surveillance domains, an improved security system is required for the identification of violent or aberrant actions in order to prevent any casualties that may result in social, economic, or environmental harm. For this purpose, a three-staged end-to-end deep learning violence detection system is presented Figure 2.21: Spatiotemporal features with 3D CNN architecture  As depicted in Figure 2.21, to minimize and overcome the excessive processing of useless frames, people are first identified in the surveillance video stream usinga lightweight CNN model. Secondly, a 16-frame sequence containing identified people is sent to 3D CNN, which extracts the spatiotemporal characteristics of the sequences and feeds them to the Softmax classifier. The authors also used open visual inference and neural networks optimization tools created by Intel to optimize the 3D CNN model, which transforms the training model into intermediate representation and modifies it for optimum execution at the end platform for the ultimate prediction of violent behaviour. When violent behaviour is detected, an alarm is sent to the closest police station or security agency so that immediate preventative measures may be taken. The datasets ‘Violent Crowd , ‘Hockey’ , and ‘Movies’  are used in the experiments. The experimental findings show that the proposed approach outperforms state-of-the-art algorithms such as ViF, AdaBoost, SVM, Hough Forest, and 2D CNN, sHOT, and others in terms of accuracy, precision, recall, and AUC.", "label": "human"}
{"ID": "00150075", "file_name": "Violence Detection in Surveillance Camera", "content": "Artificial Intelligence, Machine Learning, Deep Learning, Data Science are popular terms in this era. Knowing what they are and the differences between those areas is more crucial than ever.", "label": "human"}
{"ID": "00150076", "file_name": "Violence Detection in Surveillance Camera", "content": "Humans have long been obsessed with creating AI ever since the question, “Can machines think?”, was posed by Alan Turing in 1950. AI enables the machine to think, that is without any human intervention the machine will be able to take its own decision. It is a broad area of computer science that makes machines seem like they have human intelligence. So, it’s not only programming a computer to drive a car by obeying traffic signals but it’s when that program also learns to exhibit the signs of human-like road rage . Artificial Intelligence can be divided in to sub-fields based on the learning techniques they deploy as follows:Figure 2.22: Sub-fields of Artificial Intelligence  2.3.1 Machine Learning Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ‘training data’, in order to make predictions on unseen data or decisions without being explicitly programmed to do so . The accuracy of such predictions can be improved by adding more data samples to the training set, scaling the data, Hyper-parameter-tuning, using dimensionality reduction methods, etc. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.", "label": "human"}
{"ID": "00150077", "file_name": "Violence Detection in Surveillance Camera", "content": "Supervised Learning Supervised learning, also known as supervised machine learning, is a subcategory of machine learning and artificial intelligence. It is defined by its use of labelled datasets to train algorithms that to classify data or predict outcomes accurately. Asinput data is fed into the model, it adjusts its weights until the model has been fitted appropriately, which occurs as part of the cross-validation process. Supervised learning helps organizations solve for a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox . Supervised learning can be separated into two types of problems when mining data: Classification and Regression.", "label": "human"}
{"ID": "00150078", "file_name": "Violence Detection in Surveillance Camera", "content": "Classification Classification uses an algorithm to accurately assign test data into specific categories. It recognizes specific entities within the dataset and attempts to draw some conclusions on how those entities should be labelled or defined.", "label": "human"}
{"ID": "00150079", "file_name": "Violence Detection in Surveillance Camera", "content": "Supervised learning models can be used to build and advance a number of business applications, such as, image- and object-recognition, customer sentiment analysis, spam detection, etc. Common classification algorithms are ar classifiers, support vector machines (SVM), decision trees, k-nearest neighbours, and random forest, which are described in more detail below.", "label": "human"}
{"ID": "00150080", "file_name": "Violence Detection in Surveillance Camera", "content": "Logistic Regression is used when the dependent variable is categorical, meaning they have binary outputs, such as ”true” and ”false” or ”yes” and ”no.” The corresponding probability of the value labelled ”1” can vary between 0 (certainly the value ”0”) and 1 (certainly the value ”1”), hence the labelling; the function that converts log-odds to probability is the logistic function, hence the name.", "label": "human"}
{"ID": "00150081", "file_name": "Violence Detection in Surveillance Camera", "content": "As the number of independent variables increases, it is referred to as multiple ar regression. For each type of ar regression, it seeks to plot a  of best fit, which is calculated through the method of least squares. However, unlike other regression models, this  is straight when plotted on a graph.b, Unsupervised Learning Unsupervised Learning uses machine learning algorithms to analyse and cluster unlabelled data sets. These algorithms discover hidden patterns or data groupings without the need for human intervention. Its ability to discover similarities and differences in information make it the ideal solution for exploratory data analysis, cross-selling strategies, customer segmentation, and image recognition. Unsupervised learning models are used for three main tasks: clustering, association and dimensionality reduction.", "label": "human"}
{"ID": "00150082", "file_name": "Violence Detection in Surveillance Camera", "content": "Clustering Clustering is a data mining technique for grouping unlabelled data based on their similarities or differences. In simple words, the aim is to segregate groups with similar traits and assign them into clusters. This technique is helpful for market segmentation, image compression, etc.", "label": "human"}
{"ID": "00150083", "file_name": "Violence Detection in Surveillance Camera", "content": "Identify the two closest clusters 2. Merge those two clusters This iterative process continues until all the clusters are merged together.Association Association Rule Learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. It is intended to identify strong rules discovered in databases using some measures of interestingness. In any given transaction with a variety of items, association rules are meant to discover the rules that determine how or why certain items are connected based on a series of metrics such as, support and confidence.", "label": "human"}
{"ID": "00150084", "file_name": "Violence Detection in Surveillance Camera", "content": "Dimensionality reduction In machine learning classification problems, there are often too many factors on the basis of which the final classification is done. These factors are basically variables called features. The higher the number of features, the harder it gets to visualize the training set and then work on it. Sometimes, most of these features are correlated, and hence redundant. This is where dimensionality reduction algorithms come into play. Dimensionality reduction is the process of reducing the number of random variables under consideration, by obtaining a set of principal variables.There are two components of dimensionality reduction: feature selection and feature extraction.", "label": "human"}
{"ID": "00150085", "file_name": "Violence Detection in Surveillance Camera", "content": "Feature selection, also known as variable selection, is the process of selecting a subset of relevant features for use in model construction. Feature selection techniques are used for several reasons: simplification of models to make them easier to interpret by users, shorter training times, to avoid the curse of dimensionality, improve data’s compatibility with a learning model class, etc.", "label": "human"}
{"ID": "00150086", "file_name": "Violence Detection in Surveillance Camera", "content": "Feature extraction starts from an initial set of measured data and builds derived values (features) intended to be informative and non-redundant, facilitating the subsequent learning and generalization steps, and in some cases leading to better human interpretations.", "label": "human"}
{"ID": "00150087", "file_name": "Violence Detection in Surveillance Camera", "content": "Reinforcement Learning Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead, the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).Figure 2.28: The typical framing of a Reinforcement Learning scenario  Simply put, the purpose of reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the ”reward function” or other user-provided reinforcement signal that accumulates from the immediate rewards. This is similar to processes that appear to occur in animal psychology.", "label": "human"}
{"ID": "00150088", "file_name": "Violence Detection in Surveillance Camera", "content": "For example, biological brains are hardwired to interpret signals such as pain and hunger as negative reinforcements, and interpret pleasure and food intake as positive reinforcements. In some circumstances, animals can learn to engage in behaviours that optimize these rewards. Due to its generality, reinforcement learning is studied in many discips, such as game theory, control theory, operations research, information theory, statistics, etc.", "label": "human"}
{"ID": "00150089", "file_name": "Violence Detection in Surveillance Camera", "content": "Deep Learning Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behaviour of the human brain allowing it to “learn” from large amounts of data.", "label": "human"}
{"ID": "00150090", "file_name": "Violence Detection in Surveillance Camera", "content": "While a neural network with a single layer can still make approximate predictions, additional hidden layers can help to optimize and refine for accuracy.", "label": "human"}
{"ID": "00150091", "file_name": "Violence Detection in Surveillance Camera", "content": "Deep learning drives many artificial intelligence (AI) applications and services that improve automation, performing analytical and physical tasks without humanintervention. Deep learning technology lies behind everyday products and services (such as digital assistants, voice-enabled TV remotes, and credit card fraud detection) as well as emerging technologies (such as self-driving cars).", "label": "human"}
{"ID": "00150092", "file_name": "Violence Detection in Surveillance Camera", "content": "Note: Machine learning algorithms leverage structured, labelled data to make predictions—meaning that specific features are defined from the input data forthe model and organized into tables. Deep learning eliminates some of data pre processing that is typically involved with machine learning. These algorithms can ingest and process unstructured data, like text and images, and it automates feature extraction, removing some of the dependency on human experts. In machine learning, this hierarchy of features is established manually by a human expert.", "label": "human"}
{"ID": "00150093", "file_name": "Violence Detection in Surveillance Camera", "content": "Then, through the processes of gradient descent and back propagation, the deep learning algorithm adjusts and fits itself for accuracy, allowing it to make predictions with increased precision.", "label": "human"}
{"ID": "00150094", "file_name": "Violence Detection in Surveillance Camera", "content": "Neural Networks Neural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs) are at the heart of deep learning algorithms. Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another.", "label": "human"}
{"ID": "00150095", "file_name": "Violence Detection in Surveillance Camera", "content": "Neural networks rely on training data to learn and improve their accuracy over time. However, once these learning algorithms are fine-tuned for accuracy, they are powerful tools in computer science and artificial intelligence, allowing us to classify and cluster data at a high velocity. Tasks in speech recognition or image recognition can take minutes versus hours when compared to the manual identification by human experts. One of the most well-known neural networks is Google’s search algorithm .", "label": "human"}
{"ID": "00150096", "file_name": "Violence Detection in Surveillance Camera", "content": "Feedforward Neural Networks, or Multi-layer Perceptron (MLPs) are comprised of an input layer, a hidden layer or layers, and an output layer. While these neural networks are also commonly referred to as MLPs, it’s important to note that they are actually comprised of sigmoid neurons, not perceptrons, as most real-world problems are nonar. Data usually is fed into these models to train them, and they are the foundation for computer vision, natural language processing, and other neural networks.", "label": "human"}
{"ID": "00150097", "file_name": "Violence Detection in Surveillance Camera", "content": "Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height and depth. (Note that the word depth here refers to the third dimension of an activation volume, not to the depth of a full Neural Network, which can refer to the total number of layers in a network.) Figure 2.31: A ConvNet arranges its neurons in three dimensions: width, height and depth  A simple ConvNet is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through a differentiable function.", "label": "human"}
{"ID": "00150098", "file_name": "Violence Detection in Surveillance Camera", "content": "Three main types of layers are used to build ConvNet architectures: Convolutional Layer, Pooling Layer, and Fully-Connected Layer (exactly as seen in regular Neural Networks). We will stack these layers to form a full ConvNet architecture.", "label": "human"}
{"ID": "00150099", "file_name": "Violence Detection in Surveillance Camera", "content": "These learning algorithms are primarily leveraged when using time-series data to make predictions about future outcomes, such as stock market predictions or sales forecasting.", "label": "human"}
{"ID": "00150100", "file_name": "Violence Detection in Surveillance Camera", "content": "Recurrent neural networks are designed for this very purpose, while convolutional neural networks are incapable of effectively interpreting temporal information.", "label": "human"}
{"ID": "00150101", "file_name": "Violence Detection in Surveillance Camera", "content": "As a result, CNNs and RNNs are used for completely distinct purposes, and there are differences in the structures of the neural networks themselves to fit those different use cases. In general, RNNs allow us to wire up an architecture, where the prediction at every single timestep is a function of all the timesteps that have come before.", "label": "human"}
{"ID": "00150102", "file_name": "Violence Detection in Surveillance Camera", "content": "The cost function is the technique of evaluating “the performance of our algorithm/model”. It takes both predicted outputs by the model and actual outputs and calculates how much wrong the model was in its prediction.", "label": "human"}
{"ID": "00150103", "file_name": "Violence Detection in Surveillance Camera", "content": "It outputs a higher number if our predictions differ a lot from the actual values. As we tune our model to improve the predictions, the cost function acts as an indicator of how the model has improved. This is essentially an optimization problem. The optimization strategies always aim at “minimizing the cost function”. There are many cost functions in machine learning and each has its use cases depending on whether it is a regression problem (e.g.:", "label": "human"}
{"ID": "00150104", "file_name": "Violence Detection in Surveillance Camera", "content": "Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum or a local maximum of a given function. This method is commonly used in machine learning (ML) and deep learning (DL) to minimise a cost function (e.g., in a ar regression). However, its use is not limited to Machine Learning or Deep Learning only, it’s being widely used also in areas like, control engineering (robotics, chemical, etc.), computer games and mechanical engineering.", "label": "human"}
{"ID": "00150105", "file_name": "Violence Detection in Surveillance Camera", "content": "For a Gradient descent algorithm to work properly, a function should be differentiable (i.e.: has a derivative for each point in it’s domain) and convex (i.e.: the  segment between any two points on the graph of the function does not lie below the graph between the two points).Figure 2.33: Convex Vs. non-convex function  Gradient Descent Algorithm repetitively calculates the next point using gradient at the current position, then scales it by a user-defined learning rate () and subtracts obtained value from the current position. Simply put, the algorithm ‘takes a step’ towards the lowest point of the graph, which in this case is the smallest cost function, for each and every iteration until convergence. This process can be expressed as:", "label": "human"}
{"ID": "00150106", "file_name": "Violence Detection in Surveillance Camera", "content": "dxf(x) (2.1) It should be noted that the learning rate () has a strong influence on performance of the algorithm. If the learning rate is too small, it takes longer for Gradient Descent to converge, hence could be computationally expensive. Further, the algorithm may reach maximum iteration before reaching the optimum point.", "label": "human"}
{"ID": "00150107", "file_name": "Violence Detection in Surveillance Camera", "content": "On the other hand, if the learning rate is too large, the algorithm may not converge to the optimal point (jump around) or even to diverge completely.", "label": "human"}
{"ID": "00150108", "file_name": "Violence Detection in Surveillance Camera", "content": "In the Forward Propagation, the Activation Function is a mathematical “gate” in between the input feeding the current neuron and its output going to the next layer .In simpler terms, Forward Propagation follows 3 main steps:", "label": "human"}
{"ID": "00150109", "file_name": "Violence Detection in Surveillance Camera", "content": "Back propagation:Back propagation is the method of fine-tuning the weights of a neural network based on the ‘error rate’ obtained, as a result of the forward pass, in the previous epoch. Simply put, at the output layer, the forward pass will make a prediction, which might not be the correct prediction, hence giving rise to an ‘error’ (i.e.: the difference between the prediction and the ground-truth).", "label": "human"}
{"ID": "00150110", "file_name": "Violence Detection in Surveillance Camera", "content": "Then, the backward pass will travel back from the output layer to the hidden layers to adjust the weights in a way that the ‘error’ is reduced. This process, a forward pass followed by a backward pass, will be repeated until the neural network is optimized or stuck in a local optimum. In summary, proper tuning of the weights reduces error rates and make the model reliable by increasing its generalization.", "label": "human"}
{"ID": "00150111", "file_name": "Violence Detection in Surveillance Camera", "content": "Motion estimation methods Motion estimation is the process of determining motion vectors that describe the transformation from one 2D image to another; usually from adjacent frames in a video sequence. It is an ill-posed problem as the motion is in three dimensions but the images are a projection of the 3D scene onto a 2D plane. The motion vectors may relate to the whole image (global motion estimation) or specific parts, such as rectangular blocks, arbitrary shaped patches or even per pixel.", "label": "human"}
{"ID": "00150112", "file_name": "Violence Detection in Surveillance Camera", "content": "In order to perform motion estimation, the ‘correspondence’ between the considered frames must be taken in to account. In the domain of motion estimation, the ‘correspondence problem’ refers to the problem of ascertaining which parts of one image correspond to which parts of another image, where differences are due to movement of the camera, the elapse of time, and/or movement of objects in the photos.", "label": "human"}
{"ID": "00150113", "file_name": "Violence Detection in Surveillance Camera", "content": "Direct methods Block-matching algorithm, Pixel recursive algorithms and Optical flow are a few examples for direct methods of motion estimation.", "label": "human"}
{"ID": "00150114", "file_name": "Violence Detection in Surveillance Camera", "content": "Optical flow is the motion of objects between consecutive frames of sequence, caused by the relative movement between the object and camera. Based on the pixels that’s being processed, there are two main methods: Sparse and Dense Optical flow.", "label": "human"}
{"ID": "00150115", "file_name": "Violence Detection in Surveillance Camera", "content": "The abstract architecture of our proposed violence detection method is illustrated in Figure 3.4. It consists of three steps: human detection, candidate box extraction, and feature extraction and classification.", "label": "human"}
{"ID": "00150116", "file_name": "Violence Detection in Surveillance Camera", "content": "Finally, the extracted features are classified using a fully connected layer to decide whether the group acts are violent or not.", "label": "human"}
{"ID": "00150117", "file_name": "Violence Detection in Surveillance Camera", "content": "Human detection In this thesis’s topic, the surveillance cameras capture a wide outdoor area as input to our method. Because the camera is placed at a high place (8 meters) compared to the ground level, the region of interest (human group) in a framewould be considerred small despite having full HD resolution. For example, at a distance of 16 meters, the area that includes a violent group of three people occupies only approximately 0.8% of the entire input frame. Consequently, using the original frames serves directly as input for the feature extraction and classification stage could lead to background noise and cause poor performance. Additionally, in order to be fed into a 3D CNN, each frame has to be resized resulting in a very small number of pixels for human groups which would cause low accuracy. Therefore, human detection and region of interest selection in the frames are crucial. YOLOv4  model is chosen as a human detector since it is capable of balance between speed and accuracy as well as being suitable for detecting small objects at long distances. It receives the frame sequences as input and returns information about the position and size of the human bounding boxes on those frames.", "label": "human"}
{"ID": "00150118", "file_name": "Violence Detection in Surveillance Camera", "content": "Candidate box extraction Figure 3.4: Steps of candidate box estraction We developed this step based on Human Area Detection algorithm . After detecting bounding boxes of humans, the goal is to determine and crop areas (called candidate boxes) containing groups of humans. There are two sub-steps in this stage namely group finding and group cropping as depicted in Figure ??.", "label": "human"}
{"ID": "00150119", "file_name": "Violence Detection in Surveillance Camera", "content": "The target of the first sub-step is to determine groups of close people because these are the only areas where violent acts couple potentially happen. Firstly, the Euclidean distance between each pair of human bounding box centroids is calculated. Afterward, people are considered to be in a candidate group if the distance is smaller than a threshold (dynamically changed based on the size of human bounding boxes).", "label": "human"}
{"ID": "00150120", "file_name": "Violence Detection in Surveillance Camera", "content": "The main goal of the consecutive step is to crop input frames into groups of humans which are called candidate boxes (each frame could contain none, one, or multiple groups). A containing box is determined based on the outermost edgesof bounding boxes of each candidate group. After that, the containing box is expanded to generate the corresponding candidate box using (3.1) and (3.2) with S average human bounding box area - is calculated using (3.3) and constant k (ratio of average human bounding box area in a group) is 20% based on our survey.", "label": "human"}
{"ID": "00150121", "file_name": "Violence Detection in Surveillance Camera", "content": "However, if the width and height of candidate boxes do not ensure longer than one of containing boxes, the width and height of containing boxes will be selected to not ignore important information about humans.", "label": "human"}
{"ID": "00150122", "file_name": "Violence Detection in Surveillance Camera", "content": "Height =r k(3.1) Width =r S=Σm i=1Si m(3.3) Similarly, candidate boxes are generated and resized to 320x240 for the next 15 consecutive frames. The feature-extraction-and-classification stage uses every 16 consecutive frames to determine whether a group is violent or not.", "label": "human"}
{"ID": "00150123", "file_name": "Violence Detection in Surveillance Camera", "content": "Feature extraction and Classification In general, among non-fusion deep learning algorithms experimented on the AICS-Violence dataset, 3D DenseNet Lean  method achieved the highest accuracy on the Cam1 test set, on the other hand, its performance on the Cam2 test set witnessed a significant decrease as depicted in details at section ??. Furthermore, our preliminary experiments illustrated that using visualized optical flow as input for 3D DenseNet Lean  yielded remarkable improvement (from 82.03 to 93.7% of accuracy) for the Cam2 test set meanwhile only facing a slight dec in performance on the Cam1 test set. Therefore, we proposed a novel method to combine the strengths of visualized optical flow and 3D DenseNet Lean  in order to perform better on both test sets. Figure 3.5 shows the architecture of our proposed method.Figure 3.5: Architecture of our proposed method In our proposed method, two different 3D DenseNet Lean ’s feature extractor streams are utilized to generate features, R= [r1r2...rn]TandO= [o1o2...on]Tfrom RGB and visualized optical flow frame sequences respectively. Consecutively, both feature vectors are fused to create global features Fb= [fb1fb2...fbn]T. Finally, a fully-connected layer will be used to classify the fused features.", "label": "human"}
{"ID": "00150124", "file_name": "Violence Detection in Surveillance Camera", "content": "Particularly, at the fusion step, the feature vector O= [o1o2...on]T, extracted by 3D DenseNet Lean  on the visualized optical flow, is then normalized to L= [l1l2...ln]Tusing (3.4). After that, element-wise multiplication is applied to L andRas in (3.5) to augment features extracted from moving areas.", "label": "human"}
{"ID": "00150125", "file_name": "Violence Detection in Surveillance Camera", "content": "L=O max(O)= [O1 max(O)O2 max(O)...On max(O)]T(3.4) Fb= [fb1fb2...fbn]T=O.R= [o1.r1o2.r2...on.rn]T(3.5)4.1 Evaluation metrics True class Positive Negative Predicted classPositive TP FP Negative FN TN Table 4.1: Confusion matrix ACC =TP+TN TP+FN+TN+FP(4.1) Confusion matrix and accuracy (ACC), described at Table 4.1 and (4.1) respectively, are used to evaluate performances of SOTA and our proposed method.", "label": "human"}
{"ID": "00150126", "file_name": "Violence Detection in Surveillance Camera", "content": "Confusion matrix provides information of predicted classes of a classification model and corresponding actual labels including: true positive (TP) - the correct prediction number that the violent video is predicted as violence, false positive (FP) - the incorrect prediction number that the non-violent video is predicted as violence, true negative (TN) - the correct prediction number that the non-violent video is predicted as non-violence, and false negative (FN) - the incorrect prediction number that the violent video is predicted as non-violence.", "label": "human"}
{"ID": "00150127", "file_name": "Violence Detection in Surveillance Camera", "content": "Accuracy, computed as ratio between the number of correct predictions (TP and TN) and all predictions (TP, TN, FP, and FN), describes generally the model performance across all classes.", "label": "human"}
{"ID": "00150128", "file_name": "Violence Detection in Surveillance Camera", "content": "Evaluation on AICS - violence dataset To create a base for the AICS - violence dataset, we have evaluated the accuracies of some SOTA methods in action recognition in general and violence detection in particular namely Convolutional 3D (C3D) , Convolutional Long Short Term Memory (ConvLSTM) , 3D DenseNet , and Two-Stream Network for Violence Detection Using Separable Convolutional LSTM (TSSCL) .", "label": "human"}
{"ID": "00150129", "file_name": "Violence Detection in Surveillance Camera", "content": "As described in section 3.1, the AICS - violence dataset contains a training set and 2 test sets. The ratio of each test set to the training set is 1:9. Furthermore, during training stage, 20% of the training set is split as a validation set which is used for tuning hyper-parameters (such as epoch, batch size, learning rate,...) We selected fine-tuning through the full network as our transfer learning strategyfor all base methods. All base SOTA are pre-trained on standard benchmark datasets including Kinetics , ImageNet , and RWF-2000 . The three mentioned well-known datasets consist of about 400, 500, and 1000 samples per class respectively. However, only Kinetics  and RWF-2000 ’s contents, which are human action and violence on surveillance cameras, are similar to the AICS - violence dataset. Therefore, compared to those datasets, the AICS - violence dataset, which consists of more than 3000 images per class, could be considered large. In conclusion, we could fine-tune the entire network with significant concern about overfitting.", "label": "human"}
{"ID": "00150130", "file_name": "Violence Detection in Surveillance Camera", "content": "Besides, as depicted in Table 4.2, hyper-parameters (such as batch size, epoch, and learning rate) are selected to balance the capacity of our GPU (depicted in 4.2.3 and the convergence of models.", "label": "human"}
{"ID": "00150131", "file_name": "Violence Detection in Surveillance Camera", "content": "Method Learning rate Batch size Epoch C3D  10−48 100 ConvLSTM  10−332 100 3D DenseNet  10−332 100 3D DenseNet Lean  10−332 100 TSSCL-A  5−54 50 TSSCL-C  5−54 50 TSSCL-M  5−54 50 Table 4.2: Selected hyper-parameters for base methods 4.2.2 Evaluation on standard benchmark dataset We selected Hockey Fights , a well-known benchmark dataset, to further evaluate our proposed model. The dataset consists of fighting clips from Hockey matches that are not what our proposed method is meant to be trained on. However, we want to test our model’s generalizability in different scenarios.", "label": "human"}
{"ID": "00150132", "file_name": "Violence Detection in Surveillance Camera", "content": "As mentioned in section ??, our proposed method is developed from 3D DenseNet Lean  Therefore, in this experiment, we compare these 2 approaches on the Hockey Fights dataset .", "label": "human"}
{"ID": "00150133", "file_name": "Violence Detection in Surveillance Camera", "content": "Hockey Fights Dataset  consists of 1000 clips including fighting and normal plays captured in hockey matches. We split the dataset into training and test sets containing 800 and 200 samples respectively.", "label": "human"}
{"ID": "00150134", "file_name": "Violence Detection in Surveillance Camera", "content": "Finally, epoch, batch size, and learning rate are 150, 32, and 10−3respectively for all models.4.2.3 Infrastructures and frameworks To conduct all mentioned experiments, we used HP Workstation Z640 having GeForce GTX 1080 Ti GPU with 12GB VRAM. Additionally, famous deep learning frameworks such as PyTorch , and TensorFlow  are utilized for implementing algorithms.4.3 Results on AICS - violence dataset 4.3.1 Results of base methods on AICS - violence dataset (a)C3D (b)ConvLSTM (c)3D DenseNet (d)3D DenseNet Lean (e)TSSCL-A (f)TSSCL-C (g)TSSCL-M Figure 4.1: Training and validation losses of base methods on AICS - violence dataset Figure 4.1 illustrated changes in training and validation losses over epochs for each selected base method. In general, with the selected hyper-parametersdepicted in 4.2, all base methods converged. However, 3D DenseNet  and 3D DenseNet Lean  optimized losses at a significantly faster speed (converged after around 30 epochs) compared to the remaining algorithms (achieved best results after about 40 to 70 epochs).", "label": "human"}
{"ID": "00150135", "file_name": "Violence Detection in Surveillance Camera", "content": "C3D (b)ConvLSTM (c)3D DenseNet (d)3D DenseNet Lean (e)TSSCL-A (f)TSSCL-C (g)TSSCL-M Figure 4.2: Training and validation accuracies of base methods on AICS - violence datasetFigure 4.2 depicts changes in training and validation accuracy over epochs for base methods. Generally, among all experimented methods, only three TSSCL variants  do not have overfitting. However, the 4 remaining methods only face an insignificant of that problem. Particularly, the difference between the best validation and corresponding training accuracies of C3D , ConvLSTM , 3D DenseNet , and 3D DenseNet Lean  are 1.8, 1.82, 0.3, and 0.5 Figure 4.3: Comparison of validation accuracy over epoch of base methods on AICS violence dataset Figure 4.3 illustrates the changes in validation accuracies over epochs for all selected base methods. Generally, all base methods have robust performance (more than 95%) on the validation set of the AICS - violence dataset. Among them, 3D DenseNet  achieves the highest performance followed by its lightweight version - 3D DenseNet Lean , and 3 variants of TSSCL . Finally, the worstperformances belong to ConvLSTM  and C3D  consecutively.4.3.2 Comparison of our proposed and base methods on AICS  violence testsets MethodAccuracy on test sets (%) Cam1 Cam2 C3D  76.25 67.25 ConvLSTM  91.75 90.25 3D DenseNet  95.2 81.98 3D DenseNet Lean  96.55 82.03 TSSCL-A  95 95 TSSCL-C  92.5 92.75 TSSCL-M  96.25 94.25 3D DenseNet Fusion OF RGB  97.33 92.55 Our proposed method 97.675 93.55 Table 4.3: Comparison of base and our proposed methods on AICS - violence test sets.", "label": "human"}
{"ID": "00150136", "file_name": "Violence Detection in Surveillance Camera", "content": "MethodsAccuracy (%) 3D DenseNet Lean  98.5 Our proposed method 97 Table 4.6: Comparison of our proposed method and 3D DenseNet Lean  on Hockey Fights test set Table 4.6 describes accuracies of 3D DenseNet Lean  and our proposed methods. Generally, both methods achieved high accuracies on the Hockey Fight dataset  (At least 97%). However, there is a significant dec in the generalization of our fusion method compared to 3D DenseNet Lean  (From 98.5 to 97%).", "label": "human"}
{"ID": "00150137", "file_name": "Violence Detection in Surveillance Camera", "content": "Our model extracted normalized features from visualized optical flow, then use it to augment features from RGB images. Therefore, Hockey fight scenes are captured from moving cameras which will cause noise. In conclusion, our method performs better on fixed cameras (such as surveillance) rather than on moving ones.In this thesis, we have extended test sets of the AICS-Violence dataset which is designed specifically for outdoor surveillance cameras. Furthermore, a preprocessing method (based on a previous Human Area Detection algorithm) was proposed to focus on each group of people called candidate boxes. Finally, a novel method was introduced for violence detection by fusing features extracted from RGB and visualized optical flow frames using a 3D CNN. We then evaluated them on the extended test sets. Results illustrate that our proposed approach achieves high accuracies compared to other SOTA methods. In the future, we will enhance our models to achieve higher performance on more different camera views and angles. I. for Economics and P. (IEP), “Measuring the global economic impact of violence and conflict,” inThe Economic Value of Peace - 2016 December 21, 2016.", "label": "human"}
{"ID": "00150138", "file_name": "Violence Detection in Surveillance Camera", "content": "L. L. Jiangfan Feng Yukun Liang, “Anomaly detection in videos using two stream autoencoder with post hoc interpretability,” inComputational Intelligence and Neuroscience: 7367870 2021.", "label": "human"}
{"ID": "00150139", "file_name": "Violence Detection in Surveillance Camera", "content": "T. B. Mehran Yazdi, inNew trends on moving object detection in video images captured by a moving camera: A survey, Computer Science Review, Volume 28, 2018 .", "label": "human"}
{"ID": "00150140", "file_name": "Violence Detection in Surveillance Camera", "content": "E. Z. Amira Ben Mabrouk, inAbnormal behavior recognition for intelligent video surveillance systems: A review, Expert Systems with Applications, Volume 91, 2018: ISSN 0957-4174 .", "label": "human"}
{"ID": "00150141", "file_name": "Violence Detection in Surveillance Camera", "content": "J. C. Z. Shao and Z. Wang, “Smart monitoring cameras driven intelligent processing to big surveillance video data,” inn IEEE Transactions on Big Data, vol. 4, no. 1 March 01, 2018.", "label": "human"}
{"ID": "00150142", "file_name": "Violence Detection in Surveillance Camera", "content": "M. D. Genemo, “Suspicious activity recognition for monitoring cheating in exams,” Proceedings of the Indian National Science Academy. Part A, Physical Sciences ,jourvol 88,number 1, 1—10, 2022, ISSN : 0370-0046.", "label": "human"}
{"ID": "00150143", "file_name": "Violence Detection in Surveillance Camera", "content": "V . K. D. Nguyen Hong Son, “Violence detection in video using optical flowand deep learning features,” School of Electronics, Telecommunications  Hanoi University of Science andTechnology, VN), year = 2021.", "label": "human"}
{"ID": "00150144", "file_name": "Violence Detection in Surveillance Camera", "content": "Z. Z. G. A. K. M. Omarov B Narynov S, “State-of-the-art violence detection techniques in video surveillance security systems: A systematic review,” 2022, ISSN : 10.7717/peerj-cs.920.", "label": "human"}
{"ID": "00150145", "file_name": "Violence Detection in Surveillance Camera", "content": "N. Dalal andB. Triggs, “Histograms of oriented gradients for human detection,” in2005 IEEE computer society conference on computer vision and pattern recognition (CVPR’05) Ieee, volume 1, 2005, pages 886–893.", "label": "human"}
{"ID": "00150146", "file_name": "Violence Detection in Surveillance Camera", "content": "N. Dalal, B. Triggs andC. Schmid, “Human detection using oriented histograms of flow and appearance,” inEuropean conference on computer vision Springer, 2006, pages 428–441.", "label": "human"}
{"ID": "00150147", "file_name": "Violence Detection in Surveillance Camera", "content": "I. Laptev andT. Lindeberg, “Local descriptors for spatio-temporal recognition,” inInternational Workshop on Spatial Coherence for Visual Motion Analysis Springer, 2004, pages 91–103.", "label": "human"}
{"ID": "00150148", "file_name": "Violence Detection in Surveillance Camera", "content": "Q. Zhang, M. Zhang, T. Chen, Z. Sun, Y . Ma and B. Yu, “Recent advances in convolutional neural network acceleration,” july 2018.", "label": "human"}
{"ID": "00150149", "file_name": "Violence Detection in Surveillance Camera", "content": "G. Csurka, C. Dance, L. Fan, J. Willamowski andC. Bray, “Visual categorization with bags of keypoints,” inWorkshop on statistical learning in computer vision, ECCV Prague, volume 1, 2004, pages 1–2.", "label": "human"}
{"ID": "00150150", "file_name": "Violence Detection in Surveillance Camera", "content": "A. Lopes, E. Jr andA. Ara ´ujo, “Action recognition in videos: From motion capture labs to the web,” ArXiv CoRR ,june 2010.", "label": "human"}
{"ID": "00150151", "file_name": "Violence Detection in Surveillance Camera", "content": "K. Soomro, A. R. Zamir and M. Shah, “UCF101: A dataset of 101 human actions classes from videos in the wild,” CoRR ,jourvol abs/1212.0402, 2012.", "label": "human"}
{"ID": "00150152", "file_name": "Violence Detection in Surveillance Camera", "content": "E. Bermejo Nievas, O. Deniz Suarez, G. Bueno Garc ´ıaand R. Sukthankar, “Violence detection in video using computer vision techniques,” inComputer Analysis of Images and Patterns P. Real, D. Diaz-Pernil, H. Molina-Abril, A. Berciano andW. Kropatsch, editors , Berlin, Heidelberg: Springer Berlin Heidelberg, 2011, pages 332–339, ISBN : 978-3-642-23678-5.", "label": "human"}
{"ID": "00150153", "file_name": "Violence Detection in Surveillance Camera", "content": "P. Wang, P. Wang andE. Fan, “Violence detection and face recognition based on deep learning,” Pattern Recognition Letters ,jourvol 142, pages 20–24, february 2021. DOI:10.1016/j.patrec.2020.11.018 .", "label": "human"}
{"ID": "00150154", "file_name": "Violence Detection in Surveillance Camera", "content": "U. P andL. G G, “Skeleton-based stip feature and discriminant sparse coding for human action recognition,” International Journal of Intelligent Unmanned Systems ,jourvol 9,pages 20–24, february 2021. DOI:10 . 1016 / j .", "label": "human"}
{"ID": "00150155", "file_name": "Violence Detection in Surveillance Camera", "content": "F. Souza and H. Pedrini, “Detection of violent events in video sequences based on census transform histogram,” october 2017, pages 323–329. DOI:", "label": "human"}
{"ID": "00150156", "file_name": "Violence Detection in Surveillance Camera", "content": "Q. Zhang, M. Zhang, T. Chen, Z. Sun, Y . Ma andB. Yu, “Recent advances in convolutional neural network acceleration,” CoRR ,jourvol abs/1807.08596, 2018. arXiv: 1807.08596 .url:", "label": "human"}
{"ID": "00150157", "file_name": "Violence Detection in Surveillance Camera", "content": "P. C. Ribeiro, R. Audigier andQ. C. Pham, “Rimoc, a feature to discriminate unstructured motions: Application to violence detection for video-surveillance,” Computer Vision and Image Understanding ,jourvol 144, pages 121–143,2016, Individual and Group Activities in Video Event Analysis, ISSN : 1077 3142. DOI: .", "label": "human"}
{"ID": "00150158", "file_name": "Violence Detection in Surveillance Camera", "content": "C. Yao, X. Su, X. Wang, X. Kang, J. Zhang and J. Ren, “Motion direction inconsistency-based fight detection for multiview surveillance videos,” Wireless Communications and Mobile Computing ,jourvol 2021, pages 1–11, may 2021. DOI:10.1155/2021/9965781 .", "label": "human"}
{"ID": "00150159", "file_name": "Violence Detection in Surveillance Camera", "content": "Y . Wang, K. Huang and T. Tan, “Human activity recognition based on r transform,” june 2007. DOI:10.1109/CVPR.2007.383505 . T. Zhang, W. Jia, B. Yang, J. Yang, X. He and Z. Zheng, “Mowld: A robust motion image descriptor for violence detection,” Multimedia Tools and Applications , jourvol 76,january 2017. DOI:10.1007/s11042-015-3133-0 .", "label": "human"}
{"ID": "00150160", "file_name": "Violence Detection in Surveillance Camera", "content": "V . Machaca Arceda, K. Fern ´andez Fabi ´an, P. Laguna Laura, J. Rivera Tito andJ. Guti ´errez C ´aceres, “Fast face detection in violent video scenes,” Electronic Notes in Theoretical Computer Science ,jourvol 329, pages 5–26, 2016, CLEI 2016 - The Latin American Computing Conference, ISSN : 1571-0661.", "label": "human"}
{"ID": "00150161", "file_name": "Violence Detection in Surveillance Camera", "content": "M. Rahman, R. Rahman, K. A. Supty andothers , “A real time abysmal activity detection system towards the enhancement of road safety,” in2022 2nd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET) 2022, pages 1–5. DOI:10.1109/ IRASET52964.2022.9738165 .", "label": "human"}
{"ID": "00150162", "file_name": "Violence Detection in Surveillance Camera", "content": "J. Xie, W. Yan, C. Mu, T. Liu, P. Li and S. Yan, “Recognizing violent activity without decoding video streams,” Optik ,jourvol 127, number 2, pages 795–801, 2016, ISSN : 0030-4026. DOI:", "label": "human"}
{"ID": "00150163", "file_name": "Violence Detection in Surveillance Camera", "content": "K. Reddy and M. Shah, “Recognizing 50 human action categories of web videos,” Machine Vision and Applications ,jourvol 24,july 2013. DOI:10.", "label": "human"}
{"ID": "00150164", "file_name": "Violence Detection in Surveillance Camera", "content": "I. P. Febin, K. Jayasree and P. T. Joy, “Violence detection in videos for an intelligent surveillance system using mobsift and movement filtering algorithm,”Pattern Anal. Appl. ,jourvol 23,number 2, 611–623, 2020, ISSN : 1433 7541. DOI:10.1007/s10044-019-00821-3 .url:", "label": "human"}
{"ID": "00150165", "file_name": "Violence Detection in Surveillance Camera", "content": "V . Kantorov andI. Laptev, “Efficient feature extraction, encoding, and classification for action recognition,” inProceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition jourser CVPR ’14, USA: IEEE Computer Society, 2014, 2593–2600, ISBN : 9781479951185. DOI:10.1109/CVPR.", "label": "human"}
{"ID": "00150166", "file_name": "Violence Detection in Surveillance Camera", "content": "T. Senst, V . Eiselein, A. Kuhn and T. Sikora, “Crowd violence detectionusing global motion-compensated lagrangian features and scale-sensitive video level representation,” IEEE Transactions on Information Forensics and Security , jourvol PP,pages 1–1, july2017. DOI:10.1109/TIFS.2017.2725820 . T. Hassner, Y . Itcher andO. Kliper-Gross, “Violent flows: Real-time detectionof violent crowd behavior,” june 2012, pages 1–6, ISBN : 978-1-4673-1611 8.DOI:10.1109/CVPRW.2012.6239348 .", "label": "human"}
{"ID": "00150167", "file_name": "Violence Detection in Surveillance Camera", "content": "T. Cheng andD. Williams, “Space-time analysis of crime patterns in central london,” International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives ,jourvol 39,pages 47–52, july 2012. DOI:10.5194/isprsarchives-XXXIX-B2-47-2012 .", "label": "human"}
{"ID": "00150168", "file_name": "Violence Detection in Surveillance Camera", "content": "L. Ye, L. Wang, H. Ferdinando, T. Sepp ¨anen and E. Alasaarela, “A video based dt–svm school violence detecting algorithm,” Sensors (Basel, Switzerland) , jourvol 20, 2020.", "label": "human"}
{"ID": "00150169", "file_name": "Violence Detection in Surveillance Camera", "content": "T. Zhang, Z. Yang, W. Jia, B. Yang, J. Yang and X. He, “A new method for violence detection in surveillance scenes,” Multimedia Tools and Applications , jourvol 75,pages 7327–7349, 2015.", "label": "human"}
{"ID": "00150170", "file_name": "Violence Detection in Surveillance Camera", "content": "Y . Gao, H. Liu, X. Sun, C. Wang and Y . Liu, “Violence detection using oriented violent flows,” Image and Vision Computing ,jourvol 48-49, february 2016. DOI:10.1016/j.imavis.2016.01.006 .", "label": "human"}
{"ID": "00150171", "file_name": "Violence Detection in Surveillance Camera", "content": "k. xu, X. Jiang and T. Sun, “Anomaly detection based on stacked sparse coding with intraframe classification strategy,” IEEE Transactions on Multimedia , jourvol PP,pages 1–1, march 2018. DOI:10.1109/TMM.2018.2818942 .", "label": "human"}
{"ID": "00150172", "file_name": "Violence Detection in Surveillance Camera", "content": "D. K., V . L.K.P. and C. S., “Autocorrelation of gradients based violence detection in surveillance videos,” ICT Express ,jourvol 6,number 3,pages 155–159, 2020, ISSN : 2405-9595. DOI:https : / / doi . org / 10 . 1016 / j .", "label": "human"}
{"ID": "00150173", "file_name": "Violence Detection in Surveillance Camera", "content": "M. Al-N’awashi, O. Al-hazaimeh and M. Saraee, “A novel framework for intelligent surveillance system based on abnormal human activity detection in academic environments,” Neural Computing and Applications ,jourvol 28, december 2017. DOI:10.1007/s00521-016-2363-z .", "label": "human"}
{"ID": "00150174", "file_name": "Violence Detection in Surveillance Camera", "content": "D. Song, K. Chansu andS.-K. Park, “A multi-temporal framework for high level activity analysis: Violent event detection in visual surveillance,” Information Sciences ,jourvol 447, march 2018. DOI:10.1016/j.ins.2018.02.", "label": "human"}
{"ID": "00150175", "file_name": "Violence Detection in Surveillance Camera", "content": "N. Zhuang, G.-J. Qi, T. Kieu and K. Hua, “Differential recurrent neural network and its application for human activity recognition,” may 2019.", "label": "human"}
{"ID": "00150176", "file_name": "Violence Detection in Surveillance Camera", "content": "P. Vashistha, C. Bhatnagar and M. A. Khan, “An architecture to identify violence in video surveillance system using vif and lbp,” in2018 4th International Conference on Recent Advances in Information Technology (RAIT) 2018, pages 1–6. DOI:10.1109/RAIT.2018.8389027 .", "label": "human"}
{"ID": "00150177", "file_name": "Violence Detection in Surveillance Camera", "content": "C. Ding, S. Fan, M. Zhu, W. Feng and B. Jia, “Violence detection in video by using 3d convolutional neural networks,” inISVC 2014.", "label": "human"}
{"ID": "00150178", "file_name": "Violence Detection in Surveillance Camera", "content": "D. R, E. Fenil, G. Manogaran andothers , “Real time violence detection framework for football stadium comprising of big data analysis and deep learning through bidirectional lstm,” Computer Networks ,jourvol 151, march 2019. DOI:10.1016/j.comnet.2019.01.028 .", "label": "human"}
{"ID": "00150179", "file_name": "Violence Detection in Surveillance Camera", "content": "G. Mu, H. Cao and Q. Jin, “Violent scene detection using convolutional neural networks and deep audio features,” volume 663, november 2016,pages 451–463, ISBN : 978-981-10-3004-8. DOI:10.1007/978-981 10-3005-5_37 .", "label": "human"}
{"ID": "00150180", "file_name": "Violence Detection in Surveillance Camera", "content": "S. Sudhakaran andO. Lanz, “Learning to detect violent videos using convolutional long short-term memory,” CoRR ,jourvol abs/1709.06531, 2017. arXiv: 1709.", "label": "human"}
{"ID": "00150181", "file_name": "Violence Detection in Surveillance Camera", "content": "A. Naik and M. Gopalakrishna, “Deep-violence: Individual person violent activity detection in video,” Multimedia Tools and Applications ,jourvol 80, pages 1–16, may 2021. DOI:10.1007/s11042-021-10682-w .", "label": "human"}
{"ID": "00150182", "file_name": "Violence Detection in Surveillance Camera", "content": "M. Blank, L. Gorelick, E. Shechtman, M. Irani and R. Basri, “Action as space-time shapes,” volume 29,november 2005, 1395–1402 V ol. 2, ISBN :", "label": "human"}
{"ID": "00150183", "file_name": "Violence Detection in Surveillance Camera", "content": "C. Sch ¨uldt, I. Laptev and B. Caputo, “Recognizing human actions: A localsvm approach,” volume 3,september 2004, 32 –36 V ol.3, ISBN : 0-7695 2128-2. DOI:10.1109/ICPR.2004.1334462 .", "label": "human"}
{"ID": "00150184", "file_name": "Violence Detection in Surveillance Camera", "content": "Z. Meng, J. Yuan andZ. Li, “Trajectory-pooled deep convolutional networks for violence detection in videos,” inInternational Conference on Computer Vision Systems Springer, 2017, pages 437–447.", "label": "human"}
{"ID": "00150185", "file_name": "Violence Detection in Surveillance Camera", "content": "F. Ullah, A. Ullah, K. Muhammad, I. Haq and S. Baik, “Violence detection using spatiotemporal features with 3d convolutional neural network,” English,Sensors (Switzerland) ,jourvol 19,number 11,june 2019, ISSN : 1424-8220.", "label": "human"}
{"ID": "00150186", "file_name": "Violence Detection in Surveillance Camera", "content": "Optical flow ,flow - and - why - does - it - matter - in - deep - learning  b3278bb205b5 , Accessed: 2022-7-30.", "label": "human"}
{"ID": "00150187", "file_name": "Violence Detection in Surveillance Camera", "content": "A. Bochkovskiy, C. Wang and H. M. Liao, “Yolov4: Optimal speed and accuracy of object detection,” CoRR ,jourvol abs/2004.10934, 2020. arXiv:", "label": "human"}
{"ID": "00150188", "file_name": "Violence Detection in Surveillance Camera", "content": "D. Tran, L. Bourdev, R. Fergus, L. Torresani andM. Paluri, “Learning spatiotemporal features with 3D convolutional networks,” in2015 IEEE International Conference on Computer Vision (ICCV) Santiago, Chile: IEEE, december 2015.", "label": "human"}
{"ID": "00150189", "file_name": "Violence Detection in Surveillance Camera", "content": "X. Shi, Z. Chen, H. Wang, D.-Y . Yeung, W. K. Wong and W.-c. WOO, “Convolutional lstm network: A machine learning approach for precipitation nowcasting,” june 2015.", "label": "human"}
{"ID": "00150190", "file_name": "Violence Detection in Surveillance Camera", "content": "Z. Islam, M. Rukonuzzaman, R. Ahmed, M. Kabir andM. Farazi, “Efficient two-stream network for violence detection using separable convolutional lstm,” july 2021, pages 1–8. DOI:10 . 1109 / IJCNN52387 . 2021 .", "label": "human"}
{"ID": "00150191", "file_name": "Violence Detection in Surveillance Camera", "content": "J. Carreira, E. Noland, C. Hillier and A. Zisserman, A short note on the kinetics-700 human action dataset ,july 2019. J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and F.-F. Li, “Imagenet: A large-scale hierarchical image database,” june 2009, pages 248–255. DOI:", "label": "human"}
{"ID": "00150192", "file_name": "Violence Detection in Surveillance Camera", "content": "M. Cheng, K. Cai andM. Li, “Rwf-2000: An open large scale video database for violence detection,” in2020 25th International Conference on Pattern Recognition (ICPR) IEEE, 2021, pages 4183–4190.", "label": "human"}
{"ID": "00150193", "file_name": "Violence Detection in Surveillance Camera", "content": "M. Abadi, P. Barham, J. Chen andothers , “Tensorflow: A system for large scale machine learning,” in12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16) 2016, pages 265–283. url:https:", "label": "human"}
{"ID": "00160001", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Indoor navigation has become an increasingly important issue, particularly in large, complex buildings such as shopping malls, hospitals, airports, and so on.", "label": "human"}
{"ID": "00160002", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The traditional method of using paper maps or directories is time-consuming, cum bersome, and unreliable, especially in an emergency. With the widespread use of mobile devices, augmented reality (AR) has emerged as a promising solution to indoor navigation. ARNav is an AR-based indoor navigation Android app that provides users with a real-time, interactive, and intuitive navigation experience.", "label": "human"}
{"ID": "00160003", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The app leverages AR technology to overlay virtual information on the real envi ronment, helping users navigate more effectively and efficiently inside a building.", "label": "human"}
{"ID": "00160004", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The aim of this project is to address the need for an effective indoor navigation solution and to develop a user-friendly AR app that can be easily accessible andused by a wide range of people, from casual visitors to building staff and emer gency responders. The benefits of this project are improved navigation accuracy, reduced navigation time and effort, increased safety and convenience for users, and enhanced accessibility for people with disabilities. This project report will provide an overview of the design, development, and testing of the ARNav app, and it will also highlight its key features and benefits, as well as any limitations or areas forimprovement. The goal of this project is to demonstrate the feasibility and effec tiveness of AR-based indoor navigation and to provide a reference for future work in this field.", "label": "human"}
{"ID": "00160005", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The objective of the ARNav project is to develop a user-friendly AR-based in door navigation app that can help users navigate more effectively and efficiently inside a building. The app will be designed to provide real-time, interactive, and intuitive navigation assistance, using AR technology to overlay virtual informationon the real environment. The scope of the project is to cover the design, devel opment, and testing of the ARNav app, with a focus on its key features, benefits, limitations, and areas for improvement.", "label": "human"}
{"ID": "00160006", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Design and develop an AR-based indoor navigation app that utilizes AR tech nology to display virtual information on the real environment.", "label": "human"}
{"ID": "00160007", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Analyze and compare the ARNav app with existing indoor navigation solu tions, including traditional methods such as paper maps and directories, as well as other AR-based apps.", "label": "human"}
{"ID": "00160008", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The scope of the project report will cover the entire process of designing, devel oping, and testing the ARNav app, including a comprehensive description of the app’s features and functionality, as well as a detailed analysis of its performance and results. The report will also provide a critical evaluation of the ARNav app in comparison with other indoor navigation solutions, and will highlight its strengths and weaknesses.", "label": "human"}
{"ID": "00160009", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Indoor navigation is a crucial issue that affects a wide range of people, from casual visitors to building staff and emergency responders. Over the years, various solutions have been developed to address the needs for indoor navigation, including traditional methods such as paper maps and directories, as well as digital solutions such as indoor navigation apps and GPS-based systems. However, these solutions have several drawbacks, including poor accuracy, low user engagement, and a lack of real-time information.", "label": "human"}
{"ID": "00160010", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Recently, augmented reality (AR) technology has emerged as a promising solu tion to indoor navigation. AR allows users to see virtual information overlaid onthe real environment, providing them with a more interactive and intuitive naviga tion experience. Several AR-based indoor navigation apps have been developed, using different AR techniques such as frame detection and indoor place recognition to display navigation instructions.", "label": "human"}
{"ID": "00160011", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "ARNav, on the other hand, offers a unique solution to indoor navigation. Unlike other AR apps, ARNav uses a graph representation of the building’s blueprint to determine the navigation path, instead of continuously detecting the frame throughthe camera. This approach provides several advantages, including improved per formance, increased accuracy, and reduced battery consumption. Additionally,ARNav’s use of AR technology enhances the user experience by providing real time, interactive navigation instructions.", "label": "human"}
{"ID": "00160012", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In summary, ARNav addresses the limitations of traditional indoor navigation solutions and existing AR-based indoor navigation apps by combining the benefitsof AR technology with a graph-based approach to indoor navigation. This unique combination of AR and graph-based navigation provides a more efficient, accurate, and user-friendly solution to indoor navigation.", "label": "human"}
{"ID": "00160013", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This chapter will analyze the requirements for the ARNav app, including the user requirements, functional re quirements, and non-functional requirements. It will also provide a detaileddescription of the design constraints and trade-offs involved in the develop ment of the ARNav app.", "label": "human"}
{"ID": "00160014", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This section will provide an overview of the technologies used in the ARNav app, including AR technology, graph-based navigation,and any other relevant technologies. It will also describe the technical chal lenges faced during the development of the ARNav app and how they were overcome.", "label": "human"}
{"ID": "00160015", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This chapter will describe the design, construction, and implementation of the ARNav app, including the design process, the choice of programming languages and tools, and the architecture of the app.", "label": "human"}
{"ID": "00160016", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "It will also present the results of the app’s performance and functionality, as well as any limitations or areas for improvement.", "label": "human"}
{"ID": "00160017", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This section will highlight the most valuable contributions and innovations of me through the process of ARNav project devel opment, including the application of all the knowledge gained in the university that I am most interested: Android Programming, Backend Programming, and Data Structures and Algorithms.", "label": "human"}
{"ID": "00160018", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This chapter will summarize the key findings and results of the ARNav project, and provide a conclusion on the feasibility and effectiveness of AR-based indoor navigation. It will also suggest any future work that can be done to improve the ARNav app or to address any limitations or areas for improvement.", "label": "human"}
{"ID": "00160019", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The report will also include a comprehensive reference list, providing citations for all sources used in the research and development of the ARNav app.The Survey Chapter is an important part of the ARNav project report, as it provides valuable insights into the needs and preferences of both building visitors and building owners regarding indoor navigation. This chapter is split into two parts, the first part focuses on the survey of building visitors and building owners and the second part focuses on the functionality overview.", "label": "human"}
{"ID": "00160020", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The survey was conducted to gain a deeper understanding of the challenges faced by building visitors and building owners with regard to indoor navigation, as well as to gather information about their preferences and expectations. The results of the survey provide important information that will be used to inform the development of ARNav and to ensure that it meets the needs and expectations of both building visitors and building owners.", "label": "human"}
{"ID": "00160021", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The Survey Chapter provides a comprehensive overview of the survey results, including key findings and insights. The chapter is structured in a clear and concise manner, making it easy for the reader to understand the results and the implications for ARNav.", "label": "human"}
{"ID": "00160022", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Building Visitors In order to understand the needs and preferences of building visitors regarding indoor navigation, a survey was conducted among a sample of building visitors.", "label": "human"}
{"ID": "00160023", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The survey consisted of questions related to their experience with indoor naviga tion, their preferences and expectations, and their opinions on AR-based indoor navigation. The following are some of the key findings from the survey of building visitors:", "label": "human"}
{"ID": "00160024", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "A majority of building visitors reported that they often struggle to find their way in buildings, particularly large or complex ones.", "label": "human"}
{"ID": "00160025", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Preference for interactive navigation: Building visitors preferred interactive navigation methods, such as those using AR, over traditional methods such as paper maps or directories.", "label": "human"}
{"ID": "00160026", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "uilding visitors showed a high level of interest in AR-based indoor navigation, indicating that they believe it could be a valuable solution to indoor navigation.", "label": "human"}
{"ID": "00160027", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Building Owners In order to understand the needs and preferences of building owners regarding indoor navigation, a survey was conducted among a sample of building owners.", "label": "human"}
{"ID": "00160028", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The survey consisted of questions related to their experience with indoor naviga tion, their preferences and expectations, and their opinions on AR-based indoor navigation. The following are some of the key findings from the survey of building owners:", "label": "human"}
{"ID": "00160029", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Building owners expressed ahigh level of concern for the navigation experience of building visitors, rec ognizing its importance for visitor satisfaction and safety.", "label": "human"}
{"ID": "00160030", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Building owners showed a high level of interest in AR-based indoor navigation, indicating that they believe it could be a valuable solution to indoor navigation.", "label": "human"}
{"ID": "00160031", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Building owners placed a highvalue on efficiency and accuracy in indoor navigation, recognizing its impor tance for visitor satisfaction and safety.", "label": "human"}
{"ID": "00160032", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Building owners expressed concern for theprivacy and security of building visitors when using indoor navigation tech nology, indicating the need for secure and privacy-protected solutions.", "label": "human"}
{"ID": "00160033", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Building owners indicated a desire for cus tomizability in indoor navigation, including the ability to tailor navigation to specific building needs and preferences.", "label": "human"}
{"ID": "00160034", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In conclusion, the survey results indicated that both building visitors and buildingowners value the use of AR-based indoor navigation for its ability to provide in teractive, real-time, efficient, and accurate navigation. Both groups also expressedconcern for privacy and security, as well as a desire for customizability. These find ings provide valuable insights into the needs and preferences of building visitors and building owners, and will inform the development of ARNav.2.2 Survey on the same existing applications 2.2.1 Outdoor Navigation Apps Outdoor navigation apps are widely available and widely used for navigation in outdoor environments. These apps are designed to take advantage of the GPS(Global Positioning System) technology to provide users with accurate and up-to date information about their location and the route to their destination. Some of the most popular outdoor navigation apps include Google Maps, Waze, and Apple Maps.", "label": "human"}
{"ID": "00160035", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "These apps have a range of features designed to make navigation as simple and user-friendly as possible. For example, they typically provide turn-by-turn navigation, real-time traffic updates, and the ability to search for nearby points of interest (such as restaurants, petrol stations, and tourist attractions).", "label": "human"}
{"ID": "00160036", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "However, while outdoor navigation apps are highly effective for navigation inoutdoor environments, they are not well-suited for indoor navigation. This is because the GPS signal is weak or unavailable inside buildings, which makes it diffi cult to accurately determine the user’s location.", "label": "human"}
{"ID": "00160037", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This highlights the need for a specialized indoor navigation app like ARNav, which is specifically designed to provide accurate and reliable navigation in indoor environments. By taking a unique approach to indoor navigation (such as using AR and a graph-based navigation system), ARNav addresses the limitations of existing outdoor navigation apps and provides a much-needed solution for indoor navigation.", "label": "human"}
{"ID": "00160038", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Indoor Navigation Apps without AR integrated Indoor navigation apps without AR integration are typically designed to provide navigation inside buildings by using maps, graphs, or images. These apps usually run a path-finding algorithm to determine the quickest or most efficient route from the user’s current location to their destination. The resulting path is then displayed on a 2D screen in the form of a map or a series of instructions.", "label": "human"}
{"ID": "00160039", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Some of the most popular indoor navigation apps without AR include Floor Plans, Navmii Indoor GPS, and Micello Indoor Maps. These apps are typically used in large public buildings such as shopping malls, airports, and train stations, where traditional GPS-based navigation is not feasible.", "label": "human"}
{"ID": "00160040", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "While these apps can provide basic navigation services, they have several limitations. For example, they typically do not provide a realistic or immersive navi gation experience, as the instructions are displayed on a 2D screen and do not takeinto account the user’s surroundings. Additionally, the accuracy of these apps is limited by the quality of the underlying maps or graphs, which may not always be up-to-date or accurate.", "label": "human"}
{"ID": "00160041", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "ARNav addresses these limitations by integrating AR technology, which pro vides a more immersive and accurate navigation experience. By combining the strengths of indoor navigation apps with the immersive and interactive experience of AR, ARNav provides a cutting-edge solution for indoor navigation.", "label": "human"}
{"ID": "00160042", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Existing AR Indoor Navigation AppsAR Indoor Navigation apps are designed to provide a more immersive and inter active navigation experience by using AR technology to overlay virtual navigation elements onto the real world. There are two common approaches to implementing AR Indoor Navigation apps:", "label": "human"}
{"ID": "00160043", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This approach involves building a 3D model of the in door environment and processing all the navigation calculations in a game engine like Unity. This approach provides high accuracy, but requires a largeamount of computational resources, which can negatively impact the perfor mance of the app.", "label": "human"}
{"ID": "00160044", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This approach involves using the smartphone camera to continuously detect the current frame, and placing virtual navigation elements (e.g., anchors) in the correct location. While this approach can provide high accuracy, it also requires the app to continuously detect the frame, which can cause significant lag and impact the overall performance of the app.", "label": "human"}
{"ID": "00160045", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "ARNav offers an innovative solution to these limitations by using a graph generated from the building’s blueprint and traversing it only once to determine the path, rather than continuously detecting the frame through the camera. This approach provides high accuracy and performance, making ARNav a cutting-edge solution for indoor navigation.", "label": "human"}
{"ID": "00160046", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Indoor Positioning Indoor positioning is a critical component of AR indoor navigation. There are two main approaches to indoor positioning: automatic and manual.", "label": "human"}
{"ID": "00160047", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This approach uses Wi-Fi or Bluetooth signalsto determine the user’s location automatically. This approach can be consid ered a pseudo GPS, as it allows real-time tracking and provides a higher level of convenience, but its accuracy is not as high as manual indoor positioning.", "label": "human"}
{"ID": "00160048", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The reason for this is that the hardware required to process Wi-Fi or Bluetoothsignals can be expensive, and the accuracy of the signals can be affected by the presence of obstacles or other interference.", "label": "human"}
{"ID": "00160049", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In manual indoor positioning, the user’s location is defined manually, typically by using a floor plan or other type of map. Thisapproach involves the user inputting their current location in a form, or scan ning a QR code or image so that the system can automatically detect their location.", "label": "human"}
{"ID": "00160050", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "While manual indoor positioning may not provide real-time tracking like auto matic indoor positioning, it is more accurate and does not require any specialized hardware. ARNav allows users to scan images in a built-in image database.", "label": "human"}
{"ID": "00160051", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The image scanning option is particularly useful for ARNav, as the app already has an image database. This means that the user simply needs to scan an image that is displayed in the building, and the system will automatically detect their location based on that image. This makes the process of manual indoor positioning easier and more convenient for the user.", "label": "human"}
{"ID": "00160052", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This section describes the general overview of the system functions or business processes which are depicted in different diagrams. It shows the types of users, their granted permissions to perform specific system functions and the sequence required to complete a business workflow (if any). As the section name implies, itis high-level which means not detailed enough. For detailed requirement specifi cation, please see Use Case Specifications section below.2.3.1 Function Block Diagram A block diagram is a specialized, high-level flowchart used in engineering. It is used to design new systems or to describe and improve existing ones. Its structureprovides a high-level overview of major system components, key process partici pants, and important working relationships.", "label": "human"}
{"ID": "00160053", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "They are widely used in multiple fields to document, study, plan, improve and communicate often complex processes in clear, easy-to-understand diagrams.", "label": "human"}
{"ID": "00160054", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The Usecase Specifications, being a detailed description of the functionality of the system, are essential for the development process. However, including them in the main report would make it too lengthy and difficult to read. Therefore, they have been placed in the Appendix section for those who require a more in-depth understanding of the system’s functions. The Appendix serves as a reference for developers and other technical staff who may need to refer to the specifications during the development and testing process.", "label": "human"}
{"ID": "00160055", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Performance: The app must be able to handle a large number of users simul taneously without experiencing significant lag or slowdown.• Usability: The app should be easy to navigate and use, with intuitive controls and clear instructions. It should also be accessible to users with disabilities.", "label": "human"}
{"ID": "00160056", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Reliability: The app must be dependable and function correctly under a wide range of conditions. It should also have backup systems in place to prevent data loss or system crashes.", "label": "human"}
{"ID": "00160057", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Scalability: The app should be able to grow and expand as more users and data are added. It should be designed to handle increased load and traffic without experiencing a decrease in performance.", "label": "human"}
{"ID": "00160058", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Compatibility: The app should be compatible with a wide range of devices and operating systems, and it should be able to integrate with other apps and software.", "label": "human"}
{"ID": "00160059", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Maintainability: The app should be easy to update and maintain over time, with clear documentation and a streamd development process. It shouldalso be designed with modular components that can be easily replaced or upgraded.The Technology Used chapter provides a comprehensive overview of the vari ous technologies that were utilized in the development of the ARNav project. The chapter begins with a discussion of Mapbox, which was used to create the graphfrom the building’s blueprint. The next section of the chapter covers the Floyd Warshall algorithm, which was implemented in Python and utilized to determine all possible paths between vertices in the graph. The chapter also covers the use of MySQL as a database to store the paths and the creation of a RESTful API with NodeJS to connect the database to the ARNav app. The chapter concludes with a discussion of the Android operating system and Java, which were used to develop the ARNav app, and ARCore, which was used to implement AR features. Through this chapter, the reader will gain a thorough understanding of the key technologiesthat were used to develop ARNav and how they contributed to the overall function ality and performance of the app.", "label": "human"}
{"ID": "00160060", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Mapbox is an open-source mapping platform that provides powerful APIs and SDKs for developers to build location-based applications. It is a popular choice for ARNav due to its extensive range of features and functionalities.", "label": "human"}
{"ID": "00160061", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "One of the key features that makes Mapbox an ideal solution for ARNav is its ability to create a graph from building blueprints. With Mapbox, it is possible to convert the blueprint of a building into a graph, which can then be used for indoor navigation. This graph is a visual representation of the building’s structure and can be used to determine the optimal path for navigation.", "label": "human"}
{"ID": "00160062", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Another important feature of Mapbox is its support for real-time location dataand navigation. ARNav takes advantage of this by using Mapbox’s real-time nav igation capabilities to provide users with an up-to-date and accurate navigation experience.", "label": "human"}
{"ID": "00160063", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Mapbox also offers a range of customization options, allowing ARNav to pro vide a unique and personalized experience for each user. With its powerful APIs and SDKs, Mapbox provides ARNav with the ability to seamlessly integrate thenavigation experience into the app, making it an essential component of the tech nology stack.3.2 Floyd - Warshall AlgorithmThe Floyd-Warshall algorithm, named after Robert Floyd and Stephen War shall, is an algorithm for finding the shortest path between all pairs of vertices in a weighted graph. It was published by Robert Floyd in 1962 and independentlypublished by Stephen Warshall in the same year. The algorithm works by gradu ally improving an estimate on the length of the shortest paths between all vertices in the graph.", "label": "human"}
{"ID": "00160064", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The algorithm starts by initializing the distance between each pair of vertices to the weight of the edge between them, if it exists, or to infinity if no such edge exists.", "label": "human"}
{"ID": "00160065", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Then, for each vertex in the graph, the algorithm updates the distance estimates by considering the possibility of going through that vertex to reach other vertices. The algorithm repeats this process for every vertex in the graph, so that the distance estimates gradually improve with each iteration.", "label": "human"}
{"ID": "00160066", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Where nis the number of vertices in the graph, d[i][j] is the current estimate of the length of the shortest path between vertices iandj, and d[i][k] + d[k][j] is the length of the path from itokplus the length from ktoj. The algorithm terminates when all the estimates have stabilized and the final dmatrix contains the shortest path lengths between all pairs of vertices.", "label": "human"}
{"ID": "00160067", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In conclusion, the Floyd-Warshall algorithm is an efficient method for finding the shortest path between all pairs of vertices in a weighted graph and is widelyused in various fields, including transportation, telecommunications, and logis tics..., making it ideal for use in AR indoor navigation applications like ARNav.", "label": "human"}
{"ID": "00160068", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Python is a high-level, interpreted programming language that is widely used for a variety of applications, including web development, scientific computing, data analysis, and artificial intelligence. Its simplicity and versatility make it a popular choice for developers, especially in projects that require rapid prototyping and development.3.4 MySQL Database Management System MySQL is a widely used, open-source relational database management system that is well-suited for use in web applications and data-driven projects. It provides a powerful, flexible and scalable data storage solution, allowing users to store and manage large amounts of data easily and efficiently. With its support for SQL, it is also a popular choice for developers who want to query, manipulate and extract data from databases for use in their applications.", "label": "human"}
{"ID": "00160069", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The RESTful API (Representational State Transfer API) is a web service that follows the REST architectural style, which provides a way for web services to communicate and exchange information. RESTful API is designed to be lightweight, fast, and scalable, making it a popular choice for web developers to build APIs for various applications.", "label": "human"}
{"ID": "00160070", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "NodeJS is an open-source, cross-platform JavaScript runtime environment that executes JavaScript code outside of a web browser. It is built on Google’s V8 JavaScript engine and designed to build fast and scalable network applications.", "label": "human"}
{"ID": "00160071", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "NodeJS provides a rich library of modules for various purposes, such as connecting to databases, creating HTTP servers, handling HTTP requests and responses, and more.", "label": "human"}
{"ID": "00160072", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Javascript is a high-level, dynamic, and interpreted programming language, which is primarily used for creating web applications. Javascript is often used in combination with HTML and CSS to create dynamic and interactive web pages. It is an object-oriented language and supports a wide range of programming paradigms, including procedural, functional, and event-driven programming.", "label": "human"}
{"ID": "00160073", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Together, NodeJS and Javascript provide a powerful and flexible technology stack for building scalable and efficient RESTful APIs. By using NodeJS to build the API, I can access the MySQL database, retrieve the paths calculated by the Floyd-Warshall algorithm, and provide the data to the ARNav app for real-time navigation. The API provides a simple and consistent interface for the app to access the data, allowing me to change the underlying implementation without affecting the app’s functionality.", "label": "human"}
{"ID": "00160074", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Android is an open-source operating system for mobile devices, developed by Google. Java is a high-level programming language and the main programming language for Android app development. Java has a long history in developing ro-bust and scalable software applications, making it a perfect choice for Android app development. With Java, developers can create powerful and efficient applicationsthat can run on a variety of platforms. Additionally, Java offers a large pool of li braries, tools and a vast community of developers who provide continuous support and help in fixing bugs and issues. Java is an object-oriented language, making it easier for developers to structure the code and create reusable components. WithAndroid’s growing popularity, Java has become one of the most widely used pro gramming languages for developing mobile applications.", "label": "human"}
{"ID": "00160075", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "ARCore is a software development kit (SDK) developed by Google for aug mented reality (AR) applications. It enables developers to create AR experiencesthat can be run on Android smartphones and tablets. ARCore uses motion track ing, environmental understanding, and light estimation to integrate virtual objects with the physical world in real-time. ARCore can detect horizontal surfaces, such as floors and tables, and also features a high-performance 3D engine that allowsvirtual objects to be rendered accurately in the real world. ARCore was first re leased in 2018 and has since been constantly improved to provide more advanced AR features, such as 6DoF motion tracking, cloud anchors, and improved light estimation. The availability of ARCore has opened up new possibilities for mobile AR development, allowing developers to create more interactive and engaging AR experiences for Android users.4.1 Architecture design 4.1.1 Software architecture selection The Model-View-Controller (MVC) design pattern is one of the most commonly used architectural patterns in software development, especially in the development of user interfaces. It separates an application into three components: the Model, the View, and the Controller.", "label": "human"}
{"ID": "00160076", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In the context of this project, the Model represents the path data obtained from the API, which includes the latitude, longitude, and rotation values for each point in the path. The Controller is responsible for managing the communication between the Model and the View. It acts as an intermediary that manages the data flow between the Model and the View and ensures that the data is presented to the user in an appropriate format. In this project, the Controller is represented by the RESTful API, which serves as the middle layer between the mobile app and the server.", "label": "human"}
{"ID": "00160077", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The View is the mobile app itself, which presents the information obtained from the API to the user. It is responsible for rendering the 3D arrows on the camera screen and displaying the proper directions to the user. The View is updated in real-time based on the data received from the API, ensuring that the user always has the most up-to-date information.", "label": "human"}
{"ID": "00160078", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The MVC design pattern is suitable for this project for several reasons. Firstly, it provides a clear separation of concerns, which makes it easier to maintain and extend the code. Secondly, it helps to improve the overall performance of the application by reducing the amount of code that needs to be executed at any given time. Thirdly, it allows for greater modularity, as changes to one component of the application can be made without affecting the others. Finally, it makes it easier for multiple developers to work on the same project, as each component can be developed and tested independently before being integrated into the final product.", "label": "human"}
{"ID": "00160079", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Overall design The Overall Design subsection is a crucial part of the software architecture of the project. In this section, the packages in the system are organized and presentedin a comprehensive and easy-to-understand manner. The UML Package Relation ship Diagram below provides a visual representation of the different packages in the system, and how they interact with each other.Figure 4.1: Package Relation Diagram The UI Package is in charge of managing the user interface of the application,which includes displaying the 3D arrows and other interactive elements on the mobile app’s screen. It communicates with the AR Package to ensure proper place ment of the arrows and to handle user input.", "label": "human"}
{"ID": "00160080", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The AR Package, on the other hand, is responsible for utilizing ARCore to detect the plane and render the 3D arrows on the app’s screen. It communicates with the UI Package to receive user input and to provide information about the camera’s rotation.", "label": "human"}
{"ID": "00160081", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The AppUtils Package provides various utility functions that can be used throughout the application, such as converting latitudes and longitudes into real-world dis tances using the Great Circle Theorem.", "label": "human"}
{"ID": "00160082", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The API Package communicates with the RESTful API to receive the path data and perform other necessary tasks, such as updating the database with new infor-mation. The Data Package communicates with the API Package to retrieve the path data.", "label": "human"}
{"ID": "00160083", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The Model Package is then responsible for utilizing this preprocessed data to carry out its functions. It communicates with the Database Package to retrieve the data it needs to carry out its functions.", "label": "human"}
{"ID": "00160084", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Finally, the Database Package is responsible for managing the application’s database, which includes storing the preprocessed data, user preferences, and other necessary information.", "label": "human"}
{"ID": "00160085", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Detailed package design The Detailed Package Design subsection provides an in-depth view of the project’s package structure, which was introduced in the Overall Package Design section.", "label": "human"}
{"ID": "00160086", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This subsection includes a set of UML diagrams that present each package’s re sponsibilities and the relationships between them. By examining these diagrams,we can gain a better understanding of the project’s organization and how the dif ferent parts interact.", "label": "human"}
{"ID": "00160087", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The Spinner class and ImageScanner class are two sub-classes of the Launcherclass. They provide the user with an input channel to specify their desired destina tion and current position, respectively. The Spinner class allows the user to select a destination from a drop-down menu, while the ImageScanner class uses ARCore technology to scan an image and determine the user’s current position.", "label": "human"}
{"ID": "00160088", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Overall, the UI package plays a critical role in ensuring a smooth and user friendly experience for the application. It provides an intuitive interface for users to input their desired destinations and current location, enabling the rest of the system to process the information and generate the appropriate AR navigation path.", "label": "human"}
{"ID": "00160089", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "One of the main classes in this package is the DBConnector class, responsible for initializing the connection with the server and processing user requests. This class depends on the NavAPI interface to communicate with the server and retrieve data. Additionally, the DBConnector class utilizes the TaskDelegate interface to mount the results of server requests to the UI package.", "label": "human"}
{"ID": "00160090", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "To ensure the stability and reliability of the app, the ErrorManager interface and SnackbarHelper class are also included in the AppUtils package. These classes are responsible for logging errors and displaying messages to the user in a user-friendly way. The ErrorManager interface defines the methods used to handle exceptions,while the SnackbarHelper class implements these methods to show the messages on the UI layer.", "label": "human"}
{"ID": "00160091", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The package includes four layers: the Controller class, the Service interface, the ServiceImpl class, and the Repository interface. The Controller class serves as the entry point to the API and presents the URI routes for the client’s calls. When the mobile app calls the API with parameters such as starting and ending locations, the Controller class forwards these parameters to the Service layer.", "label": "human"}
{"ID": "00160092", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The Service layer is implemented through the ServiceImpl class, which calls the functions of the Repository interface. The Repository interface connects directly to the database, processes queries and retrieves data. After retrieving data from thedatabase, the ServiceImpl class formats it into the right form and passes it to the Controller layer.", "label": "human"}
{"ID": "00160093", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Finally, the Controller layer returns the formatted data in the form of an HTTPresponse to the client. This architecture is designed to promote separation of con cerns and improve maintainability and scalability of the application.", "label": "human"}
{"ID": "00160094", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The graphBuilder() method reads the JSON file of the map and constructs a weighted graph in the form of an adjacent matrix. The resulting matrix is passed as input to the pathFinding() method, which runs the Floyd-Warshall algorithm once to obtain all the shortest paths between all possible pairs of vertices in the graph. The resulting Python dictionary is then passed through the parseSave() method, which converts it into JSON data and calls the Model package for further processing.", "label": "human"}
{"ID": "00160095", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "On the other hand, the Model package is responsible for receiving pre-processed JSON data from the Data package and inserting it into the MySQL database. This package initializes the connection with MySQL, creates the database, creates the table, and finally inserts data into it. By doing so, it ensures that the data is stored in a structured manner, making it easy to retrieve and use later on.", "label": "human"}
{"ID": "00160096", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The Database package is a concise package that serves to represent the MySQL database, and its sole responsibility is to provide storage functionality. Therefore, a detailed description of its design is not necessary.Figure 4.6: AR package details The last package is the AR package, responsible for receiving the path data from the server and presenting it in an Augmented Reality environment. The main class of this package is the ARImageAndNavigation class, which connects to the API and retrieves the JSON path data by calling the getPath() method. The JSON path data is then passed to the calibration() method to be converted into real-world anchors, and the planeDetection() method is called to detect the plane in the camera view. Once the plane is detected, the setRenderable() method is used to place the 3D arrow anchors on the plane.", "label": "human"}
{"ID": "00160097", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Additionally, the AugmentedImageFragment class and the AugmentedImageN ode interface are helper classes used in the ARCore framework.4.2 Application Building 4.2.1 Libraries and Tools Role Tool URL Address Programming Language Java AR Programming Plat formARCore  le.com/ar Programming IDE Android Studio  id.com/ Programming Language Python  Programming IDE Pycharm  m/pycharm/ Programming Language Javascript  Backend Programming LibraryExpressJS  Backend Programming Librarymysql  m/package/mysql Programming IDE Visual Studio Code  o.com/ Database Management SystemMySQL  Web Server Xampp  ends.org/ Map Builder Mapbox  Table 4.1: Libraries and Tools Used 4.2.2 Achievement During the development of this project, I successfully created a comprehensive and functional app that allows users to navigate to their desired locations using augmented reality. The app is packaged with various components, each with a distinct purpose, which work together to deliver a seamless user experience.", "label": "human"}
{"ID": "00160098", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The UI package serves as the entry point for users, allowing them to input their starting and destination points. The AppUtils package handles the background tasks of the app, such as connecting to the server and processing user requests. The API package on the server side implements Clean Architecture, with decoupling layers that help to maintain a well-structured and easily maintainable codebase.", "label": "human"}
{"ID": "00160099", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In the Data package, the Router class efficiently pre-processes the map data using the Floyd-Warshall algorithm, and the Model package inserts this data into a MySQL database. The AR package takes the path data from the server and renders it in augmented reality, allowing users to easily navigate to their destination.Overall, the successful development of this app has allowed me to gain valuable experience in designing and implementing a complex software project from start to finish. The achievement of this project represents my ability to utilize and integratevarious software tools and technologies to create a polished and functional end product.", "label": "human"}
{"ID": "00160100", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Furthermore, the successful development of this project opens up various busi ness opportunities. With the rising popularity of AR and the demand for innovative navigation solutions, this app has the potential to be monetized through various channels such as in-app purchases, targeted advertisements, and partnerships withtransportation and tourism companies. Additionally, the comprehensive data pro cessing and analysis that takes place in this app provides opportunities for data monetization and partnerships with other data-driven businesses. The achievement of creating a fully functional and comprehensive navigation app not only offerspractical value to users but also holds significant potential for future business en deavors.", "label": "human"}
{"ID": "00160101", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Aspect Volume Unit Java Code (Application Side) 1742 line Python Code (Data Pre-processing) 583 line Javascript Code (Server Side) 251 line Android Application 45 MB Server Application 40 MB Data 736 KB Table 4.2: Overall Statistic 4.2.3 Illustration of main functions The application has two main screens, the Launcher Screen and the AR Screen.", "label": "human"}
{"ID": "00160102", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The Launcher Screen is the first screen that users encounter when they open the app. On this screen, users can choose their destinations by selecting from the list of locations available in the app. The AR Screen is the main screen of the app that works with the smartphone’s camera. It allows users to scan the images to determine their current positions and displays 3D arrows after getting the path that guides users to their chosen destinations.(a)Launcher Screen (b)Destination List Figure 4.7: Launcher ScreenThe Launcher Screen of the app shows an animated background with some im ages for decoration. The background is designed to attract the user’s attention andprovide a visually pleasing experience. At the bottom of the screen, there is a drop up menu with a list of shop names. The drop-up menu allows the user to select the desired destination by tapping on it, which expands to show the available locations.", "label": "human"}
{"ID": "00160103", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "There is also a button under the drop-up menu. After the users chose their desired locations, they will press that button and the app move to the camera screen.Figure 4.8: Scan Image Screen The scanning image screen is the second screen of the app, which is launched after the user has selected a destination on the Launcher Screen. The screen is a camera view with a frame in the center, which indicates where the user needs to position the image that defines their current location. The user needs to fit the image into the frame and wait for the app to detect it and retrieve the starting point information. Once the starting point is detected, the user’s desired destination is sent to the server along with the starting point information. The app then begins the calculation to render 3D arrows, which will guide the user to their destination.Figure 4.9: AR ScreenAfter the calculations are done, the AR screen image shows the 3D arrows ren dered on the real-world view seen through the smartphone camera. The arrows are placed on a flat surface that the app has detected through plane detection. The arrows are pointing toward the direction that the user should move to reach their destination, and they are shown in a visually appealing and easy-to-understand way. The user can use the arrows to navigate through the building and reach their destination efficiently.", "label": "human"}
{"ID": "00160104", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Pathfinding Test: Test the accuracy of the pathfinding algorithm by selecting a starting point and a destination in a building and comparing the path generated bythe app to a known correct path.", "label": "human"}
{"ID": "00160105", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Performance Test: Test the app’s performance by measuring how long it takes to generate a path between two points, and how smoothly the app runs when using AR features. Battery Usage Test: Test the battery usage of the app by measuring how long the app can run continuously on a single charge.", "label": "human"}
{"ID": "00160106", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "User Interface Test: Test the usability of the app by having users perform common tasks such as selecting a starting point and a destination, following the gener ated path, and using the AR features.", "label": "human"}
{"ID": "00160107", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "To deploy my navigation app, I used Xampp for the database and ran the server on my local machine Lenovo IdeaPad L340. I also ran the app on my Xiaomi Redmi Note 7 smartphone to simulate a real user environment. The deployment process was fairly straightforward and didn’t require any complex infrastructure.", "label": "human"}
{"ID": "00160108", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "During the testing deployment, I conducted a series of performance tests to evaluate the app’s capability to handle a high volume of requests from multiple users. I tested the app with 50 users, each sending 10 requests, and monitored the response duration to ensure it was within an acceptable range. The results showed that the app was able to handle the requests with an average response time of 1.5 seconds, which was well within the acceptable range.", "label": "human"}
{"ID": "00160109", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In addition to the performance tests, I also collected user feedback on the app’s functionality and ease of use. The feedback was overwhelmingly positive, with users praising the app’s ability to accurately guide them through large buildings and its intuitive interface. I also collected statistical data on the number of users,requests, and response times to better understand the app’s usage patterns and po tential areas for improvement.", "label": "human"}
{"ID": "00160110", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Overall, the testing deployment of the app was successful, with the app demon strating high capability and receiving positive user feedback. As I continue todevelop the app, I will use the results of the testing deployment to refine its perfor mance and enhance its functionality.The Solution Contribution chapter is the heart of this report, where we dive deep into the implementation of ARNav, the AR-based Indoor Navigation app.", "label": "human"}
{"ID": "00160111", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This chapter will take you through the key challenges faced during the develop ment of the app and how they were addressed. The Path Finding Task and the AR Integration Task are two main components of the app that were tackled with great attention to detail to create a seamless and user-friendly experience. The Path Finding Task involves finding the shortest path between two points within the building using Floyd - Warshall algorithm and storing the paths in the database.", "label": "human"}
{"ID": "00160112", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The AR Integration Task involves integrating AR features into the app, making it an AR-based navigation app that allows the user to follow the path in a unique and engaging way. Through this chapter, you will get an in-depth understanding of the design and construction of ARNav, and how the technology used was integrated to bring the app to life.", "label": "human"}
{"ID": "00160113", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In the development of the indoor navigation app, server-side processing was chosen instead of performing everything inside the mobile app. One of the main reasons for this choice was efficiency. If all the pathfinding was done within the app, each time a user request was received, the app would have to repeat the process of reading the file, creating the graph, and running the algorithm. This repeated process would not only increase the processing time required but also consume a large amount of memory and battery life, leading to a suboptimal user experience.", "label": "human"}
{"ID": "00160114", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Another reason was scalability. Storing all the building data within the mobile app would not be a practical solution as the size of the data increases with the number of buildings. Hence, to maintain the efficiency of the app, all the data was stored in a centralized server, which can easily be scaled as the number of buildings increase.", "label": "human"}
{"ID": "00160115", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "One of the main benefits of server-side processing is that it allows me to make use of powerful hardware to process the data. Mobile devices typically have limited processing power, which can make finding the path a slow and resource-intensive task. By using a server, I can take advantage of more powerful hardware, which can process the data more quickly and efficiently.", "label": "human"}
{"ID": "00160116", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Finally, running the brute-force algorithm just once also offers a better user ex perience for the users. With the data pre-processed and stored, the app can receivethe path from the server in real-time, without the need for users to wait. This makes the app more responsive and user-friendly, and can lead to higher user engagement and satisfaction.", "label": "human"}
{"ID": "00160117", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The first sub-task is Graph Construction, which involves using the blueprint of the building to create a graph of the interior. Mapbox was used to create the graph, which acts as a digital representation of the building and its different rooms. The graph provides a foundation for the path-finding algorithm to work on.", "label": "human"}
{"ID": "00160118", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The second sub-task is Algorithm Implementation. The Floyd-Warshall algo rithm was used to find the shortest path between all pairs of vertices in the graph.", "label": "human"}
{"ID": "00160119", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The algorithm was implemented in Python, a high-level programming languagewidely used for scientific and data analysis applications. The algorithm was de signed to find the shortest path between any two points in the graph, which is essential for the indoor navigation app to work correctly.", "label": "human"}
{"ID": "00160120", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The third sub-task is Backend API Development. A RESTful API was devel oped using NodeJS to communicate with the database and provide the necessary data for the app to function. The API was designed to retrieve the paths calculated by the Floyd-Warshall algorithm and make them available to the app. The API was built with NodeJS and Javascript, which are powerful technologies for building web and mobile applications.", "label": "human"}
{"ID": "00160121", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Together, these sub-tasks form the Path Finding task, which is a critical compo nent of the ARNav app. The task was designed to provide accurate and efficientindoor navigation, and to support the AR features of the app. In the three subsec tions, we will dive into how each is implemented.", "label": "human"}
{"ID": "00160122", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Graph Construction The Graph Construction task involved the use of Mapbox to create a map based on the floor plan of Aeon Mall. The map was stored in a JSON file with objects such as polygons as stores, rooms, and points. Each of these objects had its own set of coordinates that defined its location on the map.Figure 5.1: AEON Mall 1st Floor PlanThe use of Mapbox allowed for the creation of an accurate and detailed repre sentation of the indoor space, making it easier for users to navigate within the mall.", "label": "human"}
{"ID": "00160123", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The JSON file was then used as the foundation for the graph that was later used in the Path Finding task.", "label": "human"}
{"ID": "00160124", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This is the structure of a polygon, which is how a store is presented in the graph:\"coordinates\": [ // list of corners’ coordinates [ [121.43172649124074, 25.03524436104651], [121.43173334749207, 25.035150178731982], [121.43163348845076, 25.035144515336654], [121.43162764689401, 25.03523808120937], [121.43172649124074, 25.03524436104651] ] ], type\": \"Polygon\" type\": \"Feature\", type\": \"room\", id\": \"sf133\", // id of the store name\": \"YVES\", // store name multi_door\": \"0\", // if it has multidoor or not door\": [121.43162807052249, 25.035232783853886], // the door’s coordinate vertex\": [121.4316110066589, 25.035231065150953], // coordinate of the point that defines the store’s location in the graph vertex_id\": \"b19\" id of the point that define the store’ slocation inthe graph Based on the structure provided above, the polygon object represents a room or store in the graph, which is a building element that the user wants to navigate to. The polygon object has a set of coordinates which define the shape of the polygon, with type of ”Polygon” in the ”geometry” field. The ”properties” field contains information about the room, such as its type, ID, name, multi-door status, door coordinate, vertex coordinate, and vertex ID. The vertex coordinate is the important information because it serves as a point in the graph that connects to other vertices, enabling the user to navigate to the room or store represented by this polygon object.", "label": "human"}
{"ID": "00160125", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "There are many points placed through whole the campus as the graph’s vertices and play a role as the path’s components. We mainly use these points in calculating the paths and also based on them to create the AR breadcrumbs.\"coordinates\": [ 121.43178201814135, 25.035594080546232 ], type\": \"Point\" type\": \"Feature\", type\": \"point\", id\": \"a24\", rotation\": \"0,1\", index\": \"23\"The points have a structure similar to the polygon structure, with ”coordinates” in dicating the position of the point on the map and ”properties” including the type of the object, its ID, and other attributes such as rotation and index. These points are essential for building the graph as they serve as components for the paths and also for creating AR breadcrumbs for navigation. The ”rotation” and ”index” values are also important for AR integration, as they determine the orientation and position of the AR markers on the map.", "label": "human"}
{"ID": "00160126", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Algorithm Implementation Once the graph is constructed, the next step is to find the shortest path between two points in the graph. This is where the Algorithm Implementation task comesin. In this task, I used the Floyd-Warshall algorithm to find the shortest path between all pairs of vertices in the graph. The algorithm is an efficient and well established approach for solving the All-Pairs Shortest Path problem, which is what we need in this project. Below is the pseudo-code of Floyd-Warshall algorithm in my program.", "label": "human"}
{"ID": "00160127", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The code first reads in all the data from the JSON source and then starts pro cessing the information for each floor in the building. For each floor, it initializes several data structures to store the floor data, such as the features of each floor, the vertexes of each floor, the elevators of each floor, and the posters of each floor.", "label": "human"}
{"ID": "00160128", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This step is important because it lays the foundation for the later calculations, by providing the necessary information about each floor and its characteristics.", "label": "human"}
{"ID": "00160129", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The next step is to calculate the weight for each floor. This weight could be based on any desired metric, such as the distance between two points on the floor, the time it takes to travel from one point to another, or any other relevant factor.", "label": "human"}
{"ID": "00160130", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The weight calculation is important because it will be used in the later steps to determine the shortest route between two points on the floor.", "label": "human"}
{"ID": "00160131", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Once the weights for each floor have been calculated, the code uses the Floyd Warshall algorithm to calculate the shortest route and next steps for each floor.", "label": "human"}
{"ID": "00160132", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This algorithm is a well-known graph theory algorithm that finds the shortest path between all pairs of nodes in a weighted graph. In this case, the nodes are the vertexes of each floor, and the edges are the pathways between the vertexes, with the weights being the previously calculated weights.", "label": "human"}
{"ID": "00160133", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The results of the Floyd-Warshall algorithm are then stored for each floor in the building. The next step is to calculate the route and elevator information for each floor. This information is necessary to determine the best way to travel from onefloor to another, taking into account the available elevators and their locations.Finally, the code converts the index number of each floor’s route into its cor responding coordinate. This step is necessary because the route information wasstored as a series of index numbers, and now it needs to be transformed into ac tual coordinates on the floor. The code also calculates the rotation for each floor’s route, which could be used to orient a person walking along the route in the correct direction.", "label": "human"}
{"ID": "00160134", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The final step is to store the results in two arrays, totalRouteCoord andtotal RouteRot . These arrays contain information about the route and rotation for each floor in the building, providing complete information about the shortest path to travel from one floor to another.", "label": "human"}
{"ID": "00160135", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Backend API Development Firstly, we start with the database, which contains tables that stores all the paths in each specific building. Each table should have three columns:", "label": "human"}
{"ID": "00160136", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "source-vertex : This column stores the starting vertex of a path. It is used to identify the starting point of a route.", "label": "human"}
{"ID": "00160137", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "destination-vertex : This column stores the ending vertex of a path. It is used to identify the destination point of a route.", "label": "human"}
{"ID": "00160138", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "path: This column stores the details of the path between the source-vertex and thedestination-vertex . It may contain information such as the length of the path, the intermediate vertices, and any other relevant information.", "label": "human"}
{"ID": "00160139", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "By organizing the paths in this manner, it is possible to quickly and easily retrieve the information required to provide routing information to users. The source vertex and destination-vertex columns can be used as the primary keys to ensure that each path is unique, and the path column can be used to store the detailed information needed to guide users to their desired destination.", "label": "human"}
{"ID": "00160140", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The RESTful API used in the Backend is for the app to fetch path data from the database. The API has a single endpoint /getPath developed using NodeJS.", "label": "human"}
{"ID": "00160141", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This endpoint receives the source and destination vertex as query parameters, and it returns the path data between the source and destination vertex. The path data is stored in the database with three columns: source-vertex, destination-vertex, and path. The API retrieves the path data from the database based on the source and destination vertex provided as query parameters, and returns the path data to the app.5.2 AR Integration Task The AR Integration Task is a crucial part of the navigation application that aims to enhance the user experience. This task integrates augmented reality (AR) into the application to provide a more intuitive and interactive navigation experience for users. The task is split into two subtasks: Starting and Ending Point Input and JSON Path to Real-World Path.", "label": "human"}
{"ID": "00160142", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The first subtask in AR Integration Task focuses on Starting and Ending Point Input. This is a crucial aspect of the overall project as it enables users to input the starting and ending points for their desired path. This information will be used by the system to determine the most efficient route for the user The second subtask, JSON Path to Real-World Path, involves converting the JSON path data retrieved from the API into a real-world path that can be displayed in AR. The AR view will display the path as an overlay on the real-world camerafeed, guiding the user along their desired path. This integration of AR and real world navigation provides a more immersive and interactive experience for users, allowing them to easily visualize their desired path and follow it in real-time.", "label": "human"}
{"ID": "00160143", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The AR Integration Task plays a vital role in the overall navigation experience and is designed to provide a seamless and intuitive navigation experience for users.", "label": "human"}
{"ID": "00160144", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "By integrating AR, the application is able to provide a more interactive and immer sive experience, making navigation more intuitive and enjoyable for users.", "label": "human"}
{"ID": "00160145", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Starting and Ending Point Input In the first subtask of the AR Integration Task, one of the main goals is to allow users to choose their desired destination within a built-in list of shops in Aeon Mall. The selection of the destination is a crucial step toward rendering the AR path through the camera of the user’s device. However, two major challenges arise while achieving this goal. These two challenges are Indoor Positioning and Camera Rotation Detection.", "label": "human"}
{"ID": "00160146", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Indoor Positioning is one of the most significant challenges in the development of AR-based indoor navigation systems. There are two approaches to define the user’s position: auto-detection using Wi-Fi or Bluetooth, or manual input by the user. The auto-detection approach is more automated and works as an indoor GPS, allowing real-time tracking of the user’s position. However, it requires a deep dive into low-level digital processing tasks, which can be quite complicated. On theother hand, manual input by the user has the advantage of being more straightfor ward and reliable, as the user can manually enter their position.As for the manual input of the user’s location, there are several options available.", "label": "human"}
{"ID": "00160147", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "The simplest and most straightforward way is to allow the user to type in a text input bar. However, this approach may not be very practical in cases where the user is standing in the middle of a busy hall with numerous shops, billboards, and other objects around them. In such a scenario, it may not be clear what the user should enter. To address this issue, I implemented a more automated approach that allows the user to scan an image instead of entering a text input. The images used in this approach are pre-defined and have a unique name. These names are then mapped to vertex IDs in the graph through a mapping storage.", "label": "human"}
{"ID": "00160148", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In addition to inputting their location, the user also needs to provide information about the current camera rotation. This information is crucial for rendering the 3D path in the correct direction. The user can obtain this information by scanning the image, which also allows the app to detect the camera’s current rotation.", "label": "human"}
{"ID": "00160149", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "By utilizing ARCore’s Augmented Image class, the Android app is able to con tinuously detect the current frame. The app has access to a pre-defined database of images, and once it detects an image in the current frame, the detection process ispaused, ensuring optimal performance. Upon identifying the image, the app con verts its name to the corresponding location name, while also recording the current rotation of the camera. This information will be utilized when rendering the 3D path.", "label": "human"}
{"ID": "00160150", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "getUpdatedTrackables(AugmentedImage. class ); for (AugmentedImage augmentedImage : updatedAugmentedImages) // break the loop once we detected a image if(imageFound) break ; case PAUSED:", "label": "human"}
{"ID": "00160151", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "// When an image is in PAUSED state, but the camera is not PAUSED, it has been detected, but not yet tracked.", "label": "human"}
{"ID": "00160152", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "// Have to switch to UI Thread to update View.fitToScanView.setVisibility(View.GONE); // Create a new anchor for newly found images and record it.", "label": "human"}
{"ID": "00160153", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "if(!augmentedImageMap.containsKey(augmentedImage AugmentedImageNode node = new AugmentedImageNode( this ); node.setImage(augmentedImage); augmentedImageMap.put(augmentedImage, node); // record the start point, which is the image we just scan startingImage = augmentedImage; imageFound = true ; break ; case STOPPED:", "label": "human"}
{"ID": "00160154", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "augmentedImageMap.remove(augmentedImage); break ; The name of the image is specified by the developer and pre-defined in the AR project. It is used to identify each unique augmented image, and to differentiate itfrom others. The code reads the collection of updated trackables , which are aug mented images that have changed in some way (detected, started tracking, stopped tracking, etc.). For each image, the code checks its tracking state, which could be one of three values: PAUSED, TRACKING, or STOPPED.", "label": "human"}
{"ID": "00160155", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "When the image is in the PAUSED state, the code displays a message ”De tecting Image ” + augmentedImage .getName() to inform the user that the app is detecting the image but hasn’t started tracking it yet.", "label": "human"}
{"ID": "00160156", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "When the image is in the TRACKING state, the code hides the fitToScanView ,creates a new augmented image node for the newly found image, adds it to the aug mentedImageMap , and sets the startingImage to the image that was just scanned. It also sets imageFound to true to indicate that an image has been found, and cancels the ”Detecting Image” text.", "label": "human"}
{"ID": "00160157", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "When the image is in the STOPPED state, the code removes the image from the augmentedImageMap .In short, the code is checking the tracking state of each augmented image, and when an image is being tracked, it retrieves its name using the getName() method and stores it in the startingImage variable.", "label": "human"}
{"ID": "00160158", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "JSON Path to Real-World Path Transformation The task of converting the path data from an API into a usable format for AR navigation presents a significant challenge. Unlike other AR navigation apps that must continuously detect each frame to render the 3D arrows one by one, ARNav can build the entire path at once, once all conditions are met. One of the keyconditions is converting the distances between points in the path data into real world distances that the camera can comprehend. This is accomplished by utilizing the Great Circle Theorem. The formula for the Great Circle Theorem is as follows:", "label": "human"}
{"ID": "00160159", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "dis the distance between two points with latitude lat1, longitude long1 and latitude lat2, longitude long2 Ris the Earth’s radius lat1,lat2,long1 ,long2 are the latitudes and longitudes of the two points in radians sin,cosare the sine and cosine trigonometric functions, respectively In order to render the 3D arrows on the camera’s detected plane, we need to create ARCore’s Poses that include an ARCore Anchor. These Anchors will serve as the base on which the arrows will be placed, allowing the user to see the path in the real world.", "label": "human"}
{"ID": "00160160", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "To create these Poses, we must first convert the distances between the points in the path data into distances that the camera can understand. This requires a good understanding of the ARCore platform and the Java programming language, as well as a solid grasp of mathematical concepts such as 3D geometry and coordinate systems.", "label": "human"}
{"ID": "00160161", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "This is done by defining the position and orientation of each Pose, which will serve as the reference for the placement of the 3D arrows. To ensure that the arrows are rendered in the proper direction, each Pose will also be associated with a rotation value. This value is determined based on the orientation of the camera at the timeof detection, as well as the rotation of the device itself.", "label": "human"}
{"ID": "00160162", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "It’s important to note that while this process may seem complex, it is crucial to the success of the ARNav app. By converting the path data into Poses and Anchors, the app is able to accurately render the 3D arrows on the camera’s detected plane, giving the user a clear and intuitive understanding of their navigation path.6.1 Conclusion When comparing my navigation app to existing ones, several aspects must be considered. Firstly, there is the User Experience. By utilizing AR and 3D artifacts,my app is both more engaging and easier to use than traditional 2D apps. Addi tionally, compared to other AR apps, my app has significantly reduced latency and power consumption thanks to the limited use of 3D platforms and pre-processed data. During the development period, I spent a significant amount of time testing the app in AEON Mall to ensure accurate mapping of the physical locations. While my solution shows promise, mistakes are inevitable, particularly in large buildings like AEON Mall where even small movements or rotations can lead to incorrect paths. Currently, the app is only available on Android due to limited developer device availability and a lack of time to learn AR Platforms on other OS. There are also several potential features for future development, such as map management and 3D living-assistants. Overall, while there are a few drawbacks to my app, I have gained significant value from this project.", "label": "human"}
{"ID": "00160163", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "In the future, my plan is to expand the functionality of the app. The first step isto develop the map management feature, which involves creating graphs for addi tional buildings and integrating them into the app. Additionally, I will be learning how to program AR on iOS, which will require acquiring Apple devices such as aniPhone and a Macbook. Finally, I aim to enhance the User Experience by incorpo rating 3D creatures as virtual assistants that guide users along the 3D path. S. H. Kim, K. -O. Lee, Y . -J. Chae, H. -W. Lee and Y . -Y . Park. (2022).", "label": "human"}
{"ID": "00160164", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "R. Ka ´zmierczak, A. Szczepanska, C. Kowalczyk, G. Grunwald and A. Janowski(2021). “Using AR technology in tourism based on the example of maritime edu cational trips—a conceptual model”, Sustainability , 13(13), 7172.", "label": "human"}
{"ID": "00160165", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "W. Chidsin, Y . Gu and I. Goncharenko (2021). “ARbased navigation using RGB-D camera and hybrid map”. Sustainability , 13(10), 5585.", "label": "human"}
{"ID": "00160166", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "B. Arifitama, G. Hanan and M. H. Rofiqi (2021). “Mobile Augmented Real ity for Campus Visualization Using Markerless Tracking in an Indonesian Private University”. Int. J. Interact. Mob. Technol , 15, 21-33.", "label": "human"}
{"ID": "00160167", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "F. Lu, H. Zhou, L. Guo, J. Chen and L. Pei (2021). “An ARCore-Based Augmented Reality Campus Navigation System”. Applied Sciences , 11(16), 7515.", "label": "human"}
{"ID": "00160168", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "20). “DETERMINATION POSITION AND DISTANCE OF STORE BASEDON WIFI USING K-NEAREST NEIGHBOR AND FLOYD WARSHALL AL GORITHM”. Technology Reports of Kansai University . 62. 2379-2389.", "label": "human"}
{"ID": "00160169", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "X. Chen and S. Qin, ”Approach to high efficient hierarchical pathfinding of indoor mobile service robots based on grid map and Floyd-Warshall algorithm,” (2017) Chinese Automation Congress (CAC) , Jinan, China, 2017, pp. 6476-6483.", "label": "human"}
{"ID": "00160170", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "H. Wu, A. Marshall and W. Yu, “Path Planning and Following Algorithmsin an Indoor Navigation Model for Visually Impaired”, Second International Con ference on Internet Monitoring and Protection (ICIMP 2007) , San Jose, CA, USA, 2007, pp. 38-38.A.1 Enter Address A.1.1 Overview ID and Name UC01 - Enter Address Description This Use Case allows users to choose the desire locations they want to come Actor Any user Trigger After turning on the app ARNav on the user’s phone Pre-condition The location which the user request to select is validated Post-condition Your selection is successful and click the button “Go” to move on next step Table A.1: Use Case 01 Overview A.1.2 Flow of Events a, Basic Flow Step Description 1 Actor clicks the ‘Select location” button and the drop-up menu will show the list of locations, they can select the location on the screen 2 System checks the status of the location available or not through the database 3 System checks the status of the location available or not through the database Table A.2: Use Case 01 Basic Flow b, Alternative Flow <Unavailable location to select > Continued from Step 2 in the Basic FlowStep Description1 System checks the location’s status through the databaseIf the location is unavailable, ARNav displays the no tification: “Status: Unavailable; This location may have changed, please come back later” 2 Actor clicks “OK” to turn off pop-up message and select on another place 3 Continue again step 1 Table A.3: Use Case 01 Alternative Flow: Unavailable location to select <Blank selection > Continued from Step 1 in the Basic Flow Step Description 1 The actor doesn’t input any location 2 Actor clicks on the ”Next” button 3 ARNav displays success notification Table A.4: Use Case 01 Alternative Flow: Blank selection c, Exceptional Flow <No internet > Continued from Step 1, 2, 3 in the Basic Flow Step Description 1 Unplug the Wi-Fi routine or internet cable wire from the computer 2 Screen display informational message EMGS3 Table A.5: Use Case 01 Exceptional Flow: No internet <Session Timeout > Continued from step 1,2,3 in the Basic Flow:", "label": "human"}
{"ID": "00160171", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Step Description1 Actor doesn’t interact with screen for more than 15 min utes2 Actor doesn’t interact with screen for more than 15 min utes Table A.6: Use Case 01 Exceptional Flow: Session TimeoutA.2 Scan Image A.2.1 Overview ID and Name UC02 - Scan Image Description This Use Case allows users to scan the image to determine their current positions Actor Any user Trigger After the users choose their desire destinations, they startto scan the image to for the app to now their current posi tions Pre-condition The camera is accessed and operating normally Post-condition The app get the current position and send a request to the server Table A.7: Use Case 02 Overview A.2.2 Flow of Events a, Basic Flow Step Description 1 After actors clicks the “Next” button, the system accesses the camera in the user’s phone on the screen 2 The user moves the phone closer to the image to be scanned 3 After that, the app detects the imageg Table A.8: Use Case 02 Basic Flow b, Alternative Flow <Non-existence image > Continued from Step 2 in the Basic Flow Step Description1 System checks the location’s status through the databaseIf the location is unavailable, ARNav displays the no tification: “Status: Unavailable; This location may have changed, please come back later” 2 Actor clicks “OK” to turn off pop-up message 3 Continue again step 1 Table A.9: Use Case 02 Alternative Flow: Non-existence code <Out of frame >Continued from Step 1 in the Basic Flow Step Description 1 The actor doesn’t align the image with the frame such as left or right offset2 The system can’t find the image, ARNav displays the no tification: “Status: Unavailable; This location may have changed, please come back later” 3 Actor clicks “OK” to turn off pop-up message 4 Continue again step 1 Table A.10: Use Case 02 Alternative Flow: Out of frame c, Exceptional Flow <Session Timeout >Continued from step 1,2,3 in the Basic Flow:", "label": "human"}
{"ID": "00160172", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Step Description 1 Unplug the Wi-Fi routine or internet cable wire from the computer 2 Screen display informational message ”Time out! Please try again!” Table A.11: Use Case 02 Exceptional Flow: Session TimeoutA.3 Get The Path A.3.1 Overview ID and Name UC03 - Get The Path Description This Use Case allows the app to send a request to the server to get the path data from their current position to their desired location Actor Any userTrigger After scanning the image in front of each store to determine the location on the app ARNav, the app sends a re quest to the server Pre-condition The location which the user request to select exists and the image is scanned successfully Post-condition Receive the path data from the server Table A.12: Use Case 03 Overview A.3.2 Flow of Events a, Basic Flow Step Description 1 Actor finds and scans the image successfully, the app sends the starting point and the ending point to the server 2 The server queries to get the path lead from the starting point to the ending point 3 Server return the path data to the app Table A.13: Use Case 03 Basic Flow b, Alternative Flow <Unavailable location to searching > Continued from Step 2 in the Basic Flow Step Description1 System checks the location’s status through the databaseIf the location is unavailable, ARNav displays the no tification: “Status: Unavailable; This location may have changed, please come back later” 2 Actor clicks “OK” to turn off pop-up message and select on another place 3 Continue again UC02 Table A.14: Use Case 03 Alternative Flow: Unavailable location for searchingc, Exceptional Flow <No internet >Continued from Step 1, 2, 3 in the Basic Flow Step Description 1 Unplug the Wi-Fi routine or internet cable wire from the computer 2 Screen display informational message ”No internet! Please check your connection and try again!” Table A.15: Use Case 03 Exceptional Flow: No internet <Session Timeout >Continued from step 1,2,3 in the Basic Flow:", "label": "human"}
{"ID": "00160173", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Step Description 1 Similar to UC01 Table A.16: Use Case 03 Exceptional Flow: Session TimeoutA.4 Get Direction A.4.1 Overview ID and Name UC04 - Get Direction Description This Use Case allows the app to get the camera’s current direction Actor Any user Trigger After searching on the app ARNav on user’s phone, user waits for the app to get the direction automatically Pre-condition UC03 is successful Post-condition The app starts to convert the path data received from the server into real-world ”anchors” Table A.17: Use Case 04 Overview A.4.2 Flow of Events a, Basic Flow Step Description 1 Actor keeps the app on scanning the image 2 The app gets the proper direction of the smartphone’s camera and starts to convert the path data into ”anchors” Table A.18: Use Case 04 Basic Flow b, Exceptional Flow <Internal Error >Continued from Step 1, 2 in the Basic Flow Step Description 1 The app raise some error of getting the current direction 2 Screen displays the informational message ”Something wrong! Please try again another time Table A.19: Use Case 04 Exceptional Flow: Internal Error <Session Timeout >Continued from step 1,2,3 in the Basic Flow:", "label": "human"}
{"ID": "00160174", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Step Description 1 Similar to UC01 Table A.20: Use Case 04 Exceptional Flow: Session TimeoutA.5 Anchor Converting A.5.1 Overview ID and Name UC05 - Anchor Converting Description This Use Case allows the system to convert the path data to real-world ”anchors” to render Actor Any user Trigger After getting the proper direction, path data is converted into real-world ”anchors” Pre-condition The process of searching proceeded Post-condition Receive the path data from the server Table A.21: Use Case 05 Overview A.5.2 Flow of Events a, Basic Flow Step Description 1 Actor waits for the app for calculating to convert the path data into real-world anchors 2 The app gets the anchors and starts to detect the plane to render them Table A.22: Use Case 05 Basic Flow b, Exceptional Flow <Calculation Error >Continued from Step 1 in the Basic Flow Step Description 1 The path data has some exceptions that raise some errors in the calculation process 2 Screen displays the informational message ”Something wrong with the data! Please try again another time” Table A.23: Use Case 05 Exceptional Flow: Calculation Error <Session Timeout >Continued from step 1,2,3 in the Basic Flow:", "label": "human"}
{"ID": "00160175", "file_name": "ARNav - Augmented Reality Indoor Navigation Mobile Application", "content": "Step Description 1 Similar to UC01 Table A.24: Use Case 05 Exceptional Flow: Session TimeoutA.6 Render A Route A.6.1 Overview ID and Name UC06 - Render A Route Description This Use Case allows the app to render the 3D arrows in the camera screen Actor Any user Trigger After getting the anchors, the app starts to detect plane and render these anchors on that plane Pre-condition Use Case 05 is successfulPost-condition 3D arrows are rendered in the right direction with appro priate distance Table A.25: Use Case 06 Overview A.6.2 Flow of Events a, Basic Flow Step Description 1 Actor moves the camera to scan the plane that they are standing on (floor eg.) 2 The app detects the plane 3 The app puts the anchors on the plane and renders the 3D arrows on them Table A.26: Use Case 06 Basic Flow b, Exceptional Flow <Internal Error >Continued from Step 1, 2, 3 in the Basic Flow Step Description 1 The process of plane detecting and 3D rendering raise some errors 2 Screen displays the informational message ”Something wrong! Please try again another time.” Table A.27: Use Case 06 Exceptional Flow: Internal Error <Session Timeout >Continued from step 1,2,3 in the Basic Flow:", "label": "human"}
{"ID": "00170001", "file_name": "Malware Detection System Using Machine Learning", "content": "These days, the infinity development of Internet makes not only the vast of pos itive effects but also brings a large number of problems. The big problem of using network now is cyber attacks including DoS and DDoS attacks, Malware, Phishing attacks, Man-in-the-Middle attacks, Password attacks, etc.", "label": "human"}
{"ID": "00170002", "file_name": "Malware Detection System Using Machine Learning", "content": "Malware (or Malicious Software) is any programs or files that intentionallyharmful to a computer, network or server. Malware can infect networks and de vices and is designed to harm those devices, networks and their users in some way depending on type of malware and its goal.", "label": "human"}
{"ID": "00170003", "file_name": "Malware Detection System Using Machine Learning", "content": "There have been many detect system for others attacks but not much for mal ware. As there are more types of malware appears, I personally think that it is necessary to improve the existing model to detect as many types of malware as possible. That the reason why I do this thesis.", "label": "human"}
{"ID": "00170004", "file_name": "Malware Detection System Using Machine Learning", "content": "Traditionally, malware detection and classification has relied on pattern match ing against signatures extracted from specific malware samples. While simple andefficient, signature scanning is easily defeated by a number of well-known eva sive strategies. This fact has given rise to statistical and machine learning based techniques, which are more robust to code modification.", "label": "human"}
{"ID": "00170005", "file_name": "Malware Detection System Using Machine Learning", "content": "Malware is not very a complicated attacks but it leads to a vast of risky prob lems. Detecting malware soon in the cybersecurity is crucial and help decrease the negative impact.", "label": "human"}
{"ID": "00170006", "file_name": "Malware Detection System Using Machine Learning", "content": "I would like to train a model using Machine Learning and Deep Learning tech niques to detect and classsify malware attacks with a dataset cover as many types of malware as possible.", "label": "human"}
{"ID": "00170007", "file_name": "Malware Detection System Using Machine Learning", "content": "In this thesis, my goal is to compare Deep Learning for malware detection and classification. I will apply DL models using image-based features, and also opcodefeatures. The DL models consider include a wide variety of neural networking tech niques, including multilayer perceptrons (MLP), several variants of convolutional neural networks (CNN), and vanilla recurrent neural networks (RNN), as well as the advanced RNN architectures known as long short-term memory (LSTM) and gated recurrent units (GRU).I would like to use Python with skicit-learn and torch library for some reasons below:", "label": "human"}
{"ID": "00170008", "file_name": "Malware Detection System Using Machine Learning", "content": "Scikit-learn provides a user-friendly interface with a consistent API, making it accessible for beginners and easy to implement various machine learning Scikit-learn is highly compatible with other Python libraries like NumPy and Pandas, facilitating seamless data manipulation and analysisPyTorch excels in building and training deep learning models, such as convo lutional neural networks (CNNs), which are highly effective for image-based tasks PyTorch uses dynamic computation graphs, allowing for more flexibility and ease in building complex models and custom architectures Pytorch is suited for deep learning tasks, providing flexibility, powerful deep learning capabilities, and efficient training with GPU support In this work, I have built some modules including:", "label": "human"}
{"ID": "00170009", "file_name": "Malware Detection System Using Machine Learning", "content": "Section 2: I would like to represent about Theoretical basis about classification techniques such as the definition of cyber attacks especially malware, definition of techniques used in this thesis, and information about library used.", "label": "human"}
{"ID": "00170010", "file_name": "Malware Detection System Using Machine Learning", "content": "Section 3 is about how I build Model to detect and classify malware using above techniques and dataset. Furthermore, I would like to show some codes and explain them In Section 4, Result of model trained will be showed and evaluated by some criterions. I will also want to show my future work with this system to improve and widen it.This section is about the Theoretical basis. In this section the definition of ML techniques and DL techniques used will be represented in details. Furthermore,there will be the statistic of cyber attacks recently, and detail information of mal ware classification.", "label": "human"}
{"ID": "00170011", "file_name": "Malware Detection System Using Machine Learning", "content": "To the best of my knowledge, image-based analysis was first apply to malwareproblem in the research of L. Nataraj, S. Karthikeyan, G. Jacob, and B. S. Manju nath. Malware images: Visualization and automatic classification. In Proceedings of the 8th International Symposium on Visualization for Cyber Security, VizSec ’11, 2011, where high-level “gist” descriptors are used as features. More recently, S. Yajamanam, V. R. S. Selvin, F. Di Troia, and Mark Stamp confirmed the L.", "label": "human"}
{"ID": "00170012", "file_name": "Malware Detection System Using Machine Learning", "content": "Nataraj, S. Karthikeyan, G. Jacob, and B. S. Manjunath’s research result in Deeplearning versus gist descriptors for image-based malware classification. In Pro ceedings of the 4th International Conference on Information Systems Security and Privacy, ICISSP 2018, pages 553–561, 2018.", "label": "human"}
{"ID": "00170013", "file_name": "Malware Detection System Using Machine Learning", "content": "My working is based on image analysis, and I might expect models to be more robust and stronger compared to opcode based model or similar statistical features which are common in malware research.", "label": "human"}
{"ID": "00170014", "file_name": "Malware Detection System Using Machine Learning", "content": "This section 2.2 aim to define what is Malware? How many common types of Malware have been detected? 2.2.1 Definition of Malware Malware or Malicious Software is any software intentionally designed to causedisruption to a computer, server, client, or computer network, leak private information, gain unauthorized access to information or systems, deprive access to in formation, or which unknowingly interferes with the user’s computer security and privacy.", "label": "human"}
{"ID": "00170015", "file_name": "Malware Detection System Using Machine Learning", "content": "Types of Malware There are many types of Malware which have been appeared and detected until now. I will provide definition of some common types below:", "label": "human"}
{"ID": "00170016", "file_name": "Malware Detection System Using Machine Learning", "content": "Types of Malware DefinitionTrojan Trojan horse malware is a file, a program, or piece of code that appears to be legitimate and safe,but is actually malware. Tro jans are packaged and delivered inside legitimate software, and they’re often designed to spy on victims or steal data.", "label": "human"}
{"ID": "00170017", "file_name": "Malware Detection System Using Machine Learning", "content": "VirTool VirTool is a category of Riskware, is a detection foritems that are not strictly mali cious but pose some sort of risk for user in another way.", "label": "human"}
{"ID": "00170018", "file_name": "Malware Detection System Using Machine Learning", "content": "Backdoor Backdoor is a type of Trojan that can bypass security measures toaccess a network, system, or de vice. It pretends to be something for the purposes of deliveringmalware, stealing data, or opening up a backdoor on the sys tem. By using backdoor, or an entry point, cybercriminals can gain unauthorized access to data, critical systems, and other assets Rogue Rogue is a kind of malware that makes end users believe that their systems or computers are infected and they need to pay to clean the infection or to protect their system.Adware Adware is a type of Malicioussoftware that secretly installs it self on user’s device and displays advertisements. In some cases,adware can even track user’s online behavior and display person alized ads Password Stealer Password stealers are kind ofmalware or spyware that get in stalled secretly on the device. Itis a category of trojan. The sit uation usually belike: user opens up the wrong file in their spam email or executes a program thatwas downloaded from the harm ful website.", "label": "human"}
{"ID": "00170019", "file_name": "Malware Detection System Using Machine Learning", "content": "Worm A worm is a subset of trojan horse attack that can propagate or self-replicate from one computerto another without human acti vation after breaching a system.", "label": "human"}
{"ID": "00170020", "file_name": "Malware Detection System Using Machine Learning", "content": "Multiplayer Perceptron A perceptron calculates a weighted sum of its inputs, forming a hyperplane, and use a threshold to classify data. However, it cannot separate data that is not ar separable. This is a significantly limitation, as the XOR function cannot be separated linearly.", "label": "human"}
{"ID": "00170021", "file_name": "Malware Detection System Using Machine Learning", "content": "A multiplayer perceptron (MLP) is a type of Artificial Neural Network (ANN)that consists of multiple hidden layers of perceptrons. Unlike single-layer percep trons, MLPs are capable of modeling more complex functions because of unlim-ited ar decision boundaries. This relationship between perceptrons and MLPs is similar to the relationship between ar support vector machine (SVMs) and SVMs that use nonlinear kernel functions.", "label": "human"}
{"ID": "00170022", "file_name": "Malware Detection System Using Machine Learning", "content": "Training a multilayer perceptron (MLP) can seem difficult due to the presence of hidden layers between the input and output, making it unclear how adjustments to weights in these layers will influence each other or the final output. Today, MLPs are typically trained using backpropagation. The realization that backpropagation could be employed to train neural networks was a significant breakthrough, making deep learning feasible.", "label": "human"}
{"ID": "00170023", "file_name": "Malware Detection System Using Machine Learning", "content": "Convolutional Neural Network Artificial neural networks (ANN) generically use fully connected layers. The advantage of fully connected layer is that it can deal with correlations between any points within training vectors. However, for large training vectors, it is infeasible because of the vast number of weights that have to be learned.", "label": "human"}
{"ID": "00170024", "file_name": "Malware Detection System Using Machine Learning", "content": "Unlike ANN, a convolutional neural network (CNN) is specially designed tohandle local structures. A convolutional layer may not perform well when impor tant information is not local. CNNs is advantageous in the efficiency of training convolutional layers, as they require fewer weights compared to fully connected layers.", "label": "human"}
{"ID": "00170025", "file_name": "Malware Detection System Using Machine Learning", "content": "For image-based, most of important structure for example edges or gradients is totally local. Therefore, CNNs is an ideal tool for image analysis, and the fact that CNNs were developed for image classification. However, CNNs also perform well in other problem domain.", "label": "human"}
{"ID": "00170026", "file_name": "Malware Detection System Using Machine Learning", "content": "Recurrent Neural Network Above MLPs and CNNs are types of feedforward neural networks where dataflows directly through the network without retaining any memory of previous in puts. In these networks, each input vector is processed independently of others.", "label": "human"}
{"ID": "00170027", "file_name": "Malware Detection System Using Machine Learning", "content": "In some certain situations, a classifier needs to retain memory. For example,when tagging parts of speech in English text (such as nouns and verbs), it is im practical to analyze words in isolation. A recurrent neural network (RNN) offers a solution by incorporating memory (or context) into a feedforward neural network.", "label": "human"}
{"ID": "00170028", "file_name": "Malware Detection System Using Machine Learning", "content": "Recurrent Neural Networks (RNNs) are trained using a method called backprop agation through time (BPTT). A significant issue with BPTT is that the gradientcalculations can become unstable, leading to “vanishing” or “exploding” gradients.", "label": "human"}
{"ID": "00170029", "file_name": "Malware Detection System Using Machine Learning", "content": "To address these issues, one approach is to limit the number of time steps, althoughthis also restricts the effectiveness of RNNs. Alternatively, specialized RNN archi tectures can be used to allow gradients to flow over extended periods. Examples of such architectures include Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs). These specialized RNNs will be discussed next.", "label": "human"}
{"ID": "00170030", "file_name": "Malware Detection System Using Machine Learning", "content": "Long Short-term Memory Long Short-Term Memory (LSTM) networks are a type of RNN architecturespecifically designed to handle long-range dependencies. LSTMs can manage ex tended intervals between the occurrence of a feature and the moment it is required by the model. This capability is generally not feasible with standard RNNs due to the issue of vanishing gradients.", "label": "human"}
{"ID": "00170031", "file_name": "Malware Detection System Using Machine Learning", "content": "The primary distinction between an LSTM and a standard vanilla RNN is that an LSTM incorporates an extra pathway for information flow. Besides the hidden state, there is a cell state that effectively stores information from previous steps.", "label": "human"}
{"ID": "00170032", "file_name": "Malware Detection System Using Machine Learning", "content": "The cell state acts as a gradient \"highway\" during backpropagation, allowing the gradient to flow much further back with a reduced risk of vanishing or exploding.", "label": "human"}
{"ID": "00170033", "file_name": "Malware Detection System Using Machine Learning", "content": "Gated Recurrent Unit Given its widespread success, numerous variants of the LSTM architecture havebeen explored. Most of these variants involve only minor modifications to the stan dard LSTM. However, the Gated Recurrent Unit (GRU) represents a significantdeparture from the LSTM. Although the internal state of a GRU is somewhat com plex and less intuitive than that of an LSTM, it has fewer parameters. Consequently, GRUs are easier to train than LSTMs and require less training data.", "label": "human"}
{"ID": "00170034", "file_name": "Malware Detection System Using Machine Learning", "content": "ResNet152While LSTM networks use a complex gating mechanism to facilitate gradi ent flow, a residual network (ResNet) introduces additional connections known as identity layers. These identity layers enable a ResNet model to effectively skip over certain layers during training, which helps to reduce the effective depth and mitigate gradient-related issues. Essentially, ResNet can train deeper networks byinitially focusing on a much shallower network, with subsequent training stages re fining the intermediate connections. This method is inspired by pyramidal cells inthe brain, which similarly bridge different “layers” of neurons.", "label": "human"}
{"ID": "00170035", "file_name": "Malware Detection System Using Machine Learning", "content": "As one of transfer learning examples, I utilize this architecture, which consists of an impressive 152 layers. Specifically, I employ the ResNet152 model and retrain only the output layer for our malware classification task.", "label": "human"}
{"ID": "00170036", "file_name": "Malware Detection System Using Machine Learning", "content": "VGG-19 VGG-19 is a convolutional neural network with 19 layers, pre-trained on adataset with over 106images. This architecture has excelled in numerous com petitions and has been adapted for various image-related tasks. In this context, weutilize the VGG-19 architecture and its pre-trained model as one of our two exam ples of transfer learning for image-based malware classification.", "label": "human"}
{"ID": "00170037", "file_name": "Malware Detection System Using Machine Learning", "content": "That is the information about the techniques used in my work. In general, theyare all common Deep Learning techniques used for image analysis with high ef ficiency, and robust for the large dataset. I will provide more details about how I apply them in building model with dataset in the next section.3.1 Dataset The dataset consists of 20 malware families. Three of these malware families, which are Winwebsec, Xeroaccess, and Zbot, are from the Malicia dataset, while 17 remaining families are taken from the massive malware dataset has been discussed in the research of Samuel Kim called PE header analysis for malware detection.", "label": "human"}
{"ID": "00170038", "file_name": "Malware Detection System Using Machine Learning", "content": "Hence, the dataset is almost 0.5 Terabyte and contains more than 500,000 malware samples in the form of labeled executable files.", "label": "human"}
{"ID": "00170039", "file_name": "Malware Detection System Using Machine Learning", "content": "Family Type Adload Trojan Downloader Agent Trojan Alureon Trojan BHO Trojan CeeInject VirTool Cycbot Backdoor DelfInject VirTool FakeRean Rogue Hotbar Adware Lolyda Password Stealer Obfuscator VirTool Onlinegames Password Stealer Rbot Backdoor Renos Trojan Downloader Startpage Trojan Vobfus Worm Vundo Trojan Downloader Winwebsec Rogue Zbot Password Stealer Zegost Backdoor Table 3.1: Type of each malware family.", "label": "human"}
{"ID": "00170040", "file_name": "Malware Detection System Using Machine Learning", "content": "Adload : is executable files, users download this files then execute them, for the result the files will disable proxy settingsAgent : downloads trojan or other software from remote server to harm user’s de vice BHO : can perform a vast number of actions, guided by attackers.", "label": "human"}
{"ID": "00170041", "file_name": "Malware Detection System Using Machine Learning", "content": "CeeInject : can hide from antivirus software by using advanced obfuscation Cycbot.G : connects remotely to a server, exploits the vulnerabilities, and using a backdoor to attackDelfInject : steals and sends usernames, passwords, and other important personal information to attackers.", "label": "human"}
{"ID": "00170042", "file_name": "Malware Detection System Using Machine Learning", "content": "FakeRean : pretends to scan the whole system, sends notifications to user about issues and asks user to pay for cleaning system.", "label": "human"}
{"ID": "00170043", "file_name": "Malware Detection System Using Machine Learning", "content": "Hotbar : is an adware that show advertisement on webpages, once user click to that ads, it will force to install additional adware.", "label": "human"}
{"ID": "00170044", "file_name": "Malware Detection System Using Machine Learning", "content": "Lolyda : will send information from an infected system to attacker and monitor the system by sharing user credentials and network activity.", "label": "human"}
{"ID": "00170045", "file_name": "Malware Detection System Using Machine Learning", "content": "Obfuscator : attemps to conceal or disguise itself to evade malware detection sys tems Ongames : steals username, password, and other login information and tracks user’s activity.", "label": "human"}
{"ID": "00170046", "file_name": "Malware Detection System Using Machine Learning", "content": "Rbot : create backdoor, give control to attackers through the backdoor so that at tacker can access to user’s information or launch attack.", "label": "human"}
{"ID": "00170047", "file_name": "Malware Detection System Using Machine Learning", "content": "Renos : download softwares that may claim user that there was a spyware in the system and ask user to pay for removing that noexist spyware.", "label": "human"}
{"ID": "00170048", "file_name": "Malware Detection System Using Machine Learning", "content": "Vundo : uses advanced techniques to defeat detection system by show a pop-up ad vertisement and download files from that.", "label": "human"}
{"ID": "00170049", "file_name": "Malware Detection System Using Machine Learning", "content": "Zbot : is installed through email. After downloading, it will share user information to attackers, and even disable a firewall.", "label": "human"}
{"ID": "00170050", "file_name": "Malware Detection System Using Machine Learning", "content": "The \"Binaries\" column shows the number of binary executable files available, the Images\" column lists the number of images that were converted successfully from binary files, and the \"Opcodes\" column represented the number of opcodes were extracted from samples.", "label": "human"}
{"ID": "00170051", "file_name": "Malware Detection System Using Machine Learning", "content": "In addition, to process data and other related operations, I used both Numpy and Pandas library.Family Binaries Samples Images Opcodes Adload 1050 1050 1044 Agent 842 842 817 Alureon 1328 1328 1327 BHO 1176 1176 1159 CeeInject 894 894 886 Cycbot 1029 1029 1029 DelfInject 1146 1146 1097 FakeRean 1063 1063 1063 Hotbar 1491 1491 1476 Lolyda 915 915 915 Obfuscator 1445 1445 1331 Onlinegames 1293 1293 1284 Rbot 1017 1017 817 Renos 1312 1312 1309 Startpage 1136 1136 1084 Vobfus 926 926 924 Vundo 1793 1793 1784 Winwebsec 3651 3651 3651 Zbot 1786 1786 1785 Zegost 1120 1120 1119 Total 26,413 26,413 25,901 Table 3.2: Samples per malware family.", "label": "human"}
{"ID": "00170052", "file_name": "Malware Detection System Using Machine Learning", "content": "In this section, I would like to show the process of converting binaries to images and extract features, and opcodes from that.", "label": "human"}
{"ID": "00170053", "file_name": "Malware Detection System Using Machine Learning", "content": "To transform a binary to an image, I interpret the sequence of binary bytes as the pixel values of grayscale PNG image. In my experiments, I consistently use a fixed width of 256, while the length varies based on the size of the binary.", "label": "human"}
{"ID": "00170054", "file_name": "Malware Detection System Using Machine Learning", "content": "The figure below show the process of converting binary file into grayscale image The figure 2 shows samples of unrelated binaries, while figure 3 provide the samples of malware family in dataset.", "label": "human"}
{"ID": "00170055", "file_name": "Malware Detection System Using Machine Learning", "content": "I have extracted features from binary files for k-NN experiment. I adapted codefrom two publicy accessible Github repositories, namely, PE File, 2018 and Ma chine Learning, 2018 to extract 54 features from each binary sample. I can listsome of these features as SizeOfOptionalHeader, SizeOfCode, FileAlignment, Ma jorOSVersion, SizeOfImage, SizeOfHeaders, Subsystem, SizeOfStackCommit, Sec-Figure 3.1: Converting binaries to images Figure 3.2: Unrelated binaries as imagesFigure 3.3: Malware family images tionsNb, SectionsMeanEntropy, etc.", "label": "human"}
{"ID": "00170056", "file_name": "Malware Detection System Using Machine Learning", "content": "In this section, I consider MLP experiments, followed by CNN and then RNN experiments. For CNN and RNN, I have considers a large number of cases. The MLP and CNN models are based on image features, while RNN experiments based on opcode sequences.", "label": "human"}
{"ID": "00170057", "file_name": "Malware Detection System Using Machine Learning", "content": "Multilayer Perceptron Experiments I have experimented with different perceptron-based neural networks. The model uses square image as input and there are four hidden layers, each layer using the rectified ar unit (relu) activation function. The output of the final hidden layeris fed into a fully connected output layer. This output layer is responsible for clas sifying the sample. Due to 20 malware classes in the dataset, the output vector has 20 dimensions.", "label": "human"}
{"ID": "00170058", "file_name": "Malware Detection System Using Machine Learning", "content": "The hyperparameter used for MLP experiments is image-dim, learning-rate,batch-size, epochs with the accuracy of train and test are 0.9529 and 0.8644, re spectively. DelfInject and Obfuscator families have the lowest detection rates, with slightly over 0.5 accuracy.Figure 3.4: Summary hyperparameters of CNNs experiments 3.4.2 Convolutional Neural Network Experiments About Convolutional Neural Network, I have conducted numerious experiments.", "label": "human"}
{"ID": "00170059", "file_name": "Malware Detection System Using Machine Learning", "content": "In this part, I first focused on experiments involving 2-dimensional images. Then I explored 1-dimensional experiments, where malware images are converted into vectors. Additionally, the results from CNN experiments using opcode featuresextracted from PE file, instead of forming images from the raw byte values of ex ecutable files. The opcodes were extracted using objdump package, and I use the resulting mnemonic opcode sequences as features.", "label": "human"}
{"ID": "00170060", "file_name": "Malware Detection System Using Machine Learning", "content": "2-Dimensional Image CNNs experiments Based on 2-dimensional image features, I have tested CNN model using somehyperparameter suchas image-dim with test values are [64,128,256,1024], learning rate with the range of value is [0.001, 0.0001], batch-size is 256, and epochs is 50.", "label": "human"}
{"ID": "00170061", "file_name": "Malware Detection System Using Machine Learning", "content": "To be more specific, the first layer takes a square gray-scale image as input with one channel and the output data with 12 channels using kernel size of three,padding of two and a tride of one. The result of the first layer is applied relu acti vation and max pooling before going to the second convolutional layer.", "label": "human"}
{"ID": "00170062", "file_name": "Malware Detection System Using Machine Learning", "content": "The second layer produces data with 16 channels, maintaining the same hyper-parameters as the first layer. Before applying max pooling and relu activation, the output of the first layer is a 120-dimensional vector, then reduce to 90-dimensional vector, and finnaly relu activation is applied again to classifies the sample into 20 dimensions. I use 50 epochs for running 2D CNN models with image sizes smaller than 1024; for 1024 x 1024 images, I use 8 pochs due to the hgih training cost.", "label": "human"}
{"ID": "00170063", "file_name": "Malware Detection System Using Machine Learning", "content": "As the results, the accuracy for train is 0.9294 and for test is 0.8955. After 2D CNN experiments, I have noted that Obfuscator family is the most difficult to detect again.", "label": "human"}
{"ID": "00170064", "file_name": "Malware Detection System Using Machine Learning", "content": "Vectorized Image CNNs experiments I did this experiment with flattened images, or in other words I used images that are only one pixel in height. One potential advantage of this is that 2D resultscan be influenced by the image width. I have conducted two sets of such experi ments, referred to as CNN 1-d and CNN 1-d refined, with the latter incorporating additional fine-tuning parameters.", "label": "human"}
{"ID": "00170065", "file_name": "Malware Detection System Using Machine Learning", "content": "The CNN 1-d model consists of two 1-dimensional convolutional layers, followed by three fully connected layers. The first convolutional layer processes an im age with one channel and outputs data with 28 channels using kernel size of three.", "label": "human"}
{"ID": "00170066", "file_name": "Malware Detection System Using Machine Learning", "content": "The second convolutional layer outputs data with 16 channels, using the same ker nel size as the first one. The first fully connected layer produces a 120-dimensional vector, which is reduced to 90 dimensions by the second fully connected layer, and finally reduced to 20 dimensions by the third fully connected layer. All three fully connected layers apply relu activation.", "label": "human"}
{"ID": "00170067", "file_name": "Malware Detection System Using Machine Learning", "content": "The overall accuracy for CNN 1-d case is 0.8664. Agnet, Alureon, DelfInject, Obfuscator, and Rbot family have accuracy below 0.8, accounting for most of the accuracy loss.", "label": "human"}
{"ID": "00170068", "file_name": "Malware Detection System Using Machine Learning", "content": "The CNN 1-d refined tests use the same basic setup ad CNN 1-d but include different hyperparameter selections. Hence, adding parameter improved the CNN 1-d case, reaching the best overall accuracy of 0.8932.", "label": "human"}
{"ID": "00170069", "file_name": "Malware Detection System Using Machine Learning", "content": "Opcode Based CNNs experiments For opcode features, I also apply 2D CNNs. For each malware sample, I use thefirst 500-5000 opcodes from binary file. The experiment occurs with some param eter such as opcode-length, num-filters, filter-size, embedding-dim, learning-rate, batch-size, and epochs.", "label": "human"}
{"ID": "00170070", "file_name": "Malware Detection System Using Machine Learning", "content": "The results for the optimal parameters in opcode-based CNN have the overall accuracy is relatively low, at 0.8282. However, the noteworthy that several families,Figure 3.5: Summary hyperparameters of RNNs experiments which are frequently misclassified by using image-based models, are classified with higher accuracy by using opcode. For instance, DelfInject achieves over 0.9 accuracy with opcode-based instead of 0.71 as using previous CNN experiments.", "label": "human"}
{"ID": "00170071", "file_name": "Malware Detection System Using Machine Learning", "content": "Recurrent Neural Networks Experiments Next, I would like to explore a range of experiments using different recurrent neural network (RNN) architectures. Specifically, I utilize standard RNN, LSTM, and GRU models. Additionally, I examine a complex stacked model combining LSTM and GRU layers.", "label": "human"}
{"ID": "00170072", "file_name": "Malware Detection System Using Machine Learning", "content": "Vanilla RNN, LSTM, and GRU I have trained vanilla RNNs, LSTMs, and GRU-based models for 20 epochs each, using a learning rate of 0.001 and a batch size of 128, based on the first 500 opcodes from each malware sample. I have conducted multiple experiments with various other parameters. Additionally, I applied a dropout layer with 0.3 probabil-ity for all models with more than one layer.", "label": "human"}
{"ID": "00170073", "file_name": "Malware Detection System Using Machine Learning", "content": "The vanilla RNN experiments performed poorly, achieving an overall accuracy of just 0.7294, so we have omitted the confusion matrix for this case. In contrast, both the LSTM and GRU models performed well, with accuracies of 0.8916 and 0.9003, respectively. Since the LSTM results are very similar, I have omitted theLSTM confusion matrix. From Figure 4, I observe that the results of GRU exper iments qualitatively align more closely with the CNN opcode-based experimentsthan the CNN image-based experiments. However, quantitatively, GRU opcodebased experiments yield significantly better results than CNN opcode-based exper iments.", "label": "human"}
{"ID": "00170074", "file_name": "Malware Detection System Using Machine Learning", "content": "Stacked LSTM-GRU Model A configuration option, referred to as LG, determines the stacking order of the LSTM and GRU layers. When LG is set to false, the LSTM is stacked on top of the GRU. Conversely, when LG is set to true, the GRU is stacked on top of the LSTM.", "label": "human"}
{"ID": "00170075", "file_name": "Malware Detection System Using Machine Learning", "content": "For instance, with LG set to true, opcode inputs are first processed by the LSTM layers, and the output (hidden cells) from the LSTM serves as input to the GRU layers. The GRU output is then passed to fully connected layers for classification. I applied a dropout layer with a 0.3 probability for models with more than one layer.", "label": "human"}
{"ID": "00170076", "file_name": "Malware Detection System Using Machine Learning", "content": "Transfer Learning Finally, I examined two well-known image-based transfer learning model: ResNet152 and VGG-19. These models have been pre-trained for very large image datasets.", "label": "human"}
{"ID": "00170077", "file_name": "Malware Detection System Using Machine Learning", "content": "For ResNet152, I unfroze the parameters of layer four for training and added two additional fully connected layers. ResNet152, pre-trained on 1000 classes, has a final fully connected layer with 1000 output dimensions. I reduced this to 500 dimensions with an additional fully connected layer, and further to 20 dimensions, matching the number of classes in our dataset.", "label": "human"}
{"ID": "00170078", "file_name": "Malware Detection System Using Machine Learning", "content": "For VGG-19, I kept all layers frozen except for layers 34, 35, and 36. Similar to ResNet152, I added two fully connected layers to reduce the output dimension from 1000 to 20.", "label": "human"}
{"ID": "00170079", "file_name": "Malware Detection System Using Machine Learning", "content": "In all transfer learning experiments, I used a batch size of 256 and trained each model for 20 epochs with learning rates of 0.001 and 0.0001. Both ResNet152 andaccordingly.", "label": "human"}
{"ID": "00170080", "file_name": "Malware Detection System Using Machine Learning", "content": "These transfer learning models outperformed other deep learning experiments,with ResNet152 achieving an overall accuracy of 0.9150 and VGG-19 slightly bet ter at 0.9216. Compared to other image-based deep learning models we tested, these models showed significant improvement in classifying the most challenging families, such as Obfuscator.4.1 Results and discussion This section provide some matrices as the result of experiments.", "label": "human"}
{"ID": "00170081", "file_name": "Malware Detection System Using Machine Learning", "content": "KNN experiments Overall Performance Accuracy: The model has a high overall accuracy. To calculate the accuracy,sum the diagonal elements (correct predictions) and divide by the total num ber of samples.", "label": "human"}
{"ID": "00170082", "file_name": "Malware Detection System Using Machine Learning", "content": "Precision: The precision for each class measures how accurate the model is when it predicts that class. For example, the precision of \"zeroaccess\" is thenumber of correctly classified \"zeroaccess\" samples divided by the total num ber of samples predicted as \"zeroaccess.\"Recall: The recall for each class measures how well the model is able to iden tify samples belonging to that class. For example, the recall of \"zeroaccess\" is the number of correctly classified \"zeroaccess\" samples divided by the total number of actual \"zeroaccess\" samples.", "label": "human"}
{"ID": "00170083", "file_name": "Malware Detection System Using Machine Learning", "content": "Class-Specific Observations High Accuracy Classes: Some classes like \"zeroaccess\", \"vundo\", \"zbot\" havea high number of correctly classified samples. This indicates the model per forms well in identifying these specific malware families.", "label": "human"}
{"ID": "00170084", "file_name": "Malware Detection System Using Machine Learning", "content": "Challenging Classes: Classes like \"obfuscator,\" \"fakerean,\" \"delfinject\" show a lower accuracy rate. This could mean the model struggles to differentiate these malware families from others.", "label": "human"}
{"ID": "00170085", "file_name": "Malware Detection System Using Machine Learning", "content": "Misclassifications: Look for patterns in misclassifications. For example, are certain classes frequently misclassified as others? Understanding these pat-Figure 4.1: Confusion matrix of KNN experiment terns can help guide model improvement efforts.", "label": "human"}
{"ID": "00170086", "file_name": "Malware Detection System Using Machine Learning", "content": "After normalizing, I get the normalized confusion matrix which represent the proportion of samples that were classified correctly and incorrectly.", "label": "human"}
{"ID": "00170087", "file_name": "Malware Detection System Using Machine Learning", "content": "StrengthsStrong Accuracy: The model shows a high level of accuracy for several mal ware families. The diagonal of the matrix shows high values for adload, alureon, ceeinject, bho, cycbot, fakerean, hotbar, lolyda, obfuscator, ongames, rbot, renos, startpage, vobfus, vundo, winwebsec, and zbot.", "label": "human"}
{"ID": "00170088", "file_name": "Malware Detection System Using Machine Learning", "content": "Good Discrimination: The model is generally able to distinguish between different malware families. Many of the off-diagonal values are very low, indi cating minimal confusion between classes.", "label": "human"}
{"ID": "00170089", "file_name": "Malware Detection System Using Machine Learning", "content": "Area for ImprovementClass Imbalance: The matrix seems to have some class imbalances. For ex ample, delfinject has a high false positive rate, and zeroaccess is not predicted accurately. This suggests that the model might need more training data forFigure 4.2: Normalized Confusion matrix of KNN experiment these specific malware families to better represent their characteristics 4.1.2 Random Forest experiments According to the confusion matrix, the model performs well on most of the classes, achieving high accuracy and low misclassification rates. However, there are a few classes where the model struggles:", "label": "human"}
{"ID": "00170090", "file_name": "Malware Detection System Using Machine Learning", "content": "winwebsec: This class has a high number of false positives (74), meaning thatmany instances are misclassified as winwebsec when they are actually some thing else.", "label": "human"}
{"ID": "00170091", "file_name": "Malware Detection System Using Machine Learning", "content": "vundo: This class also has a high number of false positives (35), but a lower number of false negatives (1) compared to winwebsec.", "label": "human"}
{"ID": "00170092", "file_name": "Malware Detection System Using Machine Learning", "content": "alureon, fakerean, hotbar, lolyda, ongames, rbot, startpage, zeroaccess:Figure 4.3: Confusion matrix of Random Forest experiment These classes have high accuracy with low false positive and false negative rates.", "label": "human"}
{"ID": "00170093", "file_name": "Malware Detection System Using Machine Learning", "content": "In conclusion, the model shows promising performance, but improvements can be made by addressing the misclassification issues in winwebsec and vundo.", "label": "human"}
{"ID": "00170094", "file_name": "Malware Detection System Using Machine Learning", "content": "High Accuracy: The diagonal elements of the matrix are high, indicating thatFigure 4.4: Normalized Confusion matrix of Random Forest experiment the model is accurately predicting the true class for a large number of samples.", "label": "human"}
{"ID": "00170095", "file_name": "Malware Detection System Using Machine Learning", "content": "Good Precision: The model is particularly good at classifying zeroaccess, win websec, vundo, fakerean, cycbot, and adload with very few misclassifications.", "label": "human"}
{"ID": "00170096", "file_name": "Malware Detection System Using Machine Learning", "content": "Data Augmentation: Increasing the size and diversity of the training data might help the model learn subtle differences between these classes.", "label": "human"}
{"ID": "00170097", "file_name": "Malware Detection System Using Machine Learning", "content": "After normalizing, the confusion matrix the model performs well overall, withFigure 4.5: Confusion matrix of XGB experiment high accuracy for most of the malware families. However, there are some areas for improvement:", "label": "human"}
{"ID": "00170098", "file_name": "Malware Detection System Using Machine Learning", "content": "High False Positives: Some malware families, like ’vundo’ and ’zeroaccess’, have a high number of false positives, meaning they are often misclassified asother families. This might suggest that these families share some characteris tics with other malware, making it difficult for the model to distinguish them accurately.", "label": "human"}
{"ID": "00170099", "file_name": "Malware Detection System Using Machine Learning", "content": "Low Precision for ’winwebsec’: While ’winwebsec’ is correctly classified most of the time, its precision is relatively low. This suggests that other malware families are often misclassified as ’winwebsec’, indicating potential overlap in their characteristics.", "label": "human"}
{"ID": "00170100", "file_name": "Malware Detection System Using Machine Learning", "content": "RNN experimentsThe confusion matrix shows that the model is performing well, with high accu racy on most classes. However, there are some areas for improvement.", "label": "human"}
{"ID": "00170101", "file_name": "Malware Detection System Using Machine Learning", "content": "High accuracy on most classes: The model correctly predicts the majority ofFigure 4.6: Normalized Confusion matrix of XGB experiment instances for most classes, as indicated by the diagonal values.", "label": "human"}
{"ID": "00170102", "file_name": "Malware Detection System Using Machine Learning", "content": "Good performance on certain classes: The model seems to have particularly strong performance on classes like \"zeroaccess\", \"rbot\", \"agent\", \"vundo\", and hotbar\", with high numbers of correct predictions.", "label": "human"}
{"ID": "00170103", "file_name": "Malware Detection System Using Machine Learning", "content": "Confusion between certain classes: There are a few instances of misclassification, suggesting some overlap in features between certain classes. For exam ple:", "label": "human"}
{"ID": "00170104", "file_name": "Malware Detection System Using Machine Learning", "content": "Relative lack of data for some classes: Some classes have significantly fewerinstances than others. This can impact model performance. For example, \"on games\" and \"delfinject\" have limited samples, potentially leading to lessFigure 4.7: Confusion matrix of RNN experiment accurate predictions.", "label": "human"}
{"ID": "00170105", "file_name": "Malware Detection System Using Machine Learning", "content": "By comparing the accuracy of training techniques, we can see that: Among the deep learning techniques, the image-based pre-trained models, specifically ResNet152and VGG-19, perform the best, with VGG-19 correctly classifying over 92 per cent of the samples. The best of our other image-based models (i.e., those not pre-trained) achieved just under 90 percent accuracy.", "label": "human"}
{"ID": "00170106", "file_name": "Malware Detection System Using Machine Learning", "content": "Although the opcode-based results were generally less effective, it’s noteworthythat they classified certain families with higher accuracy than any of the imagebased models. This indicates that a model combining both image features and op code features could potentially be more effective than using either approach alone.Figure 4.8: Normalized Confusion matrix of RNN experiment Figure 4.9: Model loss of RNNFigure 4.10: Model loss of RNN5.1 Conclusion 5.1.1 Knowledge gained during working process During this process of working, I have gained a vast amount of knowledge about:", "label": "human"}
{"ID": "00170107", "file_name": "Malware Detection System Using Machine Learning", "content": "Researching and applying the machine learning and deep learning techniques into my working Having chance to build and train model in the field of security Testing model with a large dataset at high accuracy, and least loss sectionLimitations Due to some inevitable problems, I have to pause my process for some period of time, so I could not complete my plan on time. Therefore, this thesis is lacking of the front end UI.", "label": "human"}
{"ID": "00170108", "file_name": "Malware Detection System Using Machine Learning", "content": "Besides, I could say that I have tried my best to complete the model with the expected core. The model is stopping at testing, and have not been deployed in the real situation yet, so there would be risks while detecting malware in real life.", "label": "human"}
{"ID": "00170109", "file_name": "Malware Detection System Using Machine Learning", "content": "I would also like to research more to make to system work stably on the network.<PE header analysis for malware detection : Samuel Kim. PE header analysis for malware detection. Master’s thesis, San Jose State University, 2018. ><Malware Analysis Using Artificial Intelligence and Deep Learning : Pratikku mar Prajapati, Mark Stamp><Transfer Learning for Image-Based Malware Classification : Niket Bho dia1, Pratikkumar Prajapati1, Fabio Di Troia1 and Mark Stamp>", "label": "human"}
{"ID": "00180001", "file_name": "Vietnamese Multi-document Summarization", "content": "Text Summarization is the task of condensing lengthy texts into concise and coherent summaries that effectively conveys the main ideas and important information.", "label": "human"}
{"ID": "00180002", "file_name": "Vietnamese Multi-document Summarization", "content": "This task is exceptionally difficult, even for human beings. With the massive amount of textual content available, especially due to the ever-expanding Internet, comprising web pages, news articles, status updates, blogs, and more, it becomes increasingly challenging to navigate through this vast amount of unstructured data. As a result, we often rely on search engines and skim through the search results. However, there is a need to reduce the length of this textual data by generating focused summaries that capture the important details. This would enable us to navigate the content more efficiently and determine whether larger documents contain the information we are looking for. Additionally, it is impractical to manually create summaries for all documents.", "label": "human"}
{"ID": "00180003", "file_name": "Vietnamese Multi-document Summarization", "content": "The task of Multi-document Text Summarization is even more challenging as it involves clusters of related documents that can be lengthy, containing overlapping content and spanning thousands of words. In my research on developing a deep neural network for Vietnamese Multi-document Summarization, I encountered a major obstacle due to the scarcity of labeled data. Until recently, only three small publicly available datasets, each comprising approximately 300 samples, existed.", "label": "human"}
{"ID": "00180004", "file_name": "Vietnamese Multi-document Summarization", "content": "To overcome this limitation, recent studies such as Phobert, BartPho , and ViT5  have utilized a large amount of unlabeled data for pre-training language models, followed by fine-tuning them on a smaller set of labeled data specifically for multi-document summarization.", "label": "human"}
{"ID": "00180005", "file_name": "Vietnamese Multi-document Summarization", "content": "However, these pre-trained language models have two common limitations. Firstly, they are designed as general-purpose language models, meaning that they are trained with the objective of modeling the probability distribution over sequences of words.", "label": "human"}
{"ID": "00180006", "file_name": "Vietnamese Multi-document Summarization", "content": "For instance, BARTpho  is based on the BART model , which corrupts input text using a noising function and then learns to reconstruct the original text. Secondly, these models have architectures that are not well-suited for processing long input sequences, which poses a challenge for multi-document summarization tasks. Additionally, studies on multi-document text summarization in Vietnamese texts are still in the early phases and there are not many Vietnamese language models designed especially for this task because the resources are quite scarce.", "label": "human"}
{"ID": "00180007", "file_name": "Vietnamese Multi-document Summarization", "content": "Motivated by these limitations and my willing to contribute to the developmentof research on abstractive multi-document summarization for Vietnamese text, this Bachelor thesis focuses on building a Vietnamese task-specific language model using an objective function specifically designed for Multi-document Summarization, which is modified from a English model to be suitable for Vietnamese contexts.", "label": "human"}
{"ID": "00180008", "file_name": "Vietnamese Multi-document Summarization", "content": "Recent advancements in deep learning techniques have significantly improvedthe performance of text summarization models over the past few decades. State-of the-art approaches can be categorized as extractive (MatchSum , DiscoBERT , BertSumExt , and PNBert ), abstractive (BRIO  and SimCLS ), or hybrid (EASE ). The task is challenging due to the difficulty in data creation and performance evaluation. For Vietnamese, there has been little attention on Text Summarization, especially in the context of Multi-document Summarization.", "label": "human"}
{"ID": "00180009", "file_name": "Vietnamese Multi-document Summarization", "content": "For instance,  combined various techniques such as word co-occurrences, TF IDF, position-based, title-based, and proper noun-based methods to select salientsentences and generate the summary. Another study by  introduced a graph based system that utilized a self-organizing map to cluster documents and extract the main idea.", "label": "human"}
{"ID": "00180010", "file_name": "Vietnamese Multi-document Summarization", "content": "In terms of Vietnamese Multi-document Summarization, there have been limited studies. One of the earliest research works by  presented an extractive system comprising three phases: pre-processing, score computation, and summarization generation. The system employed a set of manually selected features at both word and sentence levels, specifically tailored for Vietnamese news text, to compute sentence scores. These features included word frequency, word location, sentence position, time, and PageRank-based sentence features.", "label": "human"}
{"ID": "00180011", "file_name": "Vietnamese Multi-document Summarization", "content": "Recent research efforts have predominantly focused on optimizing the capabilities of transformer-based models for Vietnamese Text Summarization. For instance,  introduced extractive models that utilize variations of BERT to generate sentence embeddings. These models concatenate multiple documents into a single paragraph, employ BERT for sentence encoding, and utilize K-means clustering to rank and select salient sentences for summarization. More recently,  presented BARTpho, a large-scale Vietnamese sequence-to-sequence model based on the BART architecture. BARTpho includes two versions: BARTpho wordand BARTpho syllable . Thesemodels were pretrained on extensive corpora, consisting of 145 million word segmented sentences and 4 billion syllable tokens. Subsequently, fine-tuning was performed on the VNDS dataset , which focuses on Vietnamese single-document summarization. The BARTpho models achieved notable performance compared to previous approaches. In addition, Phan et al. introduced ViT5 , a pretrained Transformer-based encoder-decoder model specifically designed for the Vietnameselanguage, based on T5-style self-supervised pretraining. ViT5-large achieved state of-the-art results on Vietnamese Abstractive Text Summarization datasets.", "label": "human"}
{"ID": "00180012", "file_name": "Vietnamese Multi-document Summarization", "content": "However, a key challenge remains that both BARTpho and ViT5 were not specifically designed for the Multi-document Summarization task, which involves processing lengthy inputs and clusters of related documents with potentially thousands of words.", "label": "human"}
{"ID": "00180013", "file_name": "Vietnamese Multi-document Summarization", "content": "In recent years, pre-trained models have demonstrated remarkable performance when fine-tuned for specific tasks. After careful examination of the challenges at hand and the modern deep neural network models available, I have made the decision to adopt the PRIMERA model  for the following reasons:", "label": "human"}
{"ID": "00180014", "file_name": "Vietnamese Multi-document Summarization", "content": "Unlike general-purpose pre-trained language models like T5  and BART , the PRIMERA model is specifically designed for multi-document summarization, building on the foundations of the Longformer architecture, which was created to address the issue of processing lengthy input data. It incorporates two key components: (1) the self-supervised objective called Gap Sentence Generation, proposed in , along with the Pyramid Entity strategy to identify and aggregate salient information from multiple documents, and (2) the Longformer architecture , which utilizes sparse local and global attentions to achieve ar complexity relative to the input length. Longformer can process input sequences of up to 16,000 tokens, making it particularly well-suited for Multi-document Summarization.", "label": "human"}
{"ID": "00180015", "file_name": "Vietnamese Multi-document Summarization", "content": "Leveraging the Transformer architecture  and trained on a substantial amount of data, the PRIMERA model exhibits excellent performance in generating grammatically and semantically correct summaries, showcasing its proficiency in capturing contextual meaning.", "label": "human"}
{"ID": "00180016", "file_name": "Vietnamese Multi-document Summarization", "content": "The training of the PRIMERA model follows a two-step process: first, it undergoes pre-training on a large, unlabeled dataset, followed by fine-tuning on a smaller dataset with labeled samples. This training scenario is ideal for supervised learning tasks with limited training data.Based on PRIMERA, I have modified the model to be applicable for the Vietnamese language. This involved three main modifications related to word segmentation, tokenization, and named entity recognition. I also tried changing a little about the input to the Query, Key, Value matrices of the Transformers architecture . To facilitate training, I generated large-scale multi-document summarization datasets using the Pyramid Entity strategy. Pseudo summaries were created by extracting sentences with high Rouge scores, considering the frequency of named entities across the documents. These datasets were then used for pre-training the model.", "label": "human"}
{"ID": "00180017", "file_name": "Vietnamese Multi-document Summarization", "content": "The proposed language model aims to address the challenges posed by multi document summarization in Vietnamese, enabling the automatic generation of abstractive summaries for a collection of news documents on a given topic. It targets the datasets ViMs, VMDS, and VLSP, which represent diverse multi-document summarization tasks in the Vietnamese language. By constructing this language model, we seek to enhance the summarization capabilities for Vietnamese texts and improve thequality of generated abstractive summaries. The model’s development and fine tuning on these datasets are expected to lead to significant advancements in the field of Vietnamese multi-document text summarization.", "label": "human"}
{"ID": "00180018", "file_name": "Vietnamese Multi-document Summarization", "content": "The successful completion of this research objective will contribute valuable insights and tools to facilitate effective information extraction and summarization from multiple sources, ultimately benefiting the broader community in understanding and accessing information in the Vietnamese language. To the best of my knowledge, this becomes the first large-scale pre-trained task-specific language model specifically designed for Vietnamese Multi-document Summarization.", "label": "human"}
{"ID": "00180019", "file_name": "Vietnamese Multi-document Summarization", "content": "Methodology: The modified PRIMERA model for Vietnamese Multi-document Text Summarization task: Case study in Vietnamese contexts and present in depth the model architecture.", "label": "human"}
{"ID": "00180020", "file_name": "Vietnamese Multi-document Summarization", "content": "Experiments Results Conclusion and Future Works2.1 Scope of Research This research focuses on Vietnamese text summarization, particularly in the context of abstractive multi-document summarization. Specifically, the author explored the use of pre-trained models and studied PRIMERA , a specialized model formulti-document summarization, due to its impressive performance. Unlike general purpose models like T5  and BART , PRIMERA is specifically designed for this task and incorporates two key components: the Gap Sentence Generation objective proposed in  and the Longformer architecture , which enables efficient processing of long sequences.", "label": "human"}
{"ID": "00180021", "file_name": "Vietnamese Multi-document Summarization", "content": "To make PRIMERA applicable for Vietnamese, certain modifications were implemented in areas such as word segmentation, tokenization, and named entity recognition.", "label": "human"}
{"ID": "00180022", "file_name": "Vietnamese Multi-document Summarization", "content": "These adjustments were necessary to accommodate the unique linguistic characteristics of Vietnamese. Additionally, large-scale multi-document summarization datasets for Vietnamese were created using the Pyramid Entity strategy. These datasets were employed in the pre-training of the model, resulting in the development of the first task-specific language model for Vietnamese multi-document summarization.", "label": "human"}
{"ID": "00180023", "file_name": "Vietnamese Multi-document Summarization", "content": "By enhancing PRIMERA and generating Vietnamese-specific datasets, this research contributes to improving the accuracy and performance of summarizing Vietnamese text across multiple documents.", "label": "human"}
{"ID": "00180024", "file_name": "Vietnamese Multi-document Summarization", "content": "English text summarization The attention mechanism  has emerged as a crucial architectural feature in transformer-based models, including the original transformer proposed by Vaswani et al. . As transformers gained popularity in text generation tasks, numerous models for text summarization have been introduced. These tasks are commonly categorized into extractive and abstractive generation, both of which can utilize different components of transformers as their backbones. BERT architecture  is often employed as a backbone for extractive-based text summarization tasks.", "label": "human"}
{"ID": "00180025", "file_name": "Vietnamese Multi-document Summarization", "content": "However, due to its bidirectional encoding nature, BERT is not easily adaptable forgenerative tasks, such as abstractive text summarization. Therefore, other transformer based models are preferred for such generative formats.", "label": "human"}
{"ID": "00180026", "file_name": "Vietnamese Multi-document Summarization", "content": "In , the BART framework was introduced as a solution to overcome generative limitations. BART is based on the Transformer architecture, similar to BERT, butFigure 2.1: Transformer-based Text Summarization models dependency hierarchy; blocks, highlighted with yellow, represent models with sparse attention mechanism that is crucial for long input token sequence; Vietnamese-targeted models are bordered  it incorporates an autoregressive decoder to enhance the generation process. Thisframework follows a denoising sequence-to-sequence approach, wherein the pre training stage involves two key tasks: (1) corrupted text restoration and (2) original text reconstruction, i.e. translation. One of the strengths of BART lies in its flexibility, as both the core components, namely the BERT-based encoder and the autoregressive decoder, can be modified to suit specific needs, including pre-training schemes modification. BART has demonstrated remarkable effectiveness in various text generation tasks, particularly text summarization. Upon its introduction, BART LARGE showed significant improvement over previous models on the XSum dataset , as illustrated in Table 2.1.", "label": "human"}
{"ID": "00180027", "file_name": "Vietnamese Multi-document Summarization", "content": "The Text-To-Text Transfer Transformer (T5) , which stems from the foundational Transformer architecture , stands out with the following modifications: (1) removing the Layer Norm bias, placing the layer normalization outside the residual path; (2) adopting a different embedding scheme by switching from absolute toward relative token positioning (the offset between «key» and «query» then to be compared in self-attention mechanism). The T5 LARGE version pre-trained with Principle Sentences Generation strategy achieved impressive Rouge scores on several common datasets (see Table 2.1). The inefficiency of this solution arises from its computational limitations ( O(n2)where nis the input size), particularly when dealing with longerinput sequences.BART, T5 have become a fundamental architecture for a variety set of text summarization oriented frameworks, such as follows. In , authors proposed PEGASUS framework, in which the masking scheme spreads not only onto tokens but also to the whole sentences(in contrast to BART, T5) considered as most significant among within the entire input text. In terms of sentence significance, the authors propose salient sentence selection approach, which involves a proposed sentence scoring algorithm with a limited selection of top scored. According to the extensive experiments on XSum, CNN/DailyMail , and GigaWord, the authors illustrate that the PEGASUS LARGE version  outperforms the other Transformer-based models including BART, T5 (see Table 2.1).", "label": "human"}
{"ID": "00180028", "file_name": "Vietnamese Multi-document Summarization", "content": "To overcome the challenges posed by the limited input length of self-attention mechanisms, researchers have explored sparse variations. In one such study, Longformer and the associated encoder-decoder model (LED) were introduced . LED is a modified version of the original transformer architecture with windowed attention (sliding window) variation. This allows tokens to attend only to their rleft and right neighboring tokens. A key advantage of Longformer is its ar complexity relative to the input length, enabling it to handle sequences of up to 16,000 tokens with accepted resources. This makes it particularly well-suited for tasks involving long documents or multi-document summarization. Figure 2.5 illustrates models with sparse-attention mechanisms. In experiments conducted on the arXiv dataset , LED LARGE (447M parameters) outperformed PEGASUS (4K)  and achieved results equivalent to BigBird (4K)  when the input size was increased from 4K to 16K tokens. The impact of LED as a backbone extends to subsequent models.", "label": "human"}
{"ID": "00180029", "file_name": "Vietnamese Multi-document Summarization", "content": "There are also some architectures dealing with long documents such as BigBird  and LongT5 . In BigBird  related studies, authors interpreted the idea of Boolean attention matrices , which treats attention as a graph of connections, described by adjacency matrices A∈[0,1]n,n(ndenotes the input size), with A[i, j] = 1 when iattends to j, and 0in case its absence. The authors treated the problem of reducing the ones-like matrix Afor self-attentive mechanism connectionas a graph sparsification problem. Being complemented slided window and global attention  with Erd ˝os-Rényi model of independently choosing edge with fixed probability, authors attempt to prove Turing Completeness of the result sparsed version of the proposed attention, computationally ar in the number of tokens.", "label": "human"}
{"ID": "00180030", "file_name": "Vietnamese Multi-document Summarization", "content": "The outcome is as follows: the more sparse the graph, the more layers are required to reach completeness. For text-summarization, the author experiment with sparsedTable 2.1: Transformer-based models statistic  CNN/DailyMail (44.17, 21.47, 41.11) PEGASUS  Transformer + Gap-Sentence Selection Multi-News (47.52, 18.72, 24.91) Gigaword (39.12, 19.86, 36.24) arXiv (44.21 16.95 38.83 BART LARGE  Bidirectional encoder + autoregressive decoder XSum (45.14 22.27 37.25) LED LARGE (16K)  Transformer + windowed attention arXiv (46.63 19.62 41.83) LED + sparse attention (encoder side) arXiv (46.63 19.02 41.77) BigBird-PEGASUS + random attention mask PubMed (46.32 20.65 42.33) PEGASUS pretraining strategy BigPatent (60.64 42.46 50.01) CNN/DailyMail (43.41 20.99 40.77) Transformer + relative token positioning Multi-News (47.48 18.60 24.31) T5LARGE  + layer norm bias and normalization changes BigPatent (67.05 52.24 58.70) PEGASUS pretraining strategy arXiv (45.86 18.40 41.62) PubMed (48.94 22.92 45.4) PRIMERA LARGE  Longformer + Entity Pyramid Strategy arXiv (47.60, 20.80, 42.60) Multi-News (49.90, 21.10, 25.90) CNN/DailyMail (42.49 20.51 40.18) LongT5 LARGE  T5 + attention from LED BigPatent (70.38 56.81 62.73) arXiv (48.28 21.63 44.11) PubMed (49.98 24.69 46.46) attention at encoder side, using pretrained schemes from PEGASUS  for LARGE sized models, which dubbed as BigBird-PEGASUS.", "label": "human"}
{"ID": "00180031", "file_name": "Vietnamese Multi-document Summarization", "content": "LongT5 , a modified version of T5, incorporates sparsed attention mechanisms proposed in the ETC model , such as windowed attention and global-local attention . It is worth highlighting that the global-local attention LongT5 (4K input) illustrates top results on the variety of text-generative tasks among other models discussed above on almost every text summarization dataset (16K input), i.e. arXiv, PubMed, BigPatent, and MediaSum, while PRIMERA LARGE (447M) achieves better results in the Multi-news dataset due to its specific adaptation to news-related information during the pretraining stage. However, this improvement comes at the cost of a larger number of parameters, with LongT5 LARGE having 780M parameters, nearly twice the size of PRIMERA LARGE with 447M parameters.", "label": "human"}
{"ID": "00180032", "file_name": "Vietnamese Multi-document Summarization", "content": "Various works experienced in English have been dedicated to to tackle the challenge of handling longer input sequences in natural language processing tasks. When being considered among noticable models in table 2.1, PRIMERA stands out with a specially designed method for multi-document context, has the best result and is also suitable for Vietnamese( which has a lack of resources) In the context of applying these advanced models to the Vietnamese language, the process involves several essential steps to ensure optimal performance and relevance:", "label": "human"}
{"ID": "00180033", "file_name": "Vietnamese Multi-document Summarization", "content": "Step 1: The first crucial task is to collect or build a comprehensive dataset specifically tailored for the Vietnamese language model. This dataset should be large-scale and encompass a diverse range of linguistic patterns and characteristicsrepresentative of the Vietnamese language’s nuances.", "label": "human"}
{"ID": "00180034", "file_name": "Vietnamese Multi-document Summarization", "content": "Step 2: Pre-train the model (modify the objective function to make it more suitable on Vietnamese language should be considered).", "label": "human"}
{"ID": "00180035", "file_name": "Vietnamese Multi-document Summarization", "content": "Step 4: Finally, the pre-trained model undergoes fine-tuning on the curated Vietnamese Text Summarization datasets. This fine-tuning process enables the model to align itself more closely with the specific language and summarization tasks, resulting in superior performance and contextually relevant summarization outputs.", "label": "human"}
{"ID": "00180036", "file_name": "Vietnamese Multi-document Summarization", "content": "By carefully following this step-by-step approach and adapting the models to suit the context of the Vietnamese language, we can harness the full potential of these advanced models and achieve highly effective and contextually accurate text summarization for Vietnamese.", "label": "human"}
{"ID": "00180037", "file_name": "Vietnamese Multi-document Summarization", "content": "Vietnamese text summarization Over the past few years, significant advancements in deep learning techniques have led to remarkable progress in text summarization models. However, the field of Vietnamese Text Summarization, especially in the context of Multi-document Summarization, has received limited attention. Previous research on Vietnamese text summarization mainly focused on single-document summarization, relying on extractive methods and traditional statistical techniques. For example, Thanh et al.  proposed a summarization approach that combined various methods, suchas word co-occurrences, TF-IDF, position-based, title-based, and proper noun based approaches, to select salient sentences for generating summaries. In a related work, Ung et al. (2015)  presented an extractive system specifically designed for Vietnamese Multi-document summarization. Their approach involved three phases:", "label": "human"}
{"ID": "00180038", "file_name": "Vietnamese Multi-document Summarization", "content": "pre-processing, score computation, and summarization generation. They incorporated a set of manually selected features at both word and sentence levels, tailored for Vietnamese news text. These features encompassed word frequency, word location, sentence position, time, and PageRank-based sentence features.", "label": "human"}
{"ID": "00180039", "file_name": "Vietnamese Multi-document Summarization", "content": "Recent research efforts have primarily focused on leveraging the power of transformer based models. For extractive summarization, models proposed by  utilized BERT variants. These models employed a strategy of combining multiple documents into a single paragraph, leveraging BERT to encode sentences, and subsequently applying K-means clustering to rank and select the most important sentences for summarization.Notably, PhoBERT , the first publicly available large-scale monolingual language model pre-trained for Vietnamese, displayed consistent improvements over the bestpre-trained multilingual model. It showcased superior performance in various Vietnamese specific NLP tasks.", "label": "human"}
{"ID": "00180040", "file_name": "Vietnamese Multi-document Summarization", "content": "More recently, BARTpho, introduced by , emerged as a significant Vietnamese sequence-to-sequence model based on the BART architecture . Comprising two versions, BARTpho wordand BARTpho syllable , these models were pretrained on extensive corpora consisting of 145 million automatically word-segmented sentences and 4 billion syllable tokens. The pre-trained models were then fine-tuned on the VNDS dataset , a Vietnamese single-document summarization dataset, where they exhibited remarkable performance surpassing previous models.", "label": "human"}
{"ID": "00180041", "file_name": "Vietnamese Multi-document Summarization", "content": "Additionally, ViT5 , introduced by Phan et al., featured a pretrained Transformer based encoder-decoder model specifically tailored for the Vietnamese language using T5-style self-supervised pretraining. ViT5-large underwent evaluation on two downstream tasks, Abstractive Text Summarization, and Named Entity Recognition, achieving state-of-the-art results on Vietnamese datasets.", "label": "human"}
{"ID": "00180042", "file_name": "Vietnamese Multi-document Summarization", "content": "However, a significant challenge is that BARTPho and ViT5 were not specifically tailored for the Multi-document Summarization task, which involves processing long inputs and clusters of related documents with potentially thousands of words.", "label": "human"}
{"ID": "00180043", "file_name": "Vietnamese Multi-document Summarization", "content": "Overall, the PRIMERA model  proves to be a well-rounded and effective choice for our multi-document summarization task, providing the potential to generate coherent and informative summaries by leveraging its Transformer-based architecture and the large-scale data-driven training approach. With all these motivations to solve above limitations, I choose the PRIMERA model and modify it to buildan end-to-end language model that is the most suitable for Vietnamese multi document context.", "label": "human"}
{"ID": "00180044", "file_name": "Vietnamese Multi-document Summarization", "content": "The English language has a wealth of training data, ranging from unlabeled to labeled, with numerous notable examples. Some of these datasets include:", "label": "human"}
{"ID": "00180045", "file_name": "Vietnamese Multi-document Summarization", "content": "Multi-News is a multi-document summarization dataset containing 56k pairs of news articles and their professionally-written human summaries from the site newer.com. The summaries are carefully crafted by editors and include links to the original articles.", "label": "human"}
{"ID": "00180046", "file_name": "Vietnamese Multi-document Summarization", "content": "DUC20041is specifically designed and used for testing purposes. It includes 1 2.2: Newshead length distribution 500 news articles, each paired with four human-written summaries. The dataset comprises 50 clusters of Text Retrieval Conference (TREC) documents from different collections.", "label": "human"}
{"ID": "00180047", "file_name": "Vietnamese Multi-document Summarization", "content": "Multi-XScience  is a large-scale dataset for multi-document summarization of scientific articles. It has 30,369, 5,066 and 5,093 samples for the train, validation and test split respectively. The average document length is 778.08 words and the average summary length is 116.44 words.", "label": "human"}
{"ID": "00180048", "file_name": "Vietnamese Multi-document Summarization", "content": "WikiHow  consists of more than 230k article and summary pairs extracted and constrcuted from the on WikiHow.com websites written by different human authors. The articles span a wide range of topics and represent high diversity styles.", "label": "human"}
{"ID": "00180049", "file_name": "Vietnamese Multi-document Summarization", "content": "Another prominent English dataset is the Newshead dataset , which contains a vast collection of English stories with a total of 369,940 stories and 932,571 unique URLs. For my research, I utilized 359,940 stories for training and reserved 5,000 stories each for validation and testing purposes. Each news story in the dataset consists of a minimum of three and a maximum of five articles. The dataset was curated from news stories published between May 2018 and May 2019. To construct the dataset, a clustering algorithm was employed to group articles based on their content similarity within specific time windows. From each cluster, up to five representative articles were chosen, which were then used to generate concise heads for the stories. To ensure the quality and relevance of the heads,curators from a crowd-sourcing platform were engaged to provide concise summaries limited to 35 characters, effectively capturing the key information covered in each story.", "label": "human"}
{"ID": "00180050", "file_name": "Vietnamese Multi-document Summarization", "content": "In the realm of text summarization model evaluation, two key metrics take center stage: the ROUGE score  and the BLEU score. These metrics serve as crucial benchmarks for assessing the performance of summarization models.", "label": "human"}
{"ID": "00180051", "file_name": "Vietnamese Multi-document Summarization", "content": "While they provide valuable insights, it is essential to acknowledge that each metric has its limitations. To further enrich the evaluation process, some metrics rely on human resources for assessment, allowing for a more nuanced understanding of model performance. However, it is important to strike a balance between automated evaluation metrics and human judgment to achieve a comprehensive and accurate evaluation. As the field of text summarization continues to evolve, researchers and practitioners strive to develop more robust evaluation methodologies that consider diverse aspects of model performance. Integrating both automated metrics and human evaluations will foster a holistic and more nuanced evaluation landscape, ultimately leading to advancements in text summarization research and applications.", "label": "human"}
{"ID": "00180052", "file_name": "Vietnamese Multi-document Summarization", "content": "In the VLSP2022 competition, the ROUGE score has still been adopted as the primary metric to facilitate result comparison among participating models. This decision highlights the significance of the ROUGE score in gauging summarization model efficacy in this specific context.", "label": "human"}
{"ID": "00180053", "file_name": "Vietnamese Multi-document Summarization", "content": "ROUGE score ROUGE , which stands for Recall-Oriented Understudy for Gisting Evaluation, is widely used as the primary metric for assessing the quality of summaries. It compares an automatically generated summary to a set of reference summaries, typically created by humans.", "label": "human"}
{"ID": "00180054", "file_name": "Vietnamese Multi-document Summarization", "content": "ROUGE evaluates the similarity between the system summary and reference summary based on the overlap of individual words. It computes precision and recall to provide a quantitative measure of the quality.", "label": "human"}
{"ID": "00180055", "file_name": "Vietnamese Multi-document Summarization", "content": "In simple terms, recall in the context of ROUGE indicates how much of the information in the reference summary is captured by the system summary. It can be calculated as:", "label": "human"}
{"ID": "00180056", "file_name": "Vietnamese Multi-document Summarization", "content": "Recall =number of overlapping words total words in the reference summary(2.1)Precision, on the other hand, measures how much of the information in the system summary is relevant and necessary. Precision is calculated as:", "label": "human"}
{"ID": "00180057", "file_name": "Vietnamese Multi-document Summarization", "content": "Precision =number of overlapping words total words in the system summary(2.2) Precision is particularly important when generating concise summaries. Therefore, it is recommended to compute both precision and recall and report the F-measure, which combines both values.", "label": "human"}
{"ID": "00180058", "file_name": "Vietnamese Multi-document Summarization", "content": "BLEU BLEU, short for Bilingual Evaluation Understudy, is a metric used to compare a candidate translation with one or more reference translations. Although initially developed for translation evaluation, it can also be employed to assess text generated for various natural language processing tasks, including text summarization. The key advantages of BLEU are its efficiency, language independence, and strong correlation with human evaluation.", "label": "human"}
{"ID": "00180059", "file_name": "Vietnamese Multi-document Summarization", "content": "To calculate the BLEU score, the first step involves computing the precision score for 1-gram through 4-gram sequences. The precision of an n-gram is determined by the ratio of the number of correctly predicted n-grams to the total number of predicted n-grams.", "label": "human"}
{"ID": "00180060", "file_name": "Vietnamese Multi-document Summarization", "content": "Precision n-gram =number of correct predicted n-gram number of total predicted n-gram(2.3) Next, these precision scores are combined using the Geometric Average Precision (GAP) formula. The GAP can be computed for different values of N and with different weight values.GAP(N) =exp(NX n=1wnlogp n) =NY n=1pwnn= (p1)1 4.(p2)1 4.(p3)1 4.(p4)1 4 (2.4) The third step involves calculating the ’Brevity Penalty’ (BP), which penalizes sentences that are excessively short. Equation below defines the Brevity Penalty, where crepresents the predicted length (number of words in the predicted sentence) andrrepresents the target length (number of words in the reference sentence).", "label": "human"}
{"ID": "00180061", "file_name": "Vietnamese Multi-document Summarization", "content": "Brevity Penalty =  1 ifc > r Finally, the BLEU score is computed by multiplying the Brevity Penalty with the Geometric Average of the Precision scores.", "label": "human"}
{"ID": "00180062", "file_name": "Vietnamese Multi-document Summarization", "content": "A language model is a model that predicts unseen words based on a given context. It plays a crucial role in Natural Language Processing (NLP) as manydownstream tasks, such as named entity recognition, question answering, and partof speech tagging, rely on its predictions. By accurately predicting unseen words, a language model can be seen as understanding human natural language.", "label": "human"}
{"ID": "00180063", "file_name": "Vietnamese Multi-document Summarization", "content": "There are two main types of language models: statistical language models and deep language models that utilize neural network. While statistical models have been traditionally used, the development of neural networks has led to the rise of deep language models. These deep models have shown promising results and gradually replaced many traditional statistical models.", "label": "human"}
{"ID": "00180064", "file_name": "Vietnamese Multi-document Summarization", "content": "Training a language model to understand human language is a time-consumingFigure 2.3: Language modeling examples: (a) next word prediction; (b) masked wordprediction.", "label": "human"}
{"ID": "00180065", "file_name": "Vietnamese Multi-document Summarization", "content": "process, often taking days or weeks. However, the advancements in deep learning have significantly improved the efficiency of training language models. In 2018, Google introduced BERT , a state-of-the-art language model that has since been widely adopted and utilized by both the research community and in production environments. BERT has demonstrated remarkable performance and has become a benchmark in the field of NLP.", "label": "human"}
{"ID": "00180066", "file_name": "Vietnamese Multi-document Summarization", "content": "During the early stages of deep learning in Natural Language Processing (NLP), Recurrent Neural Networks  (RNNs) were widely used and considered the standard approach for various NLP tasks. RNNs employed shared weights across input words to learn the contextual representation of words. Although this idea proved successful and became a popular choice, it had its limitations. Firstly, RNNs process input words sequentially, which hinder parallel computing and slow down training. Secondly, the use of shared weights cause issues with gradient vanishing and gradient exploding during backward propagation, as the gradient signals have to travel through a long path.", "label": "human"}
{"ID": "00180067", "file_name": "Vietnamese Multi-document Summarization", "content": "To address the problems associated with RNNs, two alternative architectures were introduced: Long-Short Term Memory  (LSTM) and Gated Recurrent Units  (GRU). These architectures created a \"highway\" for the gradient signal, allowing it to flow more effectively throughout the network. However, the inability to parallelize the computations remained a challenge.", "label": "human"}
{"ID": "00180068", "file_name": "Vietnamese Multi-document Summarization", "content": "In 2017, a groundbreaking architecture called Transformers  was introduced, marking a significant milestone in NLP. Transformers successfully addressed the drawbacks of previous models and outperformed existing bases. The architectureconsists of two main components: the encoder and the decoder, forming a sequence to-sequence model. The encoder converts the input sentence into a sequence of vectors in a hidden space, while the decoder utilizes these vectors to generateFigure 2.4: Transformers architecture  outputs.", "label": "human"}
{"ID": "00180069", "file_name": "Vietnamese Multi-document Summarization", "content": "Unlike RNNs, which compact contextual information into each word by processing words sequentially from left to right or right to left, transformers employ attention mechanisms. This allows each word in the sentence to directly attend to all other words, capturing contextual information across long distances. As a result, transformers overcome the issues of gradient vanishing and gradient exploding, as there is no prolonged path for backward flow of gradient signals. Figure 2.4 provides a visual representation of the transformers architecture, showcasing its sequence-to-sequence model structure. With its innovative design and attention mechanisms, transformers have revolutionized NLP and achieved superior performance compared to previous models.", "label": "human"}
{"ID": "00180070", "file_name": "Vietnamese Multi-document Summarization", "content": "The attention mechanism can be described as follows. Given a list of items, each represented by a key (K) and a value (V), a query (Q) aims to identify the important items in the list. To achieve this, the query computes similarity scores between itself and each key (K). The method for computing these similarity scores is flexible and not restricted to a specific approach. A commonly used choice is the dot product or a bi-ar function. The similarity scores are then normalized to form a probability vector known as attention scores. Each value in the attention scores represents the importance of the corresponding item.", "label": "human"}
{"ID": "00180071", "file_name": "Vietnamese Multi-document Summarization", "content": "In the final step, the query calculates a weighted sum of all the values (V) based on the probability vector. This weighted sum serves as the query’s new representationFigure 2.5: Full self-attention pattern and the configuration of attention patterns in Longformer  or output. The entire process can be mathematically formulated as follows:", "label": "human"}
{"ID": "00180072", "file_name": "Vietnamese Multi-document Summarization", "content": "Attention (Q, K, V ) =softmax\u0012 QKT ·V (2.7) here, Qrepresents the query, Kdenotes the set of keys, Vrepresents the set of values, and dkrepresents the dimensionality of the keys. The softmax function is applied to the scaled dot product of QandKdivided by the square root of dk.", "label": "human"}
{"ID": "00180073", "file_name": "Vietnamese Multi-document Summarization", "content": "This produces the attention scores, which are then multiplied element-wise with the values Vto obtain the weighted sum and the new representation of the query.", "label": "human"}
{"ID": "00180074", "file_name": "Vietnamese Multi-document Summarization", "content": "The emergence of large-scale language models has marked a significant advancementin NLP field. Among these, GPT-32stands as a remarkable example of cutting edge technology. Developed by OpenAI, GPT-3 is a highly powerful language model based on the GPT-3 architecture, trained on a massive dataset and can process up to 16,000 tokens. This model has demonstrated exceptional capabilities in understanding and generating human-like text, making it an influential force in various NLP tasks.", "label": "human"}
{"ID": "00180075", "file_name": "Vietnamese Multi-document Summarization", "content": "One of the defining features of GPT-3 is its immense size, which endows it with an unprecedented capacity for processing and comprehending lengthy input texts. Its vast token limit enables it to grasp extensive context, making it particularly adept at tasks that involve processing substantial textual content, such as multi-document summarization or long-form text generation.", "label": "human"}
{"ID": "00180076", "file_name": "Vietnamese Multi-document Summarization", "content": "GPT-3 operates on the principles of autoregressive language modeling, wherein it predicts the likelihood of each token in a sequence based on the preceding tokens.", "label": "human"}
{"ID": "00180077", "file_name": "Vietnamese Multi-document Summarization", "content": "This autoregressive nature facilitates fluent and coherent text generation, allowing the model to produce contextually appropriate responses, summaries, and evencreative writing. With its massive size and extensive training on diverse and large 2 datasets, GPT-3 has demonstrated remarkable performance in numerous natural language processing benchmarks and tasks. Its ability to comprehend and generate text across a wide range of domains and styles makes it a versatile tool with practical applications in various industries.", "label": "human"}
{"ID": "00180078", "file_name": "Vietnamese Multi-document Summarization", "content": "However, it is essential to consider that such large-scale models come with computational challenges and resource requirements. Training and utilizing GPT-3 demand significant computing power and memory resources, which may not be readily available to all researchers and developers.", "label": "human"}
{"ID": "00180079", "file_name": "Vietnamese Multi-document Summarization", "content": "Despite these challenges, the advent of GPT-3 has marked a significant milestone in natural language processing, setting new standards for language models’ capabilities.", "label": "human"}
{"ID": "00180080", "file_name": "Vietnamese Multi-document Summarization", "content": "Its remarkable performance and versatility make it a key player in the ongoing advancement of language understanding and generation technologies, opening up new possibilities for natural language applications in diverse fields.3.1 PRIMERA Similar to PEGASUS , the PRIMERA model is a task-specific pre-trained model. However, PRIMERA is specifically designed for the task of multi-document summarization. In stead of using the original Transformer architecture, PRIMERA utilizes the Longformer architecture  to handle lengthy input sequences, which in this case are the concatenation of multiple documents. The authors of PRIMERA introduce a novel masking strategy called the Entity pyramid strategy, aimed at identifying crucial information across documents and consolidating it into a single summary. Figure 3.1 illustrates the model architecture of PRIMERA.", "label": "human"}
{"ID": "00180081", "file_name": "Vietnamese Multi-document Summarization", "content": "The unit of information is called Summary Content Unit (SCU), i.e. words or phrases that are represent single facts. The Pyramid Evaluation method  is based on the intuition that relevance of a SCU can be determined by the number of (ground-truth) reference summaries that include it. PRIMERA utilizes the Pyramid Evaluation method to identify salient sentences for masking. In particular, for a cluster of multiple documents, the more documents an SCU appears in, the more salient that information should be to the cluster. However, in the original Pyramid Evaluation, SCUs are human-evaluated. This is large-time consuming and expensive.", "label": "human"}
{"ID": "00180082", "file_name": "Vietnamese Multi-document Summarization", "content": "For the purpose of generating a huge-dataset for pre-training PRIMERA, the authors leverage information expressed as named entities, since they are key part in a sentences about events/objects.", "label": "human"}
{"ID": "00180083", "file_name": "Vietnamese Multi-document Summarization", "content": "Pretraining Objective In the field of summarization, utilizing pretraining objectives tailored to specific tasks has shown significant improvements compared to using general-purpose pretrained transformers. PEGASUS  introduces the Gap Sentence Generation (GSG) objective, Figure 3.1: Model architecture of PRIMERA. Documents are separated with <doc-sep> tokens. Selected sentences are replaced with <mask> tokens.Figure 3.2: Entity Pyramid strategy for salient sentence selection.  where certain sentences in the input are masked, and the model is trained to generate them. Building upon this approach, PRIMERA incorporates the GSG objective while introducing a new masking strategy designed specifically for multi-document summarization tasks.", "label": "human"}
{"ID": "00180084", "file_name": "Vietnamese Multi-document Summarization", "content": "These selected sentences are replaced with a special token, <mask>, in the input, and the model is trained to generate the combined form of these sentences, creating a \"pseudo-summary\", shown in figure 3.1. This process resembles abstractive summarization, as the model reconstructs the masked sentences using the available information from the remaining parts of the documents.", "label": "human"}
{"ID": "00180085", "file_name": "Vietnamese Multi-document Summarization", "content": "The key concept lies in selecting sentences that effectively summarize or represent a group of related input documents, known as a \"cluster,\" instead of solely focusing on individual documents as in the standard GSG approach. PRIMERA’s authors argue that directly extending this strategy to multi-document summarization may lead to suboptimal results. This is because multi-document inputs often contain redundant information, and prioritizing exact matches between sentences would result in selecting less representative information. Therefore, PRIMERA aims to select sentences that effectively capture the overall essence of the entire cluster of input documents.", "label": "human"}
{"ID": "00180086", "file_name": "Vietnamese Multi-document Summarization", "content": "Entity Pyramid Masking The concept of Entity Pyramid Masking is inspired by the Pyramid Evaluation method introduced by Nenkova and Passonneau, which evaluates the relevance of information units based on their presence in reference summaries. In PRIMERA paper, authors proposed to apply a similar approach to multi-document summarization to identify important sentences for masking. Instead of using human-annotated Summary Content Units (SCUs), words or phrases that represent single facts as in the original Pyramid Evaluation method, authors explore the use of named entitiesas proxies for saliency.", "label": "human"}
{"ID": "00180087", "file_name": "Vietnamese Multi-document Summarization", "content": "Entity Pyramid Estimation: Based on the extracted named entities, an Entity Pyramid is constructed to estimate the salience of entities by considering their document frequency. This frequency indicates how often an entity appears across the cluster of related documents.", "label": "human"}
{"ID": "00180088", "file_name": "Vietnamese Multi-document Summarization", "content": "Sentence Selection: Following the Pyramid evaluation framework, salient sentences are identified, taking into account the cluster of related documents. The process involves iterating through the Entity Pyramid, selecting entities from top to bottom (highest to lowest frequency), and then choosing sentences that include the selected entity as the initial candidate set. To ensure that the selected sentences represent the entire cluster, their content overlap with other documents in the cluster is measured using ROUGE scores . This step encourages the model to connect and aggregate information across multiple documents during the pretraining phase.", "label": "human"}
{"ID": "00180089", "file_name": "Vietnamese Multi-document Summarization", "content": "It is important to note that entity information is only used during pretraining and not during fine-tuning or inference. Unlike previous approaches that incorporate additional information at those stages, Entity Pyramid strategy aims to select entities that better represent the entire cluster. This approach prioritizes content overlap across multiple documents rather than exact matching between a few documents.", "label": "human"}
{"ID": "00180090", "file_name": "Vietnamese Multi-document Summarization", "content": "In the PRIMERA model, two key components require modification to adapt it for the Vietnamese language: the Tokenizer model and the Named Entity Recognition (NER) model.", "label": "human"}
{"ID": "00180091", "file_name": "Vietnamese Multi-document Summarization", "content": "For the Tokenizer model, it is essential to choose a Vietnamese tokenizer that can effectively handle the specific linguistic characteristics of the Vietnamese language.", "label": "human"}
{"ID": "00180092", "file_name": "Vietnamese Multi-document Summarization", "content": "Vietnamese text often includes compound words, diacritics, and unique characters that require specialized handling during tokenization. Similarly, modifying the NER model is motivated by the need to accurately recognize and extract named entities from Vietnamese text. NER involves identifying and classifying named entities, such as person names, organization names, locations, and dates, in thetext. Vietnamese has its own set of named entities, and a dedicated NER model trained on Vietnamese data would be better suited to recognize and extract these entities accurately. Additionally, the NER model should be capable of handling the specific linguistic variations and complexities of the Vietnamese language.", "label": "human"}
{"ID": "00180093", "file_name": "Vietnamese Multi-document Summarization", "content": "By selecting the most suitable models, it can ensure that the PRIMERA model can effectively handle the linguistic nuances of Vietnamese text, ultimately leading to improved text summarization outcomes.", "label": "human"}
{"ID": "00180094", "file_name": "Vietnamese Multi-document Summarization", "content": "Tokenizer model In the section on Vietnamese tokenizer models, there are various types of tokenizersthat can be used for processing Vietnamese text: word-level tokenization, syllable level tokenization, character-level tokenization or sub-word level tokenization. The current state-of-the-art method: BPE (Byte Pair Encoding) . The drawback of character-level or word-level tokenization are that the tokens are sometimes not meaningful when considered independently or do not hanlde out-of-vocabulary cases well. Therefore, a novel method called BPE was proposed and has the ability to split words into subword units that are smaller than words but larger than individual characters. By applying BPE, most words can be represented by subwords, reducing the occurrence of the <unk> token that represents unseen words. This method has been rapidly adopted in modern NLP approaches and improved the accuracy significantly.", "label": "human"}
{"ID": "00180095", "file_name": "Vietnamese Multi-document Summarization", "content": "The BPE method statistically analyzes the co-occurrence frequencies of subwords and merges them if they have the highest frequency. This process continues to merge subwords until no more subwords can be merged, resulting in a set of subwords that can represent all the words in the text corpus. The implemented algorithm is declared in github1and involves following steps:", "label": "human"}
{"ID": "00180096", "file_name": "Vietnamese Multi-document Summarization", "content": "Step 1: Initializing the vocabulary Step 2: Representing each word in the text corpus as a combination of characters with the <\\w>token marking the end of a word.", "label": "human"}
{"ID": "00180097", "file_name": "Vietnamese Multi-document Summarization", "content": "Step 4: Merging the pairs with the highest co-occurrence frequency to form a new n-gram character level for the vocabulary.", "label": "human"}
{"ID": "00180098", "file_name": "Vietnamese Multi-document Summarization", "content": "Step 5: Repeating steps 3 and 4 until the merging process reaches a predefined threshold or the expected size of the vocabulary is achieved.", "label": "human"}
{"ID": "00180099", "file_name": "Vietnamese Multi-document Summarization", "content": "my initial experiments, I employed the Phobert-large tokenizer  to encode the dataset. This tokenizer utilizes a Byte-Pair Encoding (BPE) tokenizer and by using a segmented text approach, Phobert-large is capable of effectively handling Vietnamese text with its specific linguistic characteristics. It has been trained on a large corpus and has shown promising results in various natural language processing tasks.", "label": "human"}
{"ID": "00180100", "file_name": "Vietnamese Multi-document Summarization", "content": "In addition to the Phobert-large tokenizer, the ViT5-large tokenizer  was also considered as an alternative tokenizer option. The motivation behind exploring ViT5-large stemmed from its strong performance in language-related tasks, as reported in the ViT5 paper . The authors highlighted the significant improvementachieved by training their own tokenizer trained on preprocessed subset of a large scale dataset.", "label": "human"}
{"ID": "00180101", "file_name": "Vietnamese Multi-document Summarization", "content": "Furthermore, to enhance the tokenization process and adapt it to the specific characteristics of Vietnamese, I also try the option of training my own tokenizer. The approach I employ is Byte Pair Encoding (BPE) with a vocabulary size of 34,000 tokens. As I have just declared above, BPE has been widely used in various language processing tasks and has shown effectiveness in capturing subword-level information. By following the ViT5 paper steps to train a BPE tokenizer on my preprocessed pretraining Vietnamese text corpus of approximately 5GB.", "label": "human"}
{"ID": "00180102", "file_name": "Vietnamese Multi-document Summarization", "content": "In summary, for this research, the initial tokenization utilized the Phobert-large tokenizer. Additionally, alternative tokenizer such as ViT5-large is used to assess their potential tokenization performance and the last is to used trained custom tokenizers using BPE with a 34,000-token vocabulary on a substantial amount of preprocessed Vietnamese text. According to , , language models that arepre-trained using word-level data tend to outperform models trained on syllable level data when it comes to word-level Vietnamese natural language processing (NLP) tasks. Therefore, I have already created a 34,000 segmented tokens vocab using VnCoreNLP  and 64,000 tokens, which is the same as Phobert large , however, due to time restriction, I only experience using three mentioned tokenizers and do not dive deep into it more.", "label": "human"}
{"ID": "00180103", "file_name": "Vietnamese Multi-document Summarization", "content": "Named Entity Recognition model A Vietnamese Named Entity Recognition (NER) model is needed to effectively extract and classify general named entities from Vietnamese text. There are several existing models, including VnCoreNLP , Underthesea2, Pyvi3or PhoNLP .", "label": "human"}
{"ID": "00180104", "file_name": "Vietnamese Multi-document Summarization", "content": "of these models has its own strengths and limitations, and their performance can vary depending on the specific task and dataset.", "label": "human"}
{"ID": "00180105", "file_name": "Vietnamese Multi-document Summarization", "content": "However, due to the lack of specific benchmarks for comparing these entity extraction models and the time constraints of my thesis research, I am unable to extensively evaluate each model. Therefore, I make the decision to choose the NER PhoNLP model as it represents the most recent and up-to-date model available at the time of my research. By utilizing the NER PhoNLP model, I am able to extract and classify named entities into four main categories, namely LOCATION ,PERSON ,ORGANIZATION , andMISCELLANEOUS . These categories cover a wide range of named entities commonly found in Vietnamese text and are essential for various downstream tasks.", "label": "human"}
{"ID": "00180106", "file_name": "Vietnamese Multi-document Summarization", "content": "viPRIMERA Overall, my model is built based on the PRIMERA model  with three main modifications to make it work with the Vietnamese language. These modifications include:", "label": "human"}
{"ID": "00180107", "file_name": "Vietnamese Multi-document Summarization", "content": "Using a word segmentation model trained on Vietnamese datasets to pre process raw text and prepare it for later processing steps before feeding it into the model; Employing Vietnamese tokenizers: Initially, I used Phobert-large  to encode the dataset in my first experiments. Later, I also experimented with using ViT5-large  and trained my own tokenizer using Byte Pair Encoding (BPE) with a vocabulary size of 34,000 on approximately 5GB of preprocessed Vietnamese text; use a Named Entity Recognition model trained on Vietnamese datasets to extract named entities, and choose sentences based on Pyramid ROUGE score.", "label": "human"}
{"ID": "00180108", "file_name": "Vietnamese Multi-document Summarization", "content": "where di1·di2· ··· · dim=ci, here, each ciis a pseudo cluster of documents, symbol ·indicates the concatenation operator, and dijdenotes the jthdocuments in the ithcluster. Initially, the pre-Figure 3.3: The process of training my very first modified models training dataset Cis transformed into pseudo clusters ci, each containing multiple related documents. The word segmentation model- VnCoreNLP model  is applied to each document ciin the clusters:", "label": "human"}
{"ID": "00180109", "file_name": "Vietnamese Multi-document Summarization", "content": "dij=word_segment VnCoreNLP (dij) After that, the word-segmented text is further processed by a Vietnamese Named Entity Recognition model to extract important entities using NER PhoNLP to extract and classify named entities into four categories including LOCATION ,PERSON , ORGANIZATION andMISSCELLANEOUS . Let denote eijbe the list of entities in thejthdocument in the ithcluster.", "label": "human"}
{"ID": "00180110", "file_name": "Vietnamese Multi-document Summarization", "content": "eij=NER PhoNLP (dij) cluster ci. After that, the document frequency of each entity is used to estimate the entity importance. The higher document frequency, the more important entity is. The list of entity with high frequencies is then used to choose the candidate sentences. Among these candidate sentences, the most representative ones are selected based on the Rouge score measuring the overlap of the sentence and the documentswhich the sentence doesn’t appear in.", "label": "human"}
{"ID": "00180111", "file_name": "Vietnamese Multi-document Summarization", "content": "Algorithm 1 Entity Pyramid Sentence Selection  Input : Document cluster Input : List of entities w/ frequency > 1. N length of the list Input : n number of sentences to select Output :List of sentences to mask E←sort entities by frequency, descending selected = [] SentCand →all sentences in the cluster containing E[i] cur_sent=argmaxs∈SentCand Score (s) selected.append (cur_sent) Break end end return selected The sentence score is then used to rank the sentence importance over the cluster.", "label": "human"}
{"ID": "00180112", "file_name": "Vietnamese Multi-document Summarization", "content": "See the algorithm 1 for more details. The top sentences with the highest scores are then concatenated to create a pseudo summary, psi. So far, I generated the pseudo labeled dataset Below is the format data of pretraining dataset and finetuning datasets:", "label": "human"}
{"ID": "00180113", "file_name": "Vietnamese Multi-document Summarization", "content": "] This modified model will then be used directly for Vietnamese text summarization context. The input of the model will be text and the output will be the generated summary.4.1 Vietnamese Datasets Although there are significant English language resources, the availability of such extensive datasets is still limited in the Vietnamese language domain.", "label": "human"}
{"ID": "00180114", "file_name": "Vietnamese Multi-document Summarization", "content": "Unlabeled datasets When it comes to news datasets, NewsCorpus1is one of the largest Vietnamese news datasets containing 14.896.998 documents with unlabeled summaries crawled from about 143 Vietnamese news websites. This can be treated as a single-document summarization dataset since the title and sapo text are provided for each document.", "label": "human"}
{"ID": "00180115", "file_name": "Vietnamese Multi-document Summarization", "content": "CC100  dataset: this corpus comprises of monolingual data for 100+ languages and also includes data for romanized languages. This was constructed using the urlsand paragraph indices provided by the CC-Net repository by processing January December 2018 Commoncrawl snapshots. Each file comprises of documents separated by double-news and paragraphs within the same document separated by a new.", "label": "human"}
{"ID": "00180116", "file_name": "Vietnamese Multi-document Summarization", "content": "The data is generated using the open source CC-Net repository. CC100 corpus contains more diverse and general representation of the Vietnamese language than news data. Both of above two datasets above are single-document datasets.", "label": "human"}
{"ID": "00180117", "file_name": "Vietnamese Multi-document Summarization", "content": "Unfortunately, due to the scarity of multi-document datasets for Vietnamese, there is currently no Vietnamese multi-document unlabeled dataset. Addressing this limitation requires the collection or construction of a large Vietnamese multi-document dataset.", "label": "human"}
{"ID": "00180118", "file_name": "Vietnamese Multi-document Summarization", "content": "The approaches for generating such multi-document datasets are rather intricate and time-consuming. Therefore, I initially considered using Google’s translate API to translate English data into Vietnamese. However, due to the maximum token limit of 5000, the data had to be divided into smaller segments for translation.", "label": "human"}
{"ID": "00180119", "file_name": "Vietnamese Multi-document Summarization", "content": "After careful consideration, I opt to translate the Newshead dataset , which takes approximately 7 days to complete. I utilize it as a Vietnamese pretraining dataset for my model. The figure 2.2 illustrates the dataset length distribution.", "label": "human"}
{"ID": "00180120", "file_name": "Vietnamese Multi-document Summarization", "content": "Labeled datasets In this section, I describe the labeled datasets used for our Vietnamese text summarization task. I present two categories: single document abstractive summarization and multi-document summarization Single Document Summarization Dataset: statistics are shown in 4.1 1 the purpose of single document abstractive summarization, I have employed the VNDS dataset . This dataset comprises a collection of articles gathered from diverse categories, such as \"the world,\" \"news,\" \"law,\" and \"business,\" sourced from popular platforms like tuoitre.vn, vnexpress.net, and nguoiduatin.vn.", "label": "human"}
{"ID": "00180121", "file_name": "Vietnamese Multi-document Summarization", "content": "Each article serves as the source document, while its corresponding \"sapo\" (summary) is utilized as the target summary. The summaries vary in length, with some documents having only one sentence, while others contain up to 38 sentences, averaging around 15 sentences per document. The Vietnews dataset comprises a total of 150,704 samples, split into three sets for training (70%), development (15%), and testing (15%) Additionally, another invaluable resource used for this research is Wikilingua , a vast multilingual corpus designed for abstractive summarization tasks.", "label": "human"}
{"ID": "00180122", "file_name": "Vietnamese Multi-document Summarization", "content": "This extensive corpus covers 18 different languages, including Vietnamese, and is derived from WikiHow. Specifically, the Vietnamese articles are translations of the original English articles, which have been meticulously reviewed by WikiHow’s international translation team. For the Vietnamese language, this dataset includes a total of 19,600 samples.", "label": "human"}
{"ID": "00180123", "file_name": "Vietnamese Multi-document Summarization", "content": "Multi-Document Summarization Dataset: When tackling the Vietnamese multi document summarization task, I encountered a significant challenge due to the scarcity of labeled datasets. To the best of our knowledge, there are currently only three Vietnamese multi-document summarization datasets available. I provide the details of these datasets in Table 4.2.", "label": "human"}
{"ID": "00180124", "file_name": "Vietnamese Multi-document Summarization", "content": "The first dataset, VMDS, is a valuable collection of multi-document data gathered from the Vietnamese newspaper website baomoi.com. It comprises 600 documents thoughtfully categorized into 200 topics, offering a diverse and informative set for analysis.", "label": "human"}
{"ID": "00180125", "file_name": "Vietnamese Multi-document Summarization", "content": "Another noteworthy dataset is ViMs , introduced by Nghiem et al. This corpus was meticulously collected from various domains, utilizing Google News as the primary source. With a substantial count of 1,945 documents extracted from popular news websites in Vietnam, ViMs presents a robust and diverse dataset for multi-document summarization research.", "label": "human"}
{"ID": "00180126", "file_name": "Vietnamese Multi-document Summarization", "content": "Furthermore, we have the VLSP dataset2, which has been provided as part of a competition hosted by the Association for Vietnamese Language and Speech Processing. Encompassing Vietnamese news articles that cover a wide range of topics such as the economy, society, culture, science, and technology, the 2 VNDS WikilingualNumber of documents -  Number of samples 150,704 19600Average number of documents per cluster -  Average number of words per cluster 413,37 391 Average number of words per summary 28,48 39 Table 4.1: The statistic of Vietnews and Wikilingual datasets Item ViMs VMDS VLSP Number of documents 1945 628 925 Number of samples 300 200 300 Average number of documents per cluster 6.5 3.0 3.0 Average number of words per cluster 2208 1308 1853 Average number of words per summary 192 153 162 Table 4.2: The statistic of ViMs, VMDS, and VLSP datasets VLSP dataset serves as a valuable resource for advancing multi-document summarization techniques. In particular, the training and validation sets of the VLSP dataset consist of 300 samples, and for the purpose of this thesis, I consider the VLSP dataset as the amalgamation of VLSP-2022 training and validation sets.", "label": "human"}
{"ID": "00180127", "file_name": "Vietnamese Multi-document Summarization", "content": "Pretraining step a, Pretraining with Newscorpus In the experiment section of my thesis, I conducted an analysis and evaluation of the Vietnamese text summarization task. The motivation behind this experiment stems from the scarcity of pretraining multi-document datasets in the Vietnamese language. To address this limitation, I leveraged the Newscorpus dataset, initiallydesigned as a single-document dataset, and transformed it into a pseudo multi document dataset. Each document within the dataset was divided into smaller parts, taking into consideration the length of the document. This segmentation resulted in segments ranging from 2 to 5 parts, enabling a more robust and diverse dataset for training.", "label": "human"}
{"ID": "00180128", "file_name": "Vietnamese Multi-document Summarization", "content": "To ensure the dataset’s quality and suitability for the experiment, I followed a rigorous preprocessing pipe in Figure 3.3. PhoNLP  was utilized for the preprocessing tasks. Additionally, pyramid scores were calculated to evaluate the salience of sentences within each document. The data was then further processed using Phobert-large , a powerful language model specifically designed for theVietnamese language.", "label": "human"}
{"ID": "00180129", "file_name": "Vietnamese Multi-document Summarization", "content": "The dataset is quite large with around 15 milion documents and it takes about 2 to 3 weeks to preprocess the dataset. After that, I pretrain the model with 4 NVIDIA A100 40GB GPUs and it takes 4 days for the model to converge, however, the validation loss is quite high, at about 2.16, while the validation loss of the English PRIMERA version is around 1 when being evaluated in English pretraining dataset.", "label": "human"}
{"ID": "00180130", "file_name": "Vietnamese Multi-document Summarization", "content": "I pretrain the model for 100K steps, with early stopping, batch size of 16, Adam optimizer with a learning rate of 3e−5following , with 10K warmup steps and linear decay.", "label": "human"}
{"ID": "00180131", "file_name": "Vietnamese Multi-document Summarization", "content": "Pretraining with translated Newshead After experiencing on Newscorpus dataset, the model has a big limitation that it is not pretrained on authentic multi-document dataset so I want to create a Vietnamese multi-document. The first applicable approach is to translate a English multi-document dataset, so we choose Newshead , the pretraining dataset of PRIMERA. Because preprocessing a dataset from scratch is very time-consuming, so we ultilize the preprocessed dataset uploaded on Github3and I translate directly from that dataset. The English Newshead dataset undergoes a two-step preprocessing process:", "label": "human"}
{"ID": "00180132", "file_name": "Vietnamese Multi-document Summarization", "content": "Firstly, the ’src’ and ’tgt’ ids are decoded using PRIMERA tokenizer Secondly, the input documents and summaries from Newshead step 2 are translated using the Google Translate API. Prior to translation, the data in English had already undergone preprocessing steps, including entity identification using Spacy  and Rouge score calculation.", "label": "human"}
{"ID": "00180133", "file_name": "Vietnamese Multi-document Summarization", "content": "The dataset is much smaller the Newscorpus. I pretrain this dataset with the same steps as Newscorpus dataset. It takes us around 5 days to translate the whole dataset and about 10-14 days to pretrain this dataset on 1 NVIDIA A100 40GB GPU.", "label": "human"}
{"ID": "00180134", "file_name": "Vietnamese Multi-document Summarization", "content": "Pretraining with translated and preprocessed Newshead In order to utilize the Newshead dataset for other experiments, it is necessary to translate and preprocess the dataset from scratch. The SpaCy library recognizes various built-in entity types, including:", "label": "human"}
{"ID": "00180135", "file_name": "Vietnamese Multi-document Summarization", "content": "Therefore, to leverage the original data with entities identified by Spacy that are not available in the Vietnamese PhoNLP model like number, date or year, I translate the entities into Vietnamese and use PhoNLP to find entities once again. The counts of entities were then accumulated for further analysis. It takes around 10-14 days to translate and preprocess the dataset. All settings in the pretraining step are the same as section b.", "label": "human"}
{"ID": "00180136", "file_name": "Vietnamese Multi-document Summarization", "content": "Pretraining with new tokenizer As specified in ViT5 paper , it is said that an effective vocabulary can contribute a significant improvement to our model performance and the authors preprocess 5GB subset of 70GB text from the model’s pretraining dataset with techniques like normalizing punctuation and capitalization, splitting numbers and train new tokenizer with the 34K sub-words vocabulary using SentenecePiece . Therefore, I try to do the same with my model. I further preprocessed the Newshead dataset ( which was translated and preprocessed) using Moses4and train my own tokenizer with 34K and 64K sub-words vocabulary and also the segmented versions. However, because the pretraining step takes a lot of time, I can only try experiencing with 4 tokenizer and 34K sub-words vocabulary tokenizer.", "label": "human"}
{"ID": "00180137", "file_name": "Vietnamese Multi-document Summarization", "content": "Pretraining with modified PRIMERA In my research, I have conducted extensive experiments using various datasets and tokenizers. As a result, we have achieved highly competitive results, sometimes surpassing the performance of the current state-of-the-art abstractive model for the Vietnamese multi-document summarization task. Nevertheless, we are committed to further improving the performance of our model.", "label": "human"}
{"ID": "00180138", "file_name": "Vietnamese Multi-document Summarization", "content": "During the time of my thesis, the field of prompting engineering techniques have been experiencing advancements and widely researched with the emergent of various Large Language Models (LLMs). However, it is worth noting that the direction of development tends to be agnostic or tends to scale up the model to improve the performance. Then, it pays less attention to the specific task of summarization.", "label": "human"}
{"ID": "00180139", "file_name": "Vietnamese Multi-document Summarization", "content": "Some very popular prompting engineering techniques that can be considered using in Text Summarization task. Among those, Prefix tuning  stands out with a very promising performance on summarization task. However, when I tried implementing and applying Prefix tuning, the achieved results are still not satisfactory.", "label": "human"}
{"ID": "00180140", "file_name": "Vietnamese Multi-document Summarization", "content": "Upon analyzing the Newshead dataset and VLSP dataset, I have identified an additional source of valuable information in the form of cluster titles. Recognizing the potential benefits of incorporating this information, I have made the decision to integrate it into the input of the Transformers architecture. To accommodate and effectively utilize this supplementary information, I have made slight modifications to the architecture. The specific equation outlining these modifications is provided below:", "label": "human"}
{"ID": "00180141", "file_name": "Vietnamese Multi-document Summarization", "content": "query _matrix =ar _project (hidden _states _new) key_matrix =linear _project (hidden _states ) value _matrix =linear _project (hidden _states ) (4.1) I changed both encoder and and decoder inputs and I pretrained the modifiedPRIMERA with the translated and preprocessed Newshead dataset with Phobert large tokenizer because the experiements with that dataset and tokenizer are the highest compared to others.4.2.2 Finetuning step a, Baseline In order to assess the effectiveness of my proposed model, I compared its performance against the BARTpho  and ViT5 model , which is currently regarded as a state-of-the-art Vietnamese abstractive summarization model. As the base model, I strictly adhere to the settings and configurations outd in the BARTPho and ViT5 model’s official GitHub repository5 6.", "label": "human"}
{"ID": "00180142", "file_name": "Vietnamese Multi-document Summarization", "content": "The ViT5 models used in the evaluation are trained with a maximum sequence length of 1024. This setting ensures that the models can effectively process and summarize lengthy text inputs. By employing the BARTPho and ViT5 model as a benchmark, I aim to provide a reliable point of comparison to gauge the performanceimprovements achieved by my proposed model. I also try evaluating with GPT 3 model supplied by OpenAI to see the superiority of my model in Vietnamese context.", "label": "human"}
{"ID": "00180143", "file_name": "Vietnamese Multi-document Summarization", "content": "Finetuning on ViMs, VMDS, VLSP, VNDS We use pre-trained checkpoints to perform fine-tuning on Vietnamese labeled datasets. These datasets are divided into a ratio of 8:1:1 for training, validation, and testing, respectively. Since the model has already been pre-trained on a large unlabeled dataset, fine-tuning on a smaller dataset requires less time, and the training process typically completes after a few epochs. We save the checkpoints with the highest average Rouge scores on the validation dataset obtained during fine-tuning on the respective datasets.", "label": "human"}
{"ID": "00180144", "file_name": "Vietnamese Multi-document Summarization", "content": "Fine-tuning on ViMs: The ViMs dataset contains two reference summaries for each cluster, assigned by different annotators. To select the most appropriate reference summary for each cluster, we calculate the Rouge Score of each sentence in the reference summary with respect to the entire text in the cluster and choose the sentence with the highest Rouge Score.", "label": "human"}
{"ID": "00180145", "file_name": "Vietnamese Multi-document Summarization", "content": "Fine-tuning on VMDS: Similar to ViMs, we choose the reference summary based on the sentence with the highest Rouge Score.", "label": "human"}
{"ID": "00180146", "file_name": "Vietnamese Multi-document Summarization", "content": "on VNDS: As the above datasets are relatively small and easily susceptible to overfitting, and given that most existing Vietnamese models are focused on single-document processing, we also fine-tune our model on the VNDS dataset to compare its performance against other state-of-the-art models.", "label": "human"}
{"ID": "00180147", "file_name": "Vietnamese Multi-document Summarization", "content": "These fine-tuning processes are run on 1 NVIDIA A100 40GB GPU. Each process takes from 1-3 hours depending on the size of the dataset. Except for VNDS, it takes us more than 7 days to fully finetune the model.", "label": "human"}
{"ID": "00180148", "file_name": "Vietnamese Multi-document Summarization", "content": "For the pretraining and finetuning experiments, where all the datasets are utilized, I use Adam as the optimizer with a ar scheduled learning rate of 3e−5. This learning rate schedule helps in controlling the rate at which the model learns during training. The batch size for these experiments is set to 4, and the number of steps and warm-up steps are determined based on the size of the datasets. The input and ouput length of my model is 4096 and 1024/350 respecively.5.1 Zero-shot evaluation For zero-shot1abstractive summarization experiments, since the models have not been trained on the downstream datasets, the lengths of generated summaries mostly depend on the pretrained settings. Thus to better control the length of generated summaries and for a fair comparison between all models, I set the length limit of the output at inference time to the same length.", "label": "human"}
{"ID": "00180149", "file_name": "Vietnamese Multi-document Summarization", "content": "Results indicate that our model achieve substantial result compared with all the bases on most of the datasets. As our model are pretrained on clusters of documents with pseudo summary with longer input and output, the benefit is stronger on the dataset when our models generate better with longer summaries. Our model demonstrates exceptional zero-shot performance, outperforming both ViT5 and BARTpho models. Notably, ViT5 lacks the capability for zero-shot inference and the performance of BARTpho is lower compared to our variants of models. Moreover, to further assess our model’s effectiveness, we also conducted a comparison with the widely used GPT-3 model.", "label": "human"}
{"ID": "00180150", "file_name": "Vietnamese Multi-document Summarization", "content": "The GPT-3 model is a powerful language model known for its impressive capabilities in natural language processing tasks. One of its key strengths is its large vocabulary size of 16,000 tokens, which allows it to handle a wide range of complex language structures and nuances effectively. This model also excels in zero-shot learning scenarios, wherein it can perform tasks without any specific training or fine-tuning on the target task. Table 5.1 shows the Rouge scores for different models on various datasets. The GPT-3 model achieves the highest R-1 F1 score of 69.35 on the ViMs dataset, and scores impressively on other datasets. It also demonstrates a remarkable R-L score of 40.42 on ViMs and 37.45 on VLSP.", "label": "human"}
{"ID": "00180151", "file_name": "Vietnamese Multi-document Summarization", "content": "However, notably, our variations of modified Vietnamese PRIMERA model outperform the base Vietnamese models across all three metrics (R-1, R-2, R-L) on most datasets. The performance of PRIMERA pretrained on translated Newshead is consistently strong, with notable R-1, R-2 and R-L scores on VMDS and VLSP.", "label": "human"}
{"ID": "00180152", "file_name": "Vietnamese Multi-document Summarization", "content": "However, the model shows a slight decrease in scores on ViMs. Meanwhile, viPRIMERA pretrained on translated and preprocessed Newshead exhibited promising results on ViMs and VLSP, with high R-1 and R-2 scores. Unfortunately, the model’s performance is not yet tested for the VMDS dataset.", "label": "human"}
{"ID": "00180153", "file_name": "Vietnamese Multi-document Summarization", "content": "For clarity, by zero-shot we mean using the pretrained model directly without any additional supervision.Models ViMs VMDS VLSP R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L BARTPho large(our run) 48.90 37.24 32.55 39.98 30.86 26.92 34.41 22.22 25.32 GPT-3 (our run) 69.35 44.24 40.42 73.50 43.35 38.24 69.20 41.30 37.45 viPRIMERA Newscorpus 57.58 45.51 35.64 58.40 44.60 37.13 55.00 39.74 34.33 viPRIMERA translated Newshead 67.98 50.89 39.89 66.28 46.75 40.90 60.64 41.59 37.04viPRIMERA translated and preprocessed Newshead 68.39 51.29 39.16 - - - - -  Table 5.1: Zero-shot setting comparison on different datasets for various models. Notes:", "label": "human"}
{"ID": "00180154", "file_name": "Vietnamese Multi-document Summarization", "content": "In summary, the zero-shot experiments demonstrated the efficacy of our models, especially when handling longer summaries. viPRIMERA performs comparativelywith the base models, making it a strong contender for Vietnamese multi document summarization tasks. The evaluation results validate the effectiveness of our approach and the advantages of using pretrained models for abstractive summarization tasks in the Vietnamese language.", "label": "human"}
{"ID": "00180155", "file_name": "Vietnamese Multi-document Summarization", "content": "Finetuning on Multi-document datasetsIn the Fully Supervised evaluation, we first pretrain our model on the News corpus/Newshead dataset and then fine-tune it on the ViMs, VMDS, and VLSP datasets. This evaluation aims to examine how well the pre-trained model could adapt to new multi-document summarization datasets providing additional training samples.", "label": "human"}
{"ID": "00180156", "file_name": "Vietnamese Multi-document Summarization", "content": "In the table 5.2, we can see the comparison of Rouge scores on different Vietnamese multi-document summarization datasets: ViMs, VMDS, and VLSP datasets for various models, including ViT5, BARTPho and our variant of Vietnamese PRIMERA models. The results show that our initial model achieve competitive Rouge scores when compared to the most previous state-of-the-art models on text summarization tasks on all three datasets, indicating its effectiveness in generating accurate abstractive summaries for Vietnamese multi-document text.", "label": "human"}
{"ID": "00180157", "file_name": "Vietnamese Multi-document Summarization", "content": "BARTpho, ViT5: These models achieve good performance across all three datasets, with relatively high Rouge scores. It achieves the highest Rouge scores on ViMs for R-L, and competitive scores on VMDS and VLSP datasets.", "label": "human"}
{"ID": "00180158", "file_name": "Vietnamese Multi-document Summarization", "content": "One thing to keep in mind is that both BARTPho and ViT5 has already been pretrained on a large amount of data, 20GB and 70GB respectively.", "label": "human"}
{"ID": "00180159", "file_name": "Vietnamese Multi-document Summarization", "content": "Variants of Vietnamese PRIMERA models: our models demonstrate competitive performance and outperform BARTPho largeand ViT5 largeon different datasets, showing their effectiveness in handling Vietnamese multi-document summarization tasks. Among the viPRIMERA models, viPRIMERA pretrained on translatedModels ViMs VMDS VLSP R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L BARTPho large(our run) 74.51 45.41 41.24 72.56 46.03 43.64 67.83 36.15 37.74 ViT5 large(our run) 77.54 53.96 49.57 75.57 48.62 46.17 73.03 43.54 39.90 viPRIMERA Newscorpus 77.21 52.37 46.6 75.45 49.57 45.85 74.70 46.78 42.67 viPRIMERA translated Newshead 77.78 54.59 49.84 76.76 50.21 47.39 73.96 46.79 43.68 viPRIMERA translated and preprocessed Newshead 78.98 55.08 48.00 - - - 73.20 46.74 42.73 Table 5.2: Test result on Vietnamese Multi-document Summarization datasets. Notes: The best scores are in bold.", "label": "human"}
{"ID": "00180160", "file_name": "Vietnamese Multi-document Summarization", "content": "and preprocessed Newshead stands out with strong Rouge scores on ViMs, while viPRIMERA pretrained on translated Newshead excels on VMDS and VLSP datasets.", "label": "human"}
{"ID": "00180161", "file_name": "Vietnamese Multi-document Summarization", "content": "However, it is essential to keep in mind the small size of the datasets, which may limit the generalizability of the results. Additionally, further evaluation on larger datasets and comparisons with other state-of-the-art models would provide a more comprehensive assessment of viPRIMERA’s performance. Nevertheless, the results achieved so far are promising and lay the groundwork for future advancements in Vietnamese multi-document summarization.", "label": "human"}
{"ID": "00180162", "file_name": "Vietnamese Multi-document Summarization", "content": "Finetuning on Single-document datasets It is indeed a significant challenge that the multi-document datasets for Vietnamese summarization are relatively small, typically containing only 200-300 samples each. The small size of these datasets can make the fine-tuning process more susceptible to overfitting and can result in unstable performance comparisons between different models.", "label": "human"}
{"ID": "00180163", "file_name": "Vietnamese Multi-document Summarization", "content": "To mitigate this issue, I have taken a more practical approach by exploring fine tuning on a larger single-document dataset like VNDS. It is impressive to see that my model, which was specifically designed for multi-document summarization, still performs well on the single-document dataset. This indicates the adaptability and versatility of my model, showcasing its potential for handling different summarization tasks. Table 5.3 details the result.", "label": "human"}
{"ID": "00180164", "file_name": "Vietnamese Multi-document Summarization", "content": "In addition, I have taken the initiative to translate the Multi-News dataset, which opens up new possibilities for further experimentation. Given more time, conducting comparative experiments between different models on the translated Multi-News dataset would provide valuable insights into their relative strengths and weaknesses, enabling a more robust evaluation of their performance.Models VNDS R-1 R-2 R-L BARTpho 61.14 30.31 40.15 ViT5 base 256-length 61.85 31.70 41.70 ViT5 base 1024-length 62.77 33.16 42.75 ViT5 large 1024-length 63.37 34.24 43.55 viPRIMERA translated Newshead 63.01 33.38 42.74 Table 5.3: Comparison among various models on VNDS. Notes: The best scores are in bold and second best scores are underlined.", "label": "human"}
{"ID": "00180165", "file_name": "Vietnamese Multi-document Summarization", "content": "preprocessed Newshead with different tokenizers used on the ViMs dataset, which further supports the analysis of our model’s performance. Based on the results obtained from using different tokenizers, it is evident that the PhoBERT tokenizer yields the best performance compared to the other two tokenizers (34k-vocab tokenizer and ViT5 tokenizer).", "label": "human"}
{"ID": "00180166", "file_name": "Vietnamese Multi-document Summarization", "content": "Specifically, the Rouge scores (R-1, R-2) achieved by the PhoBERT tokenizer are significantly higher than those obtained by the other tokenizers. The average Rouge score (AVG) for the PhoBERT-large tokenizer was also the highest among all three tokenization approaches. The PhoBERT tokenizer demonstrates an impressive R-1 F1 score of 78.98 and an R-2 F1 score of 55.08 on the ViMs dataset, surpassing the performance of the 34k-vocab tokenizer, which achieves an R-1 F1 score of 76.05 and an R-2 F1 score of 52.92. The ViT5 tokenizer, on the other hand, showed the lowest Rouge scores among the three.", "label": "human"}
{"ID": "00180167", "file_name": "Vietnamese Multi-document Summarization", "content": "The results obtained using the 34k-vocab tokenizer are indeed promising, and it is noteworthy that it is a need to experiment with other tokenization approaches as well, including pre-segmentation before training the tokenizers and increasing the vocabulary size to 64k (the same size as Phobert). These additional experiments are valuable contributions and can significantly improve the model’s performance.", "label": "human"}
{"ID": "00180168", "file_name": "Vietnamese Multi-document Summarization", "content": "I have already created the segmented 34k-vocab and 64k-vocab tokenizer based on Newshead dataset, however, due to the time and resource constraints of the training process, it is sensible to leave the detailed analysis of these additional tokenization methods for future work. While the initial results with the 34k-vocab or Phobert tokenizer are satisfactory, further investigation into the impact of pre-segmentationFigure 5.1: Model with different tokenizers finetuned on ViMs Models VLSP R-1 R-2 R-L ViT5 large(our run) 73.03 43.54 39.90 viPRIMERA Newscorpus 74.70 46.78 42.67 viPRIMERA translated Newshead 73.96 46.79 43.68 viPRIMERA translated and preprocessed Newshead 73.20 46.74 42.73 viPRIMERA modified 71.8 42.3 39.8 Table 5.4: Modified PRIMERA tested on VLSP datasets comparisons. Notes: The best scores are in bold and second best scores are underd.", "label": "human"}
{"ID": "00180169", "file_name": "Vietnamese Multi-document Summarization", "content": "Modified viPRIMERA In my thesis, we conduct extensive experiments using various datasets and tokenizers, and it achieve highly competitive results, sometimes even surpassing the performance of the current state-of-the-art abstractive models for the Vietnamese multi-document summarization task. However, I am committed to continuous improvement of my model. The results on the VLSP dataset shown in table 5.4 were as follows: R-1 F1 score: 71.8, R-2 F1 score: 42.3, R-L F1 score: 39.8. Although the results have not reached the desired level yet, we acknowledge that further improvements may require more time and effort.", "label": "human"}
{"ID": "00180170", "file_name": "Vietnamese Multi-document Summarization", "content": "Model Summary BARTPho Ngày 1-6 , ông Lê Văn Khoa , Phó Chủ tịch UBND TP. HCM , cho biết sẽ xây dựng nút giao thông mới nhằm xoá điểm kẹt xe lên xuống cảng Cát Lái  nhằm xoá điểm kẹt xe đi qua ngày càng tăng mạnh ( 18.000-20.000 lượt xe / ngày ) và khiến cho khu vực qua nút cũng như khu vực luôn rơi vào ùn tắc . Tại nút giao này , sẽ có hai làn xe ô tô vành đai 2 nhằm giảm tình trạng kẹt xe cục bộ , nhằm xoá điểm kẹt xe lên xuống cảng Cát Lái , tạo thuận lợi cho xe đi về giữa cầu Phú Mỹ và đường Nguyễn Thị Định . Vành đai 2 sẽ xây dựng cầu vượt thẳng qua nút giao theo hướng đường Vành đai 2 rộng 17 m , dài 316 m cho bốn làn xe ô tô ( hướng từ cầu Phú Mỹ thẳng qua cầu Kỳ Hà 3 và ngược lại ) . Cũng trong giai đoạn đầu xây dựng , trong giai đoạn đầu xây dựng cầu vượt thẳng qua nút giao theo hướng đường Vành đai 2 rộng 17 m , dài 316 m cho bốn làn xe ô tô ( hướng từ cầu Phú Mỹ thẳng qua cầu Kỳ Hà 3 và ngược lại ) ; theo hướng từ cầu Kỳ Hà 3 sẽ xây dựng hầm chui dưới nút giao cắt rẽ về đường Nguyễn Thị Định để xuống cảng Cát Lái . Cùng với đó , thành phố sẽ xây dựng các công trình giao thông nhằm giảm lưu lượng xe qua nút giao thông trên đường Nguyễn Thị Định , Nguyễn Thị Định để giảm bớt áp lực ViT5 Ngày 3/6 , UBND TP HCM khởi công xây dựng Dự án cầu vượt , hầm chui vòng xoay Mỹ Thuỷ tại phường Cát Lái , quận 2 . Theo ông Lê Văn Khoa  việc triển khai dự án sẽ phải thu hồi , giải toả hơn 5,76 ha đất , làm ảnh hưởng đến cuộc sống của gần 150 hộ dân thuộc phường Cát Lái và Thạnh Mỹ Lợi . Theo ông , việc triển khai dự án sẽ phải thu hồi , giải toả hơn 5,76 ha đất , làm ảnh hưởng đến cuộc sống của gần 150 hộ dân thuộc phường Cát Lái . Dự án cầu vượt Mỹ Thuỷ được chia làm hai giai đoạn đầu tư : Giai đoạn 1 và giai đoạn 3 xây dựng cầu vượt , hầm chui dưới nút giao rẽ trái về đường Nguyễn Thị Định , cầu Kỳ Hà 3 sẽ hình thành vòng xoay như hiện nay . Trên mặt nền hiện hữu , từ các hướng đường Nguyễn Thị Định và Vành đai 2 sẽ xây dựng bốn nhánh rẽ phải : Từ đường Nguyễn Thị Định đi đường Vành đai 2 , nối cầu Phú Mỹ qua khu công nghệ cao ; nút giao thông Phú Hữu dẫn lên cao tốc Long Thành - Dầu Giây . Xây dựng cầu vượt Mỹ Thuỷ là công trình trọng điểm nhằm giảm ùn tắc giao thông tại cửa ngõ vào cảng Cát Lái , tạo thuận lợi cho xe đi về giữa cầu Phú Mỹ và đường Vành đai Đông ( Vành đai 2 ) , hướng về đường cao tốc Long Thành - Dầu Giây . Xây dựng đường chui dưới lòng đất tại nút giao sẽ hình thành vòng xoay như hiện nay .", "label": "human"}
{"ID": "00180171", "file_name": "Vietnamese Multi-document Summarization", "content": "Vì vậy, dự án này sẽ tăng khả năng thông xe, giảm ùn tắc và đáp ứng tốt nhu cầu vận chuyển hàng hoá vào cảng Cát Lái và kết nối đường Vành đai 2. Trên hành lang của nút giao sẽ có hầm chui và cầu vượt để tách dòng xe, đảm bảo an toàn giao thông. Dự án sẽ được triển khai theo hai giai đoạn, với tổng mức đầu tư khoảng 2.337 tỷ đồng. Giai đoạn 1 dự kiến hoàn thành vào quý I/2018, và giai đoạn 2 được dự kiến hoàn thành sau đó.", "label": "human"}
{"ID": "00180172", "file_name": "Vietnamese Multi-document Summarization", "content": "viPRIMERA Sáng 3/6 , UBND TP HCM khởi công xây dựng Dự án cầu vượt , hầm chui vòng xoay Mỹ Thuỷ tại phường Cát Lái , quận 2 . Nút giao thông Mỹ Thuỷ là điểm giao của các tuyến quan trọng là đường Nguyễn Thị Định - Đồng Văn Cống dẫn vào cảng Cát Lái ; đường Vành đai 2 nối cầu Phú Mỹ qua khu công nghệ cao ; nút giao thông Phú Hữu dẫn lên cao tốc Long Thành - Dầu Giây . Theo ông Lê Văn Khoa , Phó Chủ tịch UBND TP , nút giao bằng hiện hữu không còn đáp ứng nổi lượng xe đi qua ngày càng tăng mạnh ( 18.000-20.000 lượt xe / ngày ) và khiến cho khu vực qua nút cũng như xung quanh luôn rơi vào ùn tắc . Dự án sẽ được thi công hai giai đoạn . Giai đoạn 1 với số vốn khoảng 840 tỷ đồng , giai đoạn 2 ( hoàn chỉnh ) khoảng 1.400 tỷ đồng , trong đó chi phí xây dựng 1.000 tỷ , giải phóng mặt bằng gần 400 tỷ . Dự kiến cuối năm 2018 , toàn bộ dự án sẽ khánh thành , đưa vào sử dụng . Việc xây dựng nút giao mới khác nhằm xoá điểm kẹt xe lên xuống cảng biển Cát Lái , tạo thuận lợi cho xe đi về giữa cầu Phú Mỹ và đường vành đai Đông ( Vành đai 2 ) , hướng về đường cao tốc TP. HCM - Long Thành - Dầu Giây .", "label": "human"}
{"ID": "00180173", "file_name": "Vietnamese Multi-document Summarization", "content": "Gold summaryTheo ông Lê Văn Khoa, Phó Chủ tịch UBND TP, nút giao bằng hiện hữu không còn đáp ứng nổi lượng xe đi qua ngày càng tăng mạnh ( 18.000-20.000 lượt xe / ngày ) và khiến cho khu vực qua nút cũng như xung quanh luôn rơi vào ùn tắc. Trong giai đoạn I, chủ đầu tư sẽ đầu tư các công đoạn như : Xây dựng 1/2 chính nằm trên Vành đai 2 vượt qua đường Nguyễn Thị Định và rạch Mỹ Thuỷ ; Xây dựng một hầm chui cho các phương tiện giao thông rẽ trái từ đường Vành đai 2 vào đường Nguyễn Thị Định đến cảng Cát Lái ; Xây dựng 1/2 cầu Kỳ Hà 3 ; Xây dựng 1 đường nhánh rẽ phải cho các cklưu thông từ cảng Cát Lái vào Vành đai 2 ; Xây dựng các đường chui dành riêng cho xe hai bánh dưới các cầu Kỳ Hà 2, Kỳ Hà 3, Mỹ Thuỷ cơ bản Cải tạo vòng xoay hiện hữu. Việc xây dựng nút giao này nhằm kéo giảm tình trạng ùn tắc giao thông, TNGT, phục vụ phát triển kinh tế vùng trọng điểm phía Nam ”.", "label": "human"}
{"ID": "00180174", "file_name": "Vietnamese Multi-document Summarization", "content": "Theo ông Khoa, lễ khởi công hôm nay mới là bước khởi đầu của quá trình xây dựng dự án. Do đó lãnh đạo thành phố đề nghị các sở ngành, đơn vị liên quan cần tập trung nỗ lực thực hiện các công việc theo chức năng, nhiệm vụ của mình để công trình đúng tiến độ, chất lượng.", "label": "human"}
{"ID": "00180175", "file_name": "Vietnamese Multi-document Summarization", "content": "Overall, my efforts to tackle data limitations and adapt the model to different datasets highlight my resourcefulness. As I continue to explore possibilities and refine my model, I believe that my work will have a positive impact on the development of effective summarization systems for the Vietnamese language.", "label": "human"}
{"ID": "00180176", "file_name": "Vietnamese Multi-document Summarization", "content": "One of the most significant challenges I encountered when applying the PRIMERA model is the limited availability of Vietnamese datasets. The pre-training dataset plays a crucial role in constructing effective models for Vietnamese text summarization.", "label": "human"}
{"ID": "00180177", "file_name": "Vietnamese Multi-document Summarization", "content": "Its quality directly impacts the performance of our model. However, the existing large datasets primarily cater to single-document tasks or translated datasets, which may not be an optimal fit for our multi-document summarization task. As we look to the future, it becomes imperative to gather a substantial news dataset comprising clusters of Vietnamese documents with shared topics, aligning better with the objectives of pre-training.", "label": "human"}
{"ID": "00180178", "file_name": "Vietnamese Multi-document Summarization", "content": "Additionally, further exploration and experimentation are essential concerning Vietnamese Named Entity Recognition (NER) and Tokenizer models. Furthermore, I am currently researching and developing methods to compute sentence scores or determine important sentence instead of methods used in PRIMERA paper. This approach involvesconsidering various information aspects to gauge the importance of a sentence.Investigating the results of training these models from scratch on Vietnamese multi document news datasets can provide valuable insights into enhancing performance.", "label": "human"}
{"ID": "00180179", "file_name": "Vietnamese Multi-document Summarization", "content": "Lastly, the hyperparameter tuning in the finetuning step takes a lot of time but it also improves the performance significantly. This thesis is in its very first stage and I will leave all mentioned things above to the future with an aim to increase the result more. W. Xiao, I. Beltagy, G. Carenini andA. Cohan, “Primera: Pyramid-based masked sentence pre-training for multi-document summarization,” inProceedings of the 60th Annual Meeting of the Association for Computational Linguistics volume 1, 2022, pages 5245–5263.", "label": "human"}
{"ID": "00180180", "file_name": "Vietnamese Multi-document Summarization", "content": "C.-Y. Lin, “ROUGE: A package for automatic evaluation of summaries,” inText Summarization Branches Out Barcelona, Spain: Association for Computational Linguistics, july2004, pages 74–81. url:", "label": "human"}
{"ID": "00180181", "file_name": "Vietnamese Multi-document Summarization", "content": "N. L. Tran, D. M. Le andD. Q. Nguyen, “Bartpho: Pre-trained sequence-to sequence models for vietnamese,” inProceedings of the 23rd Annual Conference of the International Speech Communication Association 2022.", "label": "human"}
{"ID": "00180182", "file_name": "Vietnamese Multi-document Summarization", "content": "L. Phan, H. Tran, H. Nguyen andT. H. Trinh, “ViT5: Pretrained text-to-text transformer for Vietnamese language generation,” inProceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop Association for Computational Linguistics, 2022, pages 136–142. url:https:", "label": "human"}
{"ID": "00180183", "file_name": "Vietnamese Multi-document Summarization", "content": "M. Lewis, Y. Liu, N. Goyal andothers , “Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension,” inProceedings of the 58th Annual Meeting of the Association for Computational Linguistics Association for Computational Linguistics, july2020, pages 7871–7880.", "label": "human"}
{"ID": "00180184", "file_name": "Vietnamese Multi-document Summarization", "content": "M. Zhong, P. Liu, Y. Chen, D. Wang, X. Qiu andX. Huang, “Extractive summarization as text matching,” inProceedings of the 58th Annual Meeting of the Association for Computational Linguistics On: Association for Computational Linguistics, july2020, pages 6197–6208. DOI:10.18653/v1/2020.acl-main.552 .url:", "label": "human"}
{"ID": "00180185", "file_name": "Vietnamese Multi-document Summarization", "content": "J. Xu, Z. Gan, Y. Cheng andJ. Liu, “Discourse-aware neural extractive text summarization,” inProceedings of the 58th Annual Meeting of the Association for Computational Linguistics On: Association for Computational Linguistics, july2020, pages 5021–5031. DOI:10.18653/v1/2020.acl-main.", "label": "human"}
{"ID": "00180186", "file_name": "Vietnamese Multi-document Summarization", "content": "Y. Liu andM. Lapata, “Text summarization with pretrained encoders,” inThe 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing On: Association for Computational Linguistics, november 2019, pages 3730–3740.", "label": "human"}
{"ID": "00180187", "file_name": "Vietnamese Multi-document Summarization", "content": "M. Zhong, P. Liu, D. Wang, X. Qiu andX. Huang, “Searching for effective neural extractive summarization: What works and what’s next,” inProceedings of the 57th Annual Meeting of the Association for Computational Linguistics Florence, Italy: Association for Computational Linguistics, july2019, pages 1049–1058.", "label": "human"}
{"ID": "00180188", "file_name": "Vietnamese Multi-document Summarization", "content": "Y. Liu, P. Liu, D. Radev andG. Neubig, “Brio: Bringing order to abstractive summarization,” inProceedings of the 60th Annual Meeting of the Association for Computational Linguistics Association for Computational Linguistics, may2022, pages 2890–290.", "label": "human"}
{"ID": "00180189", "file_name": "Vietnamese Multi-document Summarization", "content": "Y. Liu andP. Liu, “Simcls: A simple framework for contrastive learning of abstractive summarization,” inThe 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Short Papers) Association for Computational Linguistics, august 2021, pages 1065–1072.", "label": "human"}
{"ID": "00180190", "file_name": "Vietnamese Multi-document Summarization", "content": "H. Li, A. Einolghozati, S. Iyer andothers , “Ease: Extractive-abstractive summarization with explanations,” inProceedings of the Third Workshop on New Frontiers in Summarization Association for Computational Linguistics, 2021, pages 85–95.", "label": "human"}
{"ID": "00180191", "file_name": "Vietnamese Multi-document Summarization", "content": "L. H. Thanh, T. H. Quyet andM. L. Chi, “A primary study on summarization of documents in vietnamese,” inIFSR 2005: Proceedings of the First World Congress of the International Federation for Systems JAIST Press, 2005.", "label": "human"}
{"ID": "00180192", "file_name": "Vietnamese Multi-document Summarization", "content": "D. Phuc andM. X. Hung, “Using som based graph clustering for extracting main ideas from documents,” in2008 IEEE International Conference on Research, Innovation and Vision for the Future in Computing and Communication Technologies 2008, pages 209–214. DOI:10.1109/RIVF .2008.4586357 . V.-G. Ung, A.-V. Luong, N.-T. Tran andM.-Q. Nghiem, “Combination of features for vietnamese news multi-document summarization,” inProceedings of The Seventh International Conference on Knowledge and Systems Engineering (KSE) 2015, pages 186–191.", "label": "human"}
{"ID": "00180193", "file_name": "Vietnamese Multi-document Summarization", "content": "T. H. Quoc, K. V. Nguyen, N. Luu-Thuy andN. A. Gia-Tuan, “Monolingual vs multilingual BERTology for vietnamese extractive multi-document summarization,” inProceedings of the 35th Pacific Asia Conference on Language, Information and Computation Shanghai, China: Association for Computational Lingustics, november 2021, pages 692–699. url:", "label": "human"}
{"ID": "00180194", "file_name": "Vietnamese Multi-document Summarization", "content": "V.-H. Nguyen, T.-C. Nguyen, M.-T. Nguyen and N. X. Hoai, “Vnds: A vietnamese dataset for summarization,” in2019 6th NAFOSTED Conference on Information and Computer Science 2019, pages 375–380. DOI:10 .", "label": "human"}
{"ID": "00180195", "file_name": "Vietnamese Multi-document Summarization", "content": "C. Raffel, N. Shazeer, A. Roberts andothers , “Exploring the limits of transfer learning with a unified text-to-text transformer,” Journal of Machine Learning Research ,jourvol 21,number 140, pages 1–67, 2020. url:http : / / jmlr.org/papers/v21/20-074.html .", "label": "human"}
{"ID": "00180196", "file_name": "Vietnamese Multi-document Summarization", "content": "J. Zhang, Y. Zhao, M. Saleh andP. J. Liu, Pegasus: Pre-training with extracted gap-sentences for abstractive summarization , 2019. arXiv: 1912.08777 [cs.CL] .", "label": "human"}
{"ID": "00180197", "file_name": "Vietnamese Multi-document Summarization", "content": "X. Gu, Y. Mao, J. Han andothers , “Generating Representative Heads for News Stories,” inProc. of the the Web Conf. 2020 2020.", "label": "human"}
{"ID": "00180198", "file_name": "Vietnamese Multi-document Summarization", "content": "A. Vaswani, N. Shazeer, N. Parmar andothers , “Attention is all you need,” Advances in neural information processing systems ,jourvol 30, 2017.", "label": "human"}
{"ID": "00180199", "file_name": "Vietnamese Multi-document Summarization", "content": "J. Devlin, M.-W. Chang, K. Lee andK. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” inProceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies volume 1, Association for Computational Linguistics, 2019, pages 4171–4186.", "label": "human"}
{"ID": "00180200", "file_name": "Vietnamese Multi-document Summarization", "content": "N. Rusnachenko, T. A. Le andN. D. Nguyen, “Pre-training longt5 for vietnamese mass-media multi-document summarization task,” inProceedings of the Artificial Intelligence and Natural Language Conference (AINL) Yerevan, Armenia, april 2023. S. Narayan, S. B. Cohen andM. Lapata, “Don’t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization,” arXiv preprint arXiv:1808.08745 , 2018.", "label": "human"}
{"ID": "00180201", "file_name": "Vietnamese Multi-document Summarization", "content": "R. Nallapati, B. Zhou, C. Gulcehre, B. Xiang andothers , “Abstractive text summarization using sequence-to-sequence rnns and beyond,” arXiv preprint arXiv:1602.06023 , 2016.", "label": "human"}
{"ID": "00180202", "file_name": "Vietnamese Multi-document Summarization", "content": "J. Phang, Y. Zhao andP. J. Liu, “Investigating efficiently extending transformers for long input summarization,” arXiv preprint arXiv:2208.04347 , 2022.", "label": "human"}
{"ID": "00180203", "file_name": "Vietnamese Multi-document Summarization", "content": "A. Cohan, F. Dernoncourt, D. S. Kim andothers , “A discourse-aware attention model for abstractive summarization of long documents,” arXiv preprint arXiv:1804.05685 , 2018.", "label": "human"}
{"ID": "00180204", "file_name": "Vietnamese Multi-document Summarization", "content": "M. Zaheer, G. Guruganesh, K. A. Dubey andothers , “Big bird: Transformers for longer sequences,” Advances in Neural Information Processing Systems , jourvol 33, 2020.", "label": "human"}
{"ID": "00180205", "file_name": "Vietnamese Multi-document Summarization", "content": "M. Guo, J. Ainslie, D. Uthus andothers , “LongT5: Efficient text-to-text transformer for long sequences,” inFindings of the Association for Computational Linguistics: NAACL 2022 Seattle, United States: Association for Computational Linguistics, july 2022, pages 724–736. DOI:10 . 18653 / v1 / 2022 .", "label": "human"}
{"ID": "00180206", "file_name": "Vietnamese Multi-document Summarization", "content": "J. Ainslie, S. Ontanon, C. Alberti andothers , “ETC: Encoding long and structured inputs in transformers,” inProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) On:", "label": "human"}
{"ID": "00180207", "file_name": "Vietnamese Multi-document Summarization", "content": "A. Fabbri, I. Li, T. She, S. Li andD. Radev, “Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model,” inProceedings of the 57th Annual Meeting of the Association for Computational Linguistics Florence, Italy: Association for Computational Linguistics, july 2019, pages 1074–1084. DOI:10.18653/v1/P19-1102 .url:https:", "label": "human"}
{"ID": "00180208", "file_name": "Vietnamese Multi-document Summarization", "content": "//aclanthology.org/P19-1102 . Y. Lu, Y. Dong andL. Charlin, “Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles,” inProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) On: Association for Computational Linguistics, november 2020, pages 8068–8074. DOI:10.18653/v1/2020.emnlp-main.648 .url:", "label": "human"}
{"ID": "00180209", "file_name": "Vietnamese Multi-document Summarization", "content": "K. Cho, B. van Merrienboer, C. Gulcehre andothers ,Learning phrase representations using rnn encoder-decoder for statistical machine translation , 2014. arXiv:", "label": "human"}
{"ID": "00180210", "file_name": "Vietnamese Multi-document Summarization", "content": "The pyramid method,” inProceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics 2004, pages 145–152.", "label": "human"}
{"ID": "00180211", "file_name": "Vietnamese Multi-document Summarization", "content": "M. Honnibal andI. Montani, “Spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing,” inProceedings of the 18th Conference on Computational Natural Language Learning (CoNLL) 2014, pages 573–578.", "label": "human"}
{"ID": "00180212", "file_name": "Vietnamese Multi-document Summarization", "content": "R. Sennrich, B. Haddow andA. Birch, “Neural machine translation of rare words with subword units,” inProceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) Association for Computational Linguistics, august 2016, pages 1715–1725. DOI:10.", "label": "human"}
{"ID": "00180213", "file_name": "Vietnamese Multi-document Summarization", "content": "31 . L. T. Nguyen andD. Q. Nguyen, “Phonlp: A joint multi-task learning model for vietnamese part-of-speech tagging, named entity recognition and dependency parsing,” CoRR ,jourvol abs/2101.01476, 2021. arXiv: 2101.01476 .url:", "label": "human"}
{"ID": "00180214", "file_name": "Vietnamese Multi-document Summarization", "content": "A. Conneau, K. Khandelwal, N. Goyal andothers , “Unsupervised cross lingual representation learning at scale,” inProceedings of the 58th Annual Meeting of the Association for Computational Linguistics On: Association for Computational Linguistics, july2020, pages 8440–8451. DOI:10.18653/ v1/2020.acl-main.747 .url:", "label": "human"}
{"ID": "00180215", "file_name": "Vietnamese Multi-document Summarization", "content": "Ladhak, Faisal and Durmus, Esin and Cardie, Claire and McKeown, Kathleen, Wikilingua: A new benchmark dataset for cross-lingual abstractive summarization , 2020. DOI:10.48550/ARXIV .2010.03093 .", "label": "human"}
{"ID": "00180216", "file_name": "Vietnamese Multi-document Summarization", "content": "N. T. Tran, M. Q. Nghiem, N. T. Nguyen, N. L. T. Nguyen, N. Van Chi andD. Dinh, “Vims: A high-quality vietnamese dataset for abstractive multi document summarization,” Language Resources and Evaluation ,jourvol 54, number 4,pages 893–920, 2020.", "label": "human"}
{"ID": "00180217", "file_name": "Vietnamese Multi-document Summarization", "content": "T. Kudo andJ. Richardson, “SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing,” inProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing:", "label": "human"}
{"ID": "00190001", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In the era of data-driven decision-making, the role played by machine learning models has reached noticeability across a variety of applications. From delivering personalized recommendations to facilitating predictive analytics, these models have seamlessly integrated into the fabric of technological advancements. However, the traditional approach to model training, wherein data from diverse sources is aggregated in a singular location, has revealed itself to be fraught with considerable challenges. Privacy, security, and communication bandwidth arise as primary concerns within this centralized framework, reflecting the need for an innovative and adaptive solution. Amidst this backdrop, Federated Learning (FL) emerges as a transformative approach that holds the potential to overcome the aforementioned challenges and open a new era of decentralized machine learning model training . This collaborative machine learning approach revolutionizes the traditional training methodology by enabling multiple devices to train a shared model without the necessity of exchanging raw data. Unlike the traditional centralized model training, wherein data is aggregated into a central server, FL harnesses the computational capabilities of local devices, ranging from smartphones to edge devices and other distributed nodes. This approach not only preserves the integrity of data privacy by ensuring sensitive information remains localized but also alleviates the need for extensive data transfers. The decentralized nature of FL renders it particularly suitable for applications in sectors where data confidentiality stands as a dominant concern, such as healthcare and finance. By mitigating the risks associated with centralized data aggregation, FL paves the way for a more secure and privacy-centric machine learning ecosystem.", "label": "human"}
{"ID": "00190002", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Furthermore, the flexibility in this approach aligns with the dynamic requirements of diverse sectors, offering a robust solution that overcomes the limitations imposed by traditional centralized training methodologies.", "label": "human"}
{"ID": "00190003", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Initially, a local model update is computed on the basis of the distinct data repository that resides on the individual device. This local update encapsulates the local patterns and characteristics, reflecting the unique informational context of each device.", "label": "human"}
{"ID": "00190004", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Subsequently, these local model updates undergo an aggregation process, whereby they are amalgamated into a unified global model. The aggregation, often facilitated through algorithms like weighted averaging, ensures a cohesive integration of the diverse insights contributed by each device. This collaborative learning frameworkis particularly noteworthy for its efficacy in allowing the model to gain insights from diverse data existing across the participating devices.", "label": "human"}
{"ID": "00190005", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "One of the crucial challenges faced by FL algorithms is the presence of non Independently and Identically Distributed (non-IID) data across decentralized devices . In traditional machine learning scenarios, IID assumptions are often made, implying that the training data is drawn from the same distribution across all participating devices. However, in FL, this assumption is frequently violated as devices may have diverse data distributions based on factors such as geographic location, user behavior, or device characteristics. Non-IID data poses a significant hurdle to the effective collaboration of decentralized devices in FL. When the training data on each device exhibits different statistical properties, models trained locally may specialize in capturing patterns unique to the local data distribution.", "label": "human"}
{"ID": "00190006", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Consequently, combining these locally trained models into a global model becomes challenging, leading to poor convergence rate and suboptimal generalization performance.", "label": "human"}
{"ID": "00190007", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Poor convergence arises due to the varying nature of locally trained models, leading to a difficulty in their aggregation into a unified global model. Suboptimal generalization performance further compounds the issue, as the resultant global model may struggle to capture insights from the diverse data distributions, rendering it less effective when applied to unseen data instances.", "label": "human"}
{"ID": "00190008", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Effectively addressing the challenge of non-IID data in FL becomes a major goal in the proposed novel algorithms. Such algorithms must employ sophisticated strategies to diminish the impact of this challenge. The utilization of weighted aggregation stands out as a strategic approach, wherein the contributions of different devices to the global model are weighted based on factors such as data quality or relevance. Another strategy is the implementation of data augmentation techniques, which involves artificially enriching the diversity of local datasets. By introducing variations to the existing data, this approach allows the global model to develop a more comprehensive understanding of potential patterns and features, fostering adaptability and robustness. Additionally, the incorporation of adaptive learning rates becomes a reasonable approach, controlling the pace of model updates based on the specific characteristics of each device’s data distribution. This adaptive mechanism enables a response to the varied complexities in non-IID scenarios, ensuring that the learning process is fine-tuned to the characteristics of each contributing device. This thesis introduces a novel algorithm designed to improve convergence rate of FL, particularly when confronted with the challenges posed by non-IID data distributions.1.2 Background and Problems of Research Several algorithms have been suggested to aggregate local models into a single global model, aiming for optimal outcomes . Among these algorithms, Federated Averaging (FedAvg)  stands out as one of the most widely accepted and utilized.", "label": "human"}
{"ID": "00190009", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In FedAvg, the central server averages the received model parameters from participating nodes. However, a notable drawback of FedAvg is its comparatively sluggish convergence rate and reduced accuracy, especially when handling non-IID data across nodes. It is crucial to recognize that the contributions of participating nodes to the training process are not consistently equal, so averaging the parameters of the local models may not be entirely justified. In response to FedAvg’s convergence rate limitation, Federated Adaptive Weighting (FedAdp)  was introduced. FedAdp addresses this limitation by assigning distinct weights to each participating node for updating the global model based on their contributions in each communication round. A participating node’s contribution is initially gauged by the angle between the local gradient vector and the global gradient vector, followed by quantification through a designed non-ar mapping function to determine the weights. The superior performance of FedAdp over FedAvg is evident, particularly in the presence of non-IID data. Results show that FL training with FedAdp significantly reduces the required communication rounds to achieve a 95% test accuracy on the MNIST dataset, up to 54.1% compared to FedAvg. Furthermore, FL training with FedAdp decreases the necessary communication rounds to attain an 80% test accuracy on the FashionMNIST dataset by up to 45.4% when compared to FedAvg. However, a drawback of FedAdp is that the global gradient does not always go in the right direction as expected. At certain participating nodes, the data may lack representation for all labels, causing the local gradients to deviate from the anticipated direction.", "label": "human"}
{"ID": "00190010", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "When a substantial number of nodes exhibit this behavior, the global gradient, calculated as the average of these local gradients, may go in the unfavorable direction.", "label": "human"}
{"ID": "00190011", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Consequently, assigning higher weights to nodes with local gradients closely matching the global gradient can result in slowing down the convergence and worsening the learning performance.", "label": "human"}
{"ID": "00190012", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "This thesis aims to address the previously highlighted constraint associated with two FL algorithms FedAvg and FedAdp by introducing a novel algorithm termed Federated Impurity Weighting (FedImp). Our observation reveals the diversity in contributions made by different nodes during the process of global model aggregation.", "label": "human"}
{"ID": "00190013", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Consequently, our core intuition revolves around measure the contribution of a participating node by evaluating the informational content in that node’s data.Subsequently, these contributions are normalized to form distinct weights for the aggregation of the global model. The essence of the proposed weighting strategy lies in its capacity to foster generalization across an array of data distribution scenarios. This strategic design seeks to deal with a particular behavior observed in FedAdp, wherein higher weights are assigned to the nodes where the data may lack representation for all labels in. FedImp is strategically structured to prevent such biases and pitfalls, aiming to provide a more balanced and comprehensive approach to global model aggregation within the FL framework.", "label": "human"}
{"ID": "00190014", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Determining traditional FL algorithm limitations : The initial contribution involves a critical examination of the FedAvg and FedAdp algorithms and highlighting their limitations in certain scenarios of non-IID data.", "label": "human"}
{"ID": "00190015", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Proposing a novel FL algorithm to improve the convergence in FL basing on the dataset’s impurity factor : Building upon the insights gained from the evaluation of two traditional FL algorithms, the thesis’s second significant contribution lies in the proposal and development of a novel FL algorithm.", "label": "human"}
{"ID": "00190016", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "This new algorithm is specifically engineered to overcome the identified limitations, presenting a more general and comprehensive approach solution to enhance the efficiency of FL in the presence of non-IID data.", "label": "human"}
{"ID": "00190017", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In chapter 2, the focus is on providing a comprehensive literature review. This chapter aims to discuss about the context of the problem and delve into existing studies.", "label": "human"}
{"ID": "00190018", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Chapter 3 offers necessary background information on key concepts related to federated learning and explores the various algorithms, shedding light on their functionalities and components. By doing so, chapter 3 establishes the essential background for the subsequent development and understanding of the proposed methodology.", "label": "human"}
{"ID": "00190019", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "includes two parts: (i) an insightful assessment of the contribution of eachparticipating node by evaluating the informational content within their datasets,", "label": "human"}
{"ID": "00190020", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "ii) the normalization of these contributions to establish unique weights for the aggregation of the global model. Moving forward, section 4.3 formally introduces the Federated Impurity Weighting algorithm, a key element of the proposed methodology.", "label": "human"}
{"ID": "00190021", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Chapter 5 delves into the numerical outcomes resulting from the implementation of the proposed methodology. The exploration starts with a comprehensive examination covering datasets, evaluation metrics, and the simulation method employed. Following this, the subsequent section presents the numerical results, offering valuable insights into the performance and effectiveness of the proposed approach.", "label": "human"}
{"ID": "00190022", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In chapter 6, the concluding chapter, a summary of the main findings is derived from the analysis of numerical results.This chapter delves into the scope of the research, aiming to provide a thorough understanding of the boundaries and dimensions within which the thesis operates.", "label": "human"}
{"ID": "00190023", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Concurrently, the exploration of the existing studies related to the subject matter is undertaken. Through a systematic review, this chapter aim to establish the foundation for this thesis by identifying gaps and opportunities for further exploration.", "label": "human"}
{"ID": "00190024", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "This thesis explores the challenges faced by FL algorithms, specifically focusing on the limitations encountered in presence of non-IID data. By evaluating and synthesizing previous research findings, this thesis aims to provide a more balanced and comprehensive approach to global model aggregation within the FL framework.", "label": "human"}
{"ID": "00190025", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Numerous methods have been suggested for consolidating local models into a single global model in order to attain desirable outcomes. H. Brendan McMahan et al.  introduced the Federated Averaging (FedAvg) algorithm, in which clients perform multiple epochs of SGD on their local datasets and send their models to the server, which averages them to form a new global model. FedAvg has the ability to train high-quality models using relatively few rounds of communication, as demonstrated by results on a variety of model architectures: a multi-layer perceptron, two different convolutional neural networks, a two layer character LSTM, and a large-scale word-level LSTM. However, the presence of non-IID data in FL system can negatively affect the performance of the FedAvg algorithm, including both slow convergence rate and poor accuracy. Addressing this challenge is crucial for improving the effectiveness of FL approach, and various solutions have been proposed.", "label": "human"}
{"ID": "00190026", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "SGD with momentum has demonstrated excellent success in speeding up network training in centralized machine learning approach, by accumulating the gradient history over time in order to dampen oscillations. Utilizing this idea, Tzu-Ming Harry Hsu et al.  proposed the Federated Averaging with Server Momentum (FedAvgM) algorithm. This is especially suitable for FL, where the participating parties may only hold a small subset of labels and a sparse distribution of data.", "label": "human"}
{"ID": "00190027", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Experiments on CIFAR-10 demonstrate improved classification performance for FedAvgM over FedAvg over a range of non-identicalness, with classification accuracy improved from 30.1% to 76.9% in the most skewed settings.Besides, Yousef Yeganeh et al.  proposed IDA (Inverse Distance Aggregation), a novel adaptive weighting approach for clients based on meta-information which handles unbalanced and non-IID data. It uses the distance of the model parameters as a strategy to minimize the effect of outliers and improve the model’s convergence rate. The results in the article show that IDA method outperforms FedAvg in terms of classification accuracy in non-IID scenario. IDA is also resilient to low quality or poisonous data in the clients. For instance, if the majority of clients are rather aligned, then they can rule out the out-of-distribution models. This is not the case with FedAvg, however, which is based on the presumption that the clients with more data, have a better distribution compared to other models, and they should have more voting power in the global model.", "label": "human"}
{"ID": "00190028", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Noting that minimizing the local loss function does not equate to minimizing the global loss function. Durmus Alp Emre Acar et al. addressed a fundamental issue in non-IID data in introducing the FL with Dynamic Regularization (FedDyn) algorithm . The latter dynamically regularizes loss function at each client so that the modified losses converges to the actual global loss. Since the local losses are aligned, FedDyn is robust to the different heterogeneity levels and it can safely perform full minimization in each client. FedDyn has been proven that leads to efficient training with convergence rate as O(1 T)where Tis number of rounds, in both convex and non-convex settings, and a ar rate in strongly convex setting, while being fully agnostic to device heterogeneity and robust to large number of devices, partial participation and unbalanced data.", "label": "human"}
{"ID": "00190029", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Realizing the personalization of the global model becomes crucial in handling the challenges that arise with non-IID data, Saeed Vahidian et al.  introduced Personalized Federated Learning by Pruning (Sub-FedAvg). Sub-FedAvg leverages finding a small subnetwork for each client by applying hybrid pruning (combination of structured and unstructured pruning), and unstructured pruning. By finding a subnetwork for each client rather than taking the average over all parameters of all clients as in FedAvg, Sub-FedAvg efficiently calculates the averaging on the remaining parameters of each subnetwork of each client. This algorithm has proven to outperforms existing state-of-the-art algorithms on CIFAR-10/100, MNIST, and EMNIST benchmarks.", "label": "human"}
{"ID": "00190030", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In scenarios involving non-IID data, the contributions of participating nodes to the training process are unequal. To address this, Hongda Wu et al. introduced the Federated Adaptive Weighting (FedAdp) algorithm in their work . This algorithm dynamically assigns varying weights for updating the global model based on each node’s contribution in every training round. The contribution of participatingnodes is first measured by the angle between the local gradient vector and the global gradient vector, and then, weight is quantified by a designed non-ar mapping function subsequently. The authors has shown that FL with FedAdp can reduce the number of communication rounds by up to 54.1% on MNIST dataset and up to 45.4% on FashionMNIST dataset, as compared to FedAvg algorithm.", "label": "human"}
{"ID": "00190031", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "While the FedAdp algorithm offers significant advancements, it does have certain limitation, which lies in the inconsistency of the global gradient’s alignment with the expected direction. This discrepancy arises when certain participating nodes encounter data with insufficient representation for all labels, leading to deviations in local gradients from the expected direction. If a considerable number of nodes exhibit this behavior, the global gradient, computed as the average of these local gradients, may go in an undesirable direction. Consequently, assigning higher weights to nodes with local gradients closely matching the global gradient has the potential to impede convergence speed and degrade overall learning performance. Therefore, this thesis proposes a novel algorithm to aim to offer a viable substitute, tackling the difficulties presented by the complexities associated with non-IID scenarios.Within the context of this chapter, key concepts to FL is presented with the objective of providing readers with a strong background for comprehending subsequent discussions. Furthermore, an explaination of the critical components to the FedAvg and FedAdp algorithms is undertaken, shedding light on their underlying structures and operational mechanisms.", "label": "human"}
{"ID": "00190032", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "The FL process evolves through a progression of iterative model updates. The visualization of the process is illustrated in Figure 3.1. Initially, the server initializes the model parameters, either through random initialization or by retrieving them from a previously stored checkpoint. Subsequently, the server send the global model parameters to the connected client nodes, ensuring uniformity in the starting point for local training across all participating nodes. With the updated global model parameters in hand, each client node commences its local training using its unique dataset. Notably, local training does not extend to full convergence. instead only for a single epoch or a few mini-batches. Upon completing local training, each client node possesses a slightly modified version of the initially received model parameters, reflecting the variations in its local dataset. These individualized model parameters are then transmitted back to the server. Subsequently, the server aggregates these local parameters into global parameters. This iterative process repeats, progressively refining the global model parameters, until achieving a fully trained model.", "label": "human"}
{"ID": "00190033", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "The primary goal of the FL process is to minimize the dissimilarity between the globally aggregated model and the local models distributed across multiple decentralized nodes. This is achieved through the formulation of an objective function, F(w), which is commonly expressed as the sum (or average) of local objectives from each participating node:", "label": "human"}
{"ID": "00190034", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "F(w) =1 NNX i=1Fi(w) (3.1) In this equation, Nsignifies the total number of participating nodes, and Fi(w) denotes the local objective function at node i. The local objective function Fi(w) is contingent on the model’s performance concerning the locally held data, often involving a loss function that quantifies the disparity between the predicted values of the model and the actual values within the local dataset. The overarching objectiveFigure 3.1: Federated learning process is to identify the optimal model parameters wthat minimize this global objective function.", "label": "human"}
{"ID": "00190035", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In the standard FL scenario, participating nodes engage in localized training with consistent configurations, including the optimizer and learning rate. At each model w(t−1)from the previous communication round is transmitted to the selected nodes. Subsequently, each participating node iexecutes stochastic gradient descent (SGD) training to minimize its local objective Fi(w):", "label": "human"}
{"ID": "00190036", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "FL algorithms then aim to update the global model parameters wby aggregating the local model updates (either parameters or gradients) from each node:", "label": "human"}
{"ID": "00190037", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "w(t) =KXincorporate various weighting strategies, and the subsequent section provides an in depth illustration of the process of determining node weights, specifically explicatethe FedAvg and FedAdp algorithms.", "label": "human"}
{"ID": "00190038", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "This section provides a comprehensive exploration of the foundational principles underlying FedAvg . The FedAvg algorithm operates on the premise of considering the contributions of all participating nodes as equal, with the weight assigned to each node in the global aggregation being contingent solely upon its training set size. Mathematically, this is expressed as:", "label": "human"}
{"ID": "00190039", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "While FedAvg has proven to be effective in distributed learning scenarios, its an evident limitation is relatively slow convergence rate and diminished accuracy, particularly when handling non-IID data across nodes. From the fact that not all participant nodes contribute equally valuable training data or possess comparable computational resources, the concept of averaging parameters from participant nodes might not always be reasonable or fair. As a result, alternative approaches like weighted averaging or selective aggregation are being explored within the field of FL to ensure a more equitable representation of participating nodes’ contribution.", "label": "human"}
{"ID": "00190040", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In FL, the gradient computed after each local training round on different participating nodes may be very different, especially in cases where the data distribution is heterogeneous among participating nodes. As a consequence, the contribution of the participating nodes for aggregating local models into a global model is different.", "label": "human"}
{"ID": "00190041", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Therefore, instead of assigning equal weights to participating nodes as in the FedAvg algorithm, Hongda Wu et al.  proposed an algorithm called Federated Adaptive Weighting (FedAdp) that measures the node contribution for global model aggregation based on the correlation between local gradient and global gradient. Here global gradient is defined as follows:", "label": "human"}
{"ID": "00190042", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "∇F(w(t)) =KX i=1DiPK i′=1Di′∇Fi(w(t)) (3.5) The correlation between local gradient and global gradient in each communication∥∇F(w(t))∥∥∇Fi(w(t))∥(3.6) signifies that the local gradient has direction close to the global gradient, resulting 2, the local gradient exhibits an opposing direction to that of the global gradient, thereby imparting a negative influence on the global aggregation process.", "label": "human"}
{"ID": "00190043", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In order to mitigate the volatility caused by the randomness observed in the is calculated by taking the average of the angles recorded in previous communication rounds:", "label": "human"}
{"ID": "00190044", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": " t−1 After measuring the contribution of the participating nodes based on the smoothed angles, the authors design a non-ar mapping function to quantify the contribution of each node. This function follows the criterion that nodes with higher contributions deserve higher weights for aggregation in each global round. The function is defined as:", "label": "human"}
{"ID": "00190045", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "it also means that the contribution of 2, which also means the difference between the contribution of nodes is2]narrower, while the which should be considered in this case.", "label": "human"}
{"ID": "00190046", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "After quantifying the contribution of each participating node using the non ar mapping function designed above, the authors use the softmax function to calculate the weight of each participating node for the global model aggregation:", "label": "human"}
{"ID": "00190047", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "PK Thus, the FedAdp algorithm assigns weights to the participating nodes based on In case all participating nodes have the same training set size, these weights depend entirely on the node contributions.Within this chapter, we formulate our methodology to enhance the convergence rate of federated learning. Section 4.1 analyzes the limitations of FedAdp and FedAvg, thereby motivating the proposal of a novel more comprehensive algorithm.", "label": "human"}
{"ID": "00190048", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In section 4.2, we assess the contribution of each participating node by gauging the informational content within their respective datasets. Subsequently, we normalize these contributions to establish unique weights for the global model aggregation.", "label": "human"}
{"ID": "00190049", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "The experiments in  is re-implemented to examine model convergence whenapplying two widely used algorithms in FL, FedAvg and FedAdp on various non IID data scenarios. This investigation serves as the motivation for the development of a new algorithm. Each testing case presented below illustrates the data distribution of each client across classes, the accuracy of the test dataset over communication rounds, and the allocation of weights assigned by the FedAdp algorithm to individual clients over communication rounds.", "label": "human"}
{"ID": "00190050", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Class Node 0123456789 1 58566048685469636856 2 64535576636557555359 3 50675954575465626567 4 61735960616465584653 5 63653859675968635761 6 69614657765364626250 7 51675966604775635260 8 54715262496256666563 9 63596458666558595256 10 48635980674654685659 Table 4.1: Data distribution by classes of test case: 10 balanced data nodes When considering a scenario with 10 nodes exhibiting a balanced data distribution as outd in Table 4.1, the learning curves of both the FedAvg and FedAdp algorithms, depicted in Figure 4.1a, almost overlap. This visual alignment suggests a comparable performance between the two algorithms. Furthermore, this observation is corroborated by the weight distribution depicted in Figure 4.1b, where it is evident that the weights assigned by FedAdp to individual nodes remain relatively(a) (b) Figure 4.1: Results of test case: 10 balanced data nodes. (a) Test accuracy of FedAvg and FedAdp over communication rounds. (b) Node weights of nodes assigned by FedAdp over communication rounds.", "label": "human"}
{"ID": "00190051", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Class Node 0 1 2 3 4 5 6 789 1 58 56 60 48 68 54 69 636856 2 64 53 55 76 63 65 57 555359 3 50 67 59 54 57 54 65 626567 4 61 73 59 60 61 64 65 584653 5 63 65 38 59 67 59 68 635761 6 0 0 0 0 0303 297 000 7 0 0 0 0299 301 0 000 8 0 0 0286 0314 0 000 9 0 0297 0 0303 0 000 10 302 0 0298 0 0 0 000 Table 4.3: Data distribution by classes of test case: 5 balanced data nodes + 5 imbalanced data nodes In scenarios characterized by data distributions as outd in Tables 4.3 and 4.4, where there are 5 and 7 nodes with data imbalance, respectively, the observed trend is similar to the case having 3 nodes with data imbalance. Specifically, FedAdp continues to outperform FedAvg in terms of convergence rate, as depicted in Figures 4.3a and 4.4a. This superiority becomes more pronounced with an increasing number of nodes exhibiting data imbalance. Additionally, in these scenarios, the majority of nodes in balanced data group receive higher weights compared to nodes within imbalanced data group, as depicted in Figures 4.3b and 4.4b.", "label": "human"}
{"ID": "00190052", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Since FedAdp assigns higher weights to nodes whose local gradients closely align with the global gradient calculated from the average of these local gradients,(a) (b) Figure 4.2: Results of test case: 7 balanced data nodes + 3 imbalanced data nodes. (a) Test accuracy of FedAvg and FedAdp over communication rounds. (b) Node weights of nodes assigned by FedAdp over communication rounds.", "label": "human"}
{"ID": "00190053", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "the experiments conducted above suggest that nodes with balanced data exhibit similar directions in their local gradients, bringing them closer to the global gradient.", "label": "human"}
{"ID": "00190054", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Consequently, when nodes with imbalanced data share the same data distribution, and their number is sufficiently large, they can influence the global gradient, pulling it closer to their local gradients and thereby reducing the weights assigned to nodes with balanced data. This assumption is validated by the test case where node data distribution is presented in Table 4.5, featuring 3 nodes with samples from 7 classes and 7 nodes with samples from the remaining 3 classes. In this specific scenario, the convergence rate of FedAdp is no longer superior to that of FedAvg, as illustrated in Figure 4.5a. Furthermore, the weights assigned to nodes with greater(a) (b) Figure 4.3: Results of test case: 5 balanced data nodes + 5 imbalanced data nodes. (a) Test accuracy of FedAvg and FedAdp over communication rounds. (b) Node weights of nodes assigned by FedAdp over communication rounds.", "label": "human"}
{"ID": "00190055", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "data diversity are no longer higher than those assigned to nodes with less data diversity, around from 0.095 to 0.105 for all nodes as demonstrated in Figure 4.5b.", "label": "human"}
{"ID": "00190056", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "While FedAdp successfully addresses FedAvg’s limitations in many instances, it may still encounter challenges in more complex distribution scenarios. To solve the limitations of FedAdp as analyzed, this thesis introduces a new algorithm termed Federated Impurity Weighting (FedImp). Our examination has exposed the varied contributions of different nodes during the global model aggregation process. Consequently, our fundamental insight revolves around quantifying a participating node’s contribution by assessing the informational richness in its data. Subsequently,Class Node 0 1 2 3 4 5 6 7 8 9 1 58 56 60 48 68 54 69 63 68 56 2 64 53 55 76 63 65 57 55 53 59 3 50 67 59 54 57 54 65 62 65 67 4 0 0 0298 0 0 0 0 0302 5 0305 295 0 0 0 0 0 0 0 6 0 0 0 0307 0 0 0 0293 7 0 0 0 0301 0 0299 0 0 8 0 0 0286 0314 0 0 0 0 9 0 0297 0 0303 0 0 0 0 10 302 0 0298 0 0 0 0 0 0 Table 4.4: Data distribution by classes of test case: 3 balanced data nodes + 7 imbalanced data nodes Class Node 0 1 2 3 456 7 89 1 88 88 0 0767986 09291 2 73 70 0 0869094 08899 3 85112 0 0858388 08067 4 0 0204 199 000197 00 5 0 0193 213 000194 00 6 0 0195 197 000208 00 7 0 0200 196 000204 00 8 0 0217 186 000197 00 9 0 0199 195 000206 00 10 0 0196 208 000196 00 Table 4.5: Data distribution by classes of test case: 3 nodes with samples from 7 classes + 7 nodes with samples from the remaining 3 classes these contributions are normalized to generate distinct weights for the aggregation of the global model. The core of the proposed weighting strategy lies in its ability to enhance generalization across diverse data distribution scenarios.", "label": "human"}
{"ID": "00190057", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Entropy is often employed as a tool in the evaluation of impurity or disorder inherent within the dataset linked to a specific node, particularly in structures like decision trees or complex information processing systems. The entropy of a node is higher when the data is more diverse or uncertain, and lower when the data is more homogeneous or certain. In the proposed algorithm, entropy is used as a measure the impurity or the amount of information contained in a participating node i’s data:(a) (b) Figure 4.4: Results of test case: 3 balanced data nodes + 7 imbalanced data nodes. (a) Test accuracy of FedAvg and FedAdp over communication rounds. (b) Node weights of nodes assigned by FedAdp over communication rounds.", "label": "human"}
{"ID": "00190058", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Si=−CX jpjlogCpj (4.1) where Cis the number of classes in the federated learning system and pjis proportion of samples belonging to class jin the node i.", "label": "human"}
{"ID": "00190059", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "It is noteworthy to establish that 0 log 0 is defined as 0. This property holds true in mathematical contexts and is essential to recognize when dealing with information measures. From (4.1), a crucial property of Siis its values lie within the inclusive interval from 0 to 1. The closer Siis to 0, the more concentrated(a) (b) Figure 4.5: Results of test case: 3 nodes with samples from 7 classes + 7 nodes with samples from the remaining 3 classes. (a) Test accuracy of FedAvg and FedAdp over communication rounds. (b) Node weights of nodes assigned by FedAdp over communication rounds.", "label": "human"}
{"ID": "00190060", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "the dataset is around a single class, while the closer Siis to 1, the more evenly distributed the dataset is among different classes, indicating higher uncertainty or impurity. Specifically, Siassumes a value of 0 when the examples within the dataset exclusively pertain to a single class, reflecting a state of utmost certainty. On the contrary, Siattains a value of 1 when the distribution of examples across various classes is perfectly equal, illustrating a scenario of maximum uncertainty.", "label": "human"}
{"ID": "00190061", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Upon obtaining the impurity values from individual nodes, a normalize function is employed to determine the weights assigned to the participating nodes during the process of global model aggregation. Taking inspiration from the Softmaxfunction, this variant function is defined as follows:", "label": "human"}
{"ID": "00190062", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In a hypothetical scenario where nodes with less information possess samples belonging to classes not present in nodes with more information, it would not be reasonable to significantly diminish the influence of the less informative nodes.", "label": "human"}
{"ID": "00190063", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In such cases, maintaining a certain level of influence from these nodes becomes essential, as they contribute unique information that is not available in nodes with more comprehensive data. Striking a balance in the federated learning process is crucial to ensure that all relevant information is considered and integrated, even from nodes with less data, to avoid losing valuable insights or potential improvements the subsequent Chapter.", "label": "human"}
{"ID": "00190064", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Derived from the equation (4.2), in instances where all participating nodes possess an identical quantity of data samples, the FedImp algorithm will allocate weights exclusively predicated on their respective impurity levels. Conversely, should there be variations in the sizes of data samples across participating nodes, FedImp will assign weights by considering both the impurity and the size of the data at each node.", "label": "human"}
{"ID": "00190065", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Flowchart of FedImp is shown in the Figure 4.6, the server begins with the initialization of model parameters. Then a process for each communication round is executed, involving the selection of a random set of nodes, parallel execution of local updates, and aggregation of global parameters. The algorithm terminates when it reaches a certain number of iterations.", "label": "human"}
{"ID": "00190066", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Algorithm 1 details each step of FedImp algorithm. FedImp operates over a predefined number of communication rounds denoted as T. It involves a system with Nnodes, and in each communication round, Knodes are randomly chosen to participate. The algorithm further incorporates parameters such as the local minibatch size B, the number of local epochs E, the learning rate η, and the controlFigure 4.6: Federated Impurity Weighting flowchart Lines 3-8 present main loop for communication rounds tfrom 1 to T, specifically  4: selection of a random set of Knodes for the current round, s 5, 6:", "label": "human"}
{"ID": "00190067", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "looping through each node iin parallel and updating its local model using the LocalUpdate function, which is further described later in the algorithm, Algorithm 1: Federated Impurity Weighting Algorithm Input: T: the number of communication rounds, N: the number of nodes in the system, K: the number of participating nodes in each round, B:", "label": "human"}
{"ID": "00190068", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Initialize w(0); 3 fort= 1,2, . . . , T do 4 Choose random set of Knodes; 5 foreach node i∈Knodes in parallel do 6 wi(t)←LocalUpdate (i,w(t−1)) 8 w(t) =PK 9Function LocalUpdate( i,w):", "label": "human"}
{"ID": "00190069", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "// Run on node i; 11 fore = 1, 2, ..., E do 12 forb = 1, 2, ..., ⌈Di B⌉do 13 w←w−η∇F(w) 14 return w; 9-14 indicates the definition of the LocalUpdate function, which runs on each node i,specifically  11: nested loop for local epochs e, s 12, 13: nested loop for local mini-batches b, updating the local model parameters wusing stochastic gradient descent with step size η,  14: return the updated local model parameters.", "label": "human"}
{"ID": "00190070", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In summary, FedImp introduces a novel approach to weighing the contributions of nodes based on the impurity or diversity of their data during the federated learning process. This strategic design aims to mitigate biases observed in existing algorithms, providing a more balanced and comprehensive approach to global model aggregation in federated learning scenarios.This chapter explores the numerical outcomes derived from implementing the proposed methodology. The chapter begins with an in-depth examination of covering datasets, evaluation metrics, simulation method. The subsequent section presents and analyzes the numerical results, providing valuable insights into the performance and effectiveness of the proposed approach.", "label": "human"}
{"ID": "00190071", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "This thesis is motivated by image classification and sentiment analysis tasks, with the overarching goal of significantly improving the usability of mobile devices.", "label": "human"}
{"ID": "00190072", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Three diverse datasets are employed, including EMNIST , CIFAR-10 , and Large Movie Review Dataset . Each dataset serves a distinct purpose and poses unique challenges, contributing to a comprehensive investigation into the efficacy and adaptability of the proposed algorithm across varied domains.", "label": "human"}
{"ID": "00190073", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "EMNIST : The EMNIST dataset comprises handwritten character digits that have been transformed into a standardized 28x28 pixel image format, aligning with the structure of the MNIST dataset . The EMNIST dataset offers six distinct splits, and EMNIST Balanced split is choosen in this experiment, which contains a set of 47 characters with an equal number of samples per class. The training set encompasses a total of 112,800 samples, while the testing set comprises 18,800 samples.", "label": "human"}
{"ID": "00190074", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "CIFAR-10 : The CIFAR-10 dataset encompasses a collection of 60,000 color images, each sized at 32x32 pixels, distributed across 10 distinct classes with 6,000 images each class. The dataset is further partitioned into 50,000 training images and 10,000 test images.", "label": "human"}
{"ID": "00190075", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Large Movie Review Dataset : This dataset is tailored for binary sentiment classification, featuring a curated collection of 25,000 strongly polar movie reviews designated for training and an additional 25,000 for testing purposes.", "label": "human"}
{"ID": "00190076", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "To evaluate the effectiveness of FedImp compared to FedAdp and FedAvg in improving the convergence rate of FL, the evaluation metric is the number of communication rounds required to achieve the defined target accuracy before on the test set.5.3 Simulation Method 5.3.1 Testing scenarios To compare the FedImp algorithm with the FedAdp and FedAvg algorithms, scenarios are devised with varying complexities in data distribution. The variations include changes in the number of nodes with balanced data and nodes with imbalanced data. For each of two dataset EMNIST and CIFAR10, three testing scenarios are generated for evaluation, including:", "label": "human"}
{"ID": "00190077", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "balanced data nodes + 3 imbalanced data nodes 5 balanced data nodes + 5 imbalanced data nodes 3 balanced data nodes + 7 imbalanced data nodes For the Large Movie Review Dataset, four testing scenarios are formulated for evaluation, including:", "label": "human"}
{"ID": "00190078", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "balanced data nodes + 2 imbalanced data nodes 6 balanced data nodes + 4 imbalanced data nodes 4 balanced data nodes + 6 imbalanced data nodes 2 balanced data nodes + 8 imbalanced data nodes Additionally, to test how the value of alpha affects the FedImp algorithm, a testing scenario with 5 balanced data nodes + 5 data-unbalanced nodes for the explanation of the methodology employed to generate both balanced and imbalanced datasets is provided in Section 5.3.2. Section 5.3.3 focuses on unveiling the architecture of the utilized model. The implementation details of the testing scenarios are then presented in Section 5.3.4.", "label": "human"}
{"ID": "00190079", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Data partition To simulate a diverse population across clients nodes, the same approach as in  is used with some modifications. Each client has an associated multinomial distribution over classes, which is drawn from a symmetric Dirichlet distribution, client exclusively possesses examples from a single class chosen at random.", "label": "human"}
{"ID": "00190080", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Algorithm 2 outs the process of partitioning data for EMNIST and CIFAR-Algorithm 2: Data partition 1fori= 1,2, . . . , X +Ydo 4 else 6 Di=Ø; 7 forj= 1,2, . . . , M do 8 Sample y∈Cwith probability q; 9 Sample randomly x∈Sy; 10 Di=Di∪(x, y); 11 Sy=Sy\\(x, y); 13 C\\y; 14 q←ReNormalize (q, y); 15Function ReNormalize( q= (p1, p2, ..., p C), y):", "label": "human"}
{"ID": "00190081", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "py= 0; 17 a=PC i=1pi; 18 q=q/a 19 return q; 10 datasets with a specified number of balanced ( X) and imbalanced ( Y) data nodes. The number of samples per node is ( M). The dataset creation involves sampling class probabilities from a Dirichlet distribution with concentration parameters 1 to X+Y, class probabilities qare sampled. If iis less than or equal to X, node i, loop through Msamples with the following steps: sample a class label y based on the probability distribution q, randomly select a sample (x, y)from the remaining samples of class yin the dataset S, add the sample (x, y)to the dataset Di, remove the selected sample from the dataset Syof class y. If there are no more samples for class y, remove yfrom the set of classes C, and re-normalize the class probabilities q. The ReNormalize function ensures that the class probabilities q are normalized after removing a class. This partition method guarantees all samples from the original dataset are sampled and preventing any duplication of samples dataset is utilized which ensuring that each node is allocated M=S X+Ysamples.In the case of the Large Movie Dataset, comprising only two classes (negative and positive), the division is as follows: Xnodes are allocated for balanced data, while Ynodes handle imbalanced data. Among the nodes in Ynodes, half are configured such that 80% of the samples belong to the negative class, and the remaining half have 80% of the samples attributed to the positive class.", "label": "human"}
{"ID": "00190082", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Model architecture For the EMNIST dataset, two model architecture is used including: (i) A ANN shown in Figure 5.1 with two fully connected hidden layers with 200 units each, and a final softmax output layer, and ReLU activation is applied between each layer.", "label": "human"}
{"ID": "00190083", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "ii) A CNN shown in Figure 5.2 with two 5x5 convolutional layers (the first with 32 channels, the second with 64, each followed with 2x2 max pooling), a fully connected layer with 512 units and ReLu activation, and a final softmax output layer.", "label": "human"}
{"ID": "00190084", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Implementation details Pre-processing image : Before training the model, several image transformations are executed: (i) EMNIST: normalization of the image arrays to have a mean of 0.5 and a standard deviation of 0.5, (ii) CIFAR-10: comprising random cropping of size 32 with padding of 4 pixels, random horizontal flipping and normalization of the image arrays to have a mean of 0.5 and a standard deviation of 0.5.", "label": "human"}
{"ID": "00190085", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "is chosen. In all cases, a decay rate of 0.995 is applied after each communicationFigure 5.5: LSTM model architecture used for Large Movie Review Dataset", "label": "human"}
{"ID": "00190086", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "algorithm is set to 20. Post each round, the global model’s performance is assessed using the testsets from all participating nodes.", "label": "human"}
{"ID": "00190087", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "FedAvg, and FedImp Algorithms The intricacy of the model plays a crucial role in determining the attained accuracy, resulting in distinct predefined target accuracy levels for each set of test cases utilizing different models. To be specific:", "label": "human"}
{"ID": "00190088", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "For the EMNIST dataset, an accuracy of 82.5% is set as the target for the ANN model, while 86.5% is the target for the CNN model.", "label": "human"}
{"ID": "00190089", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In the case of CIFAR-10, the target accuracy is established at 76.5% for the 2-layer CNN model and 80.5% for the 4-layer CNN model.", "label": "human"}
{"ID": "00190090", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "EMNIST Figure 5.6 depicts the dynamic evolution of test accuracy over communication rounds for FedAdp, FedAvg, and FedImp within the framework of diverse heterogeneousFigure 5.6: Test accuracy over communication rounds of FedAdp, FedAvg and FedImp with different levels of heterogeneous data distribution over participating nodes for EMNIST using ANN model.", "label": "human"}
{"ID": "00190091", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Across all three scenarios, a consistent observation emerges – FedAvg consistently displays a slower convergence rate in comparison to FedAdp and FedImp. Specifically, Table 5.1 quantifies the number of communication rounds required to surpass theTesting scenario FedAdp FedAvg FedImp 7 balanced nodes + 3 imbalanced nodes 60 67 62 5 balanced nodes + 5 imbalanced nodes 76 108 75 3 balanced nodes + 7 imbalanced nodes 146 189 113 Table 5.1: The number of communication rounds to reach over 82.5% accuracy on test set for EMNIST using ANN model 82.5% accuracy threshold on the test set using the ANN model. In the scenario featuring 7 balanced nodes and 3 imbalanced nodes, FedImp closely aligns with FedAdp, outperforming FedAvg by reducing the communication rounds from 67 to 62. Transitioning to the configuration with 5 balanced nodes and 5 imbalanced nodes, FedImp demonstrates a notable advancement, necessitating only 75 communication rounds compared to 76 for FedAdp and a significantly higher 108 for FedAvg, showcasing a remarkable improvement of approximately 30.6% over FedAvg. In the scenario characterized by 3 balanced nodes and 7 imbalanced nodes, FedImp exhibits clear superiority, achieving convergence in 113 rounds. In contrast, FedAdp and FedAvg require 146 and 189 rounds, respectively, indicating a reduction in the number of rounds by approximately 22.6% and 40.2%, highlighting the efficiency gains provided by FedImp.", "label": "human"}
{"ID": "00190092", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Testing scenario FedAdp FedAvg FedImp 7 balanced nodes + 3 imbalanced nodes 24 22 24 5 balanced nodes + 5 imbalanced nodes 26 28 26 3 balanced nodes + 7 imbalanced nodes 45 56 41 Table 5.2: The number of communication rounds to reach over 86.5% accuracy on test set for EMNIST using CNN model Figure 5.7 illustrates the dynamic evolution of test accuracy over communication rounds for FedAdp, FedAvg, and FedImp, considering diverse scenarios of heterogeneous data distribution among participating nodes and utilizing the CNN model. In the two cases with more imbalanced data nodes, FedImp and FedAdp show better convergence rate. Table 5.2 records the communication rounds required for FedAdp, FedAvg, and FedImp algorithms to achieve an accuracy threshold of over 86.5% on the test set using the CNN model. In the scenario with 7 balanced nodes and 3 imbalanced nodes, both FedImp and FedAdp demonstrate comparable performance, achieving convergence in 24 communication rounds, while FedAvg is slightly better with 22 rounds. Moving to the configuration featuring 5 balanced nodes and 5 imbalanced nodes, FedImp and FedAdp show similar levels of performance when requiring 26 rounds, an slight improvement over FedAvg, which need 28. TheFigure 5.7: Test accuracy over communication rounds of FedAdp, FedAvg and FedImp with different levels of heterogeneous data distribution over participating nodes for EMNIST using CNN model.", "label": "human"}
{"ID": "00190093", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "scenario characterized by 3 balanced nodes and 7 imbalanced nodes further highlights the efficiency gains of FedImp. It achieves convergence in 41 rounds, demonstrates a remarkable reduction in the number of rounds, with an efficiency gain of around 8.9% over FedAdp and an even more substantial improvement of about 26.8% overFedAvg.", "label": "human"}
{"ID": "00190094", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "CIFAR-10 Figure 5.8: Test accuracy over communication rounds of FedAdp, FedAvg and FedImpwith different levels of heterogeneous data distribution over participating nodes for CIFAR 10 using 2-layer CNN model.", "label": "human"}
{"ID": "00190095", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Notably, in the two scenarios characterized by a higher number of imbalanced data nodes, both FedImp and FedAdp exhibit a superior convergence rate compared to FedAvg. Table 5.3 presents the results for the number of communication rounds required by FedAdp, FedAvg, and FedImp algorithms to achieve over 76.5% accuracy on the test set using the 2-layer CNN model across different testing scenarios. In the scenario with 7 balanced nodes and 3 imbalanced nodes, FedImp and FedAdp exhibit similar efficiency, both converging in 113 rounds, while FedAvg requires a slightly higher number of rounds, namely 117. For the case with 5 balanced nodes and 5 imbalanced nodes, FedImp outperforms both FedAdp and FedAvg by converging in 125 rounds, while FedAdp and FedAvg require 138 and 183 rounds, respectively. This demonstrates a significant improvement of approximately 9.4% and 31.7% for FedImp compared to FedAdp and FedAvg, respectively. In the scenario involving 3 balanced nodes and 7 imbalanced nodes, FedImp again showcases its efficiency by achieving convergence in 259 rounds, while FedAdp and FedAvg require 292 and 315 rounds, respectively. This reflects a reduction in the number of rounds by approximately 11.3% and 17.8% when comparing FedImp to FedAdp and FedAvg, respectively.", "label": "human"}
{"ID": "00190096", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Testing scenario FedAdp FedAvg FedImp 7 balanced nodes + 3 imbalanced nodes 272 291 258 5 balanced nodes + 5 imbalanced nodes 460 667 332 3 balanced nodes + 7 imbalanced nodes 471 N/A (78.35%) 584 Table 5.4: The number of communication rounds to reach over 80.5% accuracy on test set for CIFAR-10 using 4-layer CNN model. N/A indicates that the algorithms cannot achieve the target accuracy, along with the highest test accuracy displayed.", "label": "human"}
{"ID": "00190097", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "in scenarios dominated by imbalanced nodes, both FedImp and FedAdp outperform FedAvg. Table 5.4 displays the number of communication rounds required to attain over 80.5% accuracy on the test set using a 4-layer CNN model in different testingscenarios. In the scenario with 7 balanced nodes and 3 imbalanced nodes, FedImp outperforms both FedAdp and FedAvg by achieving convergence in 258 rounds, while FedAdp and FedAvg require 272 and 291 rounds, respectively. Transitioning to the case of 5 balanced nodes and 5 imbalanced nodes, FedImp demonstrates a substantial improvement, requiring 332 rounds, as opposed to 460 for FedAdp and a significantly higher 667 for FedAvg. This signifies a decrease in the number of rounds by around 27.8% and 50.2% when comparing FedImp to FedAdp and FedAvg, respectively. In the scenario with 3 balanced nodes and 7 imbalanced nodes, while FedAvg cannot reach the target accuracy of over 80.5%, FedImp demonstrates a slower convergence, reaching convergence in 584 rounds, whereas FedAdp achieves the same in 471 rounds.", "label": "human"}
{"ID": "00190098", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Large Movie Review Dataset Figure 5.10: Test accuracy over communication rounds of FedAdp, FedAvg and FedImp with different levels of heterogeneous data distribution over participating nodes for Large Movie Review Dataset using LSTM model.Testing scenario FedAdp FedAvg FedImp 8 balanced nodes + 2 imbalanced nodes 59 49 44 6 balanced nodes + 4 imbalanced nodes 56 55 46 4 balanced nodes + 6 imbalanced nodes 66 62 52 2 balanced nodes + 8 imbalanced nodes 85 64 68 Table 5.5: The number of communication rounds to reach over 70% accuracy on test set for Large Movie Review using LSTM model Figure 5.10 illustrates the test accuracy evolution across communication rounds for FedAdp, FedAvg, and FedImp, considering different levels of heterogeneous data distribution among participating nodes using the LSTM model. The figure suggests a marginal improvement in the convergence rate of FedImp compared to FedAdp and FedAvg in most cases. Table 5.5 presents the number of communication rounds required to achieve over 70% accuracy on the test set using an LSTM model in various testing scenarios. In a scenario with 8 balanced nodes and 2 imbalanced nodes, FedImp outperformed both FedAdp and FedAvg, requiring only 44 rounds compared to 59 and 49 rounds, respectively. \"This signifies a decrease of 25.4% for FedAdp and 10.2% for FedAvg. Similarly, in a scenario with 6 balanced nodes and 4 imbalanced nodes, FedImp achieved convergence in 46 rounds, showcasing its superiority over FedAdp, which took 56 rounds, and FedAvg, which took 55 rounds, with reductions of 17.9% and 16.4%, respectively. FedImp’s efficiency was further evident in a scenario with 4 balanced nodes and 6 imbalanced nodes, converging in 52 rounds compared to 66 rounds for FedAdp, showing a dec of approximately 21.2%, and 62 rounds for FedAvg, exhibiting a dec of about 16.1%. However, in a scenario with 2 balanced nodes and 8 imbalanced nodes, while both FedImp and FedAvg outperform FedAdp that requires 85 rounds, FedImp exhibited slightly slower convergence, requiring 68 rounds, while FedAvg needed 64 rounds.", "label": "human"}
{"ID": "00190099", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "In conclusion, in nearly all test cases featuring varying numbers of balanced and unbalanced nodes, FedImp demonstrates superiority in convergence speed when compared to FedAdp and FedAvg. FedImp can reduce the number of communication rounds by up to 22.6% on the EMNIST dataset, up to 27.8% on the CIFAR-10 dataset, and up to 25.4% on the Large Movie Review Dataset, compared to the FedAdp algorithm. Furthermore, in comparison to FedAvg, FedImp can achieve a reduction in the number of communication rounds by up to 40.2% on the EMNIST dataset, up to 50.2% on the CIFAR-10 dataset, and up to 16.4% on the Large Movie Review Dataset.distribution setting is 5 balanced node + 5 imbalanced node for EMNIST and the ANN model is adopt.", "label": "human"}
{"ID": "00190100", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "9 5N/A (83.96%) 10 170 20 176 30 203 Table 5.6: The number of communication rounds to reach over 84% accuracy on test set.", "label": "human"}
{"ID": "00190101", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Data distribution setting is 5 balanced node + 5 imbalanced node for EMNIST and the ANN model is adopt. N/A indicates that the algorithms cannot achieve the target accuracy, along with the highest test accuracy displayed.", "label": "human"}
{"ID": "00190102", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "of nodes with less information. Nevertheless, it is crucial to recognize that employing scenario employing the EMNIST dataset and the ANN model with a data distributionsetting of 5 balanced nodes and 5 imbalanced nodes. Additionaly, the number of communication rounds required to surpass the 84% accuracy threshold on the test 20, and 30, the system required 170, 176, and 203 rounds, respectively, to reach the desired accuracy level. This exhibits a gradual decrease in convergence rate asThis thesis critically assess the limitations of the FedAdp algorithm in the context of non-IID data scenarios, motivating for the proposing a novel FL algorithm, FedImp, as a comprehensive solution to address these identified shortcomings.", "label": "human"}
{"ID": "00190103", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Through extensive experimental evaluations, FedImp showcases its superior convergence rate compared to both FedAdp and FedAvg in various scenarios with non-IID data. Notably, FedImp reduces the number of communication rounds by up to 22.6%, 27.8%, and 25.4% on the EMNIST, CIFAR-10, and Large Movie Review datasets, respectively, when compared to FedAdp. Moreover, when compared to FedAvg, FedImp demonstrated even more significant reductions of up to 40.2%, 50.2%, and 16.4% on the same datasets. These outcomes underscore the impactful contributions of this thesis in recognizing and addressing the limitations of FedAdp, offering a promising solution in FedImp to enhance the effectiveness of FL in the face of non-IID data distributions. T. Li, A. K. Sahu, A. Talwalkar andV. Smith, “Federated learning: Challenges, methods, and future directions,” IEEE signal processing magazine ,jourvol 37, number 3,pages 50–60, 2020.", "label": "human"}
{"ID": "00190104", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "P. Kairouz, H. B. McMahan, B. Avent andothers , “Advances and open problems in federated learning,” Foundations and Trends ®in Machine Learning ,jourvol 14, number 1–2,pages 1–210, 2021.", "label": "human"}
{"ID": "00190105", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "H. Zhu, J. Xu, S. Liu andY. Jin, “Federated learning on non-iid data: A survey,” Neurocomputing ,jourvol 465,pages 371–390, 2021.", "label": "human"}
{"ID": "00190106", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Y. Liu, L. Zhang, N. Ge andG. Li, “A systematic literature review on federated learning: From a model quality perspective,” arXiv preprint arXiv:2012.01973 , 2020.", "label": "human"}
{"ID": "00190107", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "B. McMahan, E. Moore, D. Ramage, S. Hampson andB. A. y Arcas, “Communication efficient learning of deep networks from decentralized data,” inArtificial intelligence and statistics PMLR, 2017, pages 1273–1282.", "label": "human"}
{"ID": "00190108", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "H. Wu andP. Wang, “Fast-convergent federated learning with adaptive weighting,” IEEE Transactions on Cognitive Communications and Networking ,jourvol 7, number 4,pages 1078–1088, 2021.", "label": "human"}
{"ID": "00190109", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "T.-M. H. Hsu, H. Qi andM. Brown, “Measuring the effects of non-identical data distribution for federated visual classification,” arXiv preprint arXiv:1909.06335 , 2019.", "label": "human"}
{"ID": "00190110", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Y. Yeganeh, A. Farshad, N. Navab and S. Albarqouni, “Inverse distance aggregation for federated learning with non-iid data,” inDomain Adaptation and Representation Transfer, and Distributed and Collaborative Learning:", "label": "human"}
{"ID": "00190111", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "Second MICCAI Workshop, DART 2020, and First MICCAI Workshop, DCL 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4–8, 2020, Proceedings 2 Springer, 2020, pages 150–159.", "label": "human"}
{"ID": "00190112", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "D. A. E. Acar, Y. Zhao, R. M. Navarro, M. Mattina, P. N. Whatmough and V. Saligrama, “Federated learning based on dynamic regularization,” arXiv preprint arXiv:2111.04263 , 2021.", "label": "human"}
{"ID": "00190113", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "S. Vahidian, M. Morafah andB. Lin, “Personalized federated learning by structured and unstructured pruning under data heterogeneity,” in2021 IEEE 41st international conference on distributed computing systems workshops (ICDCSW) IEEE, 2021, pages 27–34. G. Cohen, S. Afshar, J. Tapson andA. Van Schaik, “Emnist: Extending mnist to handwritten letters,” in2017 international joint conference on neural networks (IJCNN) IEEE, 2017, pages 2921–2926.", "label": "human"}
{"ID": "00190114", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng andC. Potts, “Learning word vectors for sentiment analysis,” inProceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies Portland, Oregon, USA: Association for Computational Linguistics, 2011, pages 142–150. url:", "label": "human"}
{"ID": "00190115", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "L. Deng, “The mnist database of handwritten digit images for machine learning research [best of the web],” IEEE signal processing magazine ,jourvol 29, number 6,pages 141–142, 2012.", "label": "human"}
{"ID": "00190116", "file_name": "Federated Impurity Weighting: A Novel Approach for Improving Convergence in Federated Learning", "content": "J. Pennington, R. Socher andC. D. Manning, “Glove: Global vectors for word representation,” inProceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) 2014, pages 1532–1543.", "label": "human"}
{"ID": "00200001", "file_name": "E-commerce Luxury Clothes Website", "content": "Optimization of e-commerce web applications is one of the most important factors for businesses to maximize their profits. Using React to build an e-commerce web application will make optimization easier and faster.", "label": "human"}
{"ID": "00200002", "file_name": "E-commerce Luxury Clothes Website", "content": "React provides a great web application-building tool with the most up-to-date technology and features. It also provides a model of components, allowing you to create better user interfaces and improve page load speed.", "label": "human"}
{"ID": "00200003", "file_name": "E-commerce Luxury Clothes Website", "content": "React also provides a complex development framework for e-commerce web applications. It provides tools and techniques to create a powerful and responsiveweb application for the customer. It also provides a very flexible and performance improving toolset to optimize your e-commerce web application.", "label": "human"}
{"ID": "00200004", "file_name": "E-commerce Luxury Clothes Website", "content": "The website will provide users with an intuitive and easy-to-use interface, as well as convenient and secure purchasing features. There will be a user management system to allow administrator access to each user’s account. The website will also provide forms for users to place orders and integrate many features such as on payment, courier service, and product information updates.", "label": "human"}
{"ID": "00200005", "file_name": "E-commerce Luxury Clothes Website", "content": "The scope of this graduate thesis is to build an e-commerce website using React with key features such as user management, an intuitive and easy-to-use interface, order forms, on payment, and update product information. In addition, the thesis research will also analyze the factors affecting the website design and propose appropriate solutions to improve performance.", "label": "human"}
{"ID": "00200006", "file_name": "E-commerce Luxury Clothes Website", "content": "The user interface is built using Reactjs for good and fast interoperability for web and mobile applications. Support admin to manage effectively, help employees have customer information, fastest suitable products, and help customers choose the most suitable product model.", "label": "human"}
{"ID": "00200007", "file_name": "E-commerce Luxury Clothes Website", "content": "To develop applications with the above features, I choose to build web-based applications that are easy to maintain and use. The system is separated into 3 components: a website for administrators to use in management and editing according to specific functions. For example, they can add new products, update or delete products, existing categories, statistics, account management, etc., a website forproduct managers where they can find products, customer care, and placing orders for customers, and a website for customers to buy and evaluate products, etc.", "label": "human"}
{"ID": "00200008", "file_name": "E-commerce Luxury Clothes Website", "content": "The database used for the system is MongoDB, an open-source, distributed database management system designed to serve complex web applications with large amounts of data.", "label": "human"}
{"ID": "00200009", "file_name": "E-commerce Luxury Clothes Website", "content": "The server is built with Nodejs, which is an open-source JavaScript-based platform used to build server applications. It provides the resources and tools to develop web applications efficiently and at a fast pace Client site built with Reactjs is a JavaScript library used to build intuitive user interfaces (UIs) and complex web applications.", "label": "human"}
{"ID": "00200010", "file_name": "E-commerce Luxury Clothes Website", "content": "Chapter 2 presents the requirements analysis of the projects, looking at a number of current products that have similar objectives to this project. Based on these products, define an overview of use cases and features for this project that describes some of the important use cases of the system, and the non-functional requirements of the system.", "label": "human"}
{"ID": "00200011", "file_name": "E-commerce Luxury Clothes Website", "content": "Chapter 4 presents the content of application analysis and application design including architectural design, package design, interface design, and application building.", "label": "human"}
{"ID": "00200012", "file_name": "E-commerce Luxury Clothes Website", "content": "Chapter 5 introduces the application development processes including the libraries and tools used in the project, application testing, and application deployment.", "label": "human"}
{"ID": "00200013", "file_name": "E-commerce Luxury Clothes Website", "content": "Chapter 7 presents the conclusion of the thesis, looks back at the results, knowledge, experience, and orientation for future development solutions, and draws experience after completing the system building.2.1 State of the art For this part, I will look at an existing website with similar goals to this project, Lyos - an e-commerce site selling clothes have streetwear style.", "label": "human"}
{"ID": "00200014", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC01 UC Name Login Participating Actors Customer, Staff, Admin Description Sign in to the system Trigger Event Choose login feature Precondition Have an account in the systemScenario1. The actor chooses the login feature 2. The system displays the login interface 3. The actor enters login information (Description below*) 4. The actor request login 5. The system checks the required fields but no information yet 6. The system checks if the account exists in the system 7. The system checks if the password is correct 8. The system saves the login session; Navigate to the account page Result The system announces successful login; Storing the login session; Navigate to the actor’s profile Extensions1. If the agent has logged in before, the corresponding session has not expired, and the system navigates to the profile page Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200015", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric Order Name Required Example 1 Email Yes ngocnhathht@gmai.com 2 Password Yes Abc@1232.2.3 Register Usecase Figure 2.9: Register Usecase Use Case Description:", "label": "human"}
{"ID": "00200016", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC02 UC Name Register Participating Actors Lead Description Register a valid account to access the system as a user Trigger Event Choose register feature Precondition None Scenario1. The actor chooses the register feature 2. The system displays the register interface 3. The actor enters login information (Description below*) 4. The system checks the validity of the information is entered 5. The actor request to register 6. The system checks required fields but no information yet 7. The system checks if the email address has been used to register an account 8. The system checks if the pass length is enough 9. The system saves account information; Display register successfully; Navigate to account pageResult The system announces successful registration; Store account information; Navigate to the agent’s profile Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200017", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric OrderName Required Condition Example 1 Email YesValid structured email addressngocnhathht@gmai.com 2 Password YesUnsigned, no space, Minimum of 8 characters, Contains letters, numbers, uppercase characters, and 1 special character (eg !, @, ...)Abc@123 3Confirm passwordYes Same password Abc@123 2.2.4 Rating Usecase Figure 2.10: Rating UsecaseUse Case Description:", "label": "human"}
{"ID": "00200018", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC03 UC Name Rating Participating Actors Customer Description Rate product quality Trigger Event Choose the number of stars Precondition Login in to the system Scenario1. The actor chooses the number of stars 2. The system displays the register interface 3. The system saves rating star information; Display rate successfully Result The system displays a successful rating message and stores rating star information Extensions1. None Exceptions1. None 2.2.5 Feedback Usecase Figure 2.11: Feedback Usecase Use Case Description:", "label": "human"}
{"ID": "00200019", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC05 UC Name Feeback Participating Actors Admin Description Allow actor to delete feedbacks Trigger Event Actor chooses the X button in the feedback Precondition Login into the system as an adminScenario1. The actor chooses the X button in the feedback 2. The system displays the consequences warning window, giving suggestions to disable 3. The actor chooses \"Accept\" 4. The system announces successful deletion, deleting feedback information from the database Result The system displays a successful feedback deletion message Extensions1. None Exceptions1. System displays a message: canceled if the Actor selects “Cancel” 2.2.6 Creating Feedback Usecase Figure 2.12: Creating Feedback Usecase Use Case Description:UC Code UC06 UC Name Creating Feedback Participating Actors Lead, Customer, Staff Description Help actor add new feedback Trigger Event Choose contact feature Precondition None Scenario1. The actor chooses the contact feature 2. The system displays the contact interface 3. The actor enters feedback information (Description below*) 4. The system checks the validity of the information is entered 5. The actor requested to submit 6. The system checks required fields but no information yet 7. The system saves feedback information; Displays created feedback successfully Result The system displays created feedback successfully; Store feedback information Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200020", "file_name": "E-commerce Luxury Clothes Website", "content": "Invalid information * Input Information:Numeric OrderName Required Condition Example 1 Email YesValid structured email addressngocnhathht@gmai.com 2 Name YesUnsigned, Contains letters, and no 1 special character (eg !, @, ?...)Hoang Nhat 3 Phone No Number 0946223105 4 Subject NoUnsigned, Contains lettersCan’t buy items in the cart 5 Mess YesUnsigned, Contains lettersWhen I click to buy something it doesn’t have in the cart2.2.7 Comment Usecase Figure 2.13: Comment Usecase Use Case Description:UC Code UC07 UC Name Creating Comment Participating Actors Customer, Staff Description Help actor add new comment Trigger Event Actor clicks comment button Precondition Login into the system as a customer or staff Scenario1. The actor fills content in the field 2. The actor requested to comment 3. The system checks the comment field has information yet 4. The system saves comment information; Displays created comments successfully Result The system displays created comment successfully; Store comment information Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200021", "file_name": "E-commerce Luxury Clothes Website", "content": "Content cannot be left blank UC Code UC08 UC Name Edit/Reply Comment Participating Actors Customer, Staff Description Help actor add new reply or edit comment Trigger Event Actor clicks edit/reply button Precondition Login into the system as a customer or staff Scenario1. The actor chooses the edit/reply feature 2. The actor displays a field to enter content 3. The actor fills content in the field 4. The actor requested to update/reply 5. The system checks the update/reply field has information yet 6. The system saves update/reply information; Displays created reply/updated successfullyResult The system displays created reply / updated successfully; Store update/reply information Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200022", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric OrderName Required Condition Example 5 Comments Yes This product is so great UC Code UC09 UC Name Delete Comment Participating Actors Staff Description Allow the agent to delete comments Trigger Event Actor clicks delete button Precondition Login into the system as a staff Scenario1. The actor chooses the delete feature 2. The system displays the consequences warning window, giving suggestions to disable 3. The actor chooses \"Accept\" 4. The system announces successful deletion, deleting comment information from the database Result The system displays deleted comment successfully Extensions1. None Exceptions1. System displays a message: canceled if the Actor selects “Cancel” *2.2.8 Creating Product Usecase Figure 2.14: Creating Product Usecase Use Case Description:", "label": "human"}
{"ID": "00200023", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC10 UC Name Creating Product Participating Actors Admin Description Allow actor to add new product Trigger Event Choose product feature Precondition Login into the system as an admin Scenario1. The actor chooses the product feature 2. The system displays the product creation interface 3. The actor enters product information (Description below*) 4. The actor uploads the product image 5. The system checks the format of the product image 6. The actor requested to create 7. The system checks required fields but no information yet 8. The system saves product information; Displays created products successfully Result The system displays created product successfully; Store product information Extensions1. NoneExceptions1. System displays an error message:", "label": "human"}
{"ID": "00200024", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric OrderName Required Condition Example 1 Produt_id Yes GC_01 2 Title Yes Gucci Shoes 3 Price No Number 255 4 Description YesThis is product description 5 Category Yes Cucci 6 Stock Yes Number 80 7 Image YesType of image is a jpeg, png, jpg or webp, size of image is lower than 1024*1024(<1mb)2.2.9 View Products Usecase Figure 2.15: View Product UsecaseUse Case Description:", "label": "human"}
{"ID": "00200025", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC11 UC Name Search Products Participating Actors Admin, Staff, Lead, Customer Description Allows actors to search for products by properties or name Trigger Event Select search properties or enter search product name Precondition None Scenario1. The actor chooses search properties 2. The system filters and finds products on demand 3. The system displays search products by properties or category 4. The actor enters the name product into the search field 5. The system filters and finds products that have names similar to the input value 6.", "label": "human"}
{"ID": "00200026", "file_name": "E-commerce Luxury Clothes Website", "content": "The system displays search products by name Result The system displays search products on request Extensions1. None Exceptions1. None * Input Information:", "label": "human"}
{"ID": "00200027", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric OrderName Required Condition Example 1 Search No Gucci Shoes 2 Filter by No Best Sold 3Category by:No GucciUC Code UC12 UC Name Edit Product Participating Actors Admin Description Allow admin to edit product information Trigger Event Select Edit feature Precondition Product data must be available Scenario1. The actor chooses the edit feature 2. The system displays the product edit page 3. The actor enters updated product information (Description below*) 4. The actor uploads the updated product image 5. The system checks the format of the updated product image 6. The actor requested to update 7. The system checks required fields but no information yet 8. The system saves updated product information; Displays updated products successfully Result The system displays updated product successfully; Store updated product information Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200028", "file_name": "E-commerce Luxury Clothes Website", "content": "Incomplete information * Input Information:Numeric OrderName Required Condition Example 1 Title Yes Gucci Shoes 2 Price No Number 255 3 Description YesThis is product description 4 Category Yes Cucci 5 Stock Yes Number 80 6 Image YesType of image is a jpeg, png, jpg or webp, size of image is lower than 1024*1024(<1mb) UC Code UC13 UC Name Delete/Delete All Product Participating Actors Admin Description Allow admin to delete products information or delete all product Trigger Event Select Delete/Delete All feature Precondition Login into the system as an admin Scenario1. The actor clicks product cards 2. The system displays the checked products 3. The actor chooses the delete feature 4. The system displays the consequences warning window, giving suggestions to disable 5. The actor chooses \"Yes\" 6. The system announces successful deletion, deleting checked products information from the database Result The system displays deleted product successfullyExtensions1. If the actor clicks Check All, all products will be checked Exceptions1. System displays a message: canceled if the Actor selects “No” UC Code UC14 UC Name Add Cart Participating Actors Customer, Staff Description Allow actor adds products to the cart and change the number of them in the cart Trigger Event Click Buy button Precondition Login into the system as staff or customerScenario1. The actor clicks the Buy button 2. The system displays the bought products in the cart 3. The actor increases the number of products in the cart system checks whether the number of products exceeds the quantity in stock 4. The system shows a product increase in quantity 5. The actor decreases the number of products in the cart 6. The system checks if the product quantity is less than the minimum quantity 7. The system shows a product decrease in quantity 8. The actor chooses the delete feature 9. The system displays the consequences warning window, giving suggestions to disable 10. The actor chooses \"Yes\" 11. The system announces successful deletion and removes the product from the cart Result The system displays the products and the number of them in the cart or removes the product from the cart Extensions1. If the actor clicks view detail, the detailed product page will be displayed.", "label": "human"}
{"ID": "00200029", "file_name": "E-commerce Luxury Clothes Website", "content": "The actor clicks the buy button, the system adds the product to the cartExceptions1. System displays a message: canceled if the Actor selects “No” 2. System displays a message: Minimum quantity of product is more than allowed 3. System displays a message: Product is out of stock 2.2.10 Categories Usecase Figure 2.16: Categories Usecase Use Case Description:", "label": "human"}
{"ID": "00200030", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC15 UC Name Creating Categoty Participating Actors Admin Description Allow actor to add new category Trigger Event Choose categories feature Precondition Login into the system as an adminScenario1. The actor chooses the categories feature 2. The system displays the categories creation interface 3. The actor enters category name (Description below*) 4. The actor requested to create 5. The system saves the category name; Displays created category successfully Result The system displays created category successfully; Store category name Extensions1. None Exceptions1. None UC Code UC16 UC Name Edit Categoty Participating Actors Admin Description Allow actor to edit category name Trigger Event Choose edit feature Precondition Category name must be available Scenario1. The actor chooses the edit feature 2. The system displays the edited category name in the field 3. The actor enters a new category name (Description below*) 4. The actor requested to update 5. The system saves the new category name; Displays the updated category successfully Result The system displays the updated category successfully; Store new category name Extensions1. None Exceptions1. None * Input Information:Numeric OrderName Required Condition Example 1 Name Yes Gucci UC Code UC17 UC Name Delete Categoty Participating Actors Admin Description Allow actor to delete category name Trigger Event Choose delete feature Precondition Category name must be available Scenario1. The actor chooses the delete feature 2. The system displays the consequences warning window, giving suggestions to disable 3. The actor chooses \"Yes\" 4. The system announces successful deletion, deleting checked products information from the database Result The system displays deleted product successfully Extensions1. None Exceptions1. System displays a message: canceled if the Actor selects “No”2.2.11 History Usecase Figure 2.17: History Usecase Use Case Description:", "label": "human"}
{"ID": "00200031", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC18 UC Name History Status Participating Actors Admin, Staff Description Help actor change order status Trigger Event View detail order Precondition Login into the system as a staff or adminScenario1. The actor chooses view detail order feature 2. The system displays the view detail order interface 3. The actor selects the status of the order 4. The system changes the status of the order 5. The system saves the new status of the order Result The system stores the new status of the order Extensions1. None Exceptions1. None2.2.12 Checkout Usecase Figure 2.18: Checkout Usecase Use Case Description:", "label": "human"}
{"ID": "00200032", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code UC19 UC Name PayPal Participating Actors Customer Description Sign in to the systemTrigger Event Choose PayPal feature Precondition Have item in the cart Scenario1. The actor chooses the PayPal feature 2. The system displays the form to sign in PayPal account 3. The actor enters the login information 4. The actor request login 5. The system displays the detailed order 6. The actor chooses \"Accept\" 7. The system saves payment information; Display successful payment; Navigate to product page Result The system announces successful payment; Storing the payment information; Navigate to the product page Extensions1. None Exceptions1. System displays a message: canceled if the Actor selects “Cancel\" * Input Information:", "label": "human"}
{"ID": "00200033", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric Order Name Required Example 1 Email Yes ngocnhathht@gmai.com 2 Password Yes Abc@123 UC Code UC20 UC Name Ship Cod Participating Actors Customer Description Sign in to the system Trigger Event Choose Ship Cod feature Precondition Have item in the cartScenario1. The actor chooses the Ship Cod feature 2. The system displays the Ship Cod page interface 3. The actor enters product information (Description below*) 4. The actor request payment 5. The system checks required fields but no information yet 6. The system saves payment information; Display successful payment; Navigate to product page Result The system announces successful payment; Storing the payment information; Navigate to the product page Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200034", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric OrderName Required Condition Example 1 First_name Yes Hoang 2 Family_name Yes Nhat 3 Phone Yes Number 0946225301 4 Address Yes 62 Tam Trinh 5 City Yes Ha Noi 6 Postal_code No Number 250 7 Country_code No 10000 UC Code UC21 UC Name Take Away Participating Actors Staff Description Sign in to the system Trigger Event Choose Take Away feature Precondition Have item in the cartScenario1. The actor chooses the Take Away feature 2. The system displays the Take Away page interface 3. The actor enters product information (Description below*) 4. The actor request payment 5. The system checks required fields but no information yet 6. The system saves payment information; Display successful payment; Navigate to product page Result The system announces successful payment; Storing the payment information; Navigate to the product page Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200035", "file_name": "E-commerce Luxury Clothes Website", "content": "Numeric OrderName Required Condition Example 1 First_name Yes Hoang 2 Family_name Yes Nhat 3 Phone Yes Number 0946225301 2.2.13 Creating Account Usecase Figure 2.19: Creating Account Usecase Use Case Description:UC Code UC22 UC Name Creating Account Participating Actors Admin Description Allow actor to create accounts by role Trigger Event Choose account feature Precondition Login into the system as an admin Scenario1. The actor chooses the create account feature 2. The system displays the create account interface 3. The actor enters the login information (Description below*) 4. The system checks the validity of the information is entered 5. The actor collects the role of account 6. The actor display form to enter account information 7. The actor enters the account information (Description below*) 8. The system checks the validity of the information is entered 9. The actor uploads the avatar 10. The system checks the format of the avatar 11. The actor requested to create 12. The system checks required fields but no information yet 13. The system checks if the email address has been used to register an account 14. The system checks if the pass length is enough 15. The system saves account information; Display create account successfully; Navigate to the create account pageResult Display create account successfully; Store account information; Navigate to the create account page Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200036", "file_name": "E-commerce Luxury Clothes Website", "content": "Incomplete information * Login Information:Numeric OrderName Required Condition Example 1 Email YesValid structured email addressngocnhathht@gmai.com 2 Password YesUnsigned, no space, Minimum of 8 characters, Contains letters, numbers, uppercase characters, and 1 special character (eg !, @, ...)Abc@123 3Confirm passwordYes Same password Abc@123 4 First_name Yes Hoang 5 Family_name Yes Nhat 6 Date_of_birth Yes 06/02/1999 7 Phone Yes Number 0946225301 8 Address Yes 62 Tam Trinh 9 Sex Yes Nam 10 Image YesType of image is a jpeg, png, jpg or webp, size of image is lower than 1024*1024(<1mb)2.2.14 View Account Usecase Figure 2.20: View Account Usecase Use Case Description:", "label": "human"}
{"ID": "00200037", "file_name": "E-commerce Luxury Clothes Website", "content": "UC Code 23 UC Name Change Role Account Participating Actors Admin Description Allow actor to change the role of account Trigger Event Choose manage account feature Precondition Login into the system as an adminScenario1. The actor chooses the manage account feature 2. The system displays the manage account interface 3. The actor collects role for account 4. the system sends a confirmation message 5. The actor chooses \"Yes\" 6. The system saves the role of the account; Displays the successful changing role; Provides permissions to the account Result Display the successful changing role; Store the updated role of account; Provides permissions to the account Extensions1. None Exceptions1. System displays a message: canceled if the Actor selects “No” UC Code UC24 UC Name Edit Account Participating Actors Admin Description Allow actor to update the information of account Trigger Event Choose edit feature Precondition Login into the system as an adminScenario1. The actor chooses the edit feature 2. The system displays the account edit page 3. The actor enters the updated account information (Description below*) 4. The system checks the validity of the information is entered 5. The actor uploads the updated avatar 6. The system checks the format of the updated avatar 7. The actor requested to update 8. The system checks required fields but no information yet 9. The system saves updated account information; Displays the updated account successfully Result The system displays the updated account successfully; Store updated account information Extensions1. None Exceptions1. System displays an error message:", "label": "human"}
{"ID": "00200038", "file_name": "E-commerce Luxury Clothes Website", "content": "Incomplete information * Login Information:Numeric OrderName Required Condition Example 1 Email YesValid structured email addressngocnhathht@gmai.com 2 Password YesUnsigned, no space, Minimum of 8 characters, Contains letters, numbers, uppercase characters, and 1 special character (eg !, @, ...)Abc@123 3Confirm passwordYes Same password Abc@123 4 First_name Yes Hoang 5 Family_name Yes Nhat 6 Date_of_birth Yes 06/02/1999 7 Phone Yes Number 0946225301 8 Address Yes 62 Tam Trinh 9 Sex Yes Nam 10 Image YesType of image is a jpeg, png, jpg or webp, size of image is lower than 1024*1024(<1mb) UC Code UC25 UC Name Delete Account Participating Actors Admin Description Allow actor to delete the information of account Trigger Event Choose delete feature Precondition Login into the system as an adminScenario1. The actor chooses the delete feature 2. The system displays the consequences warning window, giving suggestions to disable 3. The actor chooses \"Yes\" 4. The system announces successful deletion, deleting account information from the database Result The system displays deleted account successfully Extensions1. None Exceptions1. System displays a message: canceled if the Actor selects “No”3.1 Bcrypt Password hashing is the process of turning a password into alphanumeric letters using specific algorithms. Hashing is beneficial when bad guys breach the data.", "label": "human"}
{"ID": "00200039", "file_name": "E-commerce Luxury Clothes Website", "content": "Some popular algorithms for password hashing include bcrypt and SHA. In this article, we’ll focus on using bycrypt to hash passwords in Node.js. Here’s an example of hashing plain text:", "label": "human"}
{"ID": "00200040", "file_name": "E-commerce Luxury Clothes Website", "content": "hash(’Heypasswor’) = 1b21hb2hb1u2gu3g2fxy1v2ux1v2y3vu12g4svvdax Figure 3.1: Bcrypt Bcrypt is a library to help you hash passwords. It uses a password-hashing function that is based on the Blowfish cipher. The Blowfish cipher is a symmetric block cipher that provides the best encryption rate in the industry; thus, it can be used in cipher suites and encryption products.", "label": "human"}
{"ID": "00200041", "file_name": "E-commerce Luxury Clothes Website", "content": "Bcrypt uses salt to protect against attacks like rainbow table, brute force, and more. Bcrypt is an adaptive function, so if you call bcrypt’s function frequently, it becomes slower. This hinders an attacker’s ability to benefit from a brute-force attack.", "label": "human"}
{"ID": "00200042", "file_name": "E-commerce Luxury Clothes Website", "content": "Cloudinary is a cloud-based service, it provides an image management solution including upload, storage, manipulation, optimization and delivery. With Cloudinary, you can easily upload photos to the cloud, and automatically perform intelligent photo manipulations without having to install any other complicated software.", "label": "human"}
{"ID": "00200043", "file_name": "E-commerce Luxury Clothes Website", "content": "A software system designed with scalable internet applications in mind. The program is written in Javascript, using event-driven, input/output/asynchronous technology. Node JS is written server-side to convey APIs to other applications.", "label": "human"}
{"ID": "00200044", "file_name": "E-commerce Luxury Clothes Website", "content": "Advantages: NodeJS is easy to use and is widely installed by developers. Multiple support libraries Disadvantage: Because it is a library of Javascript (asynchronous language), Node JS is not as strict as other languages.", "label": "human"}
{"ID": "00200045", "file_name": "E-commerce Luxury Clothes Website", "content": "Is a cross-platform, open-source NoSQL database management system written in C++. Records in MongoDB are stored as text data (Document), which is a data structure consisting of corresponding value pairs and similar to a JSON object. The reason I choose MongoDB is that MongoDB is easy to use and install, and pure JS methods are what makes it easier to get used to a database. However, the rigor of a NoSQL database system is the most important thing.", "label": "human"}
{"ID": "00200046", "file_name": "E-commerce Luxury Clothes Website", "content": "Is a promise-based HTTP Client library for NodeJS and browsers. Client-side, Axios uses the form of XMLHttpRequest Features:o Make a request from the browser using XMLHttpRequest o Make requests from nodeJs using HTTP o Promise API support o Receive and block requests and responses o Change request and response data o Cancel the request o Automatic conversion for JSON data o Support client-side protection against XSRF The installation of Axios is similar to other libraries, in addition, it is also possible to embed a CDN in the project.", "label": "human"}
{"ID": "00200047", "file_name": "E-commerce Luxury Clothes Website", "content": "ReactJS is an opensource developed by Facebook, launched in 2013, itself is a Javascript library used to build interactions with components on the website. One of the most outstanding features of ReactJS is that rendering data can not only be done on the Server layer, but also below the Client.", "label": "human"}
{"ID": "00200048", "file_name": "E-commerce Luxury Clothes Website", "content": "JSON Web Token is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed.", "label": "human"}
{"ID": "00200049", "file_name": "E-commerce Luxury Clothes Website", "content": "JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA or ECDSA.", "label": "human"}
{"ID": "00200050", "file_name": "E-commerce Luxury Clothes Website", "content": "JSON Web Tokens consist of three parts separated by dots (.), which are: header, payload, and signature. The header typically consists of two parts: the type of the token, which is JWT, and the signing algorithm being used. The payload contains the claims. Claims are statements about an entity (typically, the user) and additional data. To create the signature part, you have to take the encoded header, the encoded payload, a secret, and the algorithm specified in the header, and sign that.", "label": "human"}
{"ID": "00200051", "file_name": "E-commerce Luxury Clothes Website", "content": "JWT can use for Authorization: This is the most common scenario for using JWT. Once the user is logged in, each subsequent request will include the JWT, allowing the user to access routes, services, and resources that are permitted with that token. Single Sign On is a feature that widely uses JWT nowadays, because of its small overhead and its ability to be easily used across different domains.", "label": "human"}
{"ID": "00200052", "file_name": "E-commerce Luxury Clothes Website", "content": "Information Exchange: JSON Web Tokens are a good way of securely transmitting information between parties. Because JWTs can be signed—for example, using public/private key pairs—you can be sure the senders are who they say they are.", "label": "human"}
{"ID": "00200053", "file_name": "E-commerce Luxury Clothes Website", "content": "Additionally, as the signature is calculated using the header and the payload, you can also verify that the content hasn’t been tampered with. In this scope of application,I used JWT in authorization User and Admin in the system. When the user successfully logs in using their credentials, a JSON Web Token will be returned. Whenever the user wants to access a protected route or resource, the user sends the JWT, in the Authorization header.", "label": "human"}
{"ID": "00200054", "file_name": "E-commerce Luxury Clothes Website", "content": "In addition, the Front-end side also uses some libraries such as chatJs, bootstrap, paypal-express, reactrap, swiper, v.v...4.1 Activity Diagram 4.1.1 UC01: Login Figure 4.1: Login Activity Diagram 4.1.2 UC02: Register Figure 4.2: Register Activity Diagram4.1.3 UC03: Rating Figure 4.3: Rating Activity Diagram4.1.4 UC05: Feeback Figure 4.4: Feeback Activity Diagram4.1.5 UC06: Creating Feedback Figure 4.5: Creating Feedback Activity Diagram4.1.6 UC07: Creating Comment Figure 4.6: Creating Comment Activity Diagram4.1.7 UC08: Edit/Reply Comment Figure 4.7: Edit/Reply Comment Activity Diagram4.1.8 UC09: Delete Comment Figure 4.8: Delete Comment Activity Diagram4.1.9 UC10: Creating Product Figure 4.9: Creating Product Activity Diagram4.1.10 UC11: Search Products/ UC12: Edit Product/ UC13: Delete/Delete All Product Figure 4.10: Prodcts Activity Diagram4.1.11 UC14: Add Cart Figure 4.11: Add Cart Activity Diagram4.1.12 UC15: Creating Category/ UC16: Edit Category/ UC17: Delete Category Figure 4.12: Categories Activity Diagram4.1.13 UC18: History Status Figure 4.13: History Status Activity Diagram4.1.14 UC19: PayPal/ UC20: Ship Cod Figure 4.14: Payment Activity Diagram4.1.15 UC21: Take Away Figure 4.15: Payment 2 Activity Diagram4.1.16 UC22: Creating Account Figure 4.16: Creating Account Activity Diagram4.1.17 UC23: Change Role Account Figure 4.17: Change Role Account Activity Diagram4.1.18 UC24: Edit Account Figure 4.18: Edit Account Activity Diagram4.1.19 UC25: Delete Account Figure 4.19: Delete Account Activity Diagram4.2 Sequence Diagram 4.2.1 UC01: Login4.2.2 UC02: Register 4.2.3 UC03: Rating4.2.4 UC05: Feeback 4.2.5 UC06: Creating Feedback4.2.6 UC07: Creating Comment4.2.7 UC08: Edit/Reply Comment4.2.8 UC09: Delete Comment4.2.9 UC10: Creating Product4.2.10 UC11: Search Products4.2.11 UC12: Edit Product4.2.12 UC13: Delete/Delete All Product4.2.13 UC14: Add Cart4.2.14 UC15: Creating Categoty/ UC16: Edit Categoty/ UC17: Delete Categoty4.2.15 UC18: History Status4.2.16 UC19: PayPal/ UC20: Ship Cod4.2.17 UC21: Take Away4.2.18 UC22: Creating Account4.2.19 UC23: Change Role Account4.2.20 UC24: Edit Account4.2.21 UC25: Delete Account4.3 Class Diagram 4.3.1 Overall Architectural Design4.3.2 UC01: Login 4.3.3 UC02: Register 4.3.4 UC03: Rating 4.3.5 UC05: Feeback 4.3.6 UC06: Creating Feedback 4.3.7 UC07: Creating Comment4.3.8 UC08: Edit/Reply Comment 4.3.9 UC09: Delete Comment 4.3.10 UC10: Creating Product 4.3.11 UC11: Search Products4.3.12 UC12: Edit Product 4.3.13 UC13: Delete/Delete All Product4.3.14 UC14: Add Cart 4.3.15 UC15: Creating Categoty/ UC16: Edit Categoty/ UC17: Delete Categoty 4.3.16 UC18: History Status4.3.17 UC19: PayPal/ UC20: Ship Cod 4.3.18 UC21: Take Away4.3.19 UC22: Creating Account 4.3.20 UC23: Change Role Account 4.3.21 UC24: Edit Account 4.3.22 UC25: Delete Account4.4 Database * List of database:", "label": "human"}
{"ID": "00200055", "file_name": "E-commerce Luxury Clothes Website", "content": "The first is lead functionality, which includes viewing products, viewing comments and reviews, registering for an account, and giving feedback to the admin.", "label": "human"}
{"ID": "00200056", "file_name": "E-commerce Luxury Clothes Website", "content": "The second is for the customer: add, edit, delete products to the cart, and proceed with the payment steps. You can also comment on product reviews Third is that of employees: have the same functions as customers. You can also delete comments and read feedback from customers Finally, the administrators: Can add, edit and delete information related to the product. In addition, you can manage user accounts such as: assigning new accounts, and assigning permissions to accounts, ...", "label": "human"}
{"ID": "00200057", "file_name": "E-commerce Luxury Clothes Website", "content": "There are pictures to illustrate the result of the main features of the website for users:Figure 5.1: Product Page Show user product page Figure 5.2: LoginFigure 5.3: Register Show user login and register page Figure 5.4: Feedback Page Show user contact page, user can create new feedback for adminFigure 5.5: View Feedback User login as an admin or staff that can see view feedback page Figure 5.6: History Page Show the user history page, Users can track orders hereFigure 5.7: Comment Users can comment on product reviews or read other people’s reviews about products if they are logged in and have an account if they don’t have an account, users can only read their own reviews.", "label": "human"}
{"ID": "00200058", "file_name": "E-commerce Luxury Clothes Website", "content": "Testing scenarios Function Scenario Expected Result Login•Input username and password Click the “Log in” button•If the input is correct, the home page is shown to the user.", "label": "human"}
{"ID": "00200059", "file_name": "E-commerce Luxury Clothes Website", "content": "Register•Input register information account Click the “Register” button•If the email does not exist, the home page is shown to the user.", "label": "human"}
{"ID": "00200060", "file_name": "E-commerce Luxury Clothes Website", "content": "Create feedback•Enter feedback information Click the “Submit” button•A Successful message will appear. New feedback will be in the view feedback in admin/staff interface Delete feedback •Click X item•If the user chooses Yes, the feedback will be deleted.", "label": "human"}
{"ID": "00200061", "file_name": "E-commerce Luxury Clothes Website", "content": "Comment•Enter content into field Click the “Comment” button•A Successful message will appear. New Comment will be created Edit/Reply Comment•Choose Edit/Reply feature Enter content in the field Click the “Update”/\"Reply\" button• A Successful message will appear. The system updates/creates a reply comment Delete Comment•Choose \"delete\" feature•If the email does not exist, the home page is shown to the user.", "label": "human"}
{"ID": "00200062", "file_name": "E-commerce Luxury Clothes Website", "content": "A Successful message will appear. The comment will be deletedAdd Cart•Click \"buy\" button Edit the number of the product in the cart•The product in the cart.", "label": "human"}
{"ID": "00200063", "file_name": "E-commerce Luxury Clothes Website", "content": "Payment •make the payment process•A Successful message will appear. A new order will be created on the history page Create Product•Input product information Click the “create” button•If the value is not valid, an error message is displayed.", "label": "human"}
{"ID": "00200064", "file_name": "E-commerce Luxury Clothes Website", "content": "Manage Product•Perform the process of editing, and deleting products• The information of the products is changed/ deleted Manage Category•Perform the process of adding, editing, and deleting Category•A new category is created and the information of this category is changed/deleted Manage Account•Perform the process of adding, editing, and deleting Accounts•A new account is created and the information of this account is changed/deleted Get all data calculator for dashboard•Click Dashboard button•If the data returns successfully and the data merges into the tables then all the summary tables should now be complete.", "label": "human"}
{"ID": "00200065", "file_name": "E-commerce Luxury Clothes Website", "content": "Problem description Each time a user searches for a product, he can only search by product type, product name, or unique attribute, and cannot perform multiple search filters at the same time. If the user searches for more than one filter, an error occurs or no products are displayed even though there are products that satisfy the search criteria.", "label": "human"}
{"ID": "00200066", "file_name": "E-commerce Luxury Clothes Website", "content": "Problem solving There are three methods: filtering, sorting, and paginating and I create an APIfeatures constructor that takes query and data of product as input.", "label": "human"}
{"ID": "00200067", "file_name": "E-commerce Luxury Clothes Website", "content": "2 Comment 6.2.1 Problem description When we want to edit a comment, we click on the edit button and a field will appear for us to make edits. But the problem is that when I click the edit button, all the comments show a field at the same time, not just the comment that I want to edit. Similar to the reply function, when we press the reply button, all comments will display a field. The reason this happens is that we use the map function The second problem is that comment is an attribute in the data table of products and has an array type, when we create a reply, it is impossible to determine which comment is the reply.", "label": "human"}
{"ID": "00200068", "file_name": "E-commerce Luxury Clothes Website", "content": "Problem solving We create one more child component and call that component from the comment component. In that child component, we create two variables isEdit and isReply to determine which comment is edited, and which comment is replied to.", "label": "human"}
{"ID": "00200069", "file_name": "E-commerce Luxury Clothes Website", "content": "The return data of each order that belongs to the cart is of type array, but in the cart, there are many products with different quantities. The problem here is that the returned data to be calculated is an array in an array, but only map, reduce, and filter functions can’t be processed with only one function.", "label": "human"}
{"ID": "00200070", "file_name": "E-commerce Luxury Clothes Website", "content": "When creating a monthly data chart, the data in the chart is an array containing objects with corresponding properties, we need to determine the income attribute for each month with data taken from the history table 6.3.2 Problem solving We use a filter to filter data from history to return orders for the current year, continue to use the map to filter the amount corresponding to the number of products in each cart, and then the map will get the amount of each order in that map. We use reduce to calculate the total amount. Finally, we use reduce to calculate the total amount because now the returned data is just an arrayFigure 6.9: Total income We create a function that receives the input data of the month and we proceed to use the filter function to filter which orders correspond to the first input data as above. For each income of each month, we pass the corresponding data to get the value of the income Figure 6.10: IncomeFigure 6.11: Data of chart 6.3.3 Achievement Get the correct data needed and calculate the exact parameters.7.1 Conclusion After conducting extensive research and receiving guidance from Dr.Nguyen Tuan Dung, I have successfully designed and developed a sales management system as part of my project. The system is developed and deployed on a web platform using Reactjs as a user interface and Nodejs as a server platform. It provides a wide range of functions to users, such as the ability to aggregate information about products, transactions, and customers to enhance sales performance. Meanwhile, system owners can manage employees, products, customers, and user rights, as well as track and manage orders on. Furthermore, the system Generates detailed reports on total revenue, new customers, orders, and sales trends. All these features are intended to increase revenue for managers. During the project, I learned many new technologies, including how to define a project, select system functions, test the system, and connect it to the network. In addition, I honed my analytical, problem-solving, and report-writing skills. Although the system is working and has basic user functions, it has some limitations that need improvement due to time and resource constraints.", "label": "human"}
{"ID": "00200071", "file_name": "E-commerce Luxury Clothes Website", "content": "For example, the system currently lacks a discount function. However, I plan to continue to refine the system to address these shortcomings in the future.", "label": "human"}
{"ID": "00200072", "file_name": "E-commerce Luxury Clothes Website", "content": "As part of my graduate project, I developed the basic functions of a management system. However, in order to improve the user experience and reduce the administrator’s workload, I plan to upgrade the system further. Specifically, I will focus on enhancing user engagement features such as discounts, bill payments, and the mobile app version for more accessibility. Furthermore, I see a need to improve existing functions to better serve the needs of users, especially in delivery management. To achieve this, I am going to implement a feature that allows users to track the status of their orders more easily. My ultimate goal is to create an intuitive and user-friendly system that meets the needs of all users. Lyos Shop, [On]. Available:  ,(visited on 01/15/2023)  J. Webber, “Json web tokens: Lightweight authentication and security,” 2015.", "label": "human"}
{"ID": "00210001", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Blockchain  is a decentralized information storage and transmission technology, developed in 2008 by Satoshi Nakamoto. This technology is used to confirm and store transactions and information on with high security. A blockchain is a chain of data blocks linked together using encryption and arithmetic algorithms to ensure data integrity. Each block contains information about transactions performed on the network and a hash code representing the previous block. This hash code will be used to confirm the integrity of the next block on the chain. With blockchain, data is stored on many different nodes on the network, without a single control center, so no one can tamper with the information and modify it easily. This makes blockchain a useful technology in many fields, including finance, healthcare, supply chains, and many others. Some applications of blockchain can include:", "label": "human"}
{"ID": "00210002", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Cryptocurrency: Cryptocurrencies such as Bitcoin, Ethereum, Ripple, Litecoin, and many others are created on the blockchain platform. Cryptocurrencies allow users to exchange money without going through intermediary financial institutions.", "label": "human"}
{"ID": "00210003", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Supply chain management: Blockchain is used to monitor the entire process of manufacturing, transporting, and storing products. This helps reduce paperwork and ensure transparency throughout the entire process.", "label": "human"}
{"ID": "00210004", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Asset management: Blockchain provides a reliable solution for asset management, including traditional assets such as real estate, cars, cosmetics, and jewelry.", "label": "human"}
{"ID": "00210005", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Healthcare: Blockchain can be used to manage patient medical information, ensure the security and privacy of medical information, and help increase information sharing between health agencies.", "label": "human"}
{"ID": "00210006", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Copyright management: Blockchain can be used to manage copyrights of many types of assets, including music, books, movies, and other creative products.", "label": "human"}
{"ID": "00210007", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Financial management: Blockchain can be used to manage loans, loans, and other financial transactions, ensuring integrity and transparency in the transactionprocess.", "label": "human"}
{"ID": "00210008", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Smart contract management: Blockchain provides a smart contract management solution that simplifies verifying and executing contracts while minimizing dependence on intermediaries.", "label": "human"}
{"ID": "00210009", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Therefore, it can be seen that blockchain technology has many applications and development potential in many different fields. However, this technology also has vulnerabilities that are targets for bad actors to attack. In terms of cryptocurrency, there have been many attacks that have affected the financial economy. There are some well-known attacks:", "label": "human"}
{"ID": "00210010", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "% Attack: An attack on a cryptocurrency blockchain by a group of miners who control more than 50% of the network’s mining hash rate. Owning 51% of the nodes on the network theoretically gives the controlling parties the power to alter the blockchain. The attackers would be able to prevent new transactions from gaining confirmations, allowing them to halt payments between some or all users. They would also be able to reverse transactions that were completed while they were in control. Reversing transactions could allow them to double-spend coins, one of the issues consensus mechanisms like proof-of-work were created to prevent. For example, in May 2018, Bitcoin Gold experienced a 51% attack that allowed the attacker to double-spend approximately %18 million worth of BTG. This event caused substantial damage to the coin’s reputation and market value.", "label": "human"}
{"ID": "00210011", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "DAO attack: An attack implemented in 2016 on the Ethereum system. The attacker has found a vulnerability in DAO’s smart contracts (Decentralized Autonomous Organization) and used this vulnerability to steal more than 3,6 million Ethereum units (about $50 million at that time). This incident sparked a crucial discussion in the blockchain community regarding the safety of blockchain and the role of smart contracts.", "label": "human"}
{"ID": "00210012", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Mt.Gox Attack: Mt.Gox used to be the world’s largest bitcoin exchange but eventually collapsed in 2014. The attackers found a vulnerability in their software and stole more than 850000 Bitcoins (about $450 million at that time). This attack is one of the most damaging attacks in blockchain history and has caused a lot of controversy about the safety of cryptocurrency exchanges.", "label": "human"}
{"ID": "00210013", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Parity Wallet Attack: In 2017, a cyber attack targeted Parity Wallet, a widely used Ethereum wallet. The attacker exploited a vulnerability in the wallet software and gained unauthorized access to users’ wallets, stealing over 150,000 Ethereum units, valued at approximately $30 million at the time. This incidenthas sparked renewed concerns about the security of blockchain applications and e-wallets.", "label": "human"}
{"ID": "00210014", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "According to the financial report of Reuters:  technology/crypto-ransom-attacks-rise-first-half-202 3-chainalysis-2023-07-12/ , crypto payments to ransomware attackers hit $449.1 million in the first half of 2023. The examples of attacks mentioned previously demonstrate that blockchain technology is not entirely secure and is currently facing various challenges and risks. Nonetheless, the blockchain community and developers are actively working towards improving the system’s security and confidentiality. Measures such as risk controls and security protocols are being implemented, and smart contracts are being thoroughly tested to eliminate security vulnerabilities. Additionally, the supervision and management of cryptocurrency exchanges are being enhanced to ensure user safety. Therefore, it is crucial to propose solutions to prevent security loopholes in this technology and turn blockchain into a truly safe technology for all users.", "label": "human"}
{"ID": "00210015", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Therefore, it is studied extensively by the research community as well as technologyenterprises. For example, Mythril  is a symbolic execution tool that comes pre loaded with several detection modules that check for bugs like integer overflows and reentrancy vulnerabilities. Mythril uses both dynamic and static checking methods to detect logic errors, counter overflows, and illegal interactions in smart contracts.", "label": "human"}
{"ID": "00210016", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Similarly, Oyente  is a smart contract security vulnerability detection tool on the Ethereum platform. It uses static checking to detect logic errors, counter overflows, and illegal interactions. Besides, Securify  is a tool to detect security vulnerabilities of smart contracts on the Ethereum platform. Securify uses static testing to detect logic errors, counter overflows, and illegal interactions. Moreover, it also provides solutions to fix these errors. Although there were many vulnerability detection tools aiming at detecting vulnerabilities in smart contracts, these tools require high processing time, and only support a limited number of vulnerabilities, leading to ineffective performance with new emerging vulnerabilities.", "label": "human"}
{"ID": "00210017", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "With the emergence of Machine Learning (ML) and Deep Learning (DL) techniques, many studies put a special focus on these techniques to identify the vulnerabilities.", "label": "human"}
{"ID": "00210018", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Bhargavan et al.  proposed DeepSmartCheck, a DL-based vulnerability detection mechanism to detect smart contract vulnerabilities on the Ethereum platform. Similarly, Zhuang et al.  focus on graph information to characterize the execution flowof smart contracts and then build an ML model to analyze these characteristics and identify the vulnerability. However, these approaches only focus on multi-class classification problems while a contract contains more than a vulnerability.", "label": "human"}
{"ID": "00210019", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Moreover, Duong et al.  proposed a SecBERT-based vulnerability detection mechanism to identify the vulnerabilities in smart contracts using bytecode. However, this approach suffers from a limitation related to the limited number of tokens of the pre-trained language model (SecBERT). Concretely, these models are not effective with the lengthy input sequences when the important information is not included in the considered number of tokens of language models.", "label": "human"}
{"ID": "00210020", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "In this thesis, I propose a multi-label vulnerability detection mechanism using a language model for smart contracts. The main contribution of the work is listed as follows:", "label": "human"}
{"ID": "00210021", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Unlike the existing solutions focusing on the multi-class problems which only consider a vulnerability in a smart contract, this thesis proposed a multi-label vulnerability detection mechanism that takes into account the bytecode using the pre-trained language model (SecBERT) to identify multiple vulnerabilities in smart contracts.", "label": "human"}
{"ID": "00210022", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "This thesis proposed a Multi-BERT model to deal with the limitation of a limited number of tokens of existing language models (e.g., 512, 1024, etc.), enhancing the performance with the lengthy input sequences.", "label": "human"}
{"ID": "00210023", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "To evaluate the performance of the proposed mechanism, it is evaluated with benchmarks containing recent vulnerability detection mechanisms and different multi-label classification methods (Binary relevance, Label powerset, Classifier chain, Adapted algorithm). The experimental results show that the proposed mechanism can achieve 91.54 percent accuracy while it only requires 0.0467 seconds for the processing time.", "label": "human"}
{"ID": "00210024", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "D. Vu, T. Nguyen, V. Tong and S. Souihil, \"Enhancing Multi-Label Vulnerability Detection of Smart Contract Using Language Model,\" 2023 5th Conference on Blockchain Research & Applications for Innovative Networks and Services (BRAINS), Paris, France .", "label": "human"}
{"ID": "00210025", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The rest of the project is organized with the following layout.Chapter 2 : Chapter 2 introduces the theoretical basis of the problem and the security holes discovered in smart contracts. Set out the connection between existing research and the basic knowledge needed to research the problem.", "label": "human"}
{"ID": "00210026", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Chapter 3 : Chapter 3 presents the proposed multi-label classification architecture of the study. This study helps detect one or more vulnerabilities within a given period with high accuracy. This is the basis for continuing to research data preprocessing methods and security vulnerability classification models and coming up with solutions for smart contracts in the future.", "label": "human"}
{"ID": "00210027", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Chapter 4 : Chapter 4 presents the evaluation metrics, experimental methods, and experimental results obtained. Besides, this chapter explains the results and concludes the performance of the research.", "label": "human"}
{"ID": "00210028", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Chapter 5 : Chapter 5 presents conclusions obtained from this research and suggests future works.In Chapter 2, we will prepare the basic knowledge necessary for the research.", "label": "human"}
{"ID": "00210029", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Chapter 2 will describe the blockchain definition, smart contracts, vulnerabilities in smart contracts, and artificial intelligence knowledge related to this research.", "label": "human"}
{"ID": "00210030", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Blockchain  is a ledger that records the balance information and transaction history of all accounts participating in its transaction chain. Each block in the blockchain system contains information and is called a \"block\". These blocks contain data about the creation time, along with transaction data and a timecode. They are linked to the previous block, forming a chain of information. Once data is accepted by the network, it cannot be changed or altered. Therefore, blockchain was created as a solution to prevent fraud and ensure the integrity of data in transactions.", "label": "human"}
{"ID": "00210031", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "More specifically, a blockchain is a ar chain of connected blocks secured by cryptographic proofs. A blockchain is typically built as a distributed system that functions as a decentralized ledger. This means there are multiple copies of the ledger (distributed) and no single entity has sole control (decentralized). Simply put, each user participating in the blockchain network keeps an electronic copy of the blockchain data. Blockchain data is regularly updated with all the latest transactions and synchronized with the user’s copy.", "label": "human"}
{"ID": "00210032", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "In other words, a distributed system is maintained by the collective work of many users worldwide. These users are also known as network nodes, and all of these nodes participate in the process of verifying and validating transactions according to the system’s rules. Therefore, power is decentralized. Blockchain technology can also be applied in other areas that do not necessarily involve financial activities. In the context of cryptocurrency, blockchain serves to keep a permanent record of all confirmed transactions.", "label": "human"}
{"ID": "00210033", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Smart contracts  are the core of the blockchain system, responsible for implementing logic and permissions predefined by the developer. Even so, smart contracts are difficult to operate properly. Value storage, transparency, and immutability are key attributes essential for smart contracts to function effectively. However, these properties also make many smart contracts pose security risks and are \"prey\" that many cybercriminals target. Even when targeted attacks are not carried out, many cases still involve financial resources being tied up and companies losing money due to errors and security vulnerabilities in contracts caused by intelligence.Some smart contract attacks include the DAO attack in June 2016, where the DAO was hacked and 3.6 million Ether (equivalent to 50 million USD) was stolen using the first reentrancy attack. The Ethereum Foundation later issued a significant update to roll back the hack. This led to Ethereum being divided into Ethereum Classic and Ethereum. Another attack can be mentioned as FTX injection. The attacker embedded malicious code into the FTX network system and caused damage of up to 600 million USD, spreading malicious code to users using the FTX application.", "label": "human"}
{"ID": "00210034", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Many security experts have participated and discovered many smart contract security vulnerabilities. Vulnerabilities are classified into many groups, specifically as follows.", "label": "human"}
{"ID": "00210035", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "These programs are called smart contracts, they are programmed by the developer with specifically defined functions and conventions to work for transactions performed on the blockchain network. Blockchain technology is applied in many other application platforms such as finance, health, supply services, public services, . . . However, smart contracts are only used on certain platforms such as Ethereum - the first platform to support smart contract, EOS, Lisk, Bitcoin, Hyperledger Fabric, . . . The programming language used to develop smart contracts is Solidity. This is a styled language with a high level of security, good interaction, and an object-oriented structure. Smart contracts can store and manage a lot of virtual currency (which can be equivalent to millions of USD), so many attackers try to influence the logic of smart contracts to sabotage or appropriate the assets contained in that smart contract. In essence, smart contracts are being deployed on distributed networks with open access, which, in theory, makes smart contracts vulnerable to malicious actors. However, the consensus algorithm available on the blockchain network has partly handled that problem unlike traditional models where centralized application development can easily find and patch bugs, smart contracts once deployed cannot be changed or updated, even by the developers themselves. Therefore, testing before deploying on the blockchain network is necessary to avoid potential risks.", "label": "human"}
{"ID": "00210036", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The following is the basic architecture of the Ethereum network and the environment in which smart contracts can be executed.Figure 2.2: Basic architecture of the Ethereum network and the environment in which smart contracts can be executed Application Layer : Users will execute smart contracts linked to an Ethereum account address on the EVM. Ethereum supports 2 types of accounts: independent accounts (EOA - Externally Owned Accounts) and smart contract address accounts. EOA is used to store user assets in Wei units, each Wei has a value 10−18Ether and is controlled by users. The other is the smart contract address account, which is essentially an executable piece of code controlled by the EVM. Smart contracts are a component of creating DApp applications. A DApp usually has a user interface as the front end and a smart contract as the back end. The smart contract is executed on EVM - a Turing Complete virtual machine, using a stack architecture. However, the difference between EVM and a typical Turing Complete virtual machine is that EVM needs gas to perform computational steps, and that is a limitation. Therefore, the total amount of computation that can be performed is limited by the amount of gas supplied. The application layer has many security holes leading to many attacks at this layer (one of which is listed in Figure 2.1) Data Layer : This layer includes the data structure of the blockchain. A transaction performed on Ethereum is an interaction between an EOA account to another EOA account or smart contract. A transaction includes the following information:", "label": "human"}
{"ID": "00210037", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Each time a transaction is sent, this value will increase. The nonce is created to prevent replay attacks in Ethereum.", "label": "human"}
{"ID": "00210038", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–gasPrice: value provided to perform a transaction on the Ethereum network.The higher the GasPrice, the higher the priority for decrypting the transaction.", "label": "human"}
{"ID": "00210039", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–data: Transaction information. Data includes 2 parts: Function Signature and Function Arguments. Function Signature uses the first 4 bytes in the SHA3 encoding of the Function Name to make the Function Signature.", "label": "human"}
{"ID": "00210040", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Consensus Layer : This layer ensures a consistent state of the blockchain. At the time of data recording, Ethereum will take about 12 - 14 seconds to create a block, which means that many miners can create a valid block at the same time, resulting in Stale blocks (a stale block is a valid block, however, this block must not be on the longest chain of the blockchain). Ethereum uses many consensus algorithms to choose the branch with the highest cumulative difficulty. Previously, consensus algorithms using PoW took a lot of energy and time, so Ethereum is planning to replace PoW with PoS.", "label": "human"}
{"ID": "00210041", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Network Layer : Manages state between nodes in the Ethereum network so that a node can always receive blockchain updates from some other active node. Ethereum is a P2P (Peer-to-peer) network, which helps every node on the network have the same backup data across the entire network.", "label": "human"}
{"ID": "00210042", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Ethereum Blockchain Environment : Execution environment of the blockchain ecosystem. This environment includes a user interface for users to interact with Ethereum, a database that stores block data, an encryption mechanism that ensures the security of transactions, and a network infrastructure to support communication. communication between blocks on the blockchain network.", "label": "human"}
{"ID": "00210043", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "I differentiate the Ethereum architecture and the environment because attacks often come from the environment and can be better addressed here rather than in the blockchain.", "label": "human"}
{"ID": "00210044", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Common security vulnerabilities of smart contracts Similar to other software, smart contracts may have security holes and \"bugs\" during the software development process. The Smart Contract Weakness Classification (SWC) has collected information on many types of security vulnerabilities. Those vulnerabilities can be classified as follows:", "label": "human"}
{"ID": "00210045", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "External Calls: Any public function of a smart contract can be accessed from any other contract. Attackers can take advantage of these public functions toattack vulnerabilities in smart contracts.", "label": "human"}
{"ID": "00210046", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Programming Errors: Some programming errors found in smart contracts are similar to those in other normal programs, such as failure to validate input, cast errors, failure to handle exceptions, number overflow, . . .", "label": "human"}
{"ID": "00210047", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "However, each block has a usage cost limit. An attacker could exploit this limitation to perform a Denial of Service (DoS) attack on vulnerable smart contracts.", "label": "human"}
{"ID": "00210048", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Influence by Miners: Miners are entities that actually participate in making a transaction on the blockchain. They can decide which transactions are executed, and the order in which transactions are executed, and can also influence the EVM’s execution environment (e.g. timestamp).", "label": "human"}
{"ID": "00210049", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "From there, a developer can define whether a function is secret or public. The default setting for functions is public, programmers can ignore this setting. If a variable or function is made secret, other contracts cannot read or change it.", "label": "human"}
{"ID": "00210050", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "However, even if it is set as secret, an attacker can still parse the blockchain data because the variables are stored in plain text.", "label": "human"}
{"ID": "00210051", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "From those classifications, we can go deeper into the security vulnerabilities in smart contracts. Depending on the level of danger and ability to cope, these vulnerabilities are classified into different vulnerability classes. This project will focus on the following types of vulnerabilities listed:", "label": "human"}
{"ID": "00210052", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Reentrancy : It occurs when a callee contract calls back to a function in the caller contract before the caller contract finishes, creating cyclic calls. This vulnerability can allow an attacker to bypass validity checks until the caller contract is out of gas or depleted of Ether. The root cause of this vulnerability is a control-flow decision in the contract that relies on state variables that should be updated by the contract itself before calling another contract. Moreover, there is no gas limit when transferring control to another contract, which aggravates this issue. The vulnerability can be mitigated by updating state variables before calling another contract, implementing a mutex lock on the contract state to restrict state changes to the lock owner, or using the transfer method instead of sending to limit the gas forwarded to the callee contract.", "label": "human"}
{"ID": "00210053", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Delegate call Injection : a security issue that arises when a contract uses delegate calls in an insecure manner, allowing an attacker to exploit the contract’sbehavior and potentially manipulate its state or execute malicious code. This vulnerability occurs when a contract blindly trusts and delegates control to another contract without properly validating or sanitizing the input. If the called contract contains malicious code or unintended logic, it can manipulate the state of the called contract and potentially cause financial loss or other security breaches. To mitigate this vulnerability, developers should carefully review and audit the code, validate inputs, and implement proper access control and security checks to prevent unauthorized or malicious delegate calls.", "label": "human"}
{"ID": "00210054", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Frozen Ether : It occurs when Ether becomes permanently locked or inaccessible within a smart contract, typically due to programming errors or inadequate checks.This vulnerability occurs when users deposit money into a contract but cannot withdraw or use the assets in that contract, causing their assets to be \"frozen\" in that contract.", "label": "human"}
{"ID": "00210055", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Timestamp Dependence : This vulnerability occurs when developers use block.timestamp as a condition for transaction execution or as a random value, which can lead to the contract being manipulated by a malicious miner. The vulnerability caused by Ethereum only requires that the timestamp be greater than the timestamp of the original block and within 900 seconds of the current clock.", "label": "human"}
{"ID": "00210056", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Outdated Compiler Version : This vulnerability occurs when the contract uses an outdated compiler and can be easily attacked, resulting in the use of these contracts being affected. This vulnerability can be avoided by using a new compiler at contract development time.", "label": "human"}
{"ID": "00210057", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Upgradable Contract : The idea of upgrading the contract was introduced to minimize the immutability problem of smart contracts because after implementation this graph is normalized to highlight important nodes and passed to a temporal message propagation (TMP) network for vulnerability detection .on the Ethereum network, it will not be possible to update or patch bugs. There are two ways to upgrade a contract: (i) separate the contract into a proxy contract and contract logic, however, this method is unorthodox, (ii) create a contract registry to store updated contracts. Although effective, this method creates a new vulnerability:", "label": "human"}
{"ID": "00210058", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "the developer can update a malicious contract that affects transactions using this contract (also known as Insecure Contract Updating) Leaking Ether to Arbitrary Address : This vulnerability occurs when the assets in the contract can be withdrawn by anyone, regardless of whether they are the owner or investor in the contract. This happens because the identity of the person requesting to execute the contract is not checked, resulting in anattacker being able to send Ether to an arbitrary address. This vulnerability could have been prevented by providing sufficient identity authentication for the deposit function.", "label": "human"}
{"ID": "00210059", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Authentication Through tx.origin :tx.origin is a Solidity global variable that stores the initial value of the first EOA to perform a transaction. This vulnerability occurs when a contract is used tx.origin to authorize, can lead to a phishing attack. This vulnerability can be fixed by using msg.sender to authenticate instead of tx.origin because msg.sender returns the value of the transaction requestor’s address.", "label": "human"}
{"ID": "00210060", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Unprotected Suicide : A contract can be canceled by the contract owner or a trusted third party using self-destruction. Once a contract activates this method, all bytecode and data contained in this contract will be deleted from the EVM.", "label": "human"}
{"ID": "00210061", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Unchecked Call Return Value : This vulnerability occurs when the return value of a low-level command is not checked, execution continues even if the function call fails.", "label": "human"}
{"ID": "00210062", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Artificial Intelligence Figure 2.3: Artificial intelligence Using computers to replace humans in learning the vulnerability characteristics contained in smart contracts is a good and economical method. Therefore, there have been many studies conducted using machine learning instead of traditional error code analysis, and these studies have achieved certain achievements. Before going into the details of the research, I will explain the definition of this scientific field.In computer science, artificial intelligence (AI) is a field of research and development of algorithms and computer systems capable of understanding and learning like humans. Artificial intelligence enables machines to learn from experience, adjust to new inputs, and perform human-like tasks. This is a field of computer science that emphasizes creating intelligent machines that act and react like humans. Specific applications of artificial intelligence include natural language processing, speech and vision recognition, systems management, . . . This technology has been researched and developed for a long time, but artificial intelligence has developed recently because of new advanced technologies used in RAM, helping to increase the quality and learning time of intelligence. Artificial intelligence increased many times over.", "label": "human"}
{"ID": "00210063", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "There are many different artificial intelligence methods including machine learning, natural language processing (NLP), computer vision, robotics, and others. Machine learning is an important method in the field of artificial intelligence, in which algorithms are designed to analyze data and find patterns and rules. Natural language processing is a method that allows computers to understand and produce natural human language. Computer vision is a method that allows computers to understand and process images and videos. Robotics is a method that allows computers to control robots and automation systems. This research paper uses machine learning methods to classify security vulnerabilities present in smart contracts.", "label": "human"}
{"ID": "00210064", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Machine Learning Machine Learning  is a field in computer science that deals with the development of algorithms and computer models that learn and improve performance through data processing.", "label": "human"}
{"ID": "00210065", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "In machine learning, algorithms are designed to analyze data, find patterns and regularities, and then use those regularities to predict and classify new data.", "label": "human"}
{"ID": "00210066", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Machine learning models are built on training data, i.e. a set of data with known outcomes, and from there learn and improve performance.", "label": "human"}
{"ID": "00210067", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The applications of machine learning are very diverse, from applications in the fields of health, finance, and e-commerce, to applications in industry, agriculture, transportation, and many other fields.", "label": "human"}
{"ID": "00210068", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "There are many different methods used in machine learning, including Supervised Learning, Unsupervised Learning, and Reinforcement Learning. Supervised Learning is a supervised learning method in which the model is trained on a data set with known results. Unsupervised Learning is an unsupervised learning method in which the model must find structures and patterns in the data on its own. Reinforcement Learning is a reward-based learning method in which a model is trained throughinteractions with an environment and is provided with rewards based on its actions.", "label": "human"}
{"ID": "00210069", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Gaussian Naive Bayes : Gaussian Naive Bayes (GaussianNB for short), is a probabilistic machine learning algorithm commonly used for classification tasks. It is based on the assumption of feature independence and follows the principles of Bayes’ theorem. In GaussianNB, each feature is assumed to have a Gaussian (normal) distribution within each class. During training, the algorithm estimates the mean and variance of each feature for each class. To make predictions, it calculates the posterior probability of each class given the input features using Bayes’ theorem and selects the class with the highest probability. GaussianNB is particularly effective when dealing with continuous or real-valued features, and it is known for its simplicity, computational efficiency, and ability to handle high-dimensional datasets. However, the assumption of feature independence can limit its performance in cases where the features are correlated.", "label": "human"}
{"ID": "00210070", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Logistic Regression : A statistical learning algorithm used for binary classification problems. It models the relationship between a set of input features and a binary target variable by estimating the probabilities of the target belonging to each class. Logistic Regression applies the logistic function, also known as the sigmoid function, to transform a ar combination of input features into a probability value between 0 and 1. During training, the algorithm optimizes the model parameters using maximum likelihood estimation or gradient-based optimization techniques. To make predictions, it classifies instances based on a threshold applied to the predicted probabilities. Logistic Regression is widely used due to its interpretability, simplicity, and efficiency. However, it assumes a ar relationship between features and the log odds of the target variable, which may limit its performance with complex nonar relationships.", "label": "human"}
{"ID": "00210071", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "ML-kNN : A lazy learning algorithm designed for multi-label classification tasks. It combines the principles of the k-nearest neighbors (KNN) algorithmwith a probabilistic approach to handle multiple labels simultaneously. ML KNN assigns labels to new instances by considering their nearest neighbors in the feature space. It measures the similarity between instances using a distance metric and selects the k nearest neighbors. The algorithm then estimates the probability distribution of each label based on the labels of the k neighbors and assigns the most probable labels to the new instance. ML-KNN allows fordifferent distance metrics and incorporates a smoothing parameter to handle sparsity in the label space. It is known for its simplicity, flexibility, and ability to handle large-scale multi-label datasets. However, ML-KNN assumes label independence and does not explicitly capture label correlations, which may affect its performance in datasets with strong label dependencies.", "label": "human"}
{"ID": "00210072", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Deep Learning Deep learning is a subfield within machine learning, built on deep Neural Network models. Deep learning uses deep Neural Networks to learn and automatically find complex features and patterns in data.", "label": "human"}
{"ID": "00210073", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "In deep learning, deep Neural Networks are designed with many hidden layers, allowing models to learn complex features and patterns of data. Deep learning models are capable of solving tasks such as natural language processing, image and video classification, speech recognition, translation, and many more.", "label": "human"}
{"ID": "00210074", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "There are many different Neural Network architectures in deep learning, including Convolutional Neural Network (CNN) for image processing, Recurrent Neural Network (RNN) for sequence data processing, and generative models such as Generative Adversarial Network (GAN) for generating new data.", "label": "human"}
{"ID": "00210075", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "However, deep learning requires large computational resources and huge amounts of training data to achieve good results. Therefore, deploying deep learning models requires investment in both hardware and software.", "label": "human"}
{"ID": "00210076", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "In deep learning, classification is one of the most popular downstream tasks. It categorizes data based on its features using deep neural networks. Deep learning involves training neural networks to recognize patterns in data and classify them into specific categories or labels. Training involves using labeled data to optimize the network’s parameters. Once trained, the model can classify new, unseen data.", "label": "human"}
{"ID": "00210077", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Binary classification : This type of classification involves categorizing data into two distinct classes or categories. For example, classifying emails as spam or non-spam, or predicting whether a customer will churn or not.", "label": "human"}
{"ID": "00210078", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Multi-class classification : In multiclass classification, data is classified into more than two classes. Each data sample is assigned one class label from a set of predefined classes. For example, classify images into different categories like cats, dogs, and birds.", "label": "human"}
{"ID": "00210079", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Multi-label classification : Multilabel classification deals with situations where a data sample can belong to multiple classes simultaneously. Each class labelis treated as a separate binary classification problem. For instance, classifying news articles into multiple topics like politics, sports, and entertainment. In this research, we aim to create a multi-label model that can identify multiple labels with just one scan and acceptable time.", "label": "human"}
{"ID": "00210080", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "According to the related work , there are four kinds of mechanisms for solving multi-label problems: binary relevance, label powerset, classifier chain, and adapted algorithms.", "label": "human"}
{"ID": "00210081", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Binary Relevance (BR) : This technique addresses the multi-label classification problem by treating each label as an independent binary classification task. It involves training separate binary classifiers for each label and predicting the presence or absence of each label individually. This approach provides simplicity and flexibility, as it allows the use of any binary classifier and facilitates the integration of label-specific information. However, binary relevance disregards label dependencies and correlations, which can limit its performance in scenarios where such relationships are significant. Additionally, it does not explicitly handle imbalanced label distributions. Therefore, while binary relevance offers a straightforward and scalable solution, carefulconsideration is necessary to determine its suitability for a given multi label classification problem, taking into account the presence of label dependencies and the characteristics of the dataset.", "label": "human"}
{"ID": "00210082", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Label Powerset (LP) : In this approach, the power set of all possible label combinations is created, resulting in a set of distinct class labels. Each instance is then assigned to the corresponding class label based on the presence or absence of the labels in the combination. By considering all possible label combinations, Label Powerset can handle complex relationships between labels, including cases where multiple labels can co-occur. However, as the number of labels increases, the number of possible combinations grows exponentially, leading to a potential increase in the number of classes and training complexity. Additionally, this technique requires a sufficient number of training samples for each unique label combination to ensure accurate classification. Thus, while Label Powerset offers a way to address label dependencies, its practicality depends on the specific characteristics of the dataset and the computational resources available.", "label": "human"}
{"ID": "00210083", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Classifier Chain (CC) : This approach considers label dependencies by creating a chain of binary classifiers, where each classifier is trained to predict the presence or absence of a label based on the input features aswell as the previously predicted labels in the chain. The chain is constructed in a specific order, typically determined by the label dependencies or a random permutation. During prediction, the classifiers are applied sequentially, with the output of each classifier being used as an additional input for the subsequent classifier. By incorporating the information from previously predicted labels, the Classifier Chain can capture label dependencies and improve the accuracy of multi-label classification. However, this approach is sensitive to label order, and errors made by early classifiers can propagate and affect subsequent predictions.", "label": "human"}
{"ID": "00210084", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Adapted Algorithm (AA) : Adapted algorithm refers to a modified or customized version of an existing algorithm to better suit specific requirements or address particular challenges in a given problem domain. This adaptation typically involves making changes to the original algorithm’s design, parameters, or implementation to improve its performance, efficiency, or functionality.", "label": "human"}
{"ID": "00210085", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The modifications can range from minor adjustments to major overhauls, depending on the specific needs of the problem at hand. By tailoring the algorithm to specific contexts, an adapted algorithm can offer enhanced capabilities, robustness, or scalability, thereby providing more effective solutions to complex problems in various fields such as machine learning, optimization, and data analysis. These mechanisms take into account the bytecode or extract the features from the bytecode using several common feature extraction methods such as Bag of Word (BOW), Term Frequency Inverse Document Frequency (TF-IDF), or Word to Vector (Word2Vec).", "label": "human"}
{"ID": "00210086", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "In several cases, the feature extraction methods are not effective, leading to inaccurate results. Therefore, in this paper, we take into account the SecBert pre-train model to extract the implicit features of the bytecode to improve the performance.", "label": "human"}
{"ID": "00210087", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Below is some basic knowledge related to classic neural networks in Natural Language Processing:Figure 2.4: Classic network architecture of RNN Recurrent neural network : Deep learning can be applied to many problems using a variety of algorithms. Among them, RNN (Fig.2.4) is an algorithm that is very suitable for data types with temporal relationships or in natural language processing (NLP - Natural Language Processing) problems, because part of its output in This time point is returned as input at the next time point.", "label": "human"}
{"ID": "00210088", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Because of this special way of working, it can remember past information and use the information to predict results. One of the most popular models of RNN is LSTM (Long Short-Term Memory). LSTM shows its superiority in that it can remember more steps than the traditional RNN model.", "label": "human"}
{"ID": "00210089", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Output Gate: Regulates how much of the memory cell state should be exposed as the output. The LSTM network processes sequential data by passing it through a series of LSTM cells. At each time step, the LSTM cell takes the current input and the previous hidden state as inputs and produces an output and a new hidden state. The hidden state serves as the memory of the LSTM, capturing relevant information from previous time steps.", "label": "human"}
{"ID": "00210090", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Transformers : The Transformer architecture uses an encoder-decoder structure that does not rely on recurrence and convolutions to generate an output. The encoder maps an input sequence to a series of continuous representations. The decoder receives the encoder’s output and the decoder’s output at a previous time step and generates an output sequence. The core components of a transformer architecture are as follows:", "label": "human"}
{"ID": "00210091", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Encoder: The encoder takes an input sequence (such as a sentence ordocument) and processes it by applying self-attention mechanisms. Theencoder is comprised of numerous layers, each with a multi-head self attention mechanism and feed-forward neural networks. The self-attention mechanism enables the model to effectively capture dependencies by focusing on different parts of the input sequence.", "label": "human"}
{"ID": "00210092", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Decoder: The decoder takes the encoded representation of the input sequence and generates an output sequence, typically used for tasks like machinetranslation or text generation. The decoder has multiple layers with self attention and cross-attention mechanisms, allowing it to attend to relevant parts of encoded input while generating output.", "label": "human"}
{"ID": "00210093", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Self-Attention: Self-attention is a mechanism that calculates the importance level of each word in the input sequence based on its relevance to the current context. This allows the model to handle long-range dependencies more effectively by assigning different weights to different words.", "label": "human"}
{"ID": "00210094", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Multi-Head Attention: Transformers use multiple self-attention heads in parallel to capture different aspects of the input sequence. Each attention head learns different relationships between words, allowing the model to capture various patterns and dependencies.", "label": "human"}
{"ID": "00210095", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Positional Encoding: Positional encoding is used in transformers to provide positional information, helping the model understand the relative positions of words in the input sequence, as they do not have an inherent notion of word order.", "label": "human"}
{"ID": "00210096", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Loss function : The loss function, also referred to as the error function, is a crucial component that quantifies the difference between the predicted outputs of a machine learning algorithm and the actual target values. The resulting value, the loss, reflects the accuracy of the model’s predictions. Different types of activation functions are used depending on the type of problem the Neural Network is solving. For example, in the multi-label classification problem,the commonly used loss function is Binary Cross-Entropy loss. In the multi class classification problem, the loss function commonly used is Categorical Cross-Entropy loss. In regression problems, the loss function commonly used is Mean Squared Error (MSE) loss. In this project, I use Binary Cross-Entropy for calculating loss.", "label": "human"}
{"ID": "00210097", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Activation function Activation function is a function used in a Neural Network to calculate the output of each neuron in the network. The activation function is usually applied after calculating the sum of the input weights of each neuron in the previous layer.The activation function helps the Neural Network learn and represent complex features of data by generating non-ar outputs. Without an activation function, the Neural Network would just be a simple ar operation and could not learn complex features of the data.", "label": "human"}
{"ID": "00210098", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Sigmoid function : Sigmoid function is a non-ar function that has an S-shaped shape and the output value ranges from 0 to 1. This function is often used in old Neural Networks to calculate output probability.", "label": "human"}
{"ID": "00210099", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– ReLU (Rectified Linear Unit) : ReLU is a simple non-ar function with an output equal to 0 if the input is negative and equal to the input value if the input is positive. ReLU is widely used in modern Neural Networks because of its simplicity and fast calculation speed.", "label": "human"}
{"ID": "00210100", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Tanh function : Tanh function is a non-ar function that is S-shaped and the output value ranges from -1 to 1. This function is similar to the Sigmoid function but has a negative output.", "label": "human"}
{"ID": "00210101", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Softmax function : Softmax function is a non-ar function used in Neural Networks to calculate multilayer output probabilities. This function ensures that the sum of the output probabilities of the classes is equal to 1.", "label": "human"}
{"ID": "00210102", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Optimizer : The Optimizer is an algorithm used during Neural Network training to optimize model parameters, including weights and biases, from trainingdata. The purpose of the optimizer is to find the values of the parameters that minimize the value of the model’s loss function.", "label": "human"}
{"ID": "00210103", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Different optimization algorithms have different ways of working, however, they all use the derivative of the loss function concerning the parameters to update the network parameters. Popular optimization algorithms in Neural Networks include:", "label": "human"}
{"ID": "00210104", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Gradient Descent : Gradient descent is an optimization algorithm used in machine learning to minimize the error or cost function of a model.", "label": "human"}
{"ID": "00210105", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "It iteratively adjusts the model’s parameters by calculating the gradient of the cost function and updating the parameters in the direction of the steepest descent. The process continues until a minimum is reached. Gradient descent is crucial for training machine learning models.", "label": "human"}
{"ID": "00210106", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Stochastic Gradient Descent (SGD) : SGD (Stochastic Gradient Descent) is a variant of the gradient descent optimization algorithm commonly used in training machine learning models, particularly in large-scale settings.", "label": "human"}
{"ID": "00210107", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Unlike traditional gradient descent, which computes the gradient using the entire training dataset, SGD updates the model’s parameters based on a randomly selected subset of training samples, known as a mini-batch.", "label": "human"}
{"ID": "00210108", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Adam : Adam is an optimization algorithm commonly used for training neural networks. It combines momentum and adaptive learning rates to achieve faster convergence. Adam adjusts the learning rate for each parameter based on estimates of the first and second moments of the gradients. This makes it robust to noisy gradients and suitable for a variety of tasks.", "label": "human"}
{"ID": "00210109", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– Adagrad : Adagrad (Adaptive Gradient) is an optimization algorithm used for training machine learning models. It adapts the learning rate of each parameter based on the historical gradients observed during training. Adagrad assigns a different learning rate to each parameter, with parameters that have larger gradients receiving a smaller learning rate and vice versa.", "label": "human"}
{"ID": "00210110", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "– RMSProp : RMSprop (Root Mean Square Propagation) is an optimization algorithm commonly used for training neural networks. It is an extension of the Adagrad algorithm that addresses its issue of diminishing learning rates. RMSprop calculates an exponentially weighted moving average ofthe squared gradients and uses it to adjust the learning rate for each parameter.", "label": "human"}
{"ID": "00210111", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Việc chọn bộ tối ưu phù hợp là một yếu tố quan trọng trong quá trình huấn luyện mạng Neural Network và có thể ảnh hưởng đến hiệu suất của mô hình.", "label": "human"}
{"ID": "00210112", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Backpropagation : Backpropagation is a crucial algorithm for training Neural Networks. It calculates the derivative of the loss function with respect to the weights in the network and updates them to enhance the network’s performance.", "label": "human"}
{"ID": "00210113", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Backpropagation works by traversing the entire Neural Network, calculating the derivative of the loss function with respect to the weights in the network, and using those derivatives to adjust the weights of the network. This algorithm uses the Chain Rule technique in calculating derivatives, allowing to calculation of the derivative of the loss function according to the weights in the Neural Network.", "label": "human"}
{"ID": "00210114", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "With backpropagation, the weights in the Neural Network are updated through the use of an optimization algorithm such as Gradient Descent. Gradient Descent is used to optimize the loss function by finding weight values that minimize the value of the loss function.", "label": "human"}
{"ID": "00210115", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Backpropagation is an important method for training Neural Networks because it allows updating the network’s weights based on the derivative of the loss function, which enhances the network’s performance. However, calculating the derivative of the loss function for each weight in a Neural Network can be very complex and computationally expensive, especially for deep Neural Networks.", "label": "human"}
{"ID": "00210116", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Deep learning is a very powerful field in machine learning, however, it also faces some difficulties and challenges when used. Here are some of the main difficulties when using deep learning:", "label": "human"}
{"ID": "00210117", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Difficulty in defining neural network architecture: deep learning has many different neural network architectures, such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Gated Recurrent Units (GRUs).", "label": "human"}
{"ID": "00210118", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Difficulty in training and fine-tuning the model: Deep learning requires a lot of computational resources and time to train the model. Fine-tuning modelparameters to achieve the best performance is also a time-consuming task.", "label": "human"}
{"ID": "00210119", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Difficulty in preparing data: Deep learning requires a large amount of data to effectively train the model. Collecting, preprocessing, and preparing data for use in deep learning is a time-consuming and laborious task.", "label": "human"}
{"ID": "00210120", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Because of these issues, model selection is extremely important for deep learning models. Building a model that is too simple will cause underfitting, and conversely, it can also cause overfitting.", "label": "human"}
{"ID": "00210121", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Underfitting Underfitting occurs when a model is too simplistic or cannot capture the underlying patterns in the training data. In such cases, the model fails to learn the relevant relationships, resulting in poor performance on both the training and test data.", "label": "human"}
{"ID": "00210122", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Using a model that is too simple or has too few parameters to represent the underlying complexity of the data.", "label": "human"}
{"ID": "00210123", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "If a model is underfitted, it will perform poorly on both training data and test data. This indicates that the model does not consider some crucial information in the training data and cannot recognize intricate patterns in the data. To solve underfitting, we can attempt various solutions such as utilizing a more complex model, increasing the quantity of training data, and optimizing model parameters effectively.", "label": "human"}
{"ID": "00210124", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Overfitting Overfitting occurs when a model learns the training data too well, to the point that it starts to memorize the noise or random fluctuations in the training datarather than capturing the underlying patterns or relationships. As a result, the model becomes too complex and specific to the training data, leading to poor performance on new, unseen data. Signs of overfitting include very high accuracy or low error on the training data, but poor performance on the test data.", "label": "human"}
{"ID": "00210125", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Using a model that is too complex and has too many parameters, results in the model being able to learn noisy patterns in the training data.", "label": "human"}
{"ID": "00210126", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "When a model is overfitted, it performs exceptionally well on training data, but its performance on testing data is poor. This occurs when the model learns too much detail and noise from the training data, resulting in its inability to apply the learned knowledge to new data effectively. To counter overfitting, we can implement various solutions, such as using a simpler model, increasing the amount of training data, and using regularization techniques to prevent the model from learning too much detail and noise from the training data.", "label": "human"}
{"ID": "00210127", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Reducing the complexity of the model, such as by decreasing the number of layers in a neural network or reducing the number of features in a regression model.", "label": "human"}
{"ID": "00210128", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Regularization techniques, such as L1 or L2 regularization, add a penalty term to the loss function to discourage the model from becoming too complex.", "label": "human"}
{"ID": "00210129", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Using dropout, a technique where random neurons or features are \"dropped out\" during training to prevent over-reliance on specific patterns.", "label": "human"}
{"ID": "00210130", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Vulnerability Detection Tools Many researchers and developers have come up with tools to detect smart contract security vulnerabilities. The detail of these tools is described as follows:•Oyente  - a smart contract vulnerability detection tool based on symbolic execution is proposed by Luu L. et al. Oyente is a symbolic execution engine that works directly with EVM bytecode without access to high-level representation and can identify seven different types of smart contract vulnerabilities.", "label": "human"}
{"ID": "00210131", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "SmartCheck  - an extensible static analysis tool proposed by Sergei Tikhomirov et al. SmartCheck checks Solidity source code against XPath patterns after converting them to an intermediate XML-based representation.", "label": "human"}
{"ID": "00210132", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Mythril  - Ethereum’s official smart contract security vulnerability detection tool. Mythril can identify a wide range of security vulnerabilities and uses symbolic execution to investigate all potentially dangerous paths.", "label": "human"}
{"ID": "00210133", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Slither  - a static analysis tool used to find smart contract security vulnerabilities by taking the Solidity Syntax Tree (AST) generated by the Solidity compiler as input and generating a flow graph Control Flow Graph (CFL) to detect security vulnerabilities.", "label": "human"}
{"ID": "00210134", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "ContractFuzzer  - a proposed testing tool for smart contract vulnerabilities that can generate audit inputs based on smart contract API specifications, inspect logs, and report security errors.", "label": "human"}
{"ID": "00210135", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Vulnerability Detection Mechanisms Although there were many vulnerability detection tools for smart contracts, these tools cannot achieve good accuracy while they require high processing time.", "label": "human"}
{"ID": "00210136", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Analysis based on information flow: Slither  uses error analysis to detect security vulnerabilities in Solidity source code. It can detect most vulnerabilities related to user input and critical data flows but the testing time is very long. Slither can detect security flaws in seconds or minutes, depending on the size and complexity of the contract.", "label": "human"}
{"ID": "00210137", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Analysis based on symbolic execution: Oyente  detects security vulnerabilitiesin the source code or bytecode of smart contracts using symbolic execution.", "label": "human"}
{"ID": "00210138", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Symbolic execution represents a program’s behavior as a constructed formula and uses symbolic inputs to decide whether a certain path can be reached.", "label": "human"}
{"ID": "00210139", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Therefore, its performance depends on the number of paths discovered and the complexity of the program. Oyente constructs the control flow graph of the smart contract and uses it to generate input for symbolic execution. Likewise, Securify  is a solution that retrieves contract semantic information by performing symbolic analysis of the dependency graph, then examines predefined error patterns to detect errors. show security holes.", "label": "human"}
{"ID": "00210140", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Analysis based on logic: Vandal  is a logic-based static program analysis framework. It converts low-level bytecode into semantic logical relationships and describes security issues by logical rules. The data logger implements specifications for the input and output relationships of vulnerabilities. In addition, SmartCheck  is also a vulnerability detection solution based on logic analysis. This solution converts Solidity source code into XML and verifies it against detection patterns defined in the XPath language.", "label": "human"}
{"ID": "00210141", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Integrated approach: Mythril  synthesizes a variety of vulnerability detection methods, including symbolic execution-based analysis, error analysis, and Satisfiability Modulo Theories (SMT). SMT deals with converting contracts into SMT constraints to detect program errors.", "label": "human"}
{"ID": "00210142", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Dynamic approaches: Dynamic detection techniques execute the program and observe it into behaviors to determine the existence of vulnerabilities in smart contracts.", "label": "human"}
{"ID": "00210143", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "It provides APIs for developers who can analyze smart contracts. Bernhard Mueller and colleagues  proposed a testing method that detects vulnerabilities by executing programs with invalid, unexpected, or random inputs. ContractFuzzer  performs fuzzy input generation based on smart contract ABIs. Tests are defined to monitor and analyze contract execution behavior to detect vulnerabilities.", "label": "human"}
{"ID": "00210144", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Validation-based: ContractLarva  is a runtime verification tool for smart contracts, where violations of defined properties can lead to different processing strategies, e.g. system. These properties can include control events or unusual data flows.", "label": "human"}
{"ID": "00210145", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Machine learning-based approaches: Several studies have performed smartcontract analysis using machine learning techniques. I will discuss their working mechanisms and limitations below –ContractWard: ContractWard  performs bytecode smart contract security vulnerability analysis by extracting bigram features from the simplified opcode and training an individual binary classification model for each type of vulnerability no. The research targets six vulnerabilities and experiments with the classifiers Random Forests, K-Nearest Neighbors, SVM, AdaBoost, and XGBoost. Compared to this research project, ContractWard has the disadvantage of requiring the source code of the smart contract. ContractWard’s approach is to analyze smart contracts using opcodes. To be able to do that, it reverse encodes the source code and converts it to an opcode.", "label": "human"}
{"ID": "00210146", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–Color-based: Color-based  develops a color representation for translating the bytecode of solidity into RGB color code and transforming them to a fixed-sized encoded image. After that, the encoded image is fed to a convolutional neural network for automatic feature extraction and learning (without extracting features from the solidity source code manually.", "label": "human"}
{"ID": "00210147", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–LSTM-based: Safer Smart Contract  proposed a sequential learning method for machine learning to detect vulnerabilities contained in smart contract opcodes. Essentially, this proposal uses a one-hot encoding method and an embedding matrix to represent smart contract opcodes. The obtained vectors will be used as input to train the LSTM model to determine whether the smart contract is safe or not (Binary Classification). However, the LSTM model proposed above has limited effectiveness because:", "label": "human"}
{"ID": "00210148", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The reported F1-score of 86% is relatively low *The LSTM model only gives a binary classification of security vulnerabilities without giving the exact type of smart contract vulnerability –CNN-based: Convert the smart contract bytecode to a fixed-size RGB image and train it with a convolution neural network. Similar to this project, the security vulnerability classification using CNN is a multi-label classification.", "label": "human"}
{"ID": "00210149", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "However, this method has a relatively low accuracy because converting bytecode into image format will lose the sequential nature of the information, thereby causing information loss during training.", "label": "human"}
{"ID": "00210150", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–GNN-based: Graph NN-based  proposed a method using graphs toperform vulnerability detection. This method builds a graph based on the smart contract’s source code with nodes representing a function or variable, and edges being the temporary flow of execution between that function or variable. This graph is normalized to highlight important nodes and is used as input to the Temporal Message Propagation (TMP) model for training.", "label": "human"}
{"ID": "00210151", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–ESCORT: The ESCORT  architecture is divided into two parts: feature extraction and classification. In the feature extraction part, bytecode data will be passed through a GRU/LSTM layer to create the correspondingfeature vector. Afterward, the second component of ESCORT’s multi output DNN architecture is the ensembling of multiple vulnerability branches.", "label": "human"}
{"ID": "00210152", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Each branch is a stack of layers that are trained to learn the patterns/hidden representation of the corresponding vulnerability class.In Chapter 3, I will present the proposal architecture for multi-label vulnerability detection. Chapter 3 will describe an overview of the system and the details of each component: Data preprocessing, Word embedding, and Classification.", "label": "human"}
{"ID": "00210153", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "To collect data for the research, first, we get lists of contract addresses from the website: dune and verify the source code with tintinweb . After that, we use theSafechain tool to get the description of the vulnerability type, the location where the vulnerability appears, and its details. This step helps label the data.", "label": "human"}
{"ID": "00210154", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Initial data is provided by CyStack Vietnam Joint Stock Company  in the form of source code of smart contracts. The company has supported finding and classifying the security vulnerabilities of these contracts. However, because the accuracy when using source code is not high (eg Graph-based Inspired ), I compiled the data and used bytecode for the research model.", "label": "human"}
{"ID": "00210155", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Data preprocesssing As the provided dataset was in Solidity source code, I needed to convert it into bytecode for the model to use and conduct training. For this purpose, I used solc-js , which is a Solidity compiler written in JavaScript language. However, there were many different versions of the source code (ranging from 0.4.11 to 0.8.7), so I used the Monorepo architecture and TypeScript language to compile the provided source code.", "label": "human"}
{"ID": "00210156", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Next, to be able to train the multi-label model, the data set needs to be labeled corresponding to the vulnerabilities appearing in each sample. When compiling, the smart contract’s security vulnerabilities are separated into separate errors, so I used the Pandas library to compress these vulnerabilities into separate CSV files corresponding to each. However, smart contracts can exist multiple errors at thesame time, so I need to filter duplicate contracts and re-label the data. Pandas, in addition to supporting reading and writing to separate vulnerability files, also helped me eliminate these duplicate cases. In addition, some cases may not generate bytecode data due to errors when compiling with solc-js. I have also checked and removed these samples to avoid disturbing the data set. Then I also removed the contracts whose bytecode was null after doing the compilation. The reason there is an empty contract is because the contract source code can inherit a library or an abstract, but does not exist in the source code, so the compiler cannot execute it and returns empty code. Finally, I aggregate all the data into a CSV file, which includes columns containing information about the bytecode data, labeling the corresponding vulnerabilities that appear in the corresponding bytecode cell, with 1 representing the occurrence of that vulnerability and 0 representing the remaining case.", "label": "human"}
{"ID": "00210157", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Data dimensionality reduction: feature extraction helps reduce the number of attributes in the data, thereby reducing data dimensionality and helping the training model operate more effectively.", "label": "human"}
{"ID": "00210158", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Improved accuracy: Feature extraction can help separate important features and eliminate unimportant features, thereby improving the accuracy of machine learning models for detection. security vulnerabilities at a higher rate.", "label": "human"}
{"ID": "00210159", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Increase calculation speed: This feature extraction helps reduce data size, thereby reducing calculation time and increasing data processing speed Once we have cleaned the data, we need to transform it to be used as input for the model. This transformation process is called feature extraction, or word embedding, and it involves identifying and extracting the most relevant features from the data.", "label": "human"}
{"ID": "00210160", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "By selecting and extracting the most relevant features, we can improve the accuracy and effectiveness of the model, ensuring that it can make accurate predictions on new data. For this process, we have chosen SecBERT, a BERT model that has beenFigure 3.4: Bert architecture  specifically trained on cybersecurity text and has learned cybersecurity knowledge.", "label": "human"}
{"ID": "00210161", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The model has its own vocabulary called ”secvocab” which is optimized to align with the training corpus. You can access the code and pre-trained models for SecBERT at  .", "label": "human"}
{"ID": "00210162", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "SecBERT pre-trained model As noted above, I use a pre-trained SecBERT model for extracting features from bytecode. Since SecBERT is based on BERT architecture which relies on a Transformer(the attention mechanism that learns contextual relationships between words in a text). A basic Transformer consists of an encoder to read the text input and a decoder to produce a prediction for the task. As BERT’s goal is to generate a language representation model, it only needs the encoder part. The encoder for BERT receives a series of tokens, which are subsequently transformed into vectors and processed in the neural network. The Transformer essentially stacks a layer that maps sequences to sequences, so the output is also a vector sequence with a 1:1 relationship between input and output at the same index.", "label": "human"}
{"ID": "00210163", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "When training language models, there is a challenge of defining a prediction goal. Many models predict the next word in a sequence (e.g. “The child came home from . . . ”), a directional approach that inherently limits context learning.", "label": "human"}
{"ID": "00210164", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Masked LM (MLM): Before inputting word sequences into BERT, 15% of the words are replaced with a [MASK] token. BERT then predicts the original values of the masked words by considering the context provided by the remaining non-masked words in the sequence. Technically, this prediction process involves:", "label": "human"}
{"ID": "00210165", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The BERT loss function takes into consideration only the prediction of the masked values and ignores the prediction of the non-masked words.", "label": "human"}
{"ID": "00210166", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Next Sentence Prediction (NSP): In BERT training, the model learns to predict if a second sentence follows a given first sentence. Half of the inputs have consecutive sentences, while the other half includes a random sentence. To help the model differentiate between the sentences, the input undergoes preprocessing before being fed into the model.", "label": "human"}
{"ID": "00210167", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–A [CLS] token is inserted at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.", "label": "human"}
{"ID": "00210168", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "–A sentence embedding indicating Sentence A or Sentence B is added to each token. Sentence embeddings are similar in concept to token embeddings with a vocabulary of 2.", "label": "human"}
{"ID": "00210169", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "When training the BERT model, Masked LM and Next Sentence Prediction are trained together, with the goal of minimizing the combined loss function of the two strategies.", "label": "human"}
{"ID": "00210170", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Multi-BERT Using pre-train models based on the Transformers architecture will get us into trouble with input size because most of them were trained with 512 input tokens.", "label": "human"}
{"ID": "00210171", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Therefore, I suggest extending my project by using multiple SecBERT models as multiple feature-extracting branches, the architecture is designed as follows:", "label": "human"}
{"ID": "00210172", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The extended model builds upon the same classification layers as the previous design but with a crucial enhancement regarding data input. In the original design, only a single SecBERT block was employed, which limited the model to considering only the first 512 tokens regardless of the data’s length. To address this limitation, the extended model incorporates a mechanism to handle larger input data by dividing it into segments, each containing 512 tokens. These segments are then processed individually by each SecBERT block to extract relevant features. Following the extraction process, the segmented features are concatenated back together to reconstruct the original \"sentence.\" This concatenation step ensures that the model can capture the context and relationships across the entire input text. Theoretically, this extendedFigure 3.5: Multi-BERT architecturemodel is expected to exhibit improved effectiveness due to the inclusion of more data, enabling a more comprehensive understanding of the input. By considering larger segments and preserving the context, the model can capture more explicit features. However, it is important to note that this extension comes with increased processing and training costs. Therefore, although the scaling model offers the potential to improve performance, it is necessary to consider the trade-off between efficiency and computational cost when deciding whether to apply this method in practice.", "label": "human"}
{"ID": "00210173", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "With the multi-label classification problem, in the classification step, I use a neural network model based on the Multi-layer Perceptron network to learn the complex features. MLPs are known as feedforward networks because the information flows in one direction, from the input layer through the hidden layers to the output layer. Each layer is composed of interconnected nodes that apply activation functions to their inputs. The input layer receives the input data, while the hidden layers and their activation functions perform computations and extract relevant features. The output layer produces the final prediction or output of the network. During training, the MLP adjusts the weights and biases associated with each node to minimize the difference between its predictions and the true outputs.", "label": "human"}
{"ID": "00210174", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The input layer has a size corresponding to the dimensionality of the output features extracted by the previous stage. Due to the use of BERT architecture (only accepting 512 tokens), the classification model input will be equivalent to 768.", "label": "human"}
{"ID": "00210175", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Then the feature will be passed through another MLP layer to reduce dimension, this layer will receive an input of 768 and an output is 256. Finally, the multi-label classification layer with the output will correspond to the number of labels included in the training, here we will use the output of 4 because the dataset has 4 labels. So we will have the following model:", "label": "human"}
{"ID": "00210176", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Type Value Layer MLP Input 768 Hidden layer MLP: [768, 768], MLP: [768, 256] Optimizer AdamW Loss Binary Cross-Entropy Learning rate 0.0001 Epochs 10 Batch size 8 Table 3.1: Multi-label classification modelTheoretically, the model output will predict how many vulnerabilities exist in the input data. This work helps reduce classification time but increases computational cost. Configuring the output of this model will help to perform multi-label detection as proposed by the model.4.1 Experimental setup 4.1.1 Dataset Our raw dataset which is collected from Ethereum, after being compiled, contains ten types of vulnerabilities in Table 4.1:", "label": "human"}
{"ID": "00210177", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "However, in the dataset, we encountered certain vulnerabilities that had an insufficient number of samples, making it difficult for the model to extract meaningful patterns or insights. Consequently, these vulnerabilities were deemed unsuitable for training purposes and were subsequently excluded from the dataset. As a result, we focused our analysis on four prevalent vulnerabilities that exhibited a sufficient number of samples: timestamp dependence, outdated solidity version, frozen Ether, and delegate call injection. To ensure accuracy and consistency, the contracts in the dataset were meticulously labeled using the Safechain tool. Their distribution in the dataset is in Fig 4.1.", "label": "human"}
{"ID": "00210178", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Evaluation metrics Multilabel classification refers to the case where a data point can be assigned to more than one class, and there are many classes available. Unlike in multi-class classification, in multilabel classification, the classes aren’t mutually exclusive.", "label": "human"}
{"ID": "00210179", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The proposed mechanism and benchmarks are evaluated using three evaluation metrics: exact match ratio (EMR), hamming loss, and accuracy .", "label": "human"}
{"ID": "00210180", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Accuracy: Accuracy for each instance is calculated by dividing the number of correctly predicted labels by the total number of labels (both predicted and actual) for that instance. This proportion represents how accurately the Vulnerability Total Authentication through tx.origin 22 Delegatecall Injection 35,240 Frozen Ether 97,463 Leaking Ether to arbitrary address 1,002 Timestamp dependence 62,627 Outdated Solidity version 126,976 Ugradeable contract 79 Unchecked call return value 8 Uninitialized storage pointers 144 Unprotected Suicide 15 Table 4.1: Vulnerability raw datasetFigure 4.1: Data distribution model predicted the labels for that specific instance. To determine the overall accuracy, the accuracies of all instances are averaged together, providing a measure of the model’s performance across the entire dataset.", "label": "human"}
{"ID": "00210181", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Accuracy =1 nnX Exact match ratio: One trivial way around would just be to ignore partially correct (consider them incorrect) and extend the accuracy used in single label case for multi-label prediction.", "label": "human"}
{"ID": "00210182", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "EMR =1 nnX i=1I(yi=byi) (4.2) where I is the indicator function. Clearly, a disadvantage of this measure is that it does not distinguish between completely incorrect and partially correct which might be considered harsh.", "label": "human"}
{"ID": "00210183", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Hamming loss: It reports how many times on average, the relevance of an example to a class label is incorrectly predicted. Therefore, hamming loss takes into account the prediction error (an incorrect label is predicted) and missing error (a relevant label not predicted), normalized over total number ofclasses and total number of examples.", "label": "human"}
{"ID": "00210184", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "HammingLoss =1 nLnX i=1LX j=1I(yi̸=byi) (4.3) where I is the indicator function. Ideally, we would expect the hamming loss to be 0, which would imply no error; practically the smaller the value of the hamming loss, the better the performance of the learning algorithm.", "label": "human"}
{"ID": "00210185", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Benchmarks The performance of the proposed method is assessed using different multilabel classification techniques, including binary relevance, label powerset, classifier chain, and adapted algorithm. Additionally, various feature extraction methods are employed to enhance the classification process, they are described as follows:", "label": "human"}
{"ID": "00210186", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Bag of Words Bag of Words (BoW) is the traditional vector representation most commonly used in word embedding methods. Each word or n-gram is associated with a vector index and marked as 0 or 1 depending on its occurrence in the given document.", "label": "human"}
{"ID": "00210187", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Each text is represented as a vector (array) of integers, with a size equal to the number of words in the dictionary. The value at each position in the vector corresponds to the number of times that word appears in the text.", "label": "human"}
{"ID": "00210188", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The BoW representation is commonly used in document classification methods, where the frequency of occurrence of words aids in the training of classifiers.", "label": "human"}
{"ID": "00210189", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "In BoW, the occurrence of words is evaluated independently of the frequency or context in which they occur. However, the limitation of BoW is that it does not encode any information related to the semantics of words.", "label": "human"}
{"ID": "00210190", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Term Frequency-Inverse Document Frequency TF-IDF stands for Term Frequency-Inverse Document Frequency, this is a popular method in natural language processing (NLP) to represent texts as numeric vectors.", "label": "human"}
{"ID": "00210191", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "This technique is used to estimate the importance of a word in a document or a set of documents. This method uses two main components: the frequency of a word in the text (term frequency - TF) and the importance of that word in the data set(inverse document frequency - IDF).", "label": "human"}
{"ID": "00210192", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Term Frequency (TF): Represents the frequency of occurrence of words in the text. The value of TF is calculated by counting the number of occurrences of the word in the text and dividing by the total number of words in the text.", "label": "human"}
{"ID": "00210193", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Inverse Document Frequency (IDF): Represents the importance of that word in the data set. The value of IDF is calculated by taking the base e logarithm of the total number of documents in the data set divided by the number of documents containing that word.", "label": "human"}
{"ID": "00210194", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "tf(t, d)is the frequency of occurrence of word tin a document d,f(t, d)is the number of occurrences of the word with the highest number of occurrences in text d.", "label": "human"}
{"ID": "00210195", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "D that contain word t. The logarithmic base in this formula does not change the idf value of the word but only narrows the range of that word’s value.", "label": "human"}
{"ID": "00210196", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "With this method, each text will be represented as a numeric vector, with each component of the vector corresponding to the TF-IDF value of the corresponding word in the dictionary. However, this method also has some limitations, such as not preserving information about sentence structure, thereby leading to the problem of loss of characteristic information contained in bytecode.", "label": "human"}
{"ID": "00210197", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Word2Vec Word to vector (Word2Vec) is a word representation method in natural language processing (NLP), in which words are represented as a numeric vector. This methodwas developed by Thomas Mikolov and colleagues at Google in 2013 and has been widely used in NLP applications.", "label": "human"}
{"ID": "00210198", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The Word2Vec method is based on the hypothesis that words with similar meanings often appear together in different contexts. For example, the words \"cat\" and \"dog\" often appear in contexts related to pet animals, while the words \"cat\" and \"sleep\" often appear in contexts related to the actions of pets. animal. Based on this hypothesis, the Word2Vec method uses a neural network model to learn word representations based on the context in which the word appears in texts.", "label": "human"}
{"ID": "00210199", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Word to Vector (Word2Vec) is a predictive embedding model. There are two main Word2Vec architectures used for the distributed representation of words.", "label": "human"}
{"ID": "00210200", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Continuous Bag of Words (CBOW): the order of context words does not affect the prediction. The CBOW model tries to predict the current word based on the words around it in a sentence or block of text.", "label": "human"}
{"ID": "00210201", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Continuous Skip-gram: model uses the current word to predict the surrounding range of context words. Each context vector is considered and compared independently with CBoW. The Skip-gram model tries to predict words around the current word based on that current word.", "label": "human"}
{"ID": "00210202", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "These vectors can be used to calculate the distance between words and find words with similar meanings in the vector space.", "label": "human"}
{"ID": "00210203", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "CBoW is faster while skip-gram is slower but performs better for infrequent words. In general, Word2Vec uses a machine learning model that increases the generalizability of the model while reducing computational and memory costs.", "label": "human"}
{"ID": "00210204", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Comparison with Machine learning methods According to the results presented in Table 4.2, the Binary Relevance approach appears to perform poorly. This is because it is a simplistic method for multi-label classification that overlooks interdependence and correlation among labels, leading to less accurate predictions. When labels are mutually dependent, the independent classification assumption may result in unsatisfactory outcomes. While both the Label Powerset and Classifier Chain show better results than Binary Relevance, neither can achieve an EMR of 0.8. The AA approach, on the other hand, produces the highest score, which can be attributed to customized modifications made to the original algorithm to meet specific research requirements.", "label": "human"}
{"ID": "00210205", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Based on the findings presented in Table 4.2, it appears that Word2Vec is theMulti-label Methods Extraction Classifier EMR Hamming Accuracy Binary Relevance BoW GaussianNB 0.4674 0.1611 0.7172 Binary Relevance TF-IDF GaussianNB 0.6585 0.109 0.7833 Binary Relevance W2V GaussianNB 0.1714 0.3117 0.4421 Label Powerset BoW Logistic Regression 0.7819 0.0595 0.8881 Label Powerset TF-IDF Logistic Regression 0.7841 0.0566 0.8957 Label Powerset W2V Logistic Regression 0.7891 0.0578 0.8987 Classifier Chain BoW Logistic Regression 0.7919 0.0525 0.9031 Classifier Chain TF-IDF Logistic Regression 0.7913 0.0537 0.9013 Classifier Chain W2V Logistic Regression 0.7792 0.0561 0.8996 Adapted Algorithm BoW ML-kNN 0.7919 0.0525 0.9031 Adapted Algorithm TF-IDF ML-kNN 0.7913 0.0537 0.9013 Adapted Algorithm W2V ML-kNN 0.7792 0.0561 0.8996 Adapted Algorithm SecBERT MLP 0.8184 0.0459 0.9154 Table 4.2: Comparison with Machine learning mechanisms least efficient among traditional methods for extracting information from bytecode.", "label": "human"}
{"ID": "00210206", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "However, TF-IDF and BOW still exhibit some degree of effectiveness. To further enhance this process, we conducted experiments with SecBERT’s pre-trained model by selectively freezing certain encoder blocks. Our tests revealed that freezing 5 blocks yielded good results, with an EMR rate of 0.8184 and an accuracy score of 0.9154. Furthermore, our predictions had the lowest hamming loss, indicating their proximity to the actual values.", "label": "human"}
{"ID": "00210207", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Comparison with Deep learning methods a, Comparison with single SecBERT With the method of using the Multi-BERT model, because of equipment limitations and according to the dataset’s length analysis in Chapter 3, I trained the model with the number of blocks equal to 2 and obtained the results as shown in Table 4.3. We can see that the results here have improved further, but the execution time for detection has also increased. This can be explained that because I fed more data, the model learned more clearly the complexity of the features, and this also led to increased computational costs. However, a drawback of the Multi-BERT model is the potential loss of token relationships at the boundaries of concatenated SecBERT blocks. This limitation may impact the model’s ability to effectively capture long-range dependencies and context across the entire input sequence.", "label": "human"}
{"ID": "00210208", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Despite this limitation, the utilization of more data remains beneficial in improving the model’s comprehension of complex feature representations, although it requires additional computational resources. Future research could explore strategies to mitigate the loss of token relationships while leveraging the advantages of larger datasets for even more comprehensive learning.Architecture Extraction Classifier EMR Hamming Accuracy execution (s) SecBERT SecBERT MLP 0.8184 0.0459 0.9154 0.025336 Multi-BERT (2 blocks)SecBERT MLP 0.8199 0.454 0.9199 0.046993 Table 4.3: Comparison with single SecBERT block Architecture Extraction Classifier EMR Hamming Accuracy ESCORT TFIDF GRU 0.8179 0.0459 0.9151 Color-inspired CNN MLP 0.7932 0.0539 0.8996 Multi-BERT (2 blocks)DistillBERT MLP 0.8067 0.0499 0.9097 Multi-BERT (2 blocks)SecBERT MLP 0.8199 0.0454 0.9199 Table 4.4: Comparison with existing Deep learning mechanisms b, Comparison with existing Deep learning mechanisms The results presented in Table 4.4 provide compelling evidence for the superior performance of the proposed Multi-BERT approach compared to existing deep learning mechanisms. The higher values of EMR, hamming loss, and accuracy achieved by Multi-BERT across various evaluation criteria clearly demonstrate its effectiveness in accurately identifying and classifying vulnerabilities. Notably, the execution time of just 0.0469 seconds per sample showcases the efficiency and practicality of the research model.", "label": "human"}
{"ID": "00210209", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "The exceptional performance of Multi-BERT, along with its efficient processing time, makes it a promising solution for real-time vulnerability analysis. By utilizing Multi-BERT, organizations can improve their ability to promptly detect and mitigate risks, minimizing the potential impact of security breaches. The combination of accuracy, efficiency, and real-time capability makes Multi-BERT a valuable tool in the field of vulnerability analysis, contributing to the overall security posture of systems and networks.5.1 Summary The proposed method outperforms the benchmark in detecting multiple vulnerabilities that can occur in smart contracts by using the state-of-the-art technique in Deep learning. Combining with deep learning in the Blockchain area shows us that lots of opportunities in the future to solve different problems else in this aspect. In addition, using deep learning will help us to handle large datasets, capture intricate relationships and dependencies within the code, and adapt to new uprising threats.", "label": "human"}
{"ID": "00210210", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "This topic will be the foundation for the development of automated tools that help in vulnerability detection and code analysis. In the future, we plan to use language models to learn features and relationships in the source code. Further, the topic will continue to be developed in the direction of \"explainable AI\" to explain the causes of vulnerabilities and propose solutions to prevent them. As blockchain technology continues to evolve, an ongoing effort to detect vulnerabilities will remain crucial in protecting smart contracts and fostering trust in decentralized applications. M. D. Pierro, “What is the blockchain?” Computing in Science Engineering , pages 92–95, 5 2017.", "label": "human"}
{"ID": "00210211", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "D.-H. C. Loi Luu, “Making smart contracts smarter,” Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security , pages 254–269, 2016.", "label": "human"}
{"ID": "00210212", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "D. D.-C. A. G. F. B. M. V. Petar Tsankov Andrei Dan, “Securify: Practical security analysis of smart contracts,” Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security , 67––82, 2018.", "label": "human"}
{"ID": "00210213", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "C. Z. J. Y. Y. Y. H. X. Zhifeng Wang Wanxuan Wu, “Graph neural networks enhanced smart contract vulnerability detection of educational blockchain,” 2020.", "label": "human"}
{"ID": "00210214", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "V. T. D. Vu T. Nguyen andS. Souihil, “Enhancing multi-label vulnerability detection of smart contract using language model,” Enhancing Multi-Label Vulnerability Detection of Smart Contract Using Language Model , 2023.", "label": "human"}
{"ID": "00210215", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "R. P. R. P. M. P. P. S. R. R. P. U. Muthuraman, “A novel approach to identify dynamic deficiency in cell using gaussian nb classifier,” 7th International Conference on Communication and Electronics Systems (ICCES) , 2022.", "label": "human"}
{"ID": "00210216", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "P. H. N. M. J. M. Nareshpalsingh, “Multi-label classification methods: A comparative study,” International Research Journal of Engineering and Technology. , 2017. N. P. J. U. L. J. A. N. G. K. I. P. Ashish Vaswani Noam Shazeer, “Attention is all you need,” 31st Conference on Neural Information Processing Systems (NIPS 2017) , 2017.", "label": "human"}
{"ID": "00210217", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "R. S. Christof Ferreira Torres Julian Sch ¨utte, “Osiris: Hunting for integer bugs in ethereum smart contracts.,” Proceedings of the 34th Annual Computer Security Applications Conference ,pages 664–676, 2018.", "label": "human"}
{"ID": "00210218", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "Static analysis of ethereum smart contracts,” Proceedings of the 1st International Workshop on Emerging Trends in Software Engineering for Blockchain ,pages 9–16, 2018.", "label": "human"}
{"ID": "00210219", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "A. G. Josselin Feist Gustavo Grieco, “Slither: A static analysis framework for smart contracts,” 2019 IEEE/ACM 2nd International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB) ,pages 8–15, 2019.", "label": "human"}
{"ID": "00210220", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "W. C. Bo Jiang Ye Liu, “Contractfuzzer: Fuzzing smart contracts for vulnerability detection,” Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ,pages 259–269, 2018.", "label": "human"}
{"ID": "00210221", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "M. K. E. L. F. G. V. G. R. H. B. S. Lexi Brent Anton Jurisevic, “Vandal: A scalable security analysis framework for smart contracts,” 2018.", "label": "human"}
{"ID": "00210222", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "W. W. J. S. G. X. Y. L. H. W. C. Su, “Contractward: Automated vulnerability detection models for ethereum smart contracts,” 2020 International Conference on Smart Electronics and Communication , 2020.", "label": "human"}
{"ID": "00210223", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "S. S. G. Y.-S. O. Wesley Joon-Wie Tann Xing Jie Han, “Towards safer smart contracts: A sequence learning approach to detecting security threats,” 2018.", "label": "human"}
{"ID": "00210224", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "H. F. C. S. A. D. A. R. S. F. K. Oliver Lutz Huili Chen, “Escort: Ethereum smart contracts vulnerability detection using deep neural network and transfer learning,” 2021. “Công ty cổ phần cystack việt nam,” url: .", "label": "human"}
{"ID": "00210225", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "M.-W. C. K. L. K. T. Jacob Devlin, “Bert: Pre-training of deep bidirectional transformers for language understanding,” Association for Computational Linguistics (ACL) , 2019.", "label": "human"}
{"ID": "00210226", "file_name": "Enhancing Multi-label Vulnerability Detection of Smart Contract using Language Model", "content": "J. R. L. A. F. Park, “A blended metric for multi-label optimisation and evaluation,” Springer Nature Switzerland AG 2019 , 2019.", "label": "human"}
{"ID": "00220001", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The game industry has experienced significant growth and evolution in recentyears to become one of the most exciting industries in tech. This industry has be come increasingly diverse in terms of platforms, target users, and especially gamegenres. There are a wide variety of games available, ranging from traditional gen res like action, adventure, and sports, to more modern genres like RPG, roguelike, FPS, visual novels.", "label": "human"}
{"ID": "00220002", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "A significant contribution to the success of the game industry, alongside large and professional studios, is indie games. Indie game, short for independent game, refers to a game genre developed by a small team or an individual developer, is typically characterized by the creative freedom, innovative game play mechanics, and often have a lower budget compared to larger AAA titles. Indie games offer a diverse and often refreshing alternative to mainstream gaming experiences. They provide opportunities for developers to showcase their creativity, experiment with new ideas, and connect with players who appreciate the unique and personal touch, also contruct a collaborative and supportive communication where indie players can come together to share knowledge, resources, and experiences.", "label": "human"}
{"ID": "00220003", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Along with the advantages, indie games also face challenges. Based on the in formation provided in the article \"Infographic: Indie Game Revenues on Steam\" , more than 50 percent of the total 21,000 games released on Steam, which is considered the best game distribution platform at present, have achieved revenues of $4,000 or less. Furthermore, even two-thirds of these games have failed to reach revenues of $10,000 in the whole life. Despite being released, these games have not generated enough revenue to cover the development costs and time invested. All of these games are considered failures.", "label": "human"}
{"ID": "00220004", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Typically, indie games are developed by indie developers who work alone orindie studios consisting of a small team. They are responsible for handling all aspects of game development, including design, coding, game balancing, market re search, and more. In addition to having to handle everything themselves during the game development process, indie developers also face many other challenges such as limited budget, intense competition due to a large number of indie developers, constraints on high-quality resources, and pressure regarding game development times and a lack of experience in coding.The project’s main objective is to build packages that can assist indie developers during the game development process. The selected packages for development are GUI Manager, Pool Manager, and the GOAP library.", "label": "human"}
{"ID": "00220005", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GUI Manager is crucial because every game requires graphics and a userinterface that significantly impacts player reactions. A well-designed graphical in terface can easily engage players and keep them interested in the game. Hence, having a system to manage UI elements in the game is essential.", "label": "human"}
{"ID": "00220006", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The Pool Manager is chosen because indie developers often overlook performance optimization, leading to issues like game crashes or overheating due to con tinuous garbage collector work. This negatively impacts the player’s experience, causing discomfort and reducing play session time. By providing a Pool Manager, developers can efficiently manage memory and object pooling, leading to better performance.", "label": "human"}
{"ID": "00220007", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Regarding the GOAP library, it aligns with the emerging trend of incorporat ing AI into games across various genres. However, such libraries are often scarce and come at a cost, which might not be feasible for indie developers with smaller budgets. Hence, the goal is to develop a GOAP package suitable for indie games, providing an affordable and accessible solution for integrating AI behaviors into their games.", "label": "human"}
{"ID": "00220008", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Finally, based on the developed tools, the project aims to create a complete platformer game. This game will not only validate the effectiveness of the three tools but also deliver a compelling experience for the audience. This final product will demonstrate how these packages can be utilized to create a well-designed and engaging game, catering to the players’ expectations.", "label": "human"}
{"ID": "00220009", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The project’s objective is to build useful packages like GUI Manager, Pool Man ager, and the GOAP library to support indie game developers during their gamedevelopment process. These packages will help address crucial issues in game de velopment, such as managing user interfaces, optimizing game performance, andintegrating artificial intelligence into games. The ultimate goal is to use these developed tools to create a complete platformer game, not only to validate the effec tiveness of the packages but also to deliver an engaging and enjoyable experience for players. The project aims to provide indie developers with additional options and solutions suitable for smaller production budgets, while enhancing the quality and appeal of indie games.1.3 Scope and target audiencesThe project aims at the main target group, which is \"indie developers,\" refer ring to individual developers or small teams who create games independently, not belonging to large game development studios or publishing companies. The GUIManager, Pool Manager, and Goal-Oriented Action Planning (AI library) are de signed to support these indie developers in the process of developing their games.", "label": "human"}
{"ID": "00220010", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "For the games we have used the tools to create, we aim to young individuals aged 16 to 30 who enjoy gaming experiences, exploration, and have a taste for action and boss battles. Especially for games built with a dark visual direction, while the mechanics remain basic, they still require players to explore and utilize the abilities of each character. Therefore, the target audience tends to focus on male players.", "label": "human"}
{"ID": "00220011", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Based on the tasks outd in section 0.2, the project will focus on build ing three fundamental libraries: GUI Manager, Pool Manager, and GOAP librarywithin the Unity environment. The goal is to create tools that support indie develop ers during game development and completion. Alongside this, the project aims to develop a complete pixel platformer game that utilizes these packages effectively.", "label": "human"}
{"ID": "00220012", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GUI Manager library is built with a prefab that serves as an object managingthe entire GUI system of the game. All UI components in the game will be dynam ically loaded through the Resources folder to ensure performance, reusability, and consistency of the UI system.", "label": "human"}
{"ID": "00220013", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The Pool Manager library is built with an object that manages all the pools used in the game, including objects that follow Unity’s lifecycle and memory pools that store temporary variables generated during the game’s code execution. Pools are created to optimize the game’s performance and minimize the impact of garbage collection (GC).", "label": "human"}
{"ID": "00220014", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GOAP library is built with three main components: Data, Logic, and UserInterface. The Data part contains all the fundamental algorithm-related information, including Actions, Goals, Agents, and Sensors. The Logic component re volves around the ability to build graphs and implement pathfinding algorithms.", "label": "human"}
{"ID": "00220015", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Lastly, the User Interface part provides the capability to monitor and trace the agents’ paths.Specifically, the GOAP library requires the following features:", "label": "human"}
{"ID": "00220016", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Data Component Support the declaration of actions that Agents can perform in the game.•Define goals that Agents need to achieve.", "label": "human"}
{"ID": "00220017", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The game is built in the form of a platformer with pixel art style, designed with pre-designed levels that allow players to explore mysterious lands and collect treasures to upgrade their power. The game will utilize the three libraries mentioned above to develop the game.", "label": "human"}
{"ID": "00220018", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Chapter 2 will present a detailed survey of the current state and requirements of indie developers regarding the three libraries. It will compare and evaluate the advantages and disadvantages of each library to provide guidance for the project.", "label": "human"}
{"ID": "00220019", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Chapter 3 will present the theoretical foundation for building the three li braries, along with the technologies used in the game development process.", "label": "human"}
{"ID": "00220020", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Chapter 4 will explain the design architecture of each library and its functions used in the game. This chapter will provide a detailed breakdown of each library’s structure and functionalities, including how they are integrated into the game.", "label": "human"}
{"ID": "00220021", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Chapter 5 will discuss the results obtained from the development of the three libraries and the game, cover the test cases conducted to evaluate the libraries’ performance and functionality 5. Chapter 6 will provide summary of the entire graduation thesis and a concise overview of the project’s objectives, methodologies, results, and achievements2.1 Market SurveyAs mentioned before, one of the issues leading to the failure of indie develop ers is the time pressure and lack of experience in building mechanics. Therefore, before officially developing a game, developers often choose to create prototypes.", "label": "human"}
{"ID": "00220022", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Prototyping is a virtual step in game development, enabling developers to test out ideas and gameplay mechanics quickly and iterate on them until they find the rightformula. In recent times, the utilization of pre-existing assets for prototyping pur poses has gained a significant success. Using pre-made tools or package brings forth numerous advantages that helps developers to construct superior prototypes in a shorter span of time.", "label": "human"}
{"ID": "00220023", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Specifically for the Gui Manager package, the current packages mostly only support a portion of the UI architecture, such as providing support for creating popups or adding animations to buttons. However, there is a lack of packages that have developed a complete UI management system, which can handle the overall UI structure comprehensively.", "label": "human"}
{"ID": "00220024", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Regarding the Pool Manager package, the most famous one is the Pool Managerlibrary developed by Path-o-logical Games. This library provides basic function alities of a pool, including organizing and managing pools of active objects in the scene, reusing objects to limit the impact on the garbage collector, and offering a user interface for monitoring the current pools. However, the library still has somelimitations: The library does not include memory optimization for temporary vari ables generated during game development and the cost of implementing the library is relatively high, at $24.85, which might be significant for smaller studios with limited budgets.", "label": "human"}
{"ID": "00220025", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "As for GOAP library, below table 2.1, the author has created a comparison table highlighting the strengths and weaknesses of the available GOAP packages on the Unity Asset Store.", "label": "human"}
{"ID": "00220026", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Library Strong Points Weak points ReGOAP The code is easy to read, understand, and use. It includes advanced functionalities such as multi-threading, support for pausing, and re-planning.There is no UI or debugger support, and there are no good illustrative examples. It lacks many features like flexible action or goal attribute changes. The accompanying examples do not work. Development has been suspended.", "label": "human"}
{"ID": "00220027", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "S GOAP It is the best library among the GOAP libraries available online. It provides full UI or debugger support. It offers a wide range of both basic and advanced features, making it a comprehensive GOAP library.The documentation is still rudimentary and difficult to read. It is challenging to apply because the code is not easy to read and apply in practice.GOAP of Peter Klooster It has the capability of multi-threaded computation.It uses external libraries, leading to additional installation requirements. It has basic functionalities but lacks comprehensive documentation and sample examples.", "label": "human"}
{"ID": "00220028", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Finally, the project also surveyed various game genres commonly developed by indie developers to select a suitable genre. The project has chosen a game genrethat can easily incorporate the developed packages and provide an engaging expe rience for players. The article  also conducted a survey on the number of games developed by indies and professional game studios across the top 10 most popular game genres (shown in figure 2.2), including:", "label": "human"}
{"ID": "00220029", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Platformers: Platformers are well-liked indie games where players control characters navigating obstacle-filled levels. Popular indie platformers include Celeste, Hollow Knight, and Ori and the Blind Forest.", "label": "human"}
{"ID": "00220030", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Adventure: Adventure games involve puzzle-solving and exploration in ex pansive worlds. Notable indie adventure games are Firewatch, Night in the Woods, and What Remains of Edith Finch.", "label": "human"}
{"ID": "00220031", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Puzzle: Indie puzzle games challenge players to solve puzzles using logic andcritical thinking. Examples include Tetris Effect, Baba Is You, and The Wit ness.", "label": "human"}
{"ID": "00220032", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "RPG: Indie RPGs let players assume roles and embark on journeys through immersive worlds. Popular titles include Undertale, Stardew Valley, and Disco Elysium.", "label": "human"}
{"ID": "00220033", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Action: Indie action games offer fast-paced combat against enemies. Hot  Miami, Katana Zero, and Dead Cells are among the popular indie action games.", "label": "human"}
{"ID": "00220034", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Simulation: Indie simulation games involve managing virtual worlds or en vironments. Examples include RimWorld, Oxygen Not Included, and PrisonArchitect.7. Strategy: Indie strategy games require strategic planning and outsmarting op ponents. Notable titles include Into the Breach, Slay the Spire, and Darkest Dungeon.", "label": "human"}
{"ID": "00220035", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Sports: Indie sports games offer competitive gameplay in various sports or activities. Notable titles include Rocket League, Super Mega Baseball, and Golf Story.", "label": "human"}
{"ID": "00220036", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Visual Novel: Indie visual novels are story-based games where players make choices affecting the game’s outcome. Notable examples include Doki Doki Literature Club, Long Live the Queen, and Steins;Gate.", "label": "human"}
{"ID": "00220037", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The development objective of the project is to create useful tools that assist developers in the game development process, reducing time and effort. These tools aim to help developers focus on the core aspects of the game by handling repetitive or complex tasks, ultimately streamlining the development workflow.", "label": "human"}
{"ID": "00220038", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "At the same time, the project also involves building a Pixel Platformer game, not only to validate the usability of the libraries but also to create a complete game that allows players to experience a platformer in the pixel art style. This game aims to deliver an authentic platformer gameplay experience with the charm of pixel art graphics.", "label": "human"}
{"ID": "00220039", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "When using the packages, indie developers can directly import them into the Unity Engine as external libraries, saving time and effort in building tools fromscratch. Furthermore, since the entire project focuses on creating open-source libraries, the author’s desire is to establish a community of collaborative develop ment. This means that others can also contribute to these packages, improving their quality, adding features, and fixing bugs, all working together to create useful tools for the game development community.Chapter 2 provides an overview of the functionalities that three packages provide as well as the Pixel Platformer game has achieved. In the following chapter, the theoretical background of game libraries, frameworks, and database systems used in the development of three packages and the game will be discussed, along with the reasons for their selection in this project.", "label": "human"}
{"ID": "00220040", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GUI Manager is responsible for managing the user interface elements and interactions within a game. The good GUI Manager library is one that meets the important following requirements:", "label": "human"}
{"ID": "00220041", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "UI Element Management The GUI Manager handles the creation, placement, and removal of UI elements such as buttons, text labels, images, and menus.", "label": "human"}
{"ID": "00220042", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "UI State Management: The GUI Manager keeps track of the current state of the UI, such as which menu is open, which UI elements are visible, or which UI screen is active. It manages the transitions and changes in the UI state based on the game’s logic and player 3. Event Handling and Callbacks: The GUI Manager enables communication between UI elements and other game systems or scripts. It can handle events or callbacks triggered by UI interactions and invoke appropriate actions or functions in response.", "label": "human"}
{"ID": "00220043", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "UI Customization and Styling: The GUI Manager often provides functionality for customizing the appearance, layout, and styling of UI elements. It may offer options to define colors, fonts, sizes, and other visual properties to create a consistent and visually appealing UI.", "label": "human"}
{"ID": "00220044", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "To provide clarity and tight management of UI elements appearing in the game, in my library, I define two basic types of UI: Screens and Popups (also called UI Containers). Screen is an interface that is scaled full screen according to the player’s machine. At one time, only one screen was active. Therefore, if you have an active screen, you activate another screen, the active screen will be deactivated.", "label": "human"}
{"ID": "00220045", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "In the other hand, Popup is the interface that appears when the player activates an event or when the game wants to notify the player. The popups can be opened at the same time, the popup called later will appear above the current popup. Whena user creates a container( screen or popup), smaller UI elements such as buttons, titles, text, etc., will be managed directly by these containers.", "label": "human"}
{"ID": "00220046", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Object pooling is a technique commonly used in game development to efficiently manage and reuse game objects, reducing the overhead of creating and de stroying objects at runtime. The basic idea is to create a pool of objects in advance and then reuse and recycle them as needed. Instead of instantiating and destroyingobjects repeatedly, objects are deactivated (disabled) when not in use and reacti vated (enabled) when needed again. Object pooling can improve performance by reducing the overhead of memory allocation and garbage collection, especially in scenarios where objects are frequently created and destroyed, such as projectiles, particles, or enemy spawning.", "label": "human"}
{"ID": "00220047", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "To explain GOAP more clearly, let’s start with a basic example. Suppose you want to build an NPC that can autonomously adjust its actions based on its own state and the state of the world around it. Specifically, you want to create an NPCthat knows how to eat (\"Goal = Eat\"). However, to eat, it needs to have food avail able, and to acquire food, it can choose one of the following actions:", "label": "human"}
{"ID": "00220048", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Pick Fruits: However, to harvest fruits, you have to venture into the forest, and since this task requires a lot of physical effort, the cost of implementation will be high.", "label": "human"}
{"ID": "00220049", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Buy food from the market: This activity requires you to go to the market, and in order to buy food, you need to have money. Since the journey to the market is usually easier than going up the mountain, this activity will have lower costs compared to the Pick up Fruits activity.", "label": "human"}
{"ID": "00220050", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Harvest from the garden: This is the activity with the lowest implementation cost as you only need to go behind your house and harvest food. However, this activity requires you to have planted crops in order to harvest them.", "label": "human"}
{"ID": "00220051", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Here we can see that each action has conditions that determine whether the action can be executed or not. For example, the action \"Go to the market\" can only be performed if you have money. Additionally, when an action is completed, it will have an effect on the state of the NPC itself and the state of the world. In this case, the action \"Go to the market\" will have the effect of changing the player’s state to At the market\". This is also a condition for the next action, which is \"Buy Food from market\". So, action \"Go to Market\" is connected to the Action \"Buy foodFigure 3.1: Example of GOAP Total cost Pick Fruits Go to Forsest + Pick Fruits = 10 + 10 = 20 Buy Food from market Go to market + Buy food from market = 5 + 5 = 10 Harvest from garden Harvest from garden = 1 Table 3.1: Total Cost of 3 options in example GOAP from market\".", "label": "human"}
{"ID": "00220052", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "In this way, the actions are connected to form a tree, where the root is the goal that the player is trying to achieve. The actions are linked together if the effects of the previous action align with the conditions of the subsequent action.", "label": "human"}
{"ID": "00220053", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "In the case of multiple action sequences that lead to a specific goal, the player will prioritize choosing the action sequence with the lowest total cost. In the given example, let’s assume the player has both money and vegetables grown in their house. In this scenario, all three action sequences can be executed to achieve the goal of \"Eat\". However, in this case, the player will choose the action \"Harvest from the garden\" as it has the lowest total cost, which is 1.", "label": "human"}
{"ID": "00220054", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "There were several database systems that I considered, but ultimately, my deci sion was to use MongoDB for my game due to the following reasons.", "label": "human"}
{"ID": "00220055", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Flexible Data Modeling: Games often involve complex and evolving data struc-tures. MongoDB’s document-oriented nature allows developers to store and manage diverse data types in a flexible manner. This flexibility accommodatesthe changing requirements and data structures that can arise during game de velopment.", "label": "human"}
{"ID": "00220056", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Flexible Data Modeling: Games often involve complex and evolving data struc tures. MongoDB’s document-oriented nature allows developers to store and manage diverse data types in a flexible manner. This flexibility accommodatesthe changing requirements and data structures that can arise during game de velopment.", "label": "human"}
{"ID": "00220057", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Real-time Updates: Games often require real-time updates to reflect changes in player actions, scores, or game states. MongoDB’s ability to handle highwrite throughput and support real-time data updates makes it suitable for sce narios where data needs to be updated and accessed rapidly.", "label": "human"}
{"ID": "00220058", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Performance: MongoDB is designed for high-performance applications. It uti lizes memory-mapped files and indexes for efficient data access, enabling fast read and write operations, which is crucial in gaming applications that require low latency and smooth gameplay experiences.", "label": "human"}
{"ID": "00220059", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "In multiplayer action games, synchronization among players is the most sig nificant requirement. For instance, when you and your friend are playing a game together, at time t, you successfully defeat a boss. However, at time t + 30s, your friend still sees the boss alive, or at time t, you move to the second floor of a building, while your friend only sees you standing at the front door. Asynchronous or delayed updates can heavily impact the experience and are a crucial factor in determining the success of a multiplayer game.", "label": "human"}
{"ID": "00220060", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Based on those requirements and information collected from , Photon is a suitable choice for your network framework. For detail explains:", "label": "human"}
{"ID": "00220061", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Matchmaking and Room Management: Photon offers built-in matchmaking and room management features, allowing players to be connected with each other based on specified criteria, such as skill level or game mode preferences.", "label": "human"}
{"ID": "00220062", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Photon follows a client-server model, where the server acts as the authorita tive source for game state. This ensures consistent synchronization between players, as the server controls the game logic and resolves any conflicts ordiscrepancies that may arise.Overall, Photon’s real-time communication capabilities, server authority, match making features make it a strong choice for implementing network functionality in multiplayer action games.In this chapter, I will describe the design and functionality of each package as well as the key designs of the Pixel Platformer game. Specifically, each package will have the following structure: First, I will provide an overview of the usage of each package, and then I will describe the functionalities of the important use cases. Three packages will correspond to the respective three first sections in this chapter. For the Pixel Platformer game, I will present an overview as well as the design approach that has been implemented in the game in final section.", "label": "human"}
{"ID": "00220063", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Graphical User Interface (GUI) Manager is a library implementation designed for programmers to offers a powerful API allowing to easily manage GUI in game.", "label": "human"}
{"ID": "00220064", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "General Usecase Diagram The image below provides an overview of the various use cases used in the GUI Manager package. 4.1 This library is built for all developers who want to build a Figure 4.1: Usecase Diagram of GUI Management GUI management system in a simple and efficient way. Therefore, the library willprovide two main functions for users: creating a new User Interface and customiz ing a management system to fit the developing game.", "label": "human"}
{"ID": "00220065", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Functional description a, Specification for use case \"Create Screen\"Use case code UC001 Use case name Create Screen Actor Developer Description Developer creates a new screen Preconditions1. Developer installs the package into the project 2. Developer creates a folder with a specified path : \"Resources\\Screens\" Post Consitions No Main flow of event1. Developer creates a prefab into the folder named \"Screen\" + \"Screen_name\".", "label": "human"}
{"ID": "00220066", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Developer creates a script inheritated \"ScreenBase\" 3. Developer attaches this script to prefab Alternative flow of eventNo Table 4.1: Specification for use case: \" Create Screen\" b, Specification for use case \"Create Popup\" Use case code UC002 Use case name Create Popup Actor Developer Description Developer creates a new popup Preconditions1. Developer installs the package into the project 2. Developer creates a folder with a specified path : \"Resources\\Popups\" Post Consitions No Main flow of event1. Developer creates a prefab into the folder named \"Popup\" + \"Popup_name\".", "label": "human"}
{"ID": "00220067", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "General Use case DiagramThe GOAP library’s main function is to plan and control the actions of a char acter to achieve their set goals. To accomplish this functionality, users are required to perform three functions: (i)Create Agent, (ii)Add Goal, (iii)Add Action shown in the figure 4.4.", "label": "human"}
{"ID": "00220068", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Work flow In this section, the project will explain in detail the operation process of the library in the picture 4.5. The first thing users need to do is to create a class that inherits from the Agent Behavior class. This inheritance ensures that when thecharacter operates within the scene, it will be added to the list of active agents and will be automatically planned through the underlying Planner Class.", "label": "human"}
{"ID": "00220069", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The next step is to create Actions and Goals by inheriting from the pre-existing ActionBase Class and GoalBase Class. These will be stored by the Agent in theAgentConfig. When inheriting the Action class, users need to implement the Perform function to clearly define what the character will do when performing this ac tion. The Perform function will return the state of the action: Continue (to continue the current action) or Stop (to end the current action).Users need to be mindful of returning the appropriate Action state because only when the action is completed, the Sensor Class (a function used to check the state of the world and the characters) will be called to determine the next possible actions that the character can perform.", "label": "human"}
{"ID": "00220070", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Functional DescriptionWhen starting the planning process, the program will check the required condi tions to avoid errors, such as checking if the agent is null. If the program detects an error, it will immediately stop to ensure that it does not affect other agents. After that, the program checks whether the agent is currently performing an action. If it is, the program will continue with that action; otherwise, if the current action is null (current action is finished), it will start observing the world through the SenseWorld function.", "label": "human"}
{"ID": "00220071", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Game overview Game Name – Pixel Platformer: Runner and Shooter Game Identity / Mantra - A pixelated action platformer about a character exploring new lands and fighting against evil monsters.", "label": "human"}
{"ID": "00220072", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Tag line – \"Defeat monsters to unlock new areas.\" Art style - Pixel Art 4.4.2 Gameplay First Minutes - At the start of the game, players will be able to choose a character name and access the main screen where they can select game modes, levels, as well as equip weapons and items. Once the player chooses to start, a loading screen appears, taking them to the land of their adventure. Players will control their character to navigate through obstacles and use attack skills to defeat wicked monsters, while searching for and collecting treasure chests to unlock valuable items. The objective is for players to find a mysterious portal that will help them escape from this land. If they are defeated duringFigure 4.6: Planner Flow of GOAPthis journey, they will be brought back to the main screen to start again.", "label": "human"}
{"ID": "00220073", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Objectives – The objective of the game is for the player to find the escape door and leave the land as quickly as possible, while collecting useful equipment to enhance their combat abilities.", "label": "human"}
{"ID": "00220074", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Game Progression and Play Flow Figure 4.7: Gameflow Chart 4.4.3 MechanicsRules : Pixel Platformer Games are created based on several fundamental prin ciples that players must adhere to, including:", "label": "human"}
{"ID": "00220075", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The player controls the character by moving right, left, jumping, and performing a double jump. The player navigates across terrains, avoiding ob stacles, using precise jumps, timing, and coordination to avoid falling, getting hit, or being affected by traps.", "label": "human"}
{"ID": "00220076", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The player’s mission is to find the exit portal to escape the land. Each land will have its own time limit. If the time limit is exceeded, the player will have to restart from the beginning.", "label": "human"}
{"ID": "00220077", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "When crossing the checkpoint, players will receive rewards. Players use gold to purchase equipment in the shop. The purchased equipment isstored in the inventory. Using equipment will increase the player’s power.", "label": "human"}
{"ID": "00220078", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Model of the game universe . In the game, players will embark on a journey to explore different regions. The key to unlocking new areas is to complete all the previous ones. Each region will have its own unique monsters and traps, fitting the context of that particular region. When defeating monsters, players have a chance to receive treasure chests containing equipment.", "label": "human"}
{"ID": "00220079", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "After completing the regions, players will be rewarded with gold. This goldcan be used to trade with the shop and the forge. The shop provides new equip ment such as weapons, armor, or other useful items to enhance the player’s character’s strength and abilities. Players can also sell unnecessary equipment to the shop to earn more gold or make space in their inventory.", "label": "human"}
{"ID": "00220080", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "This can help increase their power or enhance the characteristics of the equipment, allowing players to face more challenging trials in the subsequent re gions.", "label": "human"}
{"ID": "00220081", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Overall, in this pixel platformer game, players will participate in an adventure through various regions, defeat monsters, search for equipment, and enjoy the sense of progress and development of their character.", "label": "human"}
{"ID": "00220082", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Screen Flow The game has two main screens: the Main Screen and the Battle Screen. The Main Screen is where players interact when they are in the lobby.", "label": "human"}
{"ID": "00220083", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "It is used to select game modes, navigate to the shop, inventory, or forge. The Battle Screen contains information about the player while they are in the game.", "label": "human"}
{"ID": "00220084", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Control Character movement: Players move the character using the A, D keys, using space to jump, and press again to perform double jump Objects: Players collect chests by approaching items or clicking the mouse on the dropped items.", "label": "human"}
{"ID": "00220085", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Reader can observe specially in the figure 4.8Figure 4.8: Character Control in Game 4.4.5 User Interface a, Screen specification for Screen Main The main screen is the primary interface where users interact with the game and manage various game elements. It is designed to allow players to access all the game functions within a single screen, enabling them to observe and control the game effectively. (shown in figure 4.9) Figure 4.9: Screen Main template No. Control Operation Function 1 Play Button Click Load Current Level 2Select Level Button Click Open popup Select Level 3 CoOp Button Click Open Coop lobby popup 4 Inventory Button Click Open popup Inventory 5 Shop Button Click Open Shop popup 6 Forge Butotn Click Open popup ForgeNo. Control Operation Function 7 Setting Button Click Open Popup Setting Table 4.3: Main Screen specificationsThis chapter is used to describe in detail the design, results, and testing of each package as well as the game.", "label": "human"}
{"ID": "00220086", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Technical Overview The GUI Manager is designed as a lightweight library, making it easy to install and import into the Unity engine platform. As a result, the package does not require high system resources. Specifically, the details are as follows:", "label": "human"}
{"ID": "00220087", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Unity Version 2018 or later Operating System Windows Processor Intel Core i3 Memory 1GB Ram Graphics GTX 1650 Hard Drive Space 1GB free space Table 5.1: System requirements for GUI Manager Package 5.1.2 Architecture design a, Software architecture selection In this project, there will be a combination of software architectures to meet the diverse features and functionalities of the libraries. Instead of following a specific architectural model, the components within the libraries will be designed flexibly and able to effectively combine with each other to meet the specific requirements of each library.", "label": "human"}
{"ID": "00220088", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Specially, in the GUI Manager library, there will be a combination of centralized architecture and distributed architecture. The GUIManager plays a central role inmanaging UI components, while UI screens are organized in a hierarchical struc ture within ScreenContainer or PopupContainers. This combination allows for easy management of UI elements and adjusting their positions to be compatible with different screens.", "label": "human"}
{"ID": "00220089", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "By combining these different software architectures, the project aims to achieve efficiency and high scalability, meeting various requirements and needs during the development of the libraries and integrating them into the game.Figure 5.1: GUI Manager Design Package Figure 5.2: GUI Manager Detailed Package Design b, Overall designThe GUI Manager is an utility library developed to serve developers in creat ing games more easily. In order to ensure compactness, convenience, and ease of use, the overall architectural design of these libraries consists of a single package containing the core functionalities.", "label": "human"}
{"ID": "00220090", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "For the GUI Manager package, it includes a system of ScreenBase and Popup Base, which are designed independently but under the common management of the GUI Manager. These components handle the management of screens and pop-ups within the game.", "label": "human"}
{"ID": "00220091", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Detailed package design Within the GUIManager package, the GUIManager class serves as the central management entity for the game’s GUI system. The structure of the GUIManager class consists of two classes: ScreenManager and PopupManager.", "label": "human"}
{"ID": "00220092", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The ScreenManager class is responsible for managing the game’s scenes orFigure 5.3: GUI Detailed Design Package screens. It handles the loading, transitioning, and overall management of different screens within the game. The relationship between the SceneManager and other classes inheritated SceneBase class is a one-to-many relationship, indicating that the SceneManager can manage multiple instances of Sceeens.", "label": "human"}
{"ID": "00220093", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Similarly, the PopupManager class is responsible for managing all the popups within the game. It handles the creation, display, and removal of various popups that appear during gameplay. The relationship between the PopupManager and Popup classes is also a one-to-many relationship, allowing the PopupManager to manage multiple instances of Popup. .", "label": "human"}
{"ID": "00220094", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Detailed design The GUI Manager package will revolve around five main classes as shown in the figure 5.3. The \"ScreenBase\" class serves as the foundation for all screens. It is designed with two main methods, \"OnActive()\" and \"OnDeactive()\". When users create a new screen, they will create a script that inherits from the \"ScreenBase\" class.", "label": "human"}
{"ID": "00220095", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "All screens are managed by the \"Screen Manager\". The \"Screen Manager\" con tains information about the current screen being shown on the display, along with the details of all screens stored in the form of a dictionary, with keys being the names of the screens. The \"Screen Manager\" is designed with two main methods, LoadScreen\" and \"SetScreen\".", "label": "human"}
{"ID": "00220096", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The \"LoadScreen\" function takes a variable passed as a string corresponding to the screen’s name. This function is responsible for loading objects from a folderwith a pre-defined path and placing them in the correct position in the hierarchy (as children of \"ScreenContainer\").", "label": "human"}
{"ID": "00220097", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The \"SetScreen\" function is used to set a specific screen to be shown on the display. It takes the screen’s name as an input and updates the \"Screen Manager\" to display the appropriate screen.When the \"SetScreen\" function is called, it first checks if any screen is currently active. If there is an active screen, it will disable that screen and call the \"Deactive\" function to execute the logic when the screen is removed. Then, it calls the \"LoadScreen\" function to correctly position the new screen in the hierarchy. Finally, it calls the \"OnActive\" function to execute the logic specific to this screen.Afterward, it updates the \"current Screen\" variable to store the information of the newly set screen. This way, the \"Screen Manager\" keeps track of the currently active screen for future reference or potential actions related to the current screen.", "label": "human"}
{"ID": "00220098", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "AchievementThe project’s author has successfully completed package with basic functional ities as described in the previous sections. The source code of the library is hosted on GitHub at the following link:  Manager . Here, readers can download and use the library, as well as provide feedback or suggestions regarding the existing functionalities or desired features in the library.", "label": "human"}
{"ID": "00220099", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Number lines of code 515 lines Number of Classes 4 Number of packages 1 Capacity 10KB Table 5.2: Information of GUI Manager Packgae 5.1.6 Results After successful installation, the GUI Manager is used as a prefab, and users only need to drag the object into the starting scene of the game to serve as the management system for the entire game’s UI. (shown as figure 5.4) The GUIManager will automatically manage the active UI elements in the scene based on the predefined mechanism. Users can track this in the Unity hierarchy.", "label": "human"}
{"ID": "00220100", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "For example, at any given time, only one scene is active, and pop-ups that appear simultaneously will be displayed on top of the current pop-up when opened later.", "label": "human"}
{"ID": "00220101", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "shown as figure 5.5)(a)Structure of lib (b)Inspector of object Figure 5.4: GUI Manager Tool (a)Operation of GUI Manager with scenes (b)Operation of GUI Manager with popups Figure 5.5: GUI Manager Operation5.1.7 Testing In the testing process, we use manual testing techniques to ensure the gameworks as expected.Table below 5.3 is two typically test cases that cover main func tions of library.", "label": "human"}
{"ID": "00220102", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "NoSetupOutputStep by Step Expectation Create a new screen using GUI Manager Lib 1Step 1: Create a new script inhertated ScreenBase, named \"ScreenA\" Step 2: Create a prefab into the folder with path \"Resources/Screens\"  named \"ScreenA\" Step3: Call SetScreen to set the current screen with the newly created screenThe newly created screen will be placed within the screen manager hierarchy and set active, replacing the current screen.Curent Screen is ScreenA Result : Pass Create a new popup using GUI Manager Lib 2Step 1: Create a new script inhertated PopupBase, named \"PopupA\" Step 2: Create a prefab into the folder with path Resources/Popups\", named \"PopupA\" Step3: Call static method PopupA.Create to open the newly created popup.The newly created popup will be placed within the popup manager hierarchy, put into popup’stack and set active.PopupA is opened, and is on the top of stack Result : Pass Table 5.3: GUI Manager Test Case 5.1.8 DeploymentThe current library is already available on GitHub and packaged into a pack age format, allowing users to import them directly into Unity versions from 2018 onwards.5.2 Pool Manager Package 5.2.1 Technical Overview Similarly to the GUI Manager package, the Pool Manager is designed as a lightweight library, making it easy to install and use, and therefore, it does not require high system requirements for the computer used.", "label": "human"}
{"ID": "00220103", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Unity Version 2018 or later Operating System Windows Processor Intel Core i3 Memory 1GB Ram Graphics GTX 1650 Hard Drive Space 1GB free Space Table 5.4: System requirements for Pool Manager Package 5.2.2 Architecture design a, Software architecture selectionThe software architecture design of the Pool Manager typically follows a mod ular and component-based approach. Specially Object Pool Module: This module is responsible for managing the pool of objects that can be reused in the game. It includes functions to initialize the pool, allocate and deallocate objects, and keep track of the available and active objects.", "label": "human"}
{"ID": "00220104", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Variable Pool Module: Similar to the Object Pool module, this componentmanages the pool of temporary variables or data structures used during gameplay. It handles the allocation and deallocation of variables and ensures effi cient reuse.", "label": "human"}
{"ID": "00220105", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Pool Manager Core: The core of the Pool Manager is responsible for coor dinating the Object Pool and Variable Pool modules. It provides functions to request and return objects and variables from their respective pools.", "label": "human"}
{"ID": "00220106", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Overall designThe Pool Manager also contains only one package that contains data and infor mation necessary for managing object pools, as well as providing APIs that allow developers to easily utilize them in their games. (figure 5.6)Figure 5.6: Pool Manager Design Package Figure 5.7: Pool Manager Detail Package Design 5.2.3 Detailed package designAs mentioned in the previous sections, the PoolManager has two main func tions: managing active objects in the scene and managing memory for temporary variables. Therefore, the PoolManager class is associated with two classes, namely ObjectPoolManager and VariableManager, corresponding to these two functions.", "label": "human"}
{"ID": "00220107", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "shown as figure 5.7)The PoolManager class has a one-to-one relationship with both the ObjectPool Manager and VariableManager classes, reflecting the distinct roles they play in the overall functionality of the PoolManager.", "label": "human"}
{"ID": "00220108", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Additionally, within the ObjectPoolManager, there is a one-to-many relation ship with the ObjectPool class. This is because the ObjectPoolManager manages multiple object pools simultaneously, each responsible for a specific type of object.", "label": "human"}
{"ID": "00220109", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Detail DesignThe Package PoolManager is divided into two main modules: ObjectPool Man agement and Memory Management. (shown as fgure 5.8) For ObjectPool Management, the module consists of three main classes: Object-Pool, AutoUnspawnObject, and ObjectPoolManagement.", "label": "human"}
{"ID": "00220110", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "ObjectPool: This class serves as a container for objects, where each pool man ages a specific type of object, identified by the name of the gameObject prefab. The inactiveList is a variable that stores objects that are currently in the pool but not in use, while the activeList contains objects that have been spawned in the scenes.", "label": "human"}
{"ID": "00220111", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Spawn(): This method checks if there are any available objects in the pool. If there are, it will retrieve one from the pool. If not, it will instantiate a new object from the prefab as a new element in the pool.", "label": "human"}
{"ID": "00220112", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Unspawn(): This method is used to return an object from the scene back to the pool, making it inactive and available for future use.", "label": "human"}
{"ID": "00220113", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "UnspawnAll(): Similar to Unspawn(), this method returns all active objects in the activeList back to the pool, making them inactive.", "label": "human"}
{"ID": "00220114", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Clear(): If the user wants to delete the entire pool, they can call this method to destroy all elements in the pool.", "label": "human"}
{"ID": "00220115", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "ObjectPoolManagement is responsible for managing all pools using an ID (hashedfrom the pool name). Similar to individual pools, ObjectPoolManagement also pro vides methods like Spawn, UnSpawn, and ClearAll.", "label": "human"}
{"ID": "00220116", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "In addition to these methods, ObjectPoolManagement has a GetPool() method, which allows finding a specific pool based on the object or string passed in.", "label": "human"}
{"ID": "00220117", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "A unique feature of ObjectPoolManagement is the SpawnAutoUnspawn method,designed to handle objects with a predetermined lifespan in the scene. For exam ple, in the case of a continuous firing gun that shoots bullets that disappear after 1second, we know in advance that the bullet’s lifetime is 1 second. Using the Spaw nAutoUnspawn method, we can automatically return the bullet back to the pool after its lifetime expires, ensuring efficient management of objects with limited lifespans. This feature is particularly useful in scenarios where objects need to be automatically recycled after a specific duration in the scene.", "label": "human"}
{"ID": "00220118", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Number lines of code 215 lines Number of Classes 5 Number of packages 1Capacity 8KB Table 5.5: Information of Pool Manager Package 5.2.6 Results Similar to the GUI Manager Package, the Object Pool Management Package is used as a prefab to manage all object pools functioning within the game. All objects, when spawned (activated), become children of this prefab in the hierarchy.", "label": "human"}
{"ID": "00220119", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Moreover, users can monitor the number of existing pools, pool names, sample prefabs, the quantity of active objects, the quantity of objects remaining in the pool, as well as the capacity of each pool through the Object Pool Manager’s inspector.", "label": "human"}
{"ID": "00220120", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "shown as figure 5.9) (a)Operation of Pool Management in scene (b)Object Pool Manager’s inspector Figure 5.9: Pool Manager Operation In Unity 5.2.7 TestingWithin the scope of the project, the author conducted two main use cases corre sponding to the two main functions of the package as table 5.6:", "label": "human"}
{"ID": "00220121", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Step 2: Create a prefab called \"Bullet\" Step3: Call the static method ’ObjectManager.Spawn’ to spawn a bullet with each update frameA pool of prefab bullets is created and manages the bullets within the pool.A pool of bullets Result : Pass Create an array pool of temporary variables based on type: Collider.", "label": "human"}
{"ID": "00220122", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Step3: Call this method with each update frameA pool of collider arrays is created, ensuring the provisioning and reusing of arrays that are created without continuously allocating memory.A array pool of colliders Result : Pass Table 5.6: Pool Manager Packagae Test Case 5.2.8 DeploymentThe current library is already available on GitHub and packaged into a pack age format, allowing users to import them directly into Unity versions from 2018 onwards.", "label": "human"}
{"ID": "00220123", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Technical Overview Due to its nature as an AI library, the GOAP library is designed to be suitable for use in large-scale projects. The library utilizes BurstCompile, a new technology under development by Unity, to enable multi-threading for agents. Additionally, it uses node view to construct a visual window for the library.", "label": "human"}
{"ID": "00220124", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "As a result, compared to the two libraries mentioned earlier, the GOAP library will have higher requirements in terms of performance and capabilities. Specially in table 5.7 Unity Version 2022 or later Operating System WindowsProcessor Intel Core i5 Memory 1 GB Ram Graphics GTX 1650 Hard Drive Space 1GB Space Table 5.7: System requirements for Pool Manager Package 5.3.2 Architecture design a, Software architecture selection Similarly, in the GOAP library, there will be a combination of object-oriented architecture and event-driven architecture. GOAPAgent represents each agent in the game and has the ability to make decisions based on events that occur in the game.", "label": "human"}
{"ID": "00220125", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Overall designFor the GOAP package, which is a specialized AI library, the overall architec tural design consists of three packages: the GOAP data package, the GOAP logic processing package, and the visual logic package.", "label": "human"}
{"ID": "00220126", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GOAP data package serves as a repository for configurations and base classes of the GOAP system. It stores essential data structures and classes required for the functioning of the GOAP library.", "label": "human"}
{"ID": "00220127", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GOAP logic processing package is the core AI processing package of the library. It includes the logic processing between nodes, graph rendering, as well as planning and finding the shortest path for the agent. This package handles the main AI logic and decision-making processes within the GOAP library.", "label": "human"}
{"ID": "00220128", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The Visual UI package provides a user interface that allows users to monitor the actions and states of the agent. It facilitates debugging and usage for developers, providing visual feedback on the agent’s behavior and status.", "label": "human"}
{"ID": "00220129", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "As shown in the diagram 5.10, the GOAP logic package and the GOAP visual package will utilize the GOAP data package as input for their separate processing and operate independently. This separation allows for convenient management anddevelopment of the two packages, as there are no significant constraints or depen dencies between them. Additionally, it maintains synchronization throughout the entire system by using the same data package.Figure 5.10: GOAP Package design 5.3.3 AchievementThe project’s author has successfully completed package with basic functional ities as described in the previous sections.", "label": "human"}
{"ID": "00220130", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Number lines of code 2011 lines Number of Classes 8 Number of packages 3 Capacity 70KB Table 5.8: Information of GOAP Package 5.3.4 Results This is the result of the library after completing the visual interface. As seen in the image 5.11, the actions and objectives of the agent will be automatically connected to each other, forming a graph (a complete sequence of actions). Users can track the actions and conditions’ status of these actions on the graph. On the left side of the graph, there is information about the agent, including the agent’s name, current target, current action, and the action’s status.", "label": "human"}
{"ID": "00220131", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Testing Regarding the testing phase of the GOAP library, I will build a boss character with the actions that are described about conditions, effects and cost in the table 5.9. The monster’s goal is to survive for as long as possible, measured by the Live index. Based on the actions it can perform, the desired output after running the GOAP library is to be able to render a graph shown as figure 5.12 and select the correct actions for each frame.(a)Graph of an agent planning (b)Information of agent Figure 5.11: GOAP visual graph In Unity Figure 5.12: Expect GOAP graphAction Description Conditions Effects Cost IdleThe monster is in a stationary state and only performs the idle animation.The life index increases by 1.150 Find Target ActionMonster finds all target in the attack rangeThe entity is transitioned into the state of having found the target1 Choose Type ShootThe monster will rely on pre-configured information to choose the target and method of attack.The monster is in a state of having found the targetThe entity is transitioned into the state of Did Choose Type Shoot20 ShootAfter selecting its attack method, the monster will proceed to attack the targetThe monster is in the state of having chosen its gun, and the gun is ready to attack (not in a reload state).The life index increases by 11 Table 5.9: GOAP Test case actionsThe result obtained after running through the GOAP library is shown in the fig ure 5.13. Overall, the library has performed correctly with the functionalities and actions required. The rendering of the graph and the selection of the appropriateactions for each frame have been achieved as requested. This representation dis plays the optimal actions chosen for the monster to survive as long as possible, based on the Live index. If the rendered graph and action selections are accurate, the GOAP library can be considered to have worked correctly as expected.", "label": "human"}
{"ID": "00220132", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Another test case of the library has been conducted in a project  to build a city with five types of agents, including lazy students, diligent students, chefs, police officers, and office workers. Each agent is designed with specific scenarios.", "label": "human"}
{"ID": "00220133", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "DeploymentThe current library is already available on GitHub and packaged into a pack age format, allowing users to import them directly into Unity versions from 2022 onwards.Figure 5.13: GOAP graph test case5.4 Pixel Platformer Game 5.4.1 Technical OverviewThe game is designed on the Unity 2022 platform with the use of URP (Univer sal Render Pipe), along with multi-threading and BurstCompile technology. Asfor the assets used, the game utilizes tilemaps for designing maps for different lev els. Based on these requirements, the minimum system requirements for the game to operate smoothly are on table 5.10:", "label": "human"}
{"ID": "00220134", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Unity Version 2022 or later Operating System Windows 10 64-bit Processor Intel Core i5 Memory 8 GB or more Graphics NVIDIA GeForce GTX 970 and above.", "label": "human"}
{"ID": "00220135", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Hard Drive Space Minimum 5 GB of free space Table 5.10: System requirements for Platformer Game 5.4.2 Architecture design a, Software architecture selectionThe software architecture in a pixel platformer game typically follows a component based design, included below components:", "label": "human"}
{"ID": "00220136", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Player Controller: This component manages the player’s movement, jumping, and interaction with the environment. It handles input from the player and updates the player’s position and actions accordingly.", "label": "human"}
{"ID": "00220137", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "This component manages the different levels in the game. It loads and unloads levels, keeps track of the player’s progress, and handles level transitions.", "label": "human"}
{"ID": "00220138", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The UI Manager handles the game’s user interface, including menus, health bars, and time displays. It communicates with other components to update the UI based on the game state.", "label": "human"}
{"ID": "00220139", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The Game Manager oversees the overall game flow and manages the interac tion between different components. It controls the game’s state, handles game events, and determines when to switch between different game modes Networking: This module is responsible for transmitting information betweenthe client and server through network protocols such as TCP, UDP, or WebSockets. It manages the connections, synchronizes data, and handles interac tions between players and the game server.Figure 5.14: ERD diagram of Pixel Platformer Game The component-based architecture allows for modularity and reusability of code, making it easier to maintain and expand the game. Each component is responsible for a specific set of functionalities, and they communicate with each other through well-defined interfaces and events. This architecture helps in creating a flexible and organized structure for developing and managing a pixel platformer game.", "label": "human"}
{"ID": "00220140", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Detailed Design a, Database design The ERD diagram depicted in the image 5.14 is designed to manage the database system for player data in the game Pixel Platformer. The diagram consists of four main entities: Gamer, Chapter, Item, and Inventory.", "label": "human"}
{"ID": "00220141", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The Gamer entity serves as a container for basic player information, including attributes such as GID (Gamer ID), Name, CurrentChapter, and CurrentGold. The GID attribute functions as the primary key for the table.", "label": "human"}
{"ID": "00220142", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The Chapter entity represents the player’s progress in different chapters of the game. The table uses GID as the primary key, and each record corresponds to agamer. The Chapter table includes attributes such as GID and ChapterData. Chap terData is a multivalued attribute that contains a list of chapters that the gamer has played. It consists of ChapterID, isCompleted (a variable indicating whether the chapter has been cleared or not), and clearedTime (the time of completion for the chapter).Figure 5.15: Database Design for MongoDB The Inventory entity stores data about the items owned by the gamer. Each gamer has only one inventory. The Inventory table contains inventoryInfors, which represent the data for each item type. It includes attributes such as type, codename, and count, indicating the quantity of items of a particular type owned by the gamer.", "label": "human"}
{"ID": "00220143", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Lastly, the Items table holds information about the items equipped by the gamer, which is used to calculate progress and the player’s strength. Each gamer has a system of equipped item slots, which are stored in the Items table. The Items table includes attributes such as slotType (to identify the type of equipment slot) and codename (to specify the equipped item).", "label": "human"}
{"ID": "00220144", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Overall, this ERD diagram provides a representation of the relationships and structure of the database system for managing player data in the Pixel Platformer game.", "label": "human"}
{"ID": "00220145", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Based on the ERD entity diagram, I have utilized a NoSQL database manage ment system (specifically MongoDB) for data management purposes, shown as 5.15.", "label": "human"}
{"ID": "00220146", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Implementation a, Libraries and ToolsBelow is a table 5.11 listing the libraries and tools used during the game devel opment process:Purpose Tools and Libraries URL Programming Rider 2021https:", "label": "human"}
{"ID": "00220147", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "//www.mongodb.com/ Visual Query Builder Studio3T om/download/ Creating and managin animation sequencesDotween migiant.com/ Build, Test, Deploy Android SDK android.com/studio /releases/sdk-too ls?hl=vi Testing NoxPlayerhttps:", "label": "human"}
{"ID": "00220148", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "//tortoisesvn.net/ Table 5.11: List of libraries and tools 5.4.5 Achievement Category Size Percentage Textures 120.2 mb 65% Animations 3.2mb 1.6% Sounds 2.2 mb 1.0% Shaders 1.2mb 0.7% Other Assets 4.8mb 4.8% Scripts 8.4mb 4.2% Included DLLs 27.2mb 13.6% Total User Assets 167.2mb 100% Table 5.12: Compressed asset usage by categoryTable 5.12 summarizing information about the memory usage of the game.", "label": "human"}
{"ID": "00220149", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Results To start playing, the player needs to log in to the game. If the login name and device ID are not present in the database, the server will automatically create a new player. (Figure 5.16) Figure 5.16: Log In Screen After successfully logging into the game, the player will see the main interface of the game. Here, the player can start a match, upgrade their power by improving weapons, trade at the shop, and manage their inventory. Additionally, the player can also adjust the game settings from this screen. (Figure 5.17) Figure 5.17: The Main ScreenThe Inventory is a place that contains the items that the player currently possesses. The Popup Inventory is designed with three sections. The left section consists of equipment slots where the player can equip items. The middle section dis plays all the items that the player owns, which are stacked together. The right sec-tion is where item information is shown. In this section, the player can directly sell equipment to the store to earn gold. To equip an item, the player can drag the item from the bag to the appropriate item slot on the left or click the \"Equip\" button in the item information section.(Figure 5.18) Figure 5.18: Inventory PopupThe Shop is a place where players can trade with NPCs. Here, all types of equip ment from Common to Rare are available for purchase. To buy an item, the playerclicks on the desired item, selects the quantity, and presses \"Confirm\". After a suc cessful transaction, the player will receive a notification.(Figure 5.19) Figure 5.19: Popup Shop The Forge is a place where players can upgrade their equipment. Players can forge four pieces of equipment of the same type and quality to receive a higher-tier item. This is also the only place in the game where players can craft legendary equipment.(Figure 5.20)Figure 5.20: Popup Forge The game levels are designed with different themes, corresponding to differentregions. Each level comes with various difficulty levels, requiring players to nav igate to avoid traps, defeat enemies, and reach the exit door to escape from the area. The in-game display always includes information about the player’s health, the duration of the match, and additional options such as reset, back to the menu, or pause.", "label": "human"}
{"ID": "00220150", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "In the battle, the player’s mission is to defeat various monsters, each designed with different actions and abilities. The monsters will pose different challenges, requiring the player to move strategically and use attacks wisely.(Figure 5.21) Figure 5.21: Attack enemiesIn addition to monsters, the game world will feature various types of traps de signed to add more challenges. These traps may include static traps, activated traps, and moving traps, each suited to the specific terrain they are placed in. The playerwill need to use their jumping or double-jumping abilities to avoid or escape these traps effectively. Proper timing and precision will be essential for the player to navigate through the terrain and progress in the game successfully. (Figure 5.22) Figure 5.22: Avoid Traps Finally, the player’s ultimate goal is to find the exit gate to escape from the area.", "label": "human"}
{"ID": "00220151", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The faster the player escapes from the area, the more valuable rewards they will receive.( Figure 5.23) Figure 5.23: Find The Door Another feature of the game is the cooperative (coop) mode. After selecting thismode, the player will be taken to the lobby, where rooms with missing players will appear. Players can also create their own rooms to play with friends. Once there are two players in the room, the match will begin. The rules of the game in coop mode are similar to those in single-player mode. (Figure 5.24) Figure 5.24: Co-Op mode 5.4.7 Testing Description Step to test Expectation Output Control character :", "label": "human"}
{"ID": "00220152", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Control character using A and D to move, and space to jump and space again to double jump and J to attack- Step 1: Press A or D Step 2: Press space step 3: Press J when near a monsterThe character moves and rotates in the correct direction in steps 1.", "label": "human"}
{"ID": "00220153", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The player can jump on a block and perform a double jump in mid-air. The player can also attack enemies when close to them.The character moves according to the specified key pressed, and the character’s facing direction aligns with the direction of movement. The character can jump one block, double jump in the air, attack monsters.", "label": "human"}
{"ID": "00220154", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Character buy items from the shop- Step 1: Click to shop icon on the screen Main to open popup Shop Step 2: Choose items you want to buyStep 3: Choose the quan tity of this items - Step 4:", "label": "human"}
{"ID": "00220155", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Click \"Confirm\" button to complete the transaction.A popup appears to notify that the purchase was successful, accompanied by the item just bought.The interaction panel is displayed and functions correctly according to the design.", "label": "human"}
{"ID": "00220156", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Result : Pass Character Equips Item: Player equips items in theinventory- Step 1: Click the \"Inven tory\" button on the screenMain to open the Inven tory Step 2: Click to Item in the panel My InventoryStep 3: Drag to the cor rect slot Item in the panel SlotsThe item that has just been equipped will trigger a visual effect (VFX) to shine, and its information in the information panel will change to Equipped.\" At the same time, the slot type will display the icon of the newly equipped item.The actions of the tool are performed correctly, as well as the effects of the item are consistent with the design.", "label": "human"}
{"ID": "00220157", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Character upgrades items in the forge.- Step 1: Click the \"Forge\" button on the screen Main to open the Forge Step 2: Click to item has the same Type and Rarity to forgeStep 3: After success fully choosing 4 items, Forge\" button appeared,and user clicks to this but tonA popup appears when receiving a new item with a higher rarity than the component items. The component items will be removed from the inventory, and the character’s strength will be recalculated if the new item is currently equipped.The inventory update will add the newly forged item and accurately remove the corresponding component items.", "label": "human"}
{"ID": "00220158", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Character selects levelto play.- Step 1: Click the \"Lev els\" button on the screen Main to open popup Step 2: Click to level that has been unlocked.A popup loading appears and sever transfers data to client and new scene is loaded to start the correct level.The scene corresponding to the level will be loaded accurately.", "label": "human"}
{"ID": "00220159", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Character joins Room lobby inco-op mode.- Step 1: Click the \"Co op\" button on the screen Main to open popup Room LobbyStep 2: Click to \"Cre ate\" button to create a new room.", "label": "human"}
{"ID": "00220160", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Step 3: Wait for another player joining.When there are two players in a room, a loading popup appears, and the players will be taken to the pre-designed Co-op scene.The scene corresponding to the co-op mode is loaded accurately.", "label": "human"}
{"ID": "00220161", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Character saves data in game- Step 1; Exit the game Step 2: Launch the gameagain and log in to the cor rect accountThe player’s data has been updated.The player’s data has been updated and displayed correctly on the main screen.", "label": "human"}
{"ID": "00220162", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Result : Pass Table 5.13: Test Case for Platformer Game 5.4.8 DeploymentAfter completing the game testing and ensuring that the game functions cor rectly according to the pre-designed specifications, the author proceeds to build the game. In Unity 2022x, they navigate to the \"Build Settings\" menu. They selectall the scenes that make up the game and arrange them in the \"Scenes In Build\" sec tion. Then choose the platform for the game as \"PC/Windows\" with the architecture set to \"Intel 64-bit\". The compression method selected is \"Default\", and finally, they click on the \"Build\" button in the window (config like in figure 5.25). After the build process is completed, the game will appear in the \"Build/Platform.exe\" folder. Now, it has been built into an APK and the build is publicly available onGitHub. Users can download the build to experience the gameFigure 5.25: Build Setting in UnityNowadays, along with the development of the industry, the number of gam ing devices, especially mobile phones, has become incredibly diverse, leading to a wide range of choices for users. However, it also poses a challenge for developers, as they must constantly update and design games, especially UI, to be compatible with various types of devices. Because a good game is not only one with exciting mechanics but also needs to have a user-friendly and attractive user interface.", "label": "human"}
{"ID": "00220163", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Type Screen Resolution iPhone 13 Pro 1170 x 2532 iPhone XR 828 x 1792 iPhone XS 1125 x 2436 iPhone XS Max 1242 x 2688 iPhone X 1125 x 2436 iPhone 8 Plus 1080 x 1920 Samsung Galaxy Note 10+ 1440 x 3040 Samsung Galaxy Note 9 1440 x 2960 Samsung Galaxy Note 5 1440 x 2560 Samsung Galaxy S9+ 1440 x 2960 Samsung Galaxy S7 1440 x 2560 Google Pixel 7 Pro 1440 x 3120 Table 6.1: Screen Resolution of some popular types of mobie phone Usually, indie developers design interfaces with two standard sizes: 1080 x 1920 (portrait) and 1920 x 1080 (landscape), and then use Unity’s \"scale by viewport\" feature to adjust the position of UI elements on different devices. However, as seen in the resolution data for various common phone models today, there are many screens with sizes larger or smaller than the standard dimensions. For example, the Google Pixel 7 Pro has an aspect ratio of 0.46 (1440/3120). Consequently, this can lead to misalignment of UI elements, causing difficulties in interaction and even discomfort for the user experience.", "label": "human"}
{"ID": "00220164", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Therefore, to design layouts suitable for different types of devices, I have built a GUI Manager hierarchy. Instead of directly setting screens as children of the Screen Container (a panel that forces expansion based on the device’s screen resolution), when setting a screen active, I added a component called \"ratio\" to control the cases where devices have aspect ratios smaller or larger than the standard ratio.(a)Default Resolution (b)Samsung Galaxy Note 10 Resolution Figure 6.1: Difference in GUI in other devices  GUI Manager Screen Container Popup Container Top Group Event System Safe Area Ratio The Ratio element plays a role in adjusting the aspect ratio of UI elements ondifferent devices to maintain a similar design as the original one based on the stan dard aspect ratio. There are three main adjustment types:", "label": "human"}
{"ID": "00220165", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "WidthControlsHeight: This adjusts the height of the rectangle to match the aspect ratio while keeping the width of the screen unchanged.", "label": "human"}
{"ID": "00220166", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "HeightControlsWidth: This adjusts the width of the rectangle to match the aspect ratio while keeping the height of the screen unchanged.", "label": "human"}
{"ID": "00220167", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "FitInParent: This sizes the rectangle in such a way that it is fully contained within the parent rectangle, changing both the height and width of the screen(a)Hierarchy of Screen Container (b)Inspector of Ratio Figure 6.2: Screen Container Hierarchy as necessary.", "label": "human"}
{"ID": "00220168", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The general algorithm for all three types is to find a new aspect ratio based onthe standard ratio and suitable for the device. Then, scale the positions of UI ele ments according to the calculated ratio. For example, choosing the adjustment type HeightControlsWidth\" for the Samsung Galaxy Note 10 with a screen resolution of 1440 x 3040. The UI was designed with the standard design ratio of 1080 x 1920 (=0.5625).", "label": "human"}
{"ID": "00220169", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Keeping the height of the screen unchanged, we calculate the new width as follows: NewWidth = 1440 / 0.5625 = 2560. Therefore, the new screen resolution will be 1440 x 2560.", "label": "human"}
{"ID": "00220170", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "By using these adjustment types in the Ratio component, the GUI Manager can ensure that UI elements appear correctly and maintain the intended design across various devices with different aspect ratios. This allows for a consistent and visually appealing user experience regardless of the device being used.7.1 ConclusionThis project has successfully completed three essential libraries with the func tionalities described in the chapters.", "label": "human"}
{"ID": "00220171", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GUI Manager library allows developers to manage UI components coherently, establish an organized sequence, create a managing object for easy monitor ing of component activities, and facilitate scaling for large projects.", "label": "human"}
{"ID": "00220172", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The Pool Manager library enables users to pre-cache pools, observe the quantity and information of each pool within the managing object, and conveniently handle pool usage.", "label": "human"}
{"ID": "00220173", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The GOAP library constructs agents capable of actions and goals based on theirself-awareness of the world, resulting in complex and appropriate logical interac tions akin to human behavior.", "label": "human"}
{"ID": "00220174", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Additionally, the libraries have basic user interfaces that facilitate monitoring and observing agent conditions and actions. They allow automatic connection among agents and the creation of convenient paths for debugging processes.", "label": "human"}
{"ID": "00220175", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Lastly, the project has successfully developed a pixel platformer game with nec essary features and functionalities, effectively applying the three aforementioned libraries.", "label": "human"}
{"ID": "00220176", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "They are comprehensive, designed to serve the game development process in general, rather than being tailored to a specific game genre.", "label": "human"}
{"ID": "00220177", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "The libraries are easy to read, understand, and continue developing, modify ing, or applying. The author has confidence that they can be easily maintained and extended in the future.", "label": "human"}
{"ID": "00220178", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Looking forward, the author believes that these libraries will continue to be devel oped, striving for optimization in functionality and user-friendss. With ongoingimprovements, they are expected to become even more valuable tools for game de velopers.7.2 Future work During the course of one semester, the author still has many desired features that have not been implemented in this project. Some notable examples include:", "label": "human"}
{"ID": "00220179", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "It’s common for projects like this to have further potential for development and expansion. The author remains hopeful that in the future, more resources and time could be allocated to realizing these additional features and making the libraries and game even more robust and feature-rich. Video Game Insights, Hypertext transfer protocol (HTTP . [On]. Available:", "label": "human"}
{"ID": "00220180", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "/ / fungies . io / 2023 / 03 / 16 / amazing - opportunity- of  indie-gaming-market-size/ (visited on 07/05/2023).", "label": "human"}
{"ID": "00220181", "file_name": "Developing game optimisation tools and utilising in development of platformer game Pixel", "content": "Tinny Studios, Unity assest package . [On]. Available: unity. com / packages / tools / behavior- ai / s - goap - ai  solution-167167 (visited on 06/16/2021).", "label": "human"}
{"ID": "00230001", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "In background terrible international presently now, with coin position full bridge chemistry background terrible international position gender, all face of life living commune festival day more Okay elevate High, dense special To be soft bridge handed out change row of child People day more increase chief about number quantity and matter quantity. Presently now the labour I believe learn row head position gender Are not cease head private and cabbage good the prize France also as products intended to enable commercialization on the Internet. Through these products and technologies, we easily realize the importance and inevitability of e-commerce.", "label": "human"}
{"ID": "00230002", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Beside  edge  there  job spectrum  variable  history  use Internet  Satisfied  create  go out one step turn new in the development orientation of our country's IT industry, along with the need to use computers  to handed out  change  and access  Japan  pine believe  more  day increase.  From  real international  there  job give Information that meets people's needs and supports purchases and sales to take place quickly quickly,  details  frugal  Satisfied  return  should  enter  together  grant  set. Song  song with job sell passing goods  electricity  phone  then sell row via network  also To be one prize  France  dark pros in job distribution  pine believe  enter  item destination love commercial.  Job Friend  Have  can live home  but Go arrive  door This or that store in virtual space has become a reality.", "label": "human"}
{"ID": "00230003", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "With the desire to reach and contribute to promoting the popularity of e  commerce  death  live Vietnamese  Male,  me Satisfied  find understand  and set next website  management  physical  Chain  door row Coffee has many advantages that make it easy to manage.", "label": "human"}
{"ID": "00230004", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Guest  row Have  can Okay  core pellets  support  support  in job buy sell only above  one software.  Set next Website  management  physical  Chain  door row tomato  get high  help measure  measure  signal  fruit business:  In list one day to know  Have  bag much  in turn  access  access  enter  Website,  How many orders are there and which products are most popular? To meet the needs and desires of customers, as well as a path for business1.2 Objectives and scope of the topic Understand business and e -commerce working methods.", "label": "human"}
{"ID": "00230005", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "development, I researched and designed a website with the topic: \" ANALYSIS DESIGN AND BUILDING CAFÉ CHAIN MANAGEMENT WEBSITE \" .", "label": "human"}
{"ID": "00230006", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Website information is always updated and always meets customers' information search needs. Besides, it also saves time expenses for customers.", "label": "human"}
{"ID": "00230007", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The direction  awake  active  dynamic,  regulation  submit  active  dynamic  terrible  joint,  love commercial  electronically, specifically the website that manages a chain of coffee shops.", "label": "human"}
{"ID": "00230008", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Part Front  end : Deliver  face live mandarin,  close  good  with core pellets + Have  position  power  find sword  product  Products,  favorable  convenient  give core pellets.", "label": "human"}
{"ID": "00230009", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Part Back  end : Thuan  convenient  give People  management  treat sports  work with the position  power  manage  product  Products,  single  row, home  bow grant,  theTo help give topic  talent  carry  count  real international,  me decided determined  select  door row Cafe  Zodi  is the subject for survey and research during the thesis writing process.", "label": "human"}
{"ID": "00230010", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Single  taste  consult  close Single  taste consult  close:  Shop  cafe Cafe  Zodi Land  only:  floor  11, 156 Million Vietnamese  Vuong,  River  Noi.", "label": "human"}
{"ID": "00230011", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Phone: 043 9743669 Formed and developed since 2009, the shop was opened to serve the needs bridge  eat drink  prize  thirsty  also like reward  awake  Cafe  belong to  much  guest  row.", "label": "human"}
{"ID": "00230012", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Bring style  way fart believe  young  central,  Zodi  Café  Have  taste mind  floating  turn on so with the shop  other.  The restaurant is located on the 11th floor, an ideal location to avoid the noise and dust from busy Trieu Viet Vuong street. Zodi Café is luxuriously and splendidly designed with a spacious, fresh space adorned with harmonious colors and a warm welcome from the owner and staff. That always brings a feeling of relaxation, comfort and satisfaction to any guest who comes to Zodi.", "label": "human"}
{"ID": "00230013", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Outside  tomato  get high,  Zodi  still collect  suck guest  row with much  thing  drink great  great,  new strange. There  Have  can To be  special  drinking. drinking  with My love,  Love  print  blue . . . good  the type born element  fruit fragrant  tasty  original matter;  cream  cool cold and chief  these  glass  Cocktails  sweet  sweet,  passionate, counter  flutter  smell  fragrant.  Opposite to  with people  literature  room,  shop  To be one land only prefer  Suitable for the few minutes of lunch break with a menu of attractive and rich fast food dishes  do comedy  heart  all real guest  umbrella  To be difficult  count  best. Labour  job management  physical  belong to  owner  weak  based above  paper  sheet  take note  Copy,  all labour  job even  up onion  defense  labour  To be much, from updating product lists to statistics, arranging work schedules...", "label": "human"}
{"ID": "00230014", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Still much  real access  in management  physical  generation  system equal  believe  learn  in management  physical  paternal  set and customer interaction.", "label": "human"}
{"ID": "00230015", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Page  web put row live gland  still Not yet  close  good  with People use, cause  for users who encounter some difficulties when using it.", "label": "human"}
{"ID": "00230016", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Generation  system  new Pros  point:+ Consistent issues in system management using information technology in internal management and customer interaction, solving inadequacies of the old system.", "label": "human"}
{"ID": "00230017", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Due price  core labour  belong to  branch  labour  turmeric  pine believe  High should  spend  fee set next A new system will be expensive.", "label": "human"}
{"ID": "00230018", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "From  job consult  close  door row management  physical  Chain  door row tomato  get high real international,  receive  see There are still many inadequacies and inconveniences.", "label": "human"}
{"ID": "00230019", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "To manage your own cafe chain, you need to build a website, to help manage the store's products, to attract more customers as well as  job buy sell return  should favorable  convenient  easy easy,  replied  response  all soft bridge  belong to  guest  row.", "label": "human"}
{"ID": "00230020", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Dedicated advice to customers, introducing the best product s,  edema  fit best with these  Love  bridge  but guest  row topic  go out.  Direction  guide  guest  thoughtful goods.", "label": "human"}
{"ID": "00230021", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Enter complete information before issuing invoices to customers. Managing product categories can add product categories when goods are imported and added to the system.", "label": "human"}
{"ID": "00230022", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  physical  product  Products  When  name  item Okay  create  and more  the belong count  product  Products  into the system  system.  Hold  clearly  love image  buy sell, joint collect  belong to  door row. Job check  check  Manager statistics must be performed daily.", "label": "human"}
{"ID": "00230023", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "After  When  collect  cross  and stool  accumulation  Love  bridge  belong to  guest  row, theylabour  People  management  treat will history  use Okay  the position  power  belong to generation  system.", "label": "human"}
{"ID": "00230024", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Employee management function: Allows viewing, adding, updating, deleting Find sword:  Aim help give core pellets  Have  can find sword  the face row,..", "label": "human"}
{"ID": "00230025", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Position  power  management  physical  warehouse:  . give permission  see, more,  access  Japan,After surveying the system to know the business process of a sales website, I built and developed the required functions, drew general usecase diagrams, detailed usecases, and blueprints. Detailed requirements specification, sequence diagrams, operations, state and class diagrams of the system .", "label": "human"}
{"ID": "00230026", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "A Use Case General Diagram is a diagram used in software system analysis and design to describe the functions and interactions between the main components of the system and the users (actors) involved.", "label": "human"}
{"ID": "00230027", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Use Case Overview Diagram is used to create an overview of the main system functions that the system provides to users. It helps identify actors in the system, main use cases and the relationships between them. Use cases represent specificFigure  3.1: General Use Case Diagram .", "label": "human"}
{"ID": "00230028", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "In a generic Use Case diagram, actors are represented by shapes such as circles or rectangles, while use cases are represented by shapes such as ovals or rectangles with edges. rounded. The relationship between actors and use cases is shown by arrows .", "label": "human"}
{"ID": "00230029", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Work  core Use case Work  core People  use, core pill, management  treat pellets Item destination  Login Describe _ Shift  history  use This prize  prefer  one People  history use generation  system post import  talent  clause  enter  generation  system.", "label": "human"}
{"ID": "00230030", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  main  Shift  history  use this catch  head  when work  core want post import enter  generation  system:", "label": "human"}
{"ID": "00230031", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The system displays a login screen with two fields: email and password. The agent enters email and password in these two fields.", "label": "human"}
{"ID": "00230032", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  extra  Import  lack pine believe In the basic flow, if user input is missing one of the two school  Love  bridge  or chief  two school  then generation  The system will display an error message stating that the input is missing and information has not been sent  arrive  machine  owner.  People  use Have can select  import  again  as the first step of the basic flow or cancel the login. At this point the use case ends.", "label": "human"}
{"ID": "00230033", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Import  wrong  email/confidential  password In the basic flow, if the user enters both required fields but has the wrong password or email, the server will check and detect the error. Login error message wrong  will Okay  show  town.  People  use Have  can select  retype  like step head  belong to  stream. streamQueen  thing  to sue  If wall labour,  generation  obstacle  again  page  master, companion  pine newspaper  post import  wall labour.  Reverse  again status  Thai The system remains the same.", "label": "human"}
{"ID": "00230034", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are not Bảng  3.2: Use case login   Work  core Use case Work  core People  use, core pill, management  treat pellets Item destination  Logout Describe _ Shift  history  use this prize  prefer  one people  history  use generation  system post import  talent  clause  enter  generation  system.", "label": "human"}
{"ID": "00230035", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  post import enter  generation  system:", "label": "human"}
{"ID": "00230036", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The system displays a login screen with two fields: email and password. The agent enters email and password in these two fields.", "label": "human"}
{"ID": "00230037", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  extra  Import  lack pine believe In the basic flow, if user input is missing one of the two school  Love  bridge  or chief  two school  then generation  The system will display an error message stating that the input is missing and information has not been sent  arrive  machine  owner.  People  use Have can select  import  again  as the first step of the basic flow or cancel the login. At this point the use case ends.", "label": "human"}
{"ID": "00230038", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Import  wrong  email/confidential  password In the basic flow, if the user enters both required fields but has the wrong password or email, the server will check and detect the error. Login error message wrong  will Okay  show  town.  People  use Have  can select  retype  like step head  belong to  stream. stream muscle  copy  or cancel  job log in. At this point the use case ends.", "label": "human"}
{"ID": "00230039", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Work  core Use case Work  core Core  pill, management  treat pellets Item destination  Change  honey  password Describe _ Give  permission  work  core change  honey  password above  generation  system Money  thing  to sue  People  use Satisfied  post import  enter  generation system  from  before Stream  the to sue  main  • People  use access  access  page  change  honey password.", "label": "human"}
{"ID": "00230040", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Leave any fields blank in the password reset subflow Import  wrong  determined  form  honey  password  live stream. stream  child  put again  password _ Import  again  honey  password  other  with honey password  live stream. stream  child  reset Password The system will display an input error message and has not sent information to the server. The user can choose to re -import as the first step of the basic flow or cancel the modification of account information. At this point the use case ends.", "label": "human"}
{"ID": "00230041", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230042", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Give  permission  core pellets  access  Japan  again  the pine believe  bag wrong or access  Japan  the pine believe  new Describe _ Core  pellets  fix change  again  the pine believe  belong to copy  close  above  generation system Money  thing  to sue  People  use Satisfied  post import  enter  generation system  from  before Stream  the to sue  main  • Core  pellets  access  access  page  fix pine believe  fish core.", "label": "human"}
{"ID": "00230043", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  extra  Are not Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230044", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Fix pine believe  core pellets  above  generation  system Describe _ Give  permission  Admin  treat pellets  Fix pine believe core pellets  above  generation system Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230045", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  fix pine believe  core pellets  above  generation  system:", "label": "human"}
{"ID": "00230046", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  core pellets Generation  system  show  town  name  book  core pellets Admin  treat pellets  select  core pellets  need  fix pine believe Generation  system  show  town  form  fix pine believe core pellets Administration  import member  input information  of employee  need to edit and press edit The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230047", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Admin  treat pellets Item destination  Fix pine believe  core pellets  above  generation  system Describe _ Give  permission  Admin  treat pellets  Fix pine believe core pellets  above  generation system Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230048", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  fix pine believe  core pellets  above  generation  system:", "label": "human"}
{"ID": "00230049", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  core pellets Generation  system  show  town  name  book  core pellets Admin  treat pellets  select  core pellets  need  fix pine believe Generation  system  show  town  form  fix pine believe core pellets Administration  import member  input information  of employee  need to edit and press edit The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230050", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Admin  treat pellets Item destination  Find sword  core pellets  in generation  system Describe _ Give  permission  Admin  treat pellets  find sword  core pellets  in generation system  to real presently  the position  power  other Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230051", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  find sword core pellets  in generation  system:", "label": "human"}
{"ID": "00230052", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  core pellets Generation  system  show  town  name  book  core pellets Admin  treat pellets  press  enter  Umbrella  find sword Admin  treat pellets  import  pine believe  core pellets need  find sword The system displays employees with the same information as the entered input Administrators can select employees to search for to perform other operations Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether  belong to generation  system  Are not replace  change.", "label": "human"}
{"ID": "00230053", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Board  3.7: Special  description  Use case  Find sword  core pellets    Product Management  Work  core Use case Work  core Admin  treat pellets Item destination  More  product  Products  enter  generation  system Describe _ Give  permission  Admin  treat pellets  more  product Products  enter  generation  system to Okay  stool  permission Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230054", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  more  product Products  enter  generation  system:", "label": "human"}
{"ID": "00230055", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  product  Products Generation  system  show  town  name  book  product Products Admin  treat pellets  press  more  new Generation  system  show  town  form  more  new product Products Admin  treat pellets  import  input. input  pine believe belong to  product  Products The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil WhetherQueen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230056", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  fix pine believe  product  Products  above  generation  system:", "label": "human"}
{"ID": "00230057", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  product  Products Generation  system  show  town  name  book  product Products Admin  treat pellets  select  product  Products  need  fix pine believe Generation  system  show  town  form  fix pine believe product  Products The administrator enters the information of the product that needs editing and clicks edit The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230058", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Admin  treat pellets Item destination  Erase  product  Products  out generation  system Describe _ Give  permission  Admin  treat pellets  erase  product Products  go out  out generation  system Money  thing  to sue Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230059", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  more  product Products  enter  generation  system:", "label": "human"}
{"ID": "00230060", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  product  Products Generation  system  show  town  name  book  product Products The administrator moves to the category to delete and press delete The system checks the information and saves the information to the system Stream  the to sue  extra  Are not Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230061", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Admin  treat pellets Item destination  Find sword  product  Products  in generation  system Describe _ Give  permission  Admin  treat pellets  find sword product  Products  in generation system  to real presently  the position  power  other Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230062", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  find sword product  Products  in generation  system:", "label": "human"}
{"ID": "00230063", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  product  Products Generation  system  show  town  name  book  product Products Admin  treat pellets  press  enter  Umbrella  find sword Admin  treat pellets  import  pine believe  product Products  need  find sword The system displays products with similar information  as input entered Administrators can select products to search for to perform other operations Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether  belong to generation  system  Are not replace  change.", "label": "human"}
{"ID": "00230064", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Work  core Use case Work  core Admin  treat pellets Item destination  More  warehouse  enter  generation  system Describe _ Give  permission  Admin  treat pellets  more  warehouse enter  generation  system  to Okay stool  permission Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230065", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  more  warehouse enter  generation  system:", "label": "human"}
{"ID": "00230066", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  warehouse Generation  system  show  town  name  book  warehouse Admin  treat pellets  press  more  new Generation  system  show  town  form  more  new warehouse Admin  treat pellets  import  input. input  pine believe belong to  warehouse The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are notOkay  replace  change.", "label": "human"}
{"ID": "00230067", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Use case specification Add warehouse  Work  core Use case Work  core Admin  treat pellets Item destination  Fix pine believe  warehouse  above  generation  system Describe _ Give  permission  Admin  treat pellets  more  warehouse enter  generation  system  to Okay stool  permission Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230068", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  fix pine believe  warehouse  above  generation  system:", "label": "human"}
{"ID": "00230069", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  warehouse Generation  system  show  town  name  book  warehouse Admin  treat pellets  select  warehouse  need  fix pine believe Generation  system  show  town  form  fix pine believe warehouse Admin  treat pellets  import  input. input  pine believe belong to  warehouse  need  fix and press edit The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230070", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": ": Use case specification Edit warehouse  Work  core Use case Work  core Admin  treat pelletsMoney  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230071", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  more  warehouse enter  generation  system:", "label": "human"}
{"ID": "00230072", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  warehouse Generation  system  show  town  name  book  warehouse The administrator moves to the category to delete and press delete The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230073", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": ": Use case specification Delete inventory  Work  core Use case Work  core Admin  treat pellets Item destination  Find sword  warehouse  in generation  system Describe _ Give  permission  Admin  treat pellets  find sword warehouse  in generation  system to real presently  the position  power  other Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230074", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  find sword warehouse  in generation  system:", "label": "human"}
{"ID": "00230075", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pellets  real presently  position  power management  physical  warehouse Generation  system  show  town  name  book  warehouse Admin  treat pellets  press  enter  Umbrella  find sword Admin  treat pellets  import  pine believe  warehouse need  find sword Generation  system  show  town  the warehouse  Have pine believe  alike  like input entered Administrators can select the warehouse to search tospecial  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230076", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Work  core Use case Work  core Admin  treat pellets Item destination  More  home  product  export  enter  generation  system Describe _ Give  permission  Admin  treat pellets  more  home  product export  enter  generation  system to Okay  stool  permission Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230077", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The administrator performs property management functions  export Generation  system  show  town  name  book  home product  export Admin  treat pellets  press  more  new Generation  system  show  town  form  more  new home product  export Admin  treat pellets  import  input. input  pine believe belong to  home  product  export The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230078", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Admin  treat pellets Item destination  Fix pine believe  home  product  export  above  generation system Describe _ Give  permission  Admin  treat pellets  Fix pine believe home  product  export  above generation  system Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230079", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  fix pine believe  home  product  export  above  generation  system:", "label": "human"}
{"ID": "00230080", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The administrator performs property management functions  export Generation  system  show  town  name  book  home product  export Admin  treat pellets  select  home  product  export  need fix pine believe Generation  system  show  town  form  fix pine believe home  product  export The administrator enters the manufacturer's information that needs to be edited and clicks edit The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230081", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Admin  treat pellets Item destination  Erase  home  product  export  enter  generation  system Describe _ Give  permission  Admin  treat pellets  erase  home product  export  enter  generation  system to Okay  stool  permission Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230082", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want erase  home  product export  enter  generation  system:", "label": "human"}
{"ID": "00230083", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The administrator performs property management functions  export Generation  system  show  town  name  book  home product  export The administrator moves to the category to delete and press delete The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230084", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Admin  treat pellets Item destination  Find sword  home  product  export  enter  generation system Describe _ Give  permission  Admin  treat pellets  find sword  home product  export  enter  generation system  to Okay  stool  permission Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230085", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  find sword Manufacturers in the system: •  Administrators perform producer management functions Generation  system  show  town  name  book  home product  export Admin  treat pellets  press  enter  Umbrella  find sword The administrator enters the manufacturer information to find  sword Generation  system  show  town  the home  product export  Have  pine believe  same as input entered Administrators can select manufacturers to search for to perform other operations Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230086", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are not Board  3.19:  Special  description  Use case  Find sword  pine believe  home  product  export     Figure 3.9: Use Case Order management.", "label": "human"}
{"ID": "00230087", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Work  core Use case Work  core Admin  treat pill, Staff _ Item destination  Create  chemistry  single  sell row Describe _ Give  permission  Admin  treat pill, Core  pellets  create chemistry  single  sell row Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230088", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pill, core pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want create  chemistry  single sell row:", "label": "human"}
{"ID": "00230089", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pill, Core  pellets  real presently  position power  management  order management Generation  system  show  town  name  book  chemistry single Admin  treat pill, Core  pellets  press  more  new Generation  system  show  town  form  more  new chemistry  single Admin  treat pill, Core  pellets  import  input. input  pine believe  belong to  Order includes product, quantity,...", "label": "human"}
{"ID": "00230090", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The system checks the information and saves the information to the system Stream  the to sue  extra  Import  lack pine believe  or wrong  evil Whether Love  bridge  dense special  Are notreplace  change.", "label": "human"}
{"ID": "00230091", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pill, core pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want  print  chemistry  single sell row after When  guest  row Satisfied  bar maths:", "label": "human"}
{"ID": "00230092", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Admin  treat pill, Core  pellets  real presently  position power  management  order management Generation  system  show  town  name  book  chemistry single Admin  treat pill, Core  pellets  press  chemistry  single want  print  and select print Set create  machine  print  and body  receive  print chemistry  single Stream  the to sue  extra  • Error  or Not yet  Have  machine  print Chemistry  single  Satisfied  bag cancel  Are not  can print Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Are not  replace  change.", "label": "human"}
{"ID": "00230093", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Work  core Use case Work  core Admin  treat pill, Staff _ Item destination  See newspaper  fox system  list Describe _ Give  permission  Admin  treat pill, Core  pellets  see newspaper  fox system list Money  thing  to sue  Already  post import  enter  generation  system  with role.", "label": "human"}
{"ID": "00230094", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "role management  treat pill, core pellets Stream  the to sue  main  Shift  history  use This catch  head  When  work  core want see newspaper  fox system  list:", "label": "human"}
{"ID": "00230095", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Administrators and Employees select the statistical report they want to view Stream  the to sue  extra  Are not Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Are not  replace  change.", "label": "human"}
{"ID": "00230096", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Work  core Use case Work  core Core  pill, Admin  administrator _ Item destination  Save  again  pine believe  guest  row Satisfied  ever buy row in generation system Describe _ Guest  row bow grant  pine believe  and core pellets  , management The administrator will save customer information in the system Money  thing  to sue  Core  pellets  or management  treat pellets  Satisfied post import  enter  generation system.guest  row.", "label": "human"}
{"ID": "00230097", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  extra  Are not Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230098", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Describe _ Core  pellets  , management  treat pellets  fix pine believe belong to  client _ above  generation  system Money  thing  to sue  Core  pellets  or management  treat pellets  Satisfied post import  enter  generation system.", "label": "human"}
{"ID": "00230099", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  extra  In school  fit core pellets  or management  treat pellets Are not Have  permission  fix guest  row, then generation  systemQueen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230100", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are not Table 3.24: Use case specification Edit customer  Work  core Use case Work  core Core  pill, Admin  administrator _ Item destination  Give  permission  core pellets  or management  treat pellets  erase  pine believe guest  row above  generation  system.", "label": "human"}
{"ID": "00230101", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Describe _ Core  pellets  , management  treat pellets  erase  pine believe  belong to  guest  row above  generation  system Money  thing  to sue  Core  pellets  or management  treat pellets  Satisfied post import  enter  generation system.", "label": "human"}
{"ID": "00230102", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  extra  In school  fit core pellets  or management  treat pellets Are not Have  permission  erase  guest  row, then generation system  will pine newspaper  for them.", "label": "human"}
{"ID": "00230103", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230104", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The point  open  wide  Are notWork  core Core  pill, Admin  administrator _ Item destination  Give  permission  core pellets  or management  treat pellets  find sword  guest row above  generation  system  according to  the pepper will other  together.", "label": "human"}
{"ID": "00230105", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Stream  the to sue  extra  Import  lack pine believe In case an employee or administrator does not have permission to search for a customer, the system will notify them.", "label": "human"}
{"ID": "00230106", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Love  bridge  dense special  Are not Queen  thing  to sue  When  the sports  work  wall labour,  evil Whether belong to  generation  system  will Okay  replace  change.", "label": "human"}
{"ID": "00230107", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Schedule  thing  week  on one's own  position  power  Admin  physical  warehouse Image  3.16:  Schedule  thing  week  on one's own  position  power  Admin  physical warehouse.", "label": "human"}
{"ID": "00230108", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Schedule  thing  week  on one's own  position  power  Admin  physical  product ProductsImage  3.17:  Schedule  thing  week  on one's own  position  power  Admin  physical  product Products.", "label": "human"}
{"ID": "00230109", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Schedule  thing  week  on one's own  position  power  Admin  physical  home product  export Image  3.18:  Schedule  thing  week  on one's own  position  power  Admin  physical home  product  export.", "label": "human"}
{"ID": "00230110", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Gender  introduction Java is a popular and powerful programming language developed by Sun Microsystems (now Oracle). It debuted in 1995 and has since become one of the most popular programming languages in the world.", "label": "human"}
{"ID": "00230111", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Physical  due choose  select Easy to get started: Spring Boot helps reduce the complexity of configuration and deployment  response  use Spring  transmit  system.  It bow grant  one number structure  image  wear  determined  smart  and on one's own  dynamic  structure  image based  above  regulation  wish.  Thing  This help the home  broadcast  develop  Get started quickly and focus on developing the main functionality of the application.", "label": "human"}
{"ID": "00230112", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Powerful integration: Spring Boot integrates well with other popular technologies such as Spring Data, Spring Security and Spring Cloud, helping to develop scalable applications and easily integrate with different services.", "label": "human"}
{"ID": "00230113", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Add copper  strong  strong:  Spring  Boots  Have  one add copper  winter  island  and much  talent  support material  support.  Thing  This copper  means  that Have  much source  talent  original  and support  support  from  add community to solve problems, find information and share knowledge.", "label": "human"}
{"ID": "00230114", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Powerful automation and architecture: Spring Boot provides tools and features on one's own  dynamic  chemistry  strong  strong,  bag including  on one's own dynamic  structure  image,  management  physical  extra  belong  and deployment response  use. Thing  This help reduce  labour  strength  and time time broadcast development,  copper  time ensure application stability and reliability.", "label": "human"}
{"ID": "00230115", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Calculate  sacred  active  and open  wide:  Spring  Boots  give permission broadcast  develop  the response  use Java follows the traditional web application model (Servlet/JSP) or the RESTful application model  API. It also support support  much  labour  turmeric  front -end like Thymeleaf,  Angular and  React.", "label": "human"}
{"ID": "00230116", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Thing  This give permission  Friend  build  build  the response  use Multi  form  and sacred  active  according to the specific needs of the project..", "label": "human"}
{"ID": "00230117", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "React is a JavaScript library developed and maintained by Facebook. It is used to build user interfaces (UI) for web applications. React  Have  ants bamboo  based above  the wall part (component -based  architecture)  and algorithm  so compare other  special  pine bright  (intelligent  diffing  algorithm)  help give job Front -end development is more effective as complexity increases. React  bow grant  much profit  useful,  bag including  speed  degree,  sacred  active  and signal  capacity  High.", "label": "human"}
{"ID": "00230118", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "It that's OK  history  use wide  cobble  by the labour  ty big like Apple,  Netflix,  Paypal and much  another company 4.2.2 Physical  due choose  select Speed: React allows developers to use individual parts of their application on both the client -side and server -side, helping to speed up the development process.", "label": "human"}
{"ID": "00230119", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Sacred  active:  Code  React  easy tell maintain  than so with the framework  side before  other  and Flexible due to its modular structure. This helps save time and costs for businesses.", "label": "human"}
{"ID": "00230120", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Performance: React is designed to provide high performance. The core element of the framework provides a virtual DOM programming and server -side parsing, helping complex applications run faster.", "label": "human"}
{"ID": "00230121", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Based on the points analyzed above, ReactJS has been decided by me as the frontend language to use for this DATN.", "label": "human"}
{"ID": "00230122", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Gender  introduction WebSocket is a two -way data transfer protocol on the web that allows transmission  load evil Whether  in time time real between  submit  Browser  web and machine  owner.  WebSocket allows a connection to be maintained between the client and the server, so communication is possible  Okay  send Go and receive again  one way signal  fruit and fast quickly  but Are not  need  A new connection must be established each time information is transmitted 4.3.2 Physical  due choose  select Bidirectional data transmission: WebSocket allows bidirectional data transmission  custom  between  machine  guest  and machine  owner,  help give the response  use web time time real like a game  play live gland,  response  use trickDetails  frugal  power  quantity:  WebSockets  details  frugal  power  quantity  than so with the prize  Other direct data transmission methods such as Ajax or Comet.", "label": "human"}
{"ID": "00230123", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Based  enter  these  point  Okay  stool  accumulation  above,  Websockets  Satisfied Okay  me decided  determined  to integrate into the message function used for this DATN.", "label": "human"}
{"ID": "00230124", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Gender  introduction A database is a system of structured information, stored on storage devices to satisfy the simultaneous information exploitation requirements of many people.", "label": "human"}
{"ID": "00230125", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Using this database system will overcome the shortcomings of this method save reserve  below  form  generation  system  practice  believe  there  To be:  reduce coincide  repeat  pine believe  live level  lowest, ensuring data consistency and integrity, ensuring data is retrieved accordingly  much  way other  together,  from much  People  other  together  and much  response  use other  each other, increasing the ability to share information.", "label": "human"}
{"ID": "00230126", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "It is developed by the corporation  Oracle  and To be  one in these  generation management  treat muscle  department  evil Whether  spectrum  variable  best above world _ 4.4.2 Physical  due choose  select Code  source  open:  MySQL  To be  one attend  judgment  code  source  open,  thing This Have  means  To be  Friend  maybe  history  use, depends  correction  and stool coordinate  It exempt  fee. Code  source  open  bow grant  count  transparency and auditability, helping to ensure security and speedy bug fixes.", "label": "human"}
{"ID": "00230127", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "High performance: MySQL is optimized to provide high performance and good processing in heavily loaded applications. It supports query, index, and caching optimization, which improves query speed and response time.", "label": "human"}
{"ID": "00230128", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Degree  believe  trust High:  MySQL  Have  possible  power  treat physical  and management  physical  evil Whether  big but Are not  loss of stability and reliability.", "label": "human"}
{"ID": "00230129", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "It supports features such as backup, data recovery, and data replication capabilities to ensure data safety and availability .ing to split data across multiple servers. It also supports features like partitioning to manage large data and enhance performance.", "label": "human"}
{"ID": "00230130", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Support  support  standard  SQL:  MySQL  obey  defense  standard  SQL  (Structured  Query Language), article  This Have  means  To be  It soy sauce  prefer  with much  language language  create  submit  and labour  tool manage  muscle  department  evil Whether  other.", "label": "human"}
{"ID": "00230131", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Add copper  and talent  Whether  wind  rich: MySQL  Have  one add copper  boiling dynamic  and Plenty of documentation, examples, and forums to support users. You can search and  divide  shall  pine believe,  meet  remove  the specialized  family  and receive Okay  the support  support  in too database development and operations.", "label": "human"}
{"ID": "00230132", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "View The View part in the MVC (Model -View -Controller) architecture is an important component, responsible for displaying data to users and interacting with them. This is where user requests are represented as user interfaces, including websites, mobile applications, and desktop applications.", "label": "human"}
{"ID": "00230133", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The View does not have direct access to the database, but only receives information from the Controller and Model through requests.", "label": "human"}
{"ID": "00230134", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Views play a very important role in creating a beautiful and easy -to-use user experience. It is responsible for designing the user interface, including data display, buttons and images. Views also provide user feedback and perform functions such as user authentication and error handling .", "label": "human"}
{"ID": "00230135", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Controller In the MVC architecture, the Controller is responsible for monitoring the processing of requests and performing logical tasks. It interacts with the Model to query the database and return data to the View. View then uses this data to display the corresponding information to the user.", "label": "human"}
{"ID": "00230136", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "With MVC architecture, View and Controller operate independently of each other, allowing for easy modification and maintenance. This helps developers focus on data handling in the Model without worrying about user interface andThe Model part in the MVC architecture for a game system plays a very important role, it contains data related to the game, manages the state of the game, and implements methods to process data.", "label": "human"}
{"ID": "00230137", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "In a game, the Model will store information about game objects such as characters, items, terrain and events in the game. It is also responsible for determining the rules of the game and performing actions in the game. It may include data storage files to store information about stages, scores, player levels, and in -game resources.", "label": "human"}
{"ID": "00230138", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "One of the special requirements of the Model in the MVC architecture for the game system is to be able to handle events and interact with players. The model needs to respond quickly to the player's actions, such as moving, attacking, and using skills. It also needs to manage in -game resources, including items, money and scores, ensuring fairness and game balance.", "label": "human"}
{"ID": "00230139", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "The Model is also responsible for meeting the requirements of the Controller and View. The Controller uses the Model to get information and perform actions, like updating data  and event handling. Meanwhile, View uses data provided by Model to display corresponding information to the player.", "label": "human"}
{"ID": "00230140", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "One advantage of MVC architecture in games is its flexibility. Different parts of the game system can be designed and implemented independently of each other, allowing developers to focus on a specific part of the game system. With a clear division between Model, View and Controller, programmers can also easily perform game application maintenance and development in a more efficient way. .", "label": "human"}
{"ID": "00230141", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Khi khách  hàng  muốn  mua hàng  trên hệ thống  thì sẽ phải đăng  kí tài khoản  trên hệ thống.  Khách  hàng  sẽ chọn  đăng  kí và nhập  các thông  tin cần thiết mà giao diện yêu cầu nhập.", "label": "human"}
{"ID": "00230142", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Sau khi xác nhận thì hệ thống kiểm tra thông tin: Nếu hợp lệ sẽ lưu CSDL, ngược lại nếu xảy ra lỗi sẽ thông báo thất bại và cho phép nhập lại.", "label": "human"}
{"ID": "00230143", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Khi khách hàng muốn mua hàng trên hệ thống thì sẽ phải đăng nhập tài khoản đã đăng  kí trên hệ thống.  Khách  hàng  sẽ chọn  đăng  nhập  và nhập  tên tài khoản  và mật khẩu. Sau khi xác nhận thì hệ thống kiểm tra thông tin: Nếu tồn tại sẽ đăng nhập tài khoản khách hàng, ngược lại nếu xảy ra lỗi sẽ thông báo thất bại và cho phép nhập lại.", "label": "human"}
{"ID": "00230144", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "When you want to add a product for sale, the system admin (Employee or Manager) and the product add function then enter product information and confirm saving. After confirmation, the system checks the information: If valid, the database will be saved; otherwise, if an error occurs, it will notify failure and allow re -entry .", "label": "human"}
{"ID": "00230145", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Notify successful booking if customer confirms. Return to the shopping cart5.3.1 Check try position power login   No School  fit Quy submit  check try Conclude  fruit  expect wait Conclud e fruit first Testcase  first 1. Import  wrong  talent clause 2. Import  honey password 3. Click  post import  Pine newspaper  talent  clause Are not exist _ Obtain 2 Testcase  2 1. Enter  account  _ correct 2. Import  honey password  wrong 3. Click  post import  Honey  password  Are not  main body  Obtain 3 1. Cancel drum talent  clause 2. Cancel blank password 3. Click  log in In view. view  show town,  Love Requires user input enough  talent  clause, password _ Cause  close  love correct  with logic. logic  Obtain 4 Testcase  4 1. Import  wrong determined  form talent  clause 2. Enter the correct password 1. Pine newspaper  honey password  wrong 2. Data  Whether  Okay  code chemistry  meets security standards  Obtain 5 Testcase  5 1. Enter  account  _ correct 2. Enter the correct password  3. Click  post import  Transfer  direction  arrive  page owner corresponds  to  the user 's rights   Obtain  No School  fit Quy submit  check  try Conclude  fruit expect  wait Conclud e fruit 1 Testcase  1 1. Import  wrong  determined  Pine newspaper import  wrong determined  form  Obtain form  email  email,  import  again honey  password  wrong.", "label": "human"}
{"ID": "00230146", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Click  register _  No School  fit Quy submit  check try Conclude  fruit  expect  wait Conclud e fruit first Taste mind put camera.", "label": "human"}
{"ID": "00230147", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Jobs that can be done from home After completing the report, the system has achieved features that meet user needs. Build a system that includes the following features: View product details, view products, view posts, search, comment, order, manage products (search, add, edit, delete), manage lists product categories (search, add, edit, delete), post management (search, add, edit, delete), statistical reports, log in, log out. Design a friendly, eye -catching, easy -to-use website interface for tablets and laptops.", "label": "human"}
{"ID": "00230148", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Limitations The interface has not yet been able to apply discount codes, there is no forgot password function, there is no function to register to receive notifications of new products and promotions through gmail for customers, the implementation time is still limited.", "label": "human"}
{"ID": "00230149", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "Development direction Completely build functions such as: Integrating mobile interface, applying fake discount codes when paying, building forgotten password function, registration function to receive notifications of new products and regularTALENT  WHETHER  HAM  REVIEW    Tutorialspoint,  MVC  Framework  - Introduction . [On].  Available:  https:", "label": "human"}
{"ID": "00230150", "file_name": "Analysis Design And Building Café Chain Management Website.", "content": "J. Terra, Entity Component System: An Introductory Guide . [On]. Avail able:   - component - system  introductory -guide -article#what_is_an_entity_  component_system  (visited on 03/05/2023).", "label": "human"}
{"ID": "00240001", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The need for logistics services is rising along with society, science, and the economy. Since that time, logistics warehouse services are being developed and heavily invested in, becoming a crucial supply chain link. There are many different types of logistics warehouses, including bonded warehouses, transit warehouses,private warehouses, public warehouses, automated warehouses, and climate con trolled warehouses (Container Freight Station). Each warehouse will have uniquequalities appropriate to that warehouse’s function, however the majority of logis tics warehouses must guarantee that the commodities are stored in tact, with quality assurance, and unaffected by other internal or external variables. Additionally, thewarehouse especially private logistics warehouses and automated logistics warehouses must oversee and guarantee the efficient flow of activities within the facil ity.", "label": "human"}
{"ID": "00240002", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Most logistics warehouses still perform manual inventory today. Although it is simple to apply, this system, which has been used for thousands of years, carries hazards that have a direct impact on the management of items in the warehouse.", "label": "human"}
{"ID": "00240003", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Manual inventories do not accurately reflect the real condition of the products in the warehouse and are not very reliable. In order to improve the accuracy of theinventory data and satisfy the needs of the management system, an automated inventory technique must completely replace the conventional manual method. Au tomation of the inventory and warehouse rotation processes can help businessescontrol and manage items in the best warehouse, especially for logistics organi zations. Since then, businesses have been constantly in the mood to actively track the flow of commodities, changes in the market, and develop strategic or tactical business decisions.", "label": "human"}
{"ID": "00240004", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Also, as a commodities logistics warehouse engages in constant import and ex port operations throughout the day, the items are moved and organized in a messyway. This has an impact on other warehouse activities as well as the goods manage ment process and does not maximize the storage area in the warehouse. Certainly, first in, first out (FIFO) and out of stock regulations must always be followed whiledelivering items from a logistics warehouse. Moreover, goods must always be suit ably placed and accessible for picking activities (FEFO). Inventory rotation, also known as internal rotation, is the process of routinely inspecting and rearranging the items in the warehouse to maintain this.Instead of the conventional manual manner of working that requires a lot of effort and resources like previously, the industrial revolution 4.0 has significantly altered the thinking of organizations today. Businesses involved in logistics arepaying attention to how they might use technology and alter their operating procedures. The technology used for the warehouse management process and the opera tions taking place in the warehouse must be adaptable to suit the needs accordingto each type of warehouse’s characteristics and the type of items kept in that ware house. Technology like autonomous vehicles (AGVs), working robots (Cobots), theinternet of things (IoT), etc., have generated a lot of hype, but they all demand sig nificant investment and are not well suited for private logistics warehouses. Also, the usage of smart contactless cards like RFID in warehouse management by big businesses like Amazon, Zara, Uniqlo, and BJC Healthcare is evidence that this technology will soon become popular.", "label": "human"}
{"ID": "00240005", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "These cards enable repeated reading and loading of product data into the card, but they are rather expensive to purchase and necessitate extensive equipment and technological investment. RFID tags are also available that can only be read for very little money but nonetheless efficiently regulate items.", "label": "human"}
{"ID": "00240006", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "To identify the benefits that need to be promoted and current shortcomings that need to be addressed in order to address the issues outd in section 1.1 , this studyhas undertaken a survey of applications and logistics warehouse management sys tems for firms deployed in the market. Applications that support management andinventory using RFID are also available on the market, including Senitron, GaoR FID, and Trackify. Popular goods management support programs include Sapo, Misa, SAP, and others. All of these software include features to manage inventory,import and export data, and information on commodities to assist firms in increas ing the effectiveness of their logistics and business management.", "label": "human"}
{"ID": "00240007", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Every application, nevertheless, has drawbacks that prevent firms from using them to their full potential in terms of managing and controlling their inventory of items. It contains the following issues that existing applications are having. The first is that the majority of programs are solely used for inventory management, and the inventory function only shows the overall amount of products, not the specifics of their status. Second, when rotating the warehouse, organizing the items, and maximizing the storage space, the outcomes of the inventory procedure were not applied. Thirdly, there are no features to assist retrieving the history of modifica-tions made to the inventory in the warehouse. These actions are crucial becausethey enable firms to readily trace items and identify the root of issues or faults. Fi nally, the software has not been used to focus and develop the warehouse inventory reporting.", "label": "human"}
{"ID": "00240008", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "This essay concentrates on developing an automatic inventory module that is in tegrated into the digital workspace management system DxClan after recognizing the shortcomings of programs that support management, inventory, and inventory rotation in logistics warehouses. DxClan now has two more built-in features: (1) automatically inventory warehouse products using RFID tags and readers, and (2) recommend inventory rotation based on inventory results. Also, two components of the DxClan system’s initial functionality have been enhanced and upgraded,including: (3) generating and assigning RFID codes to items during import pro cessing and (4) searching and tracing changes in goods during storage, after the operations of warehousing.", "label": "human"}
{"ID": "00240009", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In modern logistics warehouses, there are numerous techniques to inventory the items. At warehouses where categorizing products is not too complex, the handcounting method is still frequently utilized. Also, it is customary in larger businesses to integrate scientific technologies in the management process. Each ap proach, though, has advantages and disadvantages of its own. In my thesis, I’vechosen to propose a solution based on Radio Frequency Identification (RFID) tech nology, which uses radio waves to identify objects.", "label": "human"}
{"ID": "00240010", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "This thesis has developed a common warehousing procedure to assign RFID numbers to items during the importation process. An RFID code will be assigned in conjunction with batching the products throughout the import process. A new consignment will be given an RFID code as soon as it enters the warehouse for management and tracking purposes. Also, each RFID tag has the ability to retrieve the information related to the goods that are attached to it. Also, to complete theprocess of storing the items, this study reuses APIs in the \"Digital workspace sys tem DXClan.com\" system.", "label": "human"}
{"ID": "00240011", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "This thesis has developed an automatic inventory procedure coupled with RFIDtags to implement automatic inventory with them. From there, companies can eas ily decide whether to perform automatic inventory based on their needs. After the inventory process is complete, the data are provided in detail so that firms may monitor, manage, and decide on the best course of action. Also, this study reuses the \"Digital workspace system DXClan.com\" APIs to carry out the task of storingdata and allocating tasks to the objects taking part in this inventory.", "label": "human"}
{"ID": "00240012", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "It is vital to base inventory rotation recommendations on the findings of the most current inventory as well as the enterprise’s actual inventory state in order to be appropriate and effective. To make sure that the items are transported to the desired place or to acquire the outcomes of the inventory rotation exactly as planned, it is required to re-invent the inventory after the warehouse has been turned.", "label": "human"}
{"ID": "00240013", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Finally, all items must be RFID-equipped and properly batched in order to be able to search for and monitor changes in goods during import, export, and storage.", "label": "human"}
{"ID": "00240014", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Through each import, export, and transfer operation, the information kept in the system must reflect reality. The \"DXClan.com Digital Workspace System\" solution also makes use of APIs to make it simple to query data from the warehouse.", "label": "human"}
{"ID": "00240015", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The DXClan.com digital workplace solution incorporates the characteristics dis cussed in this essay. Information and Communication Technologies Joint Stock Corporation created this system (VNIST). The system offers business solutions for digital transformation, with a focus on logistics enterprises.", "label": "human"}
{"ID": "00240016", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ReactJS and Redux are used for front-end programming in this thesis, MongoDB is used for database storage, and NodeJS and ExpressJS are used for backend programming. The chosen technologies are simple to implement on both traditional server architectures and cutting-edge cloud computing platforms, contribut ing to the system’s versatility.", "label": "human"}
{"ID": "00240017", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ReactJS, a Javascript library from Facebook, enables the development of highly interactive on applications that improve user experience. With MongoDB, anon-relational database management system, you may easily add, expand, and con struct data structures that are free of restrictions. NodeJS is a technology that makes it simple and easy to add new features to on applications. The MERN Stack, a combination of the three technologies mentioned above, makes it simple to grow and enhance the system, enhancing efficiency and flexibility.", "label": "human"}
{"ID": "00240018", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Chapter 2 : Presenting the survey and analysis of the need to apply practical applications with the level of responsiveness of applications already available on the market to support warehouse management. In order to draw out the advantages they bring as well as the shortcomings that still exist in that product, based on that, perfect the functions that we build.", "label": "human"}
{"ID": "00240019", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Chapter 3 : Introduction of technologies used in the study are RFID technol-ogy and technologies used to build warehouse management applications as well as DxClan systems. From there, how these technologies can be closely combined to create an application with good quality, high performance and fully meet the needs of enterprises.", "label": "human"}
{"ID": "00240020", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Chapter 4 :Showcase the deployment, creation, and development of applica tions. The application development and deployment process is clearly presented in stages including: (i) architectural design; (ii) detailed design; (iii) applicationdevelopment; (iv) test and deploy the application. The application is built, devel oped and divided by modules to ensure easy integration and development of new features as well as maintenance of old systems.", "label": "human"}
{"ID": "00240021", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Chapter 5 : Presenting solutions and contributions of construction applications and the practical benefits they bring when applied. Compare and see the highlights of the application we have built against other similar applications available in the market. Identify the benefits and highlights that the application brings in inventory and warehousing.", "label": "human"}
{"ID": "00240022", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Chapter 6 : Presenting the results achieved in the thesis, future developmentorientation of the application. Present the experiences learned during the research.The first chapter has presented why I conducted this project, the scopes and ap proaches that I took to fulfill the requirements and the structure of the thesis. In this chapter, I will discuss some similar applications in the market and their advantages and disadvantages, then give an overview of the application’s functionalities. Some major use cases will also be specified.", "label": "human"}
{"ID": "00240023", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "A logistics warehouse is a storage facility used to hold products transiently while they are being transported and distributed. When items are being transportedfrom the point of production to the final destination or when they are being distributed from warehouses to agents and customers, logistics warehouses are frequently utilized to load, store, and manage the commodities. Ultimately, the opera tion, control, cost-savings, and process management of warehouses are frequently optimized.", "label": "human"}
{"ID": "00240024", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Businesses must pay attention to building suitable warehouse management pro cesses, arranging and classifying items in the warehouse in a scientific manner, andusing technology applications to support management if they are to manage logis tics warehouses efficiently. In order to guarantee that the items are constantly in the finest condition, efficient warehouse management, in particular, must regularly monitor and inspect the commodities. Hence, inventory work is always crucial for all warehouses, not just logistics warehouses. Businesses may identify the precise quantity and quality of the actual items in the warehouse using the inventory, which also aids in the early identification of management process mistakes.", "label": "human"}
{"ID": "00240025", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Moreover, rotating inventories or moving inventory internally helps organiza tions manage inventory more efficiently and stream warehouse operations by lowering expenses and storage space requirements. In a while, the majority of firms conduct their inventory processes manually, which does not reflect the actual state of their stock. Moreover, the rules for rotating inventory in warehouses have notbeen fully followed. satisfy the needs of the company. Thus, it is required to re place the manual inventory approach with an automation method and carry out frequent rotation of goods after each inventory in order to satisfy the demands of businesses in managing goods at logistics warehouses.", "label": "human"}
{"ID": "00240026", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "There are numerous applications for supporting logistics warehouse manage ment available on the market right now, including MISA, SAP, KiotViet, and Dx-Clan. For enterprises, these programs have offered features to address issues withcommodities management, warehouse management, etc. However, due to each ap plication’s unique benefits and limitations, proper scale, and targeted users, not all applications can handle warehouses and logistics well.", "label": "human"}
{"ID": "00240027", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Application Advantage Disadvantages Warehouse management software MISASME.NETThe application meets the func tions of goods management based on classification and management of import - export inventory. Support tracking shipments and their expiry date.", "label": "human"}
{"ID": "00240028", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Suitable for small and medium businessesThe application has notfocused much on arranging goods in the warehouse, the sorting pro cess is still sketchy SAP Business One warehouse managementsoftwareThe application provides functions to manage the export - im port - inventory of goods in thewarehouse, manage the arrange ment and storage of goods in the warehouse. Satisfy the functionof performing inventory, managing goods by batch number, ex piry dateThe application does not yet support tracking shipment history and incorporating other technologies into the management process.", "label": "human"}
{"ID": "00240029", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Simple inventory management,capture inventory counts in warehouses through real-time updated metricsThe application only ap plies to small stores, product information is not detailed DxClan Digital Workspace SystemThe system is suitable for manybusiness models, providing management functions for connect ing departments in the enterprise and the warehouse department.", "label": "human"}
{"ID": "00240030", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The Warehouse Management ap plication builds a clear businessprocess, fully meeting the functions of managing goods infor mation, storage information andthe situation of import - export  inventory of goodsThe application has notfocused much on controlling the actual situ ation of goods in the warehouse.", "label": "human"}
{"ID": "00240031", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "RFID (Radio Frequency Identification) is a physical identification technology widely used in logistics warehouse management today. Data is transferred between RFID readers and tags affixed to products via radio waves in RFID devices. Fromthere, merchandise can be controlled and tracked more efficiently. RFID, in partic ular, helps the warehouse save a lot of time and money on inventory. Enterprises must overcome obstacles including investment costs, interoperability with current warehouse management systems, and data security in order to integrate RFID in the products management process.", "label": "human"}
{"ID": "00240032", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "There are numerous types of RFID tags available on the market right now, and each card type will have unique properties to meet the requirements of numerous industries. One of them is an RFID card that can only read data; it is inexpensive,provides information accuracy and security because it cannot be modified, but it also has this drawback. How therefore can the requirements of the administration of commodities information in logistics warehouses be met by the reuse of flexible RFID tags? The focus of this thesis is to develop an automatic inventory module using RFIDthat successfully interfaces with DxClan’s warehouse management system for logistics warehouses based on the aforementioned issues and constraints. This mod ule was created with the intention of making it simple for users to integrate RFIDin the automatic inventory process and to generate highly accurate inventory results, supporting efficient logistics warehouse management. In addition, the mod ule also builds additional functions such as suggesting the invnetory rotation of goods, suggesting appropriate storage locations, rearranging goods based on the results of the obtained inventory, providing solutions for creating and assigning goods. RFID tags used to store items and monitor their life cycles. Moreover, the role of searching, monitoring, and controlling changes in batches of commodities through warehouse activities exists.", "label": "human"}
{"ID": "00240033", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "General use case diagramThe user has to have an enterprise account that has been authorized by the system administrator in order to access the application - Task Management system  DxClan. Users will be given certain access privileges that have been specified onthe system by the administrator for each function and role. The location of the em ployee, the organizational structure, and the level of the company’s power all affect the functions they may access and carry out. Users will be given permissions by the management according to their position, and they are only permitted to access and utilize the resources in the warehouse where they are employed.", "label": "human"}
{"ID": "00240034", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The user with the Admin role will have access to the interface with full functionality after successfully login in, including the ability to rotate the warehouse de pending on the results and do automatic inventory with RFID while filling out the inventory form. In the course of warehousing, tracking, and managing shipments, it is necessary to inventory, generate, and assign RFID numbers to commodities.", "label": "human"}
{"ID": "00240035", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "If the user has the role of a warehouse keeper, the user can also access the fol lowing functions: perform automatic inventory with RFID during the execution ofthe inventory sheet, rotate the inventory based on the inventory results. just re ceived, generate and assign RFID codes to goods during warehousing and tracking and management of goods. The data will be displayed properly with the role of thatstorekeeper, not showing other warehouses.", "label": "human"}
{"ID": "00240036", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The ability to perform inventory and empty the warehouse of products (for the allocated ticket) can be seen if the user is logged in as a warehouse employee, such as the person in charge of creating the slip, the supervisor, or the accountant.", "label": "human"}
{"ID": "00240037", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Functions in the process of performing an inventory of goods such as viewing de-tails of slips, performing inventory, viewing details of inventory results and printing inventory report. The performance of the functions is performed by the responsible persons and assigned tasks during the creation of the ticket. Those with duties: the storekeeper is the one who creates the ticket, assigns the work, so he has the right to see the details of the slip information as well as the obtained inventory results.", "label": "human"}
{"ID": "00240038", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Warehouse staff assigned to perform the inventory will have the right to view ticketinformation, perform inventory and view detailed inventory results. Warehouse accountants are responsible for printing inventory reports and other papers. The as signed supervisor has the task to see if the ticket information has been performed on time, task, process or not.", "label": "human"}
{"ID": "00240039", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Usecase diagram for ”Internal rotation of goods from inventory results” Figure 2.3: Usecase diagram for ”Internal rotation of goods from inventory results”Figure 2.3 depicts the tasks of the internal stock movement function. Execut ing actors include storekeepers and warehouse staff. The warehouse keeper has theright to view suggestions to rotate the warehouse or rotate the goods to the appropriate location based on the inventory results generated from the system. Warehouse staff will be the person who performs the work of rotating goods from find ing and moving goods to the designated location. Finally, the warehouse keeper is the person who checks the results of the inventory rotation, ensures that the goods have been moved to the desired location and saves the results into the system.2.2.4 Use case diagram for ”Generate and assign RFID codes to goods” Figure 2.4: Use case diagram for ”Generate and assign RFID codes to goods” Figure 2.4 describes the tasks of the function to generate and assign RFID codes to goods during warehousing. Executing actors include storekeepers and warehouse staff. When the warehousekeeper receives the goods receipt, he will create and assign an RFID code to the new goods that do not have an RFID code on the system. The warehouse keeper scans, checks and ensures that the RFID code has been properly and sufficiently attached to the goods as required. Both storekeepers and warehouse staff can view the item information on each RFID tag.", "label": "human"}
{"ID": "00240040", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Usecase diagram for ”Manage consignment”Figure 2.5: Usecase diagram for ”Manage consignment”Figure 2.5 depicts the tasks of the information management function about inventory consignments being stored in the system. The actor performing the in ventory management tasks is the storekeeper. The main functions include: searchfor consignment information, view consignment details, view consignment activity history. For roles outside the warehouse department such as accounting depart ment, other department employees can view information of goods in the lot.", "label": "human"}
{"ID": "00240041", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Business process Business process of automated inventory Figure 2.6: Business process of automated inventory Figure 2.6 details the business process of performing automated inventory with RFID tags. The main roles of the unit include (i) Storekeeper, (ii) Warehouse staff, (iii) Warehouse accountant, (iv) Supervisor. Storekeepers plan to inventory thewarehouse on a regular basis or according to the request for warehousing, discharging, and returning goods from other departments. Next, the storekeeper as signs inventory work to the employees in the warehouse. The warehouse staff who perform the inventory work give the results, the number of remaining goods, the number of damaged goods, and report the results to the storekeeper to proceed with the next steps. After the inventory results are available, the warehouse accountant will print the minutes and the supervisor will follow up to make sure the inventory process takes place in the right order.", "label": "human"}
{"ID": "00240042", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Business process of inventory rotationFigure 2.7: Business process of inventory rotation Figure 2.7 describes in detail the business process to perform the job of turning the warehouse of goods. The above process will include the following main roles:", "label": "human"}
{"ID": "00240043", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Storekeeper and (ii) Warehouse staff. The storekeeper will see the suggestion to rotate the inventory and plan the rotation. Warehouse rotation request will be sent to warehouse staff and this employee is responsible for performing the request.", "label": "human"}
{"ID": "00240044", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Logical and input processing requirements The application meets the functions of decentralizing users according to each function, task, and role. In order to display the appropriate data according to theneeds, the application provides the functions of searching for information and sort ing data. Allows converting Vietnamese to English. Data is always backed up when there is a problem with data recovery. User-friendly interface, suitable for screen sizes of many devices.", "label": "human"}
{"ID": "00240045", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "General requirements The input boxes on the interface need to ensure the following principles: (i) The input data needs to be checked by the system for binding conditions, and an error will be displayed if these requirements are not met ( ii) For the selection of optional data, a search function must be provided to facilitate finding data in the case of large data (iii) For the data type of day, month and year, it is necessary to provide select interface, not for manual data entry.", "label": "human"}
{"ID": "00240046", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In addition, the application must meet the following information safety and se curity criteria: (i) Important information about the user’s password needs to beencrypted (ii) Assign role responsibilities to each user in the system, avoiding loss of information (iii) The database must always be in an active state, accessible atany time.In the previous chapter, I covered the requirements for the application and spec ified them in the diagram. I will explain the technologies and frameworks applied during the development of this application in this chapter. In this thesis, they can be classified into four groups: RFID technology, the technology used in DxClan, warehouse management module of DxClan and the algorithms used to inventory and inventory rotation.", "label": "human"}
{"ID": "00240047", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "RFID ( Radio Frequency Identification ) RFID  - Radio Frequency Identification, refers to identification using radiofrequencies. RFID is a system that automatically recognizes and tracks identify ing tags affixed to things using radio waves. Through the use of radio transceivertechnology, it is now feasible to monitor and control each thing while also recog nizing it as an object. Organizational managers can identify and manage assets andgadgets thanks to RFID tag technology. It applies to magnetic card locks in ho tels and resorts, item tagging in retail establishments, inventory systems and so on.", "label": "human"}
{"ID": "00240048", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "RFID is a technique that combines many different fields and technologies suchas: systems, software development, circuit theory, antenna theory, radio transmis sion, microwave engineering, receiver design, integrated circuit design synthesis, coding, materials technology, machine design and other related fields. An RFID system is often described as a set of devices, a simple device on one side, and amore complex device on the other. Simple devices (called RFID tags or transpon ders) are usually compact and cheap, produced in large quantities and attached to objects that need to be managed and identified automatically. Complex devices (called readers) have more features and often connect to a computer or computer network. Radio frequencies used in RFID technology from 100 kHz to 10 GHz.Figure 3.1: Overview model of the RFID systemThe use of RFID technology is widespread in many facets of daily life, including automatic toll collection, vehicle or mobile phone theft prevention, office ac cess cards, automatic door systems, book tracking in libraries, and applications for border crossing detection and electronic passports. Product tracking in logistics warehouses is one application where RFID is most commonly used.", "label": "human"}
{"ID": "00240049", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "An RFID reader is a device used to read cards with a radio antenna. When an RFID tag enters the reader’s range, it captures energy from this radio wave and activates the tag, then the tag responds these signals back to the reader with its data.", "label": "human"}
{"ID": "00240050", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The RFID reader includes 3 main functions (i) two-way communication with the tag, (ii) pre-processing of received information, (ii) connection to the information management computer system.", "label": "human"}
{"ID": "00240051", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Some important parameters of the RFID reader (i) frequency: LF, HF, UHF,some manufacturers develop multi-function reader that can work on different fre quencies, (ii) standard protocol ISO, EPC, products of several manufacturers that support many different protocols and (iii) network capabilities: TCP/IP, Wireless LAN, Ethernet LAN, RS485.", "label": "human"}
{"ID": "00240052", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The RFID system’s antenna-based design has more requirements than the RFID reader-based design. The antenna is typically stand-alone and attached for long range applications, however it is integrated into the reader for close range (LF, HF frequencies) applications like access control. includes copper cable reader for protected impedance.", "label": "human"}
{"ID": "00240053", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "An RFID tag typically consists of a microprocessor for computation, an internal memory for storage, and an antenna for communication. The card’s memory can be read-only, write-once-multiple, or fully read-write. Basic components of an RFID tag:•Antenna Silicon Chips Chip cover material Power supplies (active and semi-passive tags only) There are three types of RFID tags in use today, active RFID tags and passive RFID tags and semi-passive RFID tags, each with their own characteristics and suitable for certain functions.", "label": "human"}
{"ID": "00240054", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Active RFID tags have the ability to constantly broadcast signals by self gen erating their own power source. Active RFID tags are frequently employed as a beacon\" to precisely track the position of an object in real time. Compared to passive RFID tags, active RFID tags provide greater reading distances. However, compared to other varieties, the price of this RFID tag is now rather expensive.", "label": "human"}
{"ID": "00240055", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Semi-Passive RFID Tags are like passive tags, semi-passive tags respond (nottransmit) radio wave energy back to the reader. However, they also power the in tegrated circuits in the card. This type combines the advantages and limitations of the two types above.", "label": "human"}
{"ID": "00240056", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The three frequencies that this card uses are low, high, and very high. The capac ity of radio waves to permeate liquids and metals will dec as frequency rises, or the reading distance will rise as frequency rises. This card has the benefit ofbeing inexpensive, making it popular in many automation management application systems.", "label": "human"}
{"ID": "00240057", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "LF and HF frequencies: This type of tag uses an induction duo between the tag’s two twisted-pair coils (antennas) and the reader to provide power and send information. These coils are actually LC tuned circuits, when set to the correct frequency (eg 13.56MHz) they maximize the power transfer.", "label": "human"}
{"ID": "00240058", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "UHF frequency: Passive tags work on UHF and HF frequencies using the same modulation technique as LF (AM) tags but differ in the way they transmit power and antenna design.", "label": "human"}
{"ID": "00240059", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In addition to the above division, people also classify cards according to their memory reading and writing capabilities. According to this approach, tags fall into several categories: Read-only; Write-once-read only; Read/Write; Read/Write built-in sensor and Read/Write built-in transmitter:", "label": "human"}
{"ID": "00240060", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Read-Only RFID tags: An RFID tag is capable of storing data and being read by RFID readers, but cannot write new data to the tag. Read-only RFID tags are commonly used in barcode reading, freight tracking and access control applications.", "label": "human"}
{"ID": "00240061", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Write-Once Read-Many RFID tags (WORM): A type of RFID tag capable of writing data only once, and then can only read previously recorded data.", "label": "human"}
{"ID": "00240062", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "This type of tag is commonly used in cargo control applications, such as certification of origin, automated paperwork and asset management.", "label": "human"}
{"ID": "00240063", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Thẻ RFID đọc/ghi (Read/Write RFID tags): Là loại thẻ RFID có khả năng đọc và ghi dữ liệu nhiều lần vào bộ nhớ của thẻ. Loại thẻ này được sử dụng rộng rãi trong các ứng dụng quản lý kho hàng, đánh dấu thời gian và quản lý thời gian làm việc của nhân viên.", "label": "human"}
{"ID": "00240064", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Read/Write with Sensor RFID tags: An RFID tag capable of reading and writ ing data to the tag’s memory, and integrating one or more sensors to collectdata from the environment. This type of tag is used in environmental monitor ing, food monitoring and medical applications.", "label": "human"}
{"ID": "00240065", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Read/Write with Integrated Transmitter RFID tags: An RFID tag capable of reading and writing data to the card’s memory, and integrating a transmitter to transmit data wirelessly. for other devices. This type of tag is used in location tracking, positioning and cargo control applications.", "label": "human"}
{"ID": "00240066", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The working principle of RFID is based on electromagnetic theory. In a con ventional system, RFID tags are attached to objects, each with a certain amount ofinternal memory (EEPROM) containing information about the object carrying it.", "label": "human"}
{"ID": "00240067", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "This information depends on the intended use of the card, it may be just a unique identifier, it may be other information. When these tags pass through the magneticfield of the reader, they exchange information with the reader. From this informa tion the reader recognizes the object and other necessary information. Currently,RFID systems are always associated with information systems to become a com plete system.", "label": "human"}
{"ID": "00240068", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "If multiple tags appear in the magnetic field generated by the reader and respond to the reader at the same time, a collision occurs. To avoid this, the reader uses a collision avoidance algorithm such that the selection of tags that contact the readeris separate. Some of the algorithms used are: Binary Tree, Aloha...., these algo rithms are part of the protocol. The number of tags to be identified depends on the frequency and protocol used.", "label": "human"}
{"ID": "00240069", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The usage of RFID tags and in Logistics warehouses is progressively gainingpopularity due to the exceptional and superior qualities of RFID cards in asset management in particular and life in general. As a result, I want to learn more about this technology and make it the objective of both this thesis’s and my application development. Many companies now operating on the market have implemented the usage of RFID in the process of managing items in the warehouse. Because they are inexpensive to manufacture and to implement, passive RFID tags are widely used.", "label": "human"}
{"ID": "00240070", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO - 14443ISO (International Organization for Standardization)  and IEC (Inter national Electrotechnical Commission) establishes an international council forglobal technical standardization. ISO is a pioneer in the development of international technical standards, to ensure that products, services and processes developed and used globally comply with common rules and standards. , thereby help ing to increase efficiency, ensure safety and improve quality. ISO has developed more than 23,000 different standards, including those in the industrial, technical, medical, environmental, information and communication sectors, and more. These standards are considered international standards and are widely adopted across the globe.", "label": "human"}
{"ID": "00240071", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO 14443 is a technical standard developed by the International Organiza tion for Standardization (ISO), which defines wireless communication protocols for smart card devices using the 13.56 MHz frequency. This standard includes the necessary software and hardware for communication between smart card devices and smart card readers.", "label": "human"}
{"ID": "00240072", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO 14443 includes many parts, including communication modes between cards and card readers, classes and protocols for security and anti-conflict, and technical requirements for smart card devices. and smart card reader. Currently, users need to fully support all 4 parts of ISO/IEC 14443 in a reader (called Proximity Coupling Device - PCD) and card (called Proximity integrated Circuit Cards - PICC). The PICC is used within 10cm of the reader antenna at 13.56MHz. The selection of this frequency is based on a number of technical reasons. ISO 14443 does not specify the operating system in the card and reader, because that is the copyright of each manufacturer.", "label": "human"}
{"ID": "00240073", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO 14443 consists of 4 parts: Hardware specification; Radio frequency energy and signal interface; Initialization and anti-collision and Data Transfer Protocol.", "label": "human"}
{"ID": "00240074", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO 14443-1 : This part defines the specifications for cards and card readers. It includes size, shape, spacing and battery and voltage parameters. In addition,this section also defines the durability and water resistance requirements for smart card devices.", "label": "human"}
{"ID": "00240075", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO 14443-2 : This part defines the communication modes between the card and the card reader. It covers data communication methods, how data fieldlengths are determined, and communication rates. It also defines the specifi cations for the control signals and how the devices should be operated.", "label": "human"}
{"ID": "00240076", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO 14443-3 : This section defines classes and protocols to ensure confiden tiality and avoid collisions during communication. It covers data encryptionand authentication methods, as well as how to handle data conflicts when mul tiple cards are placed side by side near a card reader.", "label": "human"}
{"ID": "00240077", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ISO 14443-4 : This part defines the protocols for data communication betweenthe tag and the card reader. It provides rules for data exchange, including con trol signals and formatting data fields. It also defines how to handle errors during communication.", "label": "human"}
{"ID": "00240078", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Front-end TechnologiesReact  is a JavaScript library that aims to simplify development of visual in terfaces. Developed at Facebook and released to the world in 2013, it drives some of the most widely used code in the world, powering Facebook and Instagram among many, many other software companies. Its primary goal is to make it easy to reasonabout an interface and its state in any point in time, by dividing the UI into a col lection of components. React is used to build single page web applications, among with many other libraries and frameworks that were available before React came into life. I choose react because of its three advance features includes Declarative, component based and learn once, write anywhere.", "label": "human"}
{"ID": "00240079", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Nowadays, ReactJS is getting more and more popular because of its simplicityand flexibility. This is how many people see the future of web development. ReactJS is reportedly used by over 1,300 developers and over 94,000 websites. Tech nology giants like Meta (previously Facebook), PayPal, Uber, and Airbnb employ ReactJS to address UI-related issues, which contributes to its growth. Since then, a growing number of individuals and businesses have continued to support the use of ReactJS.Figure 3.4: Percentage of users who would use a framework again The important features of ReactJS include:", "label": "human"}
{"ID": "00240080", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ReactJS allows developers to write applications directly on JavaScript. Add to that JSX, one of the characteristics that makes ReactJS not just simple but also more enjoyable. Now that they can design a new feature and see it in action live, developers can include HTML snippets directly into JavaScript.", "label": "human"}
{"ID": "00240081", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Allows Developer to break complex UI constructs into independent compo nents. Because it is now easy for developers to disassemble complex UI/UX structures into simpler parts, developers won’t need to worry about the overall web application.", "label": "human"}
{"ID": "00240082", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Through Props, components can connect to each other using custom data. This helps pass customized data to a specific UI component.", "label": "human"}
{"ID": "00240083", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "State feature when using ReactJS, helps to adjust the state for components (child) that receive data from a source component (parent). A developer can change the state for multiple components (child) on the application, but it does not affect the parent component that is in Stateful state. It’s also easier to adjust apps.", "label": "human"}
{"ID": "00240084", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Virtual DOM (Virtual DOM) makes the application faster. The virtual DOM is great for structuring the UI to react promptly to changes in order to improve the user experience. When creating ReactJS, the designers correctly predicted that updating old HTML would be extremely important but also quite costly. So the idea of using a virtual DOM helps ReactJS know exactly when to re-render or when to remove elements of the main DOM because it detects changes in the data.", "label": "human"}
{"ID": "00240085", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Because ReactJS uses the principle of one-way data coordination from top tobottom, developing a large-scale application will become complex and difficult to handle. In particular, if the application has many nested subcomponents, the depth of the components is high, and the number of properties that need to be passed to the child components is large, the data will be very difficult to control, easy to lose and change. change. To solve this problem, DxClan uses a combination of ReduxJS with ReactJS.", "label": "human"}
{"ID": "00240086", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Redux  is a predictable state container designed to help write JavaScript apps that behave consistently across client, server, and native environments and are easy to test. While it’s mostly used as a state management tool with React, developer can use it with any other JavaScript framework or library. It’s lightweight at 2KB(including dependencies), so developer donnot have to worry about it making ap plication’s asset size bigger. With Redux, the state of application is kept in a store, and each component can access any state that it needs from this store. Redux have powerful features include:", "label": "human"}
{"ID": "00240087", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Predictable, Redux helps you write applications that be have consistently, run in different environments (client, server, and native), and are easy to test..", "label": "human"}
{"ID": "00240088", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Debuggable,The Redux DevTools make it easy to trace when, where, why, and how application’s state changed. Redux’s architecture lets log changes, use ”time-travel debugging”, and even send complete error reports to a server.", "label": "human"}
{"ID": "00240089", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "When using Redux, the whole global state of the app is stored in an object tree inside a single store. The only way to change the state tree is to create an action, an object describing what happened, and dispatch it to the store. To specify how the state gets updated in response to an action, I need to write pure reducer functions that calculate a new state based on the old state and the action. The Redux model is different from the traditional MVC model, the MVC model is divided into 3 separate parts when building: data, interface and logic processing. The data flow of this model is a bidirectional data flow, when changing data in one component can affect the state of the application in other components.", "label": "human"}
{"ID": "00240090", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Back-end Technologies NodeJs  is a platform built on top of the V8 JavaScript Engine – an interpreter that executes JavaScript code, making it simple and easily extensible to build webapplications. NodeJS was developed by Ryan Dahl in 2009 and can run on many different operating systems such as: OS X, Microsoft Windows, Linux.", "label": "human"}
{"ID": "00240091", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Realtime: NodeJs’ most crucial feature is realtime. Thus, \"realtime\" refers to the fact that the server will accept requests from clients and carry out such requests immediately. For instance, the author of the article and others who are interested will be notified right away when leaving a comment or engaging on Facebook.", "label": "human"}
{"ID": "00240092", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Asynchronous (Non-blocking): All NodeJs APIs are asynchronous, it is mainly based on NodeJs server. Asynchronous helps the processing tasks at the serverto return results faster, without having to wait for the previous tasks to com plete before executing.", "label": "human"}
{"ID": "00240093", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Node Express  is a popular framework today built on top of NodeJS. It sup ports powerful features to build APIs for web or mobile application development.", "label": "human"}
{"ID": "00240094", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Set common web application settings such as the port to use to connect and the position of the interface templates to display the response.", "label": "human"}
{"ID": "00240095", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "MongoDB  is an open-source document database built on horizontal scale out architecture. Founded in 2007, MongoDB has a worldwide following in the developer community.", "label": "human"}
{"ID": "00240096", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Instead of storing data in tables of rows or columns like SQL databases, each row in a MongoDB database is a document described in JSON, a formatting language.", "label": "human"}
{"ID": "00240097", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Document databases are extremely flexible, allowing variations in the structure of documents and storing documents that are partially complete. One document canhave others embedded in it. Fields in a document play the role of columns in a SQL database, and like columns, they can be indexed to increase search performance Figure 3.5: MongoDB database model It is clear that the DxClan system utilizes mongodb as the system-wide database for a variety of reasons. First off, developers can work rapidly because the data model is a strong method of storing and retrieving data. Next, a significant amountof data and traffic can be supported using MongoDB’s horizontal scalability de sign. The user interface for MongoDB is excellent, allowing programmers to install it and get started right away. Additionally, MongoDB has grown into a sizable and sophisticated platform ecosystem, making it possible to use it with all of the major programming languages, access a global network of developers and consultants for support, and utilize it with both on-premises and cloud computing platforms.", "label": "human"}
{"ID": "00240098", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The DxClan digital workspace system is a system developed by the Vietnam Information Security and Communication Technology Company (VNIST). The sys tem provides digital transformation solutions for businesses in general and logisticsbusinesses in particular. The system’s Warehouse Management application is spe cially designed to be flexible and suitable for various types of warehouses, meeting the diverse requirements of businesses. Since the warehouse management module is built on the DxClan system, it inherits and uses both the front-end and back-end technologies of DxClan.", "label": "human"}
{"ID": "00240099", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Managing warehouse information Managing the physical storage locations within the warehouse Managing category information Managing product information Managing various types of warehouse documents•Managing inventory information Managing requests between departmentsThe function of managing various types of warehouse documents includes man aging information related to warehouse receipts, warehouse releases, inventory checks, and the transfer of goods between warehouses, all of which are detailed according to the logistics warehouse process. For inventory checks, the system has a function to quickly create inventory check documents based on plans or requestsfrom other departments, with both regular and periodic inventory checks, support ing flexible display by inventory objects (batches of goods or storage locations), and clear representation of document information.", "label": "human"}
{"ID": "00240100", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "However, the results of the inventory do not accurately reflect the quantity, qual ity, and actual condition of the goods. The reason is that the inventory method used in the system is manual. Although this method is easy to perform, its accuracy is not high, leading to a decrease in the accuracy of the inventory results. In addition, this method is time-consuming, requires a lot of personnel, and increases the cost of warehouse management. The displayed inventory results only reflect the actual quantity but do not meet the requirements of the enterprise to clearly reflect the status of the goods and their current storage location. This leads to difficulties in tracing and identifying the causes of incidents to take remedial action.", "label": "human"}
{"ID": "00240101", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Furthermore, for a logistics warehouse, the import and export of goods occurcontinuously throughout the day, making it easy for goods to be moved to differ ent locations during the picking process. Knowing the precise storage location of each item in the warehouse would help the business easily monitor fluctuations in inventory and facilitate smooth import and export operations. Additionally, theinternal rearrangement or circulation of goods in the warehouse plays an impor tant role in optimizing storage space, controlling and tracking goods, and ensuring the normal flow of operations. However, the warehouse management feature of the DxClan system does not currently include this functionality, which reduces its effectiveness in managing inventory.", "label": "human"}
{"ID": "00240102", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "To perform automated inventory checks with RFID tags, all items in the ware house must have a corresponding RFID code attached to them. Therefore, during the item receiving process, RFID codes must be created and assigned to each batch of items. The warehouse management feature includes a function for generating RFID codes, and the number of codes can be easily adjusted to suit various typesof goods. However, the generated RFID codes do not comply with ISO 14443 stan dards and require updating and modification before they can be used.The inventory information management feature of the warehouse management application includes a search function and origin traceability for each batch of goods. Information such as the origin, type, and expiration date of each batch isdisplayed, making it easy for users to track the relevant information. However, de tailed information such as storage location and quantity at each location, and the changes in the quantity of goods in each batch, are not displayed, which hinders the ability of users to track and trace errors and faults.", "label": "human"}
{"ID": "00240103", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The choice of the DxClan digital workspace system is to integrate the features that I want to build in this dissertation because of the advantages of the warehousemanagement application, including inventory management, physical storage location management, product category and information management, and manage ment of warehouse process-related documents. Additionally, the features I developwill enhance the Warehouse Management application of the DxClan system, meet ing business requirements, including (i) the automatic inventory checking function using RFID tags to replace traditional manual methods, improving the accuracy ofinventory results, and (ii) suggesting inventory rearrangement based on the inven tory checking results, making the inventory management process more efficient, and maximizing storage space in the warehouse.", "label": "human"}
{"ID": "00240104", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In addition, to meet the requirement of automatic inventory checking using RFID, I have also modified and updated the system with the additional functionsof (iii) assigning RFID tags to goods during the warehouse receiving process to en sure that all goods in the warehouse have RFID tags based on the initial warehouse receipt function of the DxClan system, and (iv) tracking and tracing the movement of goods through activities in the warehouse based on the function of searching for the origin history of the batch on the DxClan system.", "label": "human"}
{"ID": "00240105", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The algorithms in Inventory In today’s popular inventory check algorithms, there are the ABC inventorycheck algorithm, cycle counting inventory check algorithm, and intelligent inven tory check algorithm. These algorithms are designed to optimize the inventory checking process and reduce errors in this process. However, the choice of theappropriate algorithm also depends on the needs and actual situation of each ware house.", "label": "human"}
{"ID": "00240106", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The ABC inventory check algorithm is a prioritization method for high-value items (A), followed by items with average value (B), and finally low-value items (C). This algorithm helps optimize inventory checking and reduce checking timefor low-value items. However, this method only focuses on the value of goods and does not consider quantity. Therefore, if an item has low value but a large quantity, this method may not be effective.", "label": "human"}
{"ID": "00240107", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The cycle counting inventory check algorithm is a method that uses cycles to check inventory. For example, checking once every 6 months or once a year. This algorithm ensures regular inventory checks, helps detect and correct errors and omissions in the storage process early. This helps increase accuracy and reliability in the inventory checking process while reducing long-term inventory.", "label": "human"}
{"ID": "00240108", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The intelligent inventory check algorithm is a method that uses intelligent tech nologies such as artificial intelligence (AI) and machine learning to predict the quantity of goods in the warehouse and reduce checking time. This helps increaseaccuracy and reliability in the inventory checking process while reducing long term inventory. However, this method requires the use of advanced technologies and the initial investment cost may be quite high.", "label": "human"}
{"ID": "00240109", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Of all the algorithms, the cycle counting inventory check algorithm is still the most popular trend that businesses are using due to its ease of implementation and relatively low cost. In addition, using the cycle counting inventory check algorithm in logistics warehouses is a suitable choice for the automatic inventory checking method using RFID tags when developing this feature in the DxClan system.", "label": "human"}
{"ID": "00240110", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The algorithms in inventory rotation To organize and manage internal operations in the warehouse and support other activities, various algorithms such as FIFO (First In, First Out), LIFO (Last In, First Out), FEFO (First Expired, First Out), and ABC (Activity Based Costing) are being widely applied. All of these algorithms have their own advantages and disadvantages, therefore, the appropriate algorithm should be selected depending on the purpose of use and the characteristics of the goods.", "label": "human"}
{"ID": "00240111", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "FIFO algorithm (First In, First Out): According to this algorithm, goods are arranged in the order they arrive, and are taken out and distributed in the order they arrived. This ensures that goods are distributed in a timely manner and minimizes the risk of expired products staying in the warehouse for too long.", "label": "human"}
{"ID": "00240112", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "LIFO algorithm (Last In, First Out): This algorithm is the opposite of the FIFOalgorithm, as goods are arranged in the order they arrive with the most recent arrivals being taken out first. This algorithm is typically used for new and higher value products.", "label": "human"}
{"ID": "00240113", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "FEFO algorithm (First Expired, First Out): According to this algorithm, goodsare arranged in the order of the nearest expiration date, ensuring that products that are about to expire are used first. This helps minimize the risk of expired products staying in the warehouse for too long.", "label": "human"}
{"ID": "00240114", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ABC algorithm (Activity Based Costing): This algorithm evaluates the value of goods based on frequency of use, and is often used in managing the distribution of goods in the warehouse. Products are classified into A, B, and C groups based on their value and quantity of use, which helps manage the storage and distribution of goods more efficiently.", "label": "human"}
{"ID": "00240115", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In logistics warehouses, the goods stored are not just those that have been or dered, but also many goods waiting to be distributed to other locations. Therefore, combining the FIFO and FEFO algorithms is a suitable option for managing these goods effectively.", "label": "human"}
{"ID": "00240116", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Inventory recordsThe proper issuance of inventory checklists in accordance with regulations is es sential to ensure transparency and the ability to retrieve the information collected during the inventory check process. The information in the inventory checklist mustcomply with information No. 200 and 133 (from the Ministry of Finance), includ ing:", "label": "human"}
{"ID": "00240117", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The department or unit conducting the inventory check The type of inventory check form Information on the individuals participating in the inventory check activity The inventory check results of the goods4.1 Architecture design 4.1.1 Software architecture of DxClan system The functions built into the Warehouse Management module inside the DxClan system should follow the Client-server model, also known as client-server of the system. In this model, the Server assumes the role of connecting to the database, handling the logic, providing APIs that allow clients or 3rd parties to access and use those APIs to access and exploit data. When a client or a 3rd party sends a request to the Server, the Server authenticates the information the user is sent to. After the authentication is complete, ensuring valid access rights, the server processes the request, updates the data into the database if necessary, and returns the data to the requesting party. The client assumes the role of displaying the interface on the Web interface so that the user can easily interact and make requests to send to the Serverside. Server is built according to the MVC architecture model, including 3 com ponents Mode, View, Controller. The client is built on top of Redux’s architecture and is repackaged into modules corresponding to separate functions.", "label": "human"}
{"ID": "00240118", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "React-routes: Provides navigation to application components Layout: Build the overall layout of the application Redux: An application’s data storage and control component Components: Interface components on the application’s Browser.The server consists of the following main components:", "label": "human"}
{"ID": "00240119", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Controller: has the function of receiving, processing and responding to data when there is an incoming request, possibly from the client or from a third party.", "label": "human"}
{"ID": "00240120", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Services: contains functions that handle the application logic, because it is separate from the controller, so the services are highly reusable and easy to access.", "label": "human"}
{"ID": "00240121", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Model: The model component stores data and its related logic. It includes class functions that perform tasks such as querying, adding, modifying, or deleting data. For example, a Controller object will retrieve customer information from the database. It manipulates the data and sends it back to the database or uses it to display data.", "label": "human"}
{"ID": "00240122", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "View: The view is a part of the application that represents the data. The viewcontains interfaces such as buttons, text boxes, menus, images, etc. It is re sponsible for displaying data and allowing users to interact with the system.", "label": "human"}
{"ID": "00240123", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Views are created using data from the model. A view requires the model toprovide all the necessary data to display output to the user.•Controller: The controller is where requests from users are received and pro cessed. It consists of classes/functions that handle various logic tasks to help retrieve the necessary data from the model and display it to the user through the view. The controller sends commands to the model to modify its state (e.g., adding a new user or updating the name of a user). The controller also sends commands to its related view to change the display of the view (e.g., viewing user information...).", "label": "human"}
{"ID": "00240124", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Overall design 4.1.3 Packet diagram for client Figure 4.3: Packet diagram for clientFigure 4.3 depicts an overview package diagram for the warehouse chain man agement application client. The main functions of the client part will be located in the src folder, where:", "label": "human"}
{"ID": "00240125", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Modules: contains all the interface components for each function in the system and the redux package is used to call the server-side APIs to get the required data.", "label": "human"}
{"ID": "00240126", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Helpers: files that provide support functions for handling client-side tasks Node modules: Is the directory containing the library files installed on the client side Public: The functions and resources are allowed to be public when deploying the system4.1.4 Overview package chart for server Figure 4.4: Overview package chart for server Figure 4.4 depicts an overview package diagram for the folders on the server side of the warehouse chain management application. In there:", "label": "human"}
{"ID": "00240127", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "logs: A folder of the system to save the history of requests sent from the client to the server Middle-ware: A class that authenticates requests sent from the client before these requests are processed logically and returns correct data.", "label": "human"}
{"ID": "00240128", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Node modules: A directory containing library files installed on the server side Modules: The folder that contains all the logic on the server side. There are 3 main files:", "label": "human"}
{"ID": "00240129", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "–Route: the routing file contains the–Controller: Receives incoming requests from the client, handles user au thentication and is responsible for returning data to the client.", "label": "human"}
{"ID": "00240130", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "–Service: Contains functions that handle the server’s logic, query the database, and return data to the function caller Models - directory that stores the structure of the data.4.1.5 Detailed package design Figure 4.5: Detailed package design for client Figure 4.5 shows the details for the client-side repository management package that will have 7 parts including:", "label": "human"}
{"ID": "00240131", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Stock-management: Contains functional interface files for managing ware house informationBin-location-management: Contains functional interface files that manage phys ical storage location information in the warehouseCategory-management: Contains functional interface files to manage infor mation on the list of goods Good-management: Contains functional interface files to manage commodity information Bill-management: Contains functional interface files to manage information of all kinds of vouchers Inventory-management: Contains the file management function interface files, the functional interface for managing information of all kinds of couponsRequest-management: Contains functional interface files for managing re quests to the repository and other requests Packages include 2 main packages component and redux:", "label": "human"}
{"ID": "00240132", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Component package: Contains jsx files to display the interface on the browser•Redux package: Save data returned from the server into state variables to be accessible in the system.", "label": "human"}
{"ID": "00240133", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In order to build and develop the functions in this study, and reuse resources from the Warehouse Management application, some client-side packages will bepreserved including Stock management, Bin location management, Category man agement , Request management.", "label": "human"}
{"ID": "00240134", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "User interface design Design requirements When building the interface, it is necessary to ensure the following factors: (i) must be synchronized with the DxClan system and the warehouse management application, (ii) must be able to ensure interaction with users; (iii) must respond to user interactions so that users know the results of their actions; (iv) Requirements for interaction on the interface with the user must be suggested by other forms such as highlighting, announcements, etc. to help users easily identify the features.", "label": "human"}
{"ID": "00240135", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In order to optimize the user experience, the application must ensure that the user interface is interrupted, seamless from start to finish, and consistent from start to finish.", "label": "human"}
{"ID": "00240136", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Colors need to follow a dominant tone, do not use colors that are too bright. In ad dition, the colors need to be selected so that they are easy to observe, not confusing, inhibiting the user and suitable for the function you want to convey.", "label": "human"}
{"ID": "00240137", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Interface designThe interface of the application is designed for use on desktop and laptop de vices. However, the interface needs to be compatible on many different screen sizes such as Ipad, smartphone for the most convenience for users.", "label": "human"}
{"ID": "00240138", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Header: the page title is displayed above the interface Sidebar: menu section that displays a list of service functions Content: The main body of the pageFooter: the bottom of the screen, containing annotations about the author, soft ware copyright, interface copyright For the automatic inventory execution interface, it is necessary to synchronize with the manual inventory execution screen. At the same time, the detailed screen of inventory results and the movement between the two screens to perform theinventory and view the details of the results need to be designed flexibly, conve niently and optimally for users.", "label": "human"}
{"ID": "00240139", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Interface design for automatic inventory executionFigure 4.14: Interface design for automatic inventory execution Figure 4.15: Detailed interface design of inventory results 4.2.2 Layer design The module is built and integrated into the DxClan system with a total of 32 layers. Here are some typical class designs:Class name automaticInventory Attribute List Attribute name Type Description rfidBinError array List rfid wrong location rfidCodeError array List rfid wrong code stockId string warehouse’s id Method list Method name Description getListData Data format for the table save Perform vote saving handleImportExcel Processing input files handleDisplayTypeChange Change the display style compareDate Calculate the number of days difference compareRfidBinLocation Compare rfidCode and binLocation of rfid saveScanForm Save input file data for processing Table 4.1: Specifies the properties and methods of the auto-inventory class Class name createRFID Attribute List Attribute name Type Description rfidError array List rfid error lot object Consignment information good string Goods name Method list Method name Description handleExpirationDateChange Handling Expiration Date Change isRfidCodeValidate rfidCode Authentication compareRfidCode Compare rfidCode save Save bill handleGenerateRfid Processing rfid code generation Table 4.2: Specifies the properties and methods of the class that generates and assigns an RFID code4.2.3 Database design Figure 4.16: Data link diagramFigure 4.16 provides information about entities and their connections. The fol lowing are the entities in the application:", "label": "human"}
{"ID": "00240140", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "productRequest: Entity used to store information about offers.Figure 4.17: Database details Figure 4.17 describes in detail a database consisting of 8 collections designed and built in a warehouse management application. Details of the data of each table are shown in the figures below.", "label": "human"}
{"ID": "00240141", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Attribute Datatype Description _id ObjectId Warehouse’s id code String Warehouse’s code name String Warehouse’s name description String Warehouse’s descriptionn address String Warehouse’s address status String Usage status of the warehousemanagementLocation Array List of roles that have manage ment rights in the repository goods Array List of goods that can be stored in warehouse Table 4.3: Details of the data of the warehouse collection Table 4.3 includes the attributes of the warehouse information field, used to store warehouse information.Attribute Datatype Description _id ObjectId Warehouse manager position id role ObjectId Warehouse manager role id managementGood String Managed commodities Table 4.4: Details of the data of the warehouse management roles Table 4.4 includes the attributes of the warehouse management roles, which is responsible for storing information about the user roles that are managed and what kind of goods are in the warehouse.", "label": "human"}
{"ID": "00240142", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Attribute Datatype Description _id ObjectId Warehouse manager position id good ObjectId Goods’s id maxQuantity Number Maximum quantity of goods in stock minQuantity Number Minimum quantity of goods in stock Table 4.5: Details data of goods information in stock Table 4.5 describes the data fields of information about goods in the warehouse,including the maximum and minimum inventory levels of each type of goods al lowed to be stored in the warehouse.Attribute Datatype Description _id ObjectId Storage location’s id code String Code of the storage location name String The name of the storage locationdescription String Description of the storage loca tion stock ObjectId Warehouse’s idparent ObjectId The id parent of the storage loca tionchild Array The id children of the storage lo cation path String The path to the storage location status String Status of the storage location users Array List of Ids of people who manage this position enableGoods Array List of goods that can be stored in the storage location capacity Number Quantity that the storage location can hold contained Number Quantity already containedunit String Unit of capacity of storage loca tion Table 4.6: Details data of physical storage location information in the warehouse Table 4.6 describes in detail the data of physical storage location information in the warehouse.", "label": "human"}
{"ID": "00240143", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Attribute Datatype Description good ObjectId Goods’s idcontained Number Number of goods already con tained in the location capacity Number Maximum quantity of goods that can be accommodated Table 4.7: Detail data of goods information in stock Table 4.7 describes in detail the data of the goods that can be stored, which are used to store information about the goods that can be stored in physical storage locations in the warehouse.Attribute Datatype Description _id ObjectId Category’s id parent ObjectId Id of category’s parent code String Category code name String The name of category type String The type of category Table 4.8: Details data of category information in warehouseTable 4.8 includes the attributes of the category, which are used to store infor mation about the category.", "label": "human"}
{"ID": "00240144", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Attribute Datatype Description _id ObjectId Goods’s id category ObjectId Category’s id code String Code of the goods name String Name of the goods type String Type of goods description String Description baseUnit String Basic unit unit Array Packing rule list creator ObjectId Id of data creator materials Array List of ingredients of goods if finished products Table 4.9: Details data of goods information in the warehouseTable 4.9 includes the properties of the goods, which are used to store the infor mation of each commodityAttribute Datatype Description _id ObjectId Bill’s id fromStock ObjectId Id of the created warehouse toStock ObjectId Id of the receipted warehouse group String Description bill ObjectId Id of export bill (used for return bill) code String code of bill type String Type of bill status String status of bill description String Description of bill creator ObjectId Id of creator stockWorkAssignment Array List of tasks and performers custommer ObjectId Id of customer supplier ObjectId Id of supplier receiver Object Information of shipper manufacturingWork ObjectId Id of manufacturer goods Array The list of goods information contained in bill logs Array List of bill change history Table 4.10: Details data of bill information Attribute Datatype Description good ObjectId Goods’s id quantity Number Quantity returnQuantity Number Number of returned goods damagedQuantity Number Number of damaged goods realQuantity Number Actual quantity in stocklots Array Information on the list of con signments in the billunpassedquality Array Information on the list of consignments that do not pass in spection in the bill Table 4.11: Details data of the goods information in the bill In addition to being able to store RFID code information on goods, a number of collections have been inherited and expanded, including:Attribute Datatype Description _id ObjectId Consignment’s id code String Code of consignment good ObjectId Id of the goodstype String The type of consignment corre sponds to the type of goods rfid Array The rfid information of connsignment description String Descriptionstock Array Warehouses are holding consign mentsoriginalQuantity Number Initial quantity of the consign ment quantity Number Actual remaining quantity of consignment expriationdate Date Expiry date of the connsignment lotLogs Array Consignment activity history lots Array Connsignment change history Table 4.12: Details data of consignment informationTable 4.12 includes attributes of a consignment, used to store consignment in formation Attribute Datatype Description lot ObjectId Consignment’s id quantity Number Quantity returnQuantity Number Number of returned goods damagedQuantity Number Number of damaged goods realQuantity Number Actual quantity in stockrfid Array Information on the rfid of con signments in the bill note String note Table 4.13: Details data of the consignment information of the goods are in the bill Attribute Datatype Description _id ObjectId RFID’s id code String RFID code binLocationOfRfid String Code of storage loaction quantity Number number of goods in one RFID code status String usage status of the RFID tag Table 4.14: Data details of the RFID code information of the goods in the lotTable 4.14 describes the data fields of commodity information included in an RFID code, including the RFID code, the storage location of that RFID code, and the quantity of goods assigned to an RFID code. The number of goods assigned to an RFID code depends on the type of goods and the requirements and wishes from the user input. However, the number of goods in a lot must be divisible by the number of goods in an RFID code to ensure that for each RFID code the number of goods is the same.", "label": "human"}
{"ID": "00240145", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Libraries and Tools Purpose Tools URL address Programming IDE Visual Studio Code 64 bit  Programming language Javascript  Database Administration MongoDB  Interface Library ReactJS  Interface Library Redux  Database Library Mongoose  Framework server Expressjs  Table 4.15: List of libraries and tools used 4.3.2 Achievement This thesis has constructed support functions to carry out automatic inventoryand inventory rotation for private warehouses, automatically in logistics ware houses, and incorporated into the digital workspace system DxClan of VNIST. The application’s primary features that have been put into practice and used with the real data are as follows:", "label": "human"}
{"ID": "00240146", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The module is built within a warehouse management application deployed on the internet with the domain name \"Dxclan.com\". In addition, the application canbe installed and tested on personal computers. Thanks to the flexibility of the technologies used, the application is not limited by different operating system environ ments and can run on Windows, MacOS, and Linux. The steps to test the product on a Windows 10 server on an Acer machine with 8GB RAM are as follows:", "label": "human"}
{"ID": "00240147", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Step 3 : Run the \"npm install\" command on both the client and server directories of the project to install the necessary libraries for running the application.", "label": "human"}
{"ID": "00240148", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Step 5 : Navigate to the server directory, run the \"npm run init\" command to initialize sample data for the entire system.", "label": "human"}
{"ID": "00240149", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Step 6 : Run \"npm run dev\" or \"npm run start\" on the server, and \"npm start\" on the client to start the project.", "label": "human"}
{"ID": "00240150", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The testing scenario is applied to a small-scale Logistics warehouse with electronic devices such as laptops, computer monitors, and computer accessories instock. The testing data set is obtained from the inventory list at a logistics ware house of Phong Vu. The dataset includes information on the category of goods, product names, units of measurement, a list of physical storage locations in the warehouse, and the number of products that can be stored at each location. The testing equipment consists of one RFID card reader with a frequency of 13.56 MHz and 20 passive RFID tags.", "label": "human"}
{"ID": "00240151", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Create a warehouse receipt and assign an RFID code to a new consignmentDuring the process of receiving goods from manufacturers or suppliers, ware houses must create and execute a warehouse receipt for the received goods. For new goods that have not been tagged with RFID or have not been assigned astorage lot, a new batch must be added. Depending on the packaging specifi cations of the supplier, whether by individual product or by batch of multipleproducts, the quantity of goods that the user enters, based on the correspond ing basic unit of measurement, will be assigned to one RFID tag. Next, theuser performs tasks such as sorting goods and inspecting their quality to com plete the receiving process. After completing the warehouse receipt, the RFID code associated with the goods and storage location will be represented in the RFID management section.", "label": "human"}
{"ID": "00240152", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "For example, when importing a shipment of 10 laptops, if they are packed into 10 separate packages, the number of products on 1 RFID code needs to be 1.", "label": "human"}
{"ID": "00240153", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Create inventory bill and perform automated inventory with RFID With the function of creating inventory checklists, there are two types: regular inventory checks and periodic inventory checks. For regular inventory checks, users are required to add each product they want to check to the list, while for periodic inventory checks, the system automatically takes all products in the warehouse for inventory checking. During the inventory check, the person in charge uses the RFID tag and performs the check by using the RFID reader to scan the RFID code at all areas and shelves in the warehouse and saves the collected data for the system to process. At the same time, during the scanning process, the quality control staff also visually inspects to ensure that all goods are still sealed and not tampered with, as well as their storage condition.", "label": "human"}
{"ID": "00240154", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "View detailed inventory results by each RFID codeAfter completing the inventory check, the system compares the quantity of goods between the system and the data collected. The displayed results of the inventory check include information about the goods, the batch of goods, the quantity according to the system, the actual quantity obtained during thecheck, and the difference and loss. In addition, users can view detailed inven tory check results for each RFID tag, the current storage location for each tag, and view a list of goods that are incorrectly placed. After saving the inventory check results, users can print the inventory check report or download it as a PDF file.", "label": "human"}
{"ID": "00240155", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "See the suggestion to rotate the goods and perform a re-inventory after inven tory rotation After completing the inventory check and obtaining detailed inventory results for each RFID tag, the user can view the suggested inventory rearrangement information, including information such as the product, batch, RFID code, quantity, current location, suggested location, and reason for rearrangement.", "label": "human"}
{"ID": "00240156", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The suggested inventory rearrangement information is based on the inventory results obtained, with products that are misplaced, have low quantities, or areapproaching expiration (warranty period) being suggested to be moved to suit able storage locations to optimize storage space.", "label": "human"}
{"ID": "00240157", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After rearranging the inventory, the user performs a recheck to ensure that the goods have been moved to the desired location. The inventory rearrangement screen displays the storage location before rearrangement, the desired location,and the storage location after rearrangement for each product’s RFID tag. Af ter the inventory rearrangement process is complete, the user can check the RFID management page to verify that the product’s storage location has been updated accurately according to the actual location.", "label": "human"}
{"ID": "00240158", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Users enter the consignment management to search and check the consign ment’s information, storage status, changes in the quantity of goods in the lotthrough warehouse operations.In chapter 4, I introduced the process of developing and deployment the applica tion. I explained the whole architecture of system. Use cases and database design were also clarified. In this chapter, I will present my main contributions to the application development process, including:", "label": "human"}
{"ID": "00240159", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ProblemIn reality, companies providing logistics warehousing services are always com peting with each other. They are constantly compared and evaluated for the quality of their services and work efficiency. Therefore, they need to standardize theirmanagement processes, reduce implementation time, improve accuracy, and min imize risks to succeed in this industry. Currently, although the storage of goods varies between different companies, the inventory process is similar. The nature of inventory is to confirm the existence of goods in the warehouse, along with thecorrect quantity and updated storage status to ensure the quality of the goods. How ever, a relatively large proportion of companies still perform inventory by manual counting - a method that has existed for centuries.", "label": "human"}
{"ID": "00240160", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In addition, the application of modern technologies and digital transformation is a trend for most businesses, not only in the logistics warehousing industry. A notable example is the use of RFID technology in managing goods in general and inventory in particular. So, how does the inventory process with RFID differ from manual inventory? For all logistics warehouses, inventorying goods in the warehouse is always acritical task. The result of the inventory process greatly affects the company’s sub sequent plans. However, encountering errors or issues is inevitable. And when they occur, businesses need to immediately review, search for information about the shipment, and plan to remedy the damage. In reality, despite businesses’ attention to this issue, cases still arise where incidents or errors occur but cannot be traced.", "label": "human"}
{"ID": "00240161", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Therefore, what information about inventory results is important and needs to be displayed after each inventory? Therefore, automating the inventory process in logistics warehouses is essential.", "label": "human"}
{"ID": "00240162", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "At that time, businesses can easily grasp accurate information about the storage of goods and easily make appropriate plans for the company. So, how does the current inventory process take place, how is the automatic inventory process withRFID performed, how are inventory results processed and displayed? These are the problems that need to be prioritized for handling.", "label": "human"}
{"ID": "00240163", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Solution According to Touchretail , inventory is crucial to the process of managing the items in Logistics facilities. Inventory your inventory system to identify errors and, most importantly, to make the necessary corrections. There is no right or wrong method to stock; nonetheless, if you want to build your business, it is critical that the inventory is accurate. Stocking frequency varies from business to business.", "label": "human"}
{"ID": "00240164", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Additionally, the reputation of the organization is also impacted by the variation ininventory statistics. In other words, the difference reflects on the standard of man agement, the way that items are stored in the warehouse, and most importantly, it results in a substantial loss. For logistics warehouses, keeping track of the inventory is always a top responsibility.", "label": "human"}
{"ID": "00240165", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In her master’s thesis, Ms. Tong Thi Luyen  also clarified the meaning and role of inventory. \"Inventory inventory is one of an entity’s essential processes forfiguring out how much and what kind of inventory it has. The outcomes of the in ventory have an immediate effect on the entity’s financial accounts. The inventoryrecord must be updated with the findings of the audit and inspection, and the Di rector must be informed. Any nonconforming items must be segregated, labelled, and held in reserve while management evaluates them\".", "label": "human"}
{"ID": "00240166", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Regardless of the products the company sells, inventory management is an essential component of logistics warehouse management. Businesses’ inventory procedures can vary, but the nature of this work goes beyond simple inventory man agement because all stock items must be kept under control. In reality, corporationsfrequently separate inventory into tiny batches and cycle count it rather than count ing the full stock at once.", "label": "human"}
{"ID": "00240167", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Currently there are two main types of inventory checks: periodic inventory checks and perpetual inventory checks. These are two types of inventory checks that any business has already applied or is currently using. Periodic inventory checks are a method of inventory management that relies entirely on the counting process. Business cycles often perform periodic inventory checks quite regularly, such as every 3 to 6 months, to verify the accuracy of inventory, check whether the quantity of goods matches sales data or not. In addition, perpetual inventory checks are a type of inventory check related to monitoring inventory quantities when goods are exported, imported, circulated or returned to the store. Perpetual inventory checks can be performed every day when goods need to be exported orimported, and this method tends to rely less on inventory levels to ensure accuracy.", "label": "human"}
{"ID": "00240168", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Although there are differences between periodic and perpetual inventory checks, they generally follow a three-stage process of preparation, implementation, and completion, as shown in Figure 5.1 (before, during and after the stocktake).", "label": "human"}
{"ID": "00240169", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The inventory implementation stage, depending on the inventory method that the enterprise chooses, will have different processes. But at this point, the essential task is to precisely count and record every item in the inventory. The set time must be followed for the sequential inventorying of all items. You must examine any deviations after finishing the initial inventory and retake it if necessary. Variation can be smaller or higher, but both have an impact on inventory valuation and the effectiveness of inventory management. It’s time to update inventory levels when all deviations have been correctly identified.", "label": "human"}
{"ID": "00240170", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "All information must be available in the business system and able to report on the current value of all inventory. This will be the new authentication basis that the inventory system will use to record transactions. From here, businesses can make better choices based on what is in stock and what needs to be ordered.", "label": "human"}
{"ID": "00240171", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After the inventory check or at the end of the inventory check phase, when the inventory check results are available, the inventory management tasks are not yetcompleted. The first task is to accurately revalue the entire inventory. For busi nesses that have accurate knowledge of which goods are in stock and their value, it is time to rearrange the items that are about to run out and analyze the results ofinventory management. Pay special attention to the differences between the results of the inventory check and the management system. Any discrepancy in inventory is bad news for the business. They are often a sign of a larger problem in inventory control, which can be disastrous if left unchecked. In addition, they mean that the business is being run based on inaccurate information.", "label": "human"}
{"ID": "00240172", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "During the process of checking goods, accurate product information and corresponding quantities need to be recorded. Ensuring the accuracy of the inven tory check results is crucial, as this information will be used for other tasks such as monitoring inventory, import-export, and making further business decisions.", "label": "human"}
{"ID": "00240173", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In practice, there are many ways to check goods in stock, such as (i) attaching QR codes/Barcodes to product batches and using scanning devices, (ii) using NFC (Near-Field Communications) tags, etc. They all have the common feature of using labels, tags attached to products, and using other reading devices to read product information.", "label": "human"}
{"ID": "00240174", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Therefore, to automate the inventory check process and ensure accurate inven tory check results, this research proposes a solution to automate the inventory check process using RFID. The process of using RFID in inventory checks is described in 5.2:", "label": "human"}
{"ID": "00240175", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "As explained in section 3.1, to read RFID tags, a reader device such as hand held devices or compatible antennas is required. At this stage, the reader device will scan RFID tags in all storage areas in the warehouse. Depending on the typeof inventory check or management assignment, inventory checkers will use hand held RFID readers or scan tags using antennas on the system. The collected data includes (i) RFID tags and (ii) their current storage location. This information will be transmitted from the reader devices to the management support software.", "label": "human"}
{"ID": "00240176", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After scanning the RFID tags on the products, the collected information is theinitial inventory check result or evidence of the presence of goods in the ware house, including (i) RFID tags and (ii) their current storage location. The software application will receive this information and process it. It will compare the results obtained with the stored data on the system.", "label": "human"}
{"ID": "00240177", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After the integrated software application has successfully processed the data, the resulting inventory check includes (i) information on goods, (ii) system quantity, (iii) actual quantity, (iv) actual storage location, and (v) discrepancies. All this information will be saved to the system and displayed on the application screen. At this point, the warehouse manager will have information on goods, actual quantity, and any damage. From there, they can make decisions on further actions.", "label": "human"}
{"ID": "00240178", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "This thesis has established an integrated inventory process with an automatedinventory technique utilizing RFID and connected with the human inventory pro cess of the company after studying the overview process of products inventory. The business flow in the DxClan system is defined in detail as follows and is depicted in Figure 5.3:", "label": "human"}
{"ID": "00240179", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Create inventory checklists, which are created by warehouse staff to serve re quests for warehouse import-export, return goods, or regular inventory checksat fixed intervals.", "label": "human"}
{"ID": "00240180", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Person in charge: Person responsible for managing the goods inventory check process on the checklist Supervisor: Person responsible for supervising the goods inventory check process Accountant: Responsible for checking the invoices and documents related to goods, creating inventory check invoices, reporting to the warehouse.", "label": "human"}
{"ID": "00240181", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Warehouse workers: Perform tasks related to inventory check 3. Perform goods inventory tasks. There are two methods of inventory, manual inventory and automated inventory.", "label": "human"}
{"ID": "00240182", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "For automated inventory: warehouse personnel perform inventory withRFID devices, with monitoring from accounting personnel and supervi sion from monitoring personnel.", "label": "human"}
{"ID": "00240183", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Quality inspection personnel perform quality control checks on stored goods,packaging conditions using visual inspections and report to inventory person nel.", "label": "human"}
{"ID": "00240184", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The inventory supervisor receives the preliminary report from warehouse per sonnel, updates information, matches the quantity of goods in the system with the report, and simultaneously sends invoices and related documents to theaccounting department.8. Warehouse accounting personnel print out reports, inventory records, and re lated documents for storage.", "label": "human"}
{"ID": "00240185", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The warehouse manager receives the completed inventory request from the responsible personnel. Then, he/she checks and confirms the completion of the inventory process.", "label": "human"}
{"ID": "00240186", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After the warehouse staff performs an inventory with RFID, the system receivesa data set that includes all the RFID codes in the warehouse and the actual stor age location of each RFID code at the warehouse. Next, the system compares each RFID code and their storage location according to the data on the system and thedata obtained from the inventory. The result of this comparison is the final inven tory result. According to Ms. Tong Thi Luyen’s master’s thesis on the process oflogistics warehouse management , for the inventory results, important informa tion to be presented includes:", "label": "human"}
{"ID": "00240187", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Quantity: The number of products in stock that are counted, including the actual quantity and the quantity being stored in the system.", "label": "human"}
{"ID": "00240188", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Therefore, when displaying detailed inventory results with RFID tags in logis tics warehouses, it is necessary to show full information including:", "label": "human"}
{"ID": "00240189", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Lot Number: The lot number and quantity of the goods in that lot.•RFID: The corresponding RFID code in each batch of goods and the number of products corresponding to each RFID code.", "label": "human"}
{"ID": "00240190", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The physical storage location according to the data from the management soft ware and the physical storage location of that RFID code in the warehouse.", "label": "human"}
{"ID": "00240191", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "ResultThis thesis has successfully installed the feature of performing automatic inven tory of items in accordance with the typical process of inventory operations on theDxClan system through the research and development process. Putting this capa bility into the warehouse enables organizations to easily inventory products and categorize them as needed. reducing expenses and operating time while increasing warehouse management productivity.", "label": "human"}
{"ID": "00240192", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "To access this screen, the user selects View inventory details after performing an automatic inventory. This screen displays information including: (i) Commodity information, (ii) Shipment information - quantity of goods in the lot, (iii) list of RFID codes of that shipment and quantity of goods. on 1 RFID tag (iv) storage location of goods according to each RFID code. The red RFID code is the RFID code of the goods that are not found at the warehouse and with the warehouse location, the red shows that the goods are not in their correct location being stored on the system.", "label": "human"}
{"ID": "00240193", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The application’s automatic inventory function makes it simple to complete the inventory process quickly and with extremely accurate results. Also, each RFID code for each shipment is given a detailed presentation of the inventory findings, which also amply illustrates the current status of the inventory of the items.", "label": "human"}
{"ID": "00240194", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Problem Managing and storing items in the warehouse is a crucial task for companies that offer logistics services. A liquid asset of the company, goods in stock have a direct impact on both the operation’s success and its long-term development plans.", "label": "human"}
{"ID": "00240195", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "So, it’s essential to organize and arrange the goods in the warehouse in a system atic manner. Businesses benefit greatly from this, saving money on storage costs, improving managerial effectiveness, rotating inventory, and lowering operational costs. But, in practice, there are still many of companies who haven’t concentrated on managing and optimizing the placement of their goods storage. When does the necessity to construct the warehouse island process become an issue, and when is it reasonable?In addition to housing a vast quantity of items in the warehouse, the classifi cation of those goods is also enormous and intricate. Sorted into each package according to size and expiration date depending on the type of commodities that require various storage facilities and storage conditions. To assist maintain safety and stream the process of storing and moving goods, it is crucial to find the appropriate storage location for each type of good in a logistics warehouse. Above all, consistent monitoring to determine the precise location of products in storage so that necessary adjustments can be made. hence reducing a number of hazards associated with the management of items in the warehouse.", "label": "human"}
{"ID": "00240196", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "When managing and storing goods in logistics warehouses, difficulties are often encountered, including: (i) because the warehouse area is very large, the areas store a lot of goods, so it is difficult to determine the exact locations where the goods are stored. goods are stored in the warehouse, (ii) because it is difficult to locate the goods, so it takes a long time in the process of importing and exporting goods, (iii) there is a high risk of loss of goods because the goods are not strictly controlled(expiry goods, damaged, stolen, ...).In order to develop the functions of warehouse rotation in accordance with real ity, to help businesses save costs and operate effectively, the process of performinggoods warehouse rotation, input data to perform warehouse rotation, storage spec ifications, finding a suitable new storage location for the goods and how to ensure that after this process of turning the warehouse, the goods have been arranged to the desired location are issues that need to be solved.", "label": "human"}
{"ID": "00240197", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Solution When storing goods in the logistics warehouse, goods information needs to be stored correctly. The storage of goods is very important, that information will be used to perform other tasks such as shipping, inventory, maintenance, returns, etc.", "label": "human"}
{"ID": "00240198", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In fact, there are many ways to save goods. goods storage such as: (i) block storage loading goods into a large block, (ii) pallet storage - goods are stored in specially designed shelves with the help of planks , (iii) shelves - flexible, optimal storage system, providing a large storage space,...", "label": "human"}
{"ID": "00240199", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "At a logistics warehouse, the inventory is primarily made up of finished goods that have been imported from manufacturers and suppliers and have already been pre-packaged into boxes or packages with clear seals. Consequently, managing this information in a hierarchical model is the best option for a logistics warehouse’s shelf storage approach with a flexible storage system.", "label": "human"}
{"ID": "00240200", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "A large amount of a business’s working capital is made up of inventory. Organizing the storage of goods, rotating commodities in the warehouse, or rearranging goods to reduce the loss of expired or defective inventory are all crucial pro cesses. Moving items with close-to-expiry and close-to-sold dates to the front of the shelves and shifting items with longer expiration dates to the back of the shelves is the basic concept behind turning inventory. A stock return policy that addresses both inventory and business requirements is crucial for managing better items and can assist avoid products from becoming worn out or out of date.", "label": "human"}
{"ID": "00240201", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Depending on the needs of the business and the type of goods stored in the warehouse, they will use different internal circulation methods and best fit their system. In fact, commonly known methods such as: (i) First In First Out (FIFO) are the preferred inventory control method of most retail businesses, especially in the food sector. When new goods arrive, it will be placed in the back, pushing old goods to the front to be sold first. While this method is simple and economical for retailers, not all businesses take the time to do so. (ii) First Expiry, First Out (FEFO), instead of defaulting to the latest coming order at the back, the soon toexpire date comes first like FIFO. This technique is time-consuming to perform, but is evaluated for perishable goods with a short shelf life. (iii) Last In First Out (LIFO) is not commonly used in stores, these methods are also notable. LIFO is often used with heavy, fast-moving, non-perishable or homogeneous goods in the warehouse. When the rotation of items is not necessary. In particular, this method also saves a large amount of time.", "label": "human"}
{"ID": "00240202", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In order for warehouse operations to go smoothly, tasks are clearly assigned, ensuring work efficiency and management efficiency. Then any activity in the ware house needs to build a clear process, from which to build the details of each specific business to complete that activity. This study has built up the process of rotation and rearrangement of goods in the following Figure 5.13:", "label": "human"}
{"ID": "00240203", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Get data on the quantity of goods, the type of goods and the allowable storagelocation that the goods are in the warehouse. This data is taken from the man agement system, especially the data needs to be accurate and updated regularly to ensure all adjustments in stock are reasonable and timely.", "label": "human"}
{"ID": "00240204", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Rotate goods or rearrange the storage location of goods in the warehouse as required and optimize the storage location of goods to optimize the usable area of the warehouse.", "label": "human"}
{"ID": "00240205", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Updating data on the quantity of goods, the type of goods and the storage loca tion of goods in the warehouse is very important. Timely and accurate updating of goods information is a premise for getting data to perform all other activities in the warehouse from importing and exporting goods to management and statistics.Finally, check if the goods have been moved and rearranged according to the original wishes. This check acts as a confirmation step, ensuring this rotation has been performed on the goods and physical storage location and not just the numbers that appear on the system.", "label": "human"}
{"ID": "00240206", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "To be able to get the most accurate and complete data set in terms of goods in formation, quantity and location of goods stored at the warehouse in real time, theinventory results are the ideal data source. In addition, the use of automated inven tory methods using RFID tags in the warehouse further increases the accuracy of the inventory results. Therefore, this thesis has proposed the function of suggesting warehouse rotation based on inventory results.", "label": "human"}
{"ID": "00240207", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "As described in Section 5.1, after performing automatic inventory with RFID, the resulting inventory includes the actual quantity and actual storage location of goods according to each RFID code. From there, it is easy to recognize that the goods are in the wrong position compared to the information on the system or the goods are in small quantity, the goods are about to expire. These are the reasons that goods need to be moved to the appropriate storage location to optimize storage space in the warehouse as well as to manage inventory effectively. For goods in the wrong location, the suggested location to move to will be their storage location stored on the system. Or for goods with a small quantity, it will be suggested to move them to a suitable shelf to make room for goods with a larger quantity, helping to optimize storage space effectively. Finally, items that are about to expire should be prioritized for moving out over newer items under the FEFO or FIFO method.", "label": "human"}
{"ID": "00240208", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In addition, the study also builds a business process to rotate goods in the ware house based on the inventory results as shown in Figure 5.14:Figure 5.14: Business process of inventory rotation The detailed description of the process of moving goods in the warehouse is as follows:", "label": "human"}
{"ID": "00240209", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Step 1 : The warehouse keeper looks at a suggestion to rotate goods based onthe inventory results obtained from the last inventory. Information suggested ware house island includes.", "label": "human"}
{"ID": "00240210", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Commodity information: SKU, name, shipment RFID code of the package to be moved Current storage location Required storage location Reason for rotation Step 2 : The storekeeper creates a goods rotation note and assigns personnel to perform.", "label": "human"}
{"ID": "00240211", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Print shipping slip Search and retrieve goods to be moved Sort goods into new location Confirm job completionStep 4 : The warehouse staff reports the completion of the work to the store keeper and updates the status of the slip.", "label": "human"}
{"ID": "00240212", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Step 5 : The storekeeper receives the request and conducts a re-inventory of the goods to ensure they have been moved to the desired storage location.", "label": "human"}
{"ID": "00240213", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "There are a number of requirements that must be followed while moving prod ucts internally in order to ensure a smooth and effective movement, such as the necessity to ensure the safety of the carrier, the items, and the transport equipment.", "label": "human"}
{"ID": "00240214", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "To guarantee effective warehouse management, deliveries of goods must be made at the appropriate time and location and must be precisely recorded. Internal goodstransportation procedures must be flexible enough to accommodate changing busi ness needs. To prevent theft or loss during rotation, it is important to keep an eye on the procedure for rotating the warehouse of goods.", "label": "human"}
{"ID": "00240215", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Nowadays, there are numerous ways to transport products internally, including employing forklifts, which is the simplest and most popular approach, as well asconveyors, elevators, slides, and goods tubular systems. small, lightweight, or uti lizing robotic and automated technology to stream procedures and cut down on labor. Each of these approaches has benefits and drawbacks of its own, thus the best approach should be chosen based on the demands and circumstances of the organization.", "label": "human"}
{"ID": "00240216", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "To maintain correctness and transparency of the products management process in the warehouse, the warehouse keeper must re-invent the items after completing internal rotation of the goods in the warehouse. This is another requirement that must be fulfilled when moving items within a warehouse, as mistakes like loss,loss, or additional may happen. A re-inventory will reduce errors and assist estab lish the precise amount of stock still available. Re-inventory is therefore crucial to assure accuracy, demonstrate a successful warehouse rotation, and adhere to the requirements of the products management process in the logistics warehouse.5.2.3 ResultThis research has successfully implemented and installed the function of suggesting and reversing the goods warehouse to a suitable storage location. The con struction of this function in the warehouse makes it easy to optimize the storagespace of goods and capture timely goods information. Thereby saving costs, oper ating time and improving the productivity of warehouse management.", "label": "human"}
{"ID": "00240217", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "screen to perform the job of goods warehouse islandFigure 5.16: The screen of performance the inventory rotationThe inventory rotation screen is shown in Figure 5.16. Similar to the inven tory island suggestion screen is this one. Another another Re-Inventory button is present. When this button is pressed, the system will automatically re-invent the inventory to see if the items have been stored in the desired location in accordance with the warehouse rotation request or not. You can view the outcomes of rotating the warehouse using the storage locations on this screen, including the positioningof the items based on inventory data, the desired location while rotating the ware house, and the position after the warehouse has been turned. When the placement of the goods at the end of the warehouse rotation matches the intended location, the operation was successful.", "label": "human"}
{"ID": "00240218", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Problem Businesses must process goods information, attach goods information, and RFIDtag codes before using RFID and the process of inventorying items in the warehouse. The most accurate inventory results will be obtained if all items are RFID tagged, which also helps with efficient inventory management. The development,implementation, and administration of warehouse activities are crucial for the ware house. A warehouse is a component of an organization, with its own managers, staff, and activity flows. Building a consistent operating flow aids the warehousemanager in efficiently managing the space, ensuring correct data and documen tation, and providing clear and appropriate assignment. So how and when should the RFID code be applied to the goods in order to prevent interference with other processes?A problem that needs to be given priority in order to be solved is also listed in the information attached to the RFID tag. While scanning the RFID tag code during the inventory process, make sure to precisely and clearly identify the items information so that the most full and accurate results are acquired. At the same time, how to search and view the goods information corresponding to each RFID code and how does the tag management take place? Finally, with this type of RFID tag, after the goods are out of the logistics warehouse, can businesses reuse this card?In order to develop the functions of assigning RFID codes and goods infor mation to satisfy the necessary information for the automatic inventory process and help businesses manage effectively, the integration of the process of assigningRFID codes into the inventory process is necessary. Warehouse entry and manage ment of RFID tags are urgent issues that need to be dealt with.", "label": "human"}
{"ID": "00240219", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Solution The act of receiving or storing items in a business has a direct bearing on allof that business’s operations. Receiving, verifying, counting, storing, and manag ing the items in the warehouse are all parts of the process of goods warehousing.", "label": "human"}
{"ID": "00240220", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Building a clear warehousing process in the logistics warehouse is crucial. By ver ifying data such as production date, expiry date, manufacturer’s inspection reports, and other pertinent information, the warehousing process is intended to ensure andmanage the amount and quality of goods. Also, the creation of a defined warehous ing method aids the warehouse management process in order to boost productivity, guarantee security during storage and transportation, and lower risks and accidents.", "label": "human"}
{"ID": "00240221", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Also, the process of establishing and assigning RFID codes to goods must be com pleted during the warehousing process to guarantee that the items in the warehouse are equipped with RFID tags.", "label": "human"}
{"ID": "00240222", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In the process of studying the warehousing process and the process of assigning RFID codes to goods on applications in the market and integrating the inventory management feature of the DxClan system, this study has inherited, reproduced use and add the function of generating and assigning RFID codes to goods according to the procedure below:Figure 5.17: Import business process The statuses of the import business process at the warehouse as shown in the figure are described as follows:", "label": "human"}
{"ID": "00240223", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Create inventory requisition. The request for warehousing is sent from the sales department of purchased goods that need to be warehoused.", "label": "human"}
{"ID": "00240224", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Sales department staff make inventory schedule and list of goods 3. Sales department staff sends approval request to management 4. Once approved by the management, the requisition is sent to the storekeeper 5. The warehouse keeper confirms the request for warehousing of goods. The storekeeper needs to identify the following information in order to approve the request:", "label": "human"}
{"ID": "00240225", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Information about the department to submit the proposal Desired time to import 6. The warehouse keeper checks the current warehouse information, if it is notdetermined, it is necessary to conduct an inventory of the warehouse to de termine whether the current warehouse condition meets the requirements to enter the warehouse or not.", "label": "human"}
{"ID": "00240226", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After approving the warehouse entry request, the warehouse keeper creates a warehouse receipt and assigns warehouse personnel to participate in the warehousing process, including:•Person in charge: is responsible for managing the process of warehousing the goods of the voucher.", "label": "human"}
{"ID": "00240227", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After receiving the goods from the carrier, the staff in charge of importing goods check the relevant documents and the list of goods in the import note.", "label": "human"}
{"ID": "00240228", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "If there are enough documents and necessary information, the warehouse staff will count the quantity and quality of goods 10. After checking, the warehouse staff reports to the staff in charge of importing goods the actual quantity received and the condition and quality of the goods.", "label": "human"}
{"ID": "00240229", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The staff in charge of importing goods selects the appropriate storage location for each shipment and sends the information to the warehouse staff.", "label": "human"}
{"ID": "00240230", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Warehouse staff receive information and paste the shipment code, RFID code on the corresponding goods and arrange them in the designated position.", "label": "human"}
{"ID": "00240231", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "After completing the job, the warehouse employee sends a request to confirm the completion of the work to the staff in charge.", "label": "human"}
{"ID": "00240232", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The employee in charge of importing goods completes the input and sends a report to the warehouse keeper, and at the same time sends the request for invoices and related documents to the accounting department.", "label": "human"}
{"ID": "00240233", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In the process of creating and assigning RFID codes to goods, in order to ensure the uniqueness of each tag and ensure that all goods are labeled with RFID, it is necessary to define how to assign codes to goods. For logistics warehouses,most of the goods in the warehouse are finished products imported from suppliers and manufacturers. They are temporarily stored in the logistics warehouse while waiting for distribution, so the goods are carefully packed and sealed. Thus, when typing a shipment for storage with new shipments without data, it is necessary to determine the information of imported goods, quantity, quality, and expiry date.", "label": "human"}
{"ID": "00240234", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Next, depending on the packaging of the goods to be sealed, determine howto assign the RFID code to each package. Therefore, the quantity of goods cor responding to 1 RFID tag needs to be flexibly changed according to the type ofgoods and the method of packing. For example, if the warehouse imports 10 lap tops packed into 10 separate boxes, the number of RFID codes to create is 10, which means the number of goods assigned with 1 RFID code is 1. Conversely, ifthose 10 laptops are packed into 2 packages. For goods with each package of 5 lap tops, it is necessary to create 2 RFID codes and then the number of goods assigned with 1 RFID code is 5.", "label": "human"}
{"ID": "00240235", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In addition, the storage of RFID card code information associated with products or goods information corresponding to each RFID tag also needs to be stored into the system for comparison and management. Also, although there are restrictions on looking for and retrieving information about items stored in the card due to the usage of RFID tags, the card can still be used numerous times. Build tools to manage, search, track, and retrieve data about the commodities associated with each RFID tag and the status of that tag’s usage.", "label": "human"}
{"ID": "00240236", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "RFID card code The usage status of the RFID tag includes using or not using Name of goods assigned with RFID tag Quantity of goods assigned with RFID tag Goods lot code assigned with RFID tag Expiry date of the shipment Current storage location of the RFID tag 5.3.3 Results Through the process of research and development, this study has successfully implemented and installed the function of generating RFID codes in accordance with the standard process of importing goods on the DxClan system. Building thisfunction in the warehouse makes it easy for businesses to generate RFID codes suitable for products, flexible in categories. Thereby saving costs, operating time and improving the productivity of warehouse management.", "label": "human"}
{"ID": "00240237", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Therefore, the work of repairing damage is difficult, takes a lot of time, costs and can cause serious damage to businesses and greatly affects customers.", "label": "human"}
{"ID": "00240238", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Controlling movement or movement of goods in the warehouse and inventorymanagement are both very challenging tasks. The items change continuously through out the day while importing, exporting, inventorying, or rotating because there is so much work going on in the warehouse. To enable businesses and managers have a general idea of the situation with items in the warehouse as well as the situation with import and export in the warehouse, statistics and reports in the warehouse in real time are crucial. One of the secrets to a successful business is also this.", "label": "human"}
{"ID": "00240239", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Finding and tracking the movement of commodities, as well as the history of successful import and export, is therefore crucial and has a direct impact on how a business operates. Controlling that information enables organizations to readily track specific shipping details and make business-appropriate strategies.", "label": "human"}
{"ID": "00240240", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "SolutionThe first step is to establish the fundamental data for goods management in or der to be able to rapidly search for goods information and easily trace their daily changes through professional operations in the warehouse. In actuality, various batches of each kind of product will be imported into the warehouse. Althoughbeing the same commodities, each batch of these imports has a different manu facture and expiration date. The best course of action at the moment is to handle products through consignments.", "label": "human"}
{"ID": "00240241", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The code, name, and maker of goods belonging to the same lot will be the same, but the expiration date for each batch will be different. When goods having a fixed shelf life, such as cosmetics, agricultural products, medications, or clothing, expire, substantial injury and loss result. sizeable for business. Also, grouping products into batches will make it easier for firms to track, search for, and manage the qualityor expiry date of the products, reducing unneeded risks.", "label": "human"}
{"ID": "00240242", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "This thesis creates a function that enables users to search and track informa tion on the activity history of each shipment in recognition of the significance of such information for helping businesses manage the shipments of items kept in the warehouse.", "label": "human"}
{"ID": "00240243", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Jobs like warehousing, discharging, returning items, etc. will be kept in the his tory of that cargo after they are finished in order to save shipment information.", "label": "human"}
{"ID": "00240244", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The manager will be able to access more information by connecting the history information with the ticket information using the coupon code. The data is readily accessible when managers need to retrieve it.", "label": "human"}
{"ID": "00240245", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "History record time: is the time to execute that order History type (material entry, damage, expiry date, return, . . . ) Quantity of goods involved in that activity The warehouse performs that operation.", "label": "human"}
{"ID": "00240246", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Results After the operations of warehousing, rotating the warehouse, and releasing the warehouse, this thesis has successfully developed the function of searching and tracing changes of items during storage. From there, it makes it simple for the management to keep track of the precise time, the number of items, the activity that is being performed, and the people who are actually interacting with the batch of that item.", "label": "human"}
{"ID": "00240247", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In the case of a consignment that has a problem, recording the specifics of the consignment’s history can be easily accessed by the user, confirming which step ithappened from in the warehouse processes, by which individual, thereby determin ing which individual’s responsibility belongs to, and giving appropriate solutions.6.1 ConclusionIn order to complete the warehouse management application for logistics warehouses, this thesis successfully developed and published a tiny module that is incor porated into the DxClan digital workspace system. The module’s primary functions are as follows:", "label": "human"}
{"ID": "00240248", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "Automate inventory with RFID as planned Suggestion to rotate the goods warehouse based on the results of the obtained inventory Generate and assign RFID codes to goods during warehousingSearch, track and trace the movement of goods through activities in the ware houseAutomated inventory methods are utilized instead of traditional manual meth ods in problem-solving functions to improve the accuracy of inventory data and satisfy management system criteria for logistics warehouses. From there, the firm is in a proactive position to monitor the flow of goods and changes in the market and to formulate the best business decisions or plans. It also regulates and captures the status of commodities with the greatest accuracy. Also, the services address theissues of organizing and internally cycling inventory in the warehouse, maximiz ing the storage space, and facilitating the smooth operation of import and export activities in the warehouse. When integrated with other programs like productionmanagement and transportation management, the functionalities added to the Dx Clan digital workspace system also lay the groundwork for future expansion.", "label": "human"}
{"ID": "00240249", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "The application is built based on the two most popular architectural models today, MVC and Redux. With this combination, the system will add flexibility to the user interface and can be easily integrated and expanded when the scale of the system is expanded.", "label": "human"}
{"ID": "00240250", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "In addition to the accomplishments, the proposed system has significant limita tions, including the inability to address all of the actual job cases in the warehouseand the absence of a code management function. RFID data has not yet been cor rectly represented to support additional tasks like storing and transporting items between warehouses. The most accurate modeling of the products’ storage location has not been done, and the storage sites with photos have not been represented.During the process of doing my graduation project, I have gained professional knowledge and work experience, helping me to enhance my ability to search for information, read and study documents, as well as better understand the logistics warehouse management in practice. Not only that, it also helps me develop skills to find solutions, handle and solve a real-life problem when given. B. B. K. I. Informatics and L. Automation Co., Rfid technology features and working principle . [Online]. Available: tin-tuc/411-cong-nghe-rfid-dac-diem-va-nguyen-li hoat-dong (visited on 07/20/2022).", "label": "human"}
{"ID": "00240251", "file_name": "Inventory rotation using RFID automated inventory in logistics warehouses", "content": "T. T. Luyen, “Central warehouse administration at sc-th group logistics joint stock company,” Ph.D. dissertation, Vietnam Academy of Social Sciences, VN, 2019.", "label": "human"}
{"ID": "00250001", "file_name": "Mobile application for providing home services", "content": "The motivation for developing a mobile application for providing family ser vices is driven by several key factors. Firstly, the increasing adoption of mobile phones and intelligent gadgets in today’s society has revolutionized the way people interact and access information. With a growing number of individuals relying on mobile devices, leveraging this technology becomes essential to offer convenient services.", "label": "human"}
{"ID": "00250002", "file_name": "Mobile application for providing home services", "content": "In the past, acquiring services often involved cumbersome processes such assearching the internet for contact information or relying on word-of-mouth recom mendations, resulting in time-consuming and inconvenient experiences for users.", "label": "human"}
{"ID": "00250003", "file_name": "Mobile application for providing home services", "content": "Furthermore, smartphones have become ubiquitous, transcending generational boundaries. Even elderly individuals now embrace smartphones, making mobile applications a viable and inclusive option for delivering services to a wide user base.", "label": "human"}
{"ID": "00250004", "file_name": "Mobile application for providing home services", "content": "By utilizing the application, users can efficiently browse and explore a compre hensive range of family services. The app provides a convenient and user-friendly interface, allowing easy navigation through service options, reading ratings andcomments, and making informed decisions. This enhanced accessibility and con venience enhance the overall efficiency of daily life.", "label": "human"}
{"ID": "00250005", "file_name": "Mobile application for providing home services", "content": "Moreover, the application acts as a platform for service providers to showcase their expertise and reach a broader audience. Offering services through the appenables providers to expand their customer base and benefit from direct interac tions with users. Transparency and accountability are facilitated through features like ratings and comments, allowing users to share experiences and guide others in making informed choices.", "label": "human"}
{"ID": "00250006", "file_name": "Mobile application for providing home services", "content": "In summary, the motivation behind developing a mobile application for pro viding family services lies in leveraging technological advancements, improving convenience, and enhancing the overall service experience for users and providers.", "label": "human"}
{"ID": "00250007", "file_name": "Mobile application for providing home services", "content": "The application streams service delivery, offers a wide range of choices, and fosters a more efficient and interconnected community.1.2 Objectives and scope of the graduation thesisThe objective of this graduation thesis is to develop a specialized mobile application for providing family services in Vietnam. Currently, there are limited appli cations in this domain, with only one existing app, Jupviec, focusing on cleaning services. Therefore, there is a pressing need to develop this app model, as it holds practical significance for the lives of young people and the general population.", "label": "human"}
{"ID": "00250008", "file_name": "Mobile application for providing home services", "content": "The existing app, Jupviec, has limitations as it solely caters to one specific ser vice. The scope of this thesis aims to serve similar services while intending to expand and elevate the service offerings to a more sophisticated and diverse level.", "label": "human"}
{"ID": "00250009", "file_name": "Mobile application for providing home services", "content": "Additionally, the thesis will focus on the development of an on communi cation feature for both customers and service providers. Currently, the app only provides the service provider with the customer’s profile and contact information for direct phone calls. The intention is to enhance the user experience by enabling on communication between customers and providers.", "label": "human"}
{"ID": "00250010", "file_name": "Mobile application for providing home services", "content": "The scope of this graduation thesis is practical and highly applicable to meetthe growing demands of the younger generation and the current population. By developing a comprehensive family service application, it aims to address the short comings of existing platforms and provide a wider range of services. Furthermore, the addition of on communication capabilities will enhance convenience and user interaction, improving the overall experience for both customers and service providers.", "label": "human"}
{"ID": "00250011", "file_name": "Mobile application for providing home services", "content": "Provider: Service providers who create and offer their services within the appli-cation. They can directly interact with the frontend to manage their services.", "label": "human"}
{"ID": "00250012", "file_name": "Mobile application for providing home services", "content": "Frontend: The user-facing part of the application where customers and providersinteract. Customers can easily access and book services, while providers can man age their offerings.", "label": "human"}
{"ID": "00250013", "file_name": "Mobile application for providing home services", "content": "Backend: The core logic and processing component of the application. It han dles incoming requests from the frontend, processes them, and interacts with the database to store and retrieve data.", "label": "human"}
{"ID": "00250014", "file_name": "Mobile application for providing home services", "content": "This architecture allows for a seamless and direct interaction between customers and providers. The frontend and backend work together to create a smooth userexperience, while the database stores and manages all the essential data. The sys tem’s efficiency and convenience contribute to a dynamic ecosystem where users can easily find and access the services they need, and service providers can reach their target audience directly.", "label": "human"}
{"ID": "00250015", "file_name": "Mobile application for providing home services", "content": "Requirements Survey and Analysis: This chapter will analyze the require ments for the Providing Family Services app, including the user requirements, functional requirements, and non-functional requirements. It will also provide a detailed description of the design constraints and trade-offs involved in the development of the Attendance app 2. Technology Used: This section will provide an overview of the technologies used in the app. It will also describe the technical challenges faced during the development of the app and how they were overcome.", "label": "human"}
{"ID": "00250016", "file_name": "Mobile application for providing home services", "content": "Experiment Evaluation: This chapter will describe the design, construction, and implementation of the app, including the design process, the choice of programming languages and tools, and the architecture of the app. It will also present the results of the app’s performance and functionality, as well as any limitations or areas for improvement.", "label": "human"}
{"ID": "00250017", "file_name": "Mobile application for providing home services", "content": "Solution And Contribution: This section will highlight the most valuable con tributions and innovations of me through the process of Attendance projectdevelopment, including the application of all the knowledge gained in the uni versity that I am most interested: IOS Programming, Backend Programming, and Data Structures.5. Conclusion And Future Work: This chapter presents the achieved results, strengths,and weaknesses of the application. It also outs future development direc tions for the system.2.0.1 Survey on the Users/Customers In order to understand the needs and preferences of customers and service providers regarding appointment scheduling, a survey was conducted among a sample of users. The survey aimed to gather valuable insights into their appointment booking experiences, expectations, and views on using an application for family services,such as tutor, house cleaning, and nanny services. By understanding the perspectives of both customers and providers, we aimed to enhance our application’s fea tures and functionalities to better meet the diverse requirements of our users.", "label": "human"}
{"ID": "00250018", "file_name": "Mobile application for providing home services", "content": "Comprehensive Service Listings: Our family services application offers a wide range of services, including tutoring, house cleaning, and nanny services, all within one platform. This comprehensive listing ensures that customers caneasily find and book the services they need, streamlining the process and sav ing time for busy families. Service providers, on the other hand, benefit from increased visibility, leading to potential new clients.", "label": "human"}
{"ID": "00250019", "file_name": "Mobile application for providing home services", "content": "Verified and Trustworthy Providers: We prioritize the safety and reliability of our users by thoroughly vetting and verifying all service providers on our platform. Customers can trust that the professionals they book through our app are qualified, experienced, and committed to providing top-notch services.", "label": "human"}
{"ID": "00250020", "file_name": "Mobile application for providing home services", "content": "Detailed Service Provider Profiles: Making informed decisions is essential, which is why our family services application provides detailed profiles of all service providers. We understand that families want to ensure they are hiring trustworthy and qualified professionals to care for their loved ones or manage their household tasks. By accessing comprehensive service provider profiles, you can review information about their qualifications, certifications, years ofexperience, areas of expertise, and any specializations they may have. Ad ditionally, our app includes user reviews and ratings, allowing you to read feedback from previous customers and gain valuable insights into the quality of service provided. Having access to this wealth of information empowers you to make the best choice for your family’s unique needs, ensuring peace of mind and confidence in the services you book.", "label": "human"}
{"ID": "00250021", "file_name": "Mobile application for providing home services", "content": "Secure and Convenient Payment Options: We prioritize your security and con-venience when using our family services application. We understand the im portance of safeguarding your financial information, and that’s why we offer a variety of secure payment options. Our in-app payment system ensures thatall transactions are encrypted and protected, reducing the risk of unautho rized access to your sensitive data. You can complete payments with ease, directly within the app, eliminating the need for handling cash or relying on third-party payment platforms. With secure and convenient payment options,you can book services worry-free, knowing that your financial details are pro tected throughout the entire transaction process.", "label": "human"}
{"ID": "00250022", "file_name": "Mobile application for providing home services", "content": "The survey results offer valuable insights into the preferences of customers and providers, with a particular focus on the Comprehensive Service Listings feature.", "label": "human"}
{"ID": "00250023", "file_name": "Mobile application for providing home services", "content": "This feature enables customers to access a diverse range of family services con veniently, while service providers benefit from increased visibility and access to a broader customer base. By understanding the needs of both users, we can enhance the platform to better meet their expectations and deliver an optimal family services experience.", "label": "human"}
{"ID": "00250024", "file_name": "Mobile application for providing home services", "content": "Survey on the existing applications This section was conducted to gain valuable insights into users’ experienceswith various apps for domestic services and caregiving. We examined user ex periences with Jupviec and Care.com, focusing on their features, usability, and effectiveness in finding domestic service providers and caregivers. With providedvaluable feedback, revealing that both applications were commended for their userfriendly interfaces and extensive range of service providers available. Jupviec received praise for its efficient booking system and the variety of household ser vices offered, including house cleaning, babysitting, and elderly care. Care.comwas also appreciated for its thorough screening and verification process, provid ing users with references and background checks for caregivers. However, some respondents noted the need for better communication channels between users andservice providers on both platforms. Additionally, a few users suggested the inclu sion of more integrated features to facilitate payments and stream the hiring process.", "label": "human"}
{"ID": "00250025", "file_name": "Mobile application for providing home services", "content": "Jupviec Jupviec is a Vietnamese platform that specializes in providing house cleaning services for residential and commercial properties. As a leading service provider inVietnam, Jupviec offers a wide range of cleaning solutions, including basic clean ing, kitchen and bathroom cleaning, window cleaning, and deep cleaning services.With a user-friendly interface, Jupviec allows customers to easily book cleaning services, making it convenient for busy individuals and families seeking reliable and efficient cleaning solutions. Whether it’s regular maintenance or thorough deep cleaning, Jupviec aims to deliver quality service, ensuring that all surfaces are spotless and sparkling, providing a clean and comfortable living environment for its clients.", "label": "human"}
{"ID": "00250026", "file_name": "Mobile application for providing home services", "content": "Wide Range of Service Providers: The app provides access to a diverse pool of domestic service providers, allowing users to choose from different options based on their preferences and needs.", "label": "human"}
{"ID": "00250027", "file_name": "Mobile application for providing home services", "content": "User-Friendly Interface: Jupviec’s app is designed with a user-friendly inter-face, making it easy for customers to browse services, book appointments, and manage their cleaning schedules efficiently.", "label": "human"}
{"ID": "00250028", "file_name": "Mobile application for providing home services", "content": "Customer Reviews and Ratings: Jupviec typically includes customer reviews and ratings for its service providers, helping users make informed decisions and select trustworthy and reliable cleaners.", "label": "human"}
{"ID": "00250029", "file_name": "Mobile application for providing home services", "content": "Care.comCare.com is an on platform that connects individuals and families with care givers and service providers for various needs, including childcare, senior care, petcare, housekeeping, tutoring, and more. It operates in multiple countries and al lows users to search for caregivers or service providers based on their location and specific requirements.", "label": "human"}
{"ID": "00250030", "file_name": "Mobile application for providing home services", "content": "Search Filters: The application allows users to apply various search filters to find caregivers based on location, availability, experience, hourly rates, and other preferences.", "label": "human"}
{"ID": "00250031", "file_name": "Mobile application for providing home services", "content": "Messaging and Communication: Care.com provides a messaging system within the app, allowing users to communicate with potential caregivers and service providers to discuss their needs and requirements.", "label": "human"}
{"ID": "00250032", "file_name": "Mobile application for providing home services", "content": "Reviews and Ratings: Users can read reviews and view ratings given by previ ous clients, helping them make informed decisions when selecting caregivers or service providers.2.1 Functional Overview 2.1.1 General use case diagram Figure 2.3: General Usecase The actors within the system include:", "label": "human"}
{"ID": "00250033", "file_name": "Mobile application for providing home services", "content": "Customer: Customers with registered accounts enjoy comprehensive accessto the system. They can fully utilize the search and view services, book ap pointments with their preferred service providers, and provide ratings andcomments upon completion. Additionally, customers have the option to make payments via bank transfer and manage their own accounts.", "label": "human"}
{"ID": "00250034", "file_name": "Mobile application for providing home services", "content": "Provider: Providers with registered accounts enjoy a range of features and ca pabilities. They have the ability to view their own appointments and utilize charts to monitor their performance and identify opportunities for growth.", "label": "human"}
{"ID": "00250035", "file_name": "Mobile application for providing home services", "content": "Providers are empowered to accept or dec appointments made by cus tomers, although declining appointments may result in point deductions and impact their overall rating. Additionally, providers can effectively manage their list of services using CRUD functions and maintain control over their account settings.", "label": "human"}
{"ID": "00250036", "file_name": "Mobile application for providing home services", "content": "System Admin: The System Admin assumes the role of the system administra tor, taking responsibility for the management of both customer and provider accounts. They play a crucial role in overseeing and managing appointments and addressing any issues or incidents that may arise within the system.", "label": "human"}
{"ID": "00250037", "file_name": "Mobile application for providing home services", "content": "Detailed use case diagram a, Manage account Figure 2.4: Use case LoginBoth customers and service providers can easily access the application by log ging in with their credentials. During the registration process, they provide their personal information, including name, location, and phone number. This enables accurate communication and efficient service delivery. The application ensures aseamless user experience by offering consistent functionalities for managing per sonal details.b, Manage appointments Figure 2.5: Use case manage appointments The \"Manage Appointment\" use case allows customers to book appointments, provide ratings and comments after the service is completed, and make payments.", "label": "human"}
{"ID": "00250038", "file_name": "Mobile application for providing home services", "content": "Simultaneously, service providers have the ability to accept or dec appoint ments, change the status of appointments, receive payments, and view customer profiles for communication purposes.", "label": "human"}
{"ID": "00250039", "file_name": "Mobile application for providing home services", "content": "Manage services Figure 2.6: Use case manage servicesCustomers have the option to view a list of services and apply filters such as cat egory, price range, and location to refine their search. This enables them to quickly find the desired service and make appointments accordingly. Meanwhile, serviceproviders have access to CRUD functionalities, allowing them to create, read, up date, and delete services. They can add new services, review booking details and ratings, modify service information like descriptions and pricing, and remove ser-vices as necessary. These functionalities support service providers in attracting customers and maintaining an up-to-date and appealing service portfolio.", "label": "human"}
{"ID": "00250040", "file_name": "Mobile application for providing home services", "content": "Manage booking histories Figure 2.7: Use case manage booking histories Both customers and service providers can access their booking histories, which include both upcoming and past appointments. Customers have visibility into their scheduled and completed services, while service providers can view both pending and completed appointments. Service providers have the flexibility to accept or dec pending appointments based on their availability. This functionality ensures that both customers and service providers can conveniently track their booking history and effectively manage their appointments.", "label": "human"}
{"ID": "00250041", "file_name": "Mobile application for providing home services", "content": "Manage view detail Figure 2.8: Use case manage appointmentsThe manage view detail use case revolves around functions related to presenting information to customers. This use case assists customers in gathering information about providers and services they find interesting.", "label": "human"}
{"ID": "00250042", "file_name": "Mobile application for providing home services", "content": "Business processFigure 2.9: Booking ProcessThe booking process involves two interacting factors within the system: the customer and the service provider. On the provider’s side, they can access a com prehensive list of services with the ability to perform CRUD functions, includingcreating, updating, and deleting services. Once the provider has set up their ser vices, the system renders them on the customer app, where customers can browse and select their preferred options using various filters.", "label": "human"}
{"ID": "00250043", "file_name": "Mobile application for providing home services", "content": "To proceed with the booking, the system first checks if the customer is logged in and then presents them with a booking page to choose the available time range and location for the service. Once the customer completes these steps, they move on to the transaction process. The booking process only concludes successfully when the transaction is completed.", "label": "human"}
{"ID": "00250044", "file_name": "Mobile application for providing home services", "content": "Upon a successful transaction, the system notifies the provider of the newly cre ated appointment. The provider has two options: they can either accept or dec the appointment. If the provider accepts the appointment, the system updates the status to \"accepted\" and notifies both the customer and the provider.", "label": "human"}
{"ID": "00250045", "file_name": "Mobile application for providing home services", "content": "As the scheduled date approaches, the service provider performs the booked service, and after completion, they provide evidence of the service through the app. The system verifies the evidence and updates the status to \"done,\" sending a notification to the customer app. At this point, the customer has the option to give a rating or leave a comment about the service if they wish.", "label": "human"}
{"ID": "00250046", "file_name": "Mobile application for providing home services", "content": "In case of any issues or cancellations, the system handles the situation accord ingly and updates the booking status accordingly. Ultimately, this concludes the booking process, ensuring a seamless experience for both the customer and the service provider.2.2 Functional description 2.2.1 Description of use case Search ID and Name UC01 - Search Description This use case allows customers to easily find and select services based on specific criteria Actor Customer Trigger User navigates to the service screen by clicking on the third icon in the navigation bar, located on the left side of the application interface Pre-condition User needs to allow location request permission Post-condition User can view a list of search results based on the applied filters, meeting their specific criteria.", "label": "human"}
{"ID": "00250047", "file_name": "Mobile application for providing home services", "content": "Basic Flow 1. User opens app 2. User navigates to the list services screen by choosing the third icon in the navbar 3. User selects one or multiple filtering options based on their preferences 4. The application displays a list of available services oritems, presenting essential details for each entry (e.g., ser vice name, item description, price) Alternative Flow 2a. User clicks on one of the six services displayed on the dashboard screen to apply a preliminary filter based on the selected category or type.", "label": "human"}
{"ID": "00250048", "file_name": "Mobile application for providing home services", "content": "User decides to further refine their search and clicks on the \"More Filters\" button or a similar option available on the screen.", "label": "human"}
{"ID": "00250049", "file_name": "Mobile application for providing home services", "content": "Exception Flow 5a. System error during get process 5a1. User not allowed to use location2.2.2 Description of use case Add/Update new service ID and Name UC02 - Add/Update new service Description This use case outs the register function performed by a service provider to manage services offered through the application.", "label": "human"}
{"ID": "00250050", "file_name": "Mobile application for providing home services", "content": "Actor Provider Trigger User navigates to the service screenPre-condition User must be logged in to the application, and their as signed role should be \"provider.\" Post-condition The service is being created or updated Basic Flow 1. User opens app 2. User navigates to the service screen by clicking on the third icon in the navigation bar, located on the left side of the application interface 3. User clicks on plus button located on the bottom right of the application or clicks right on the service button 4. The app opens the add new/update service screen 3.", "label": "human"}
{"ID": "00250051", "file_name": "Mobile application for providing home services", "content": "User fills all the required fields and additional ones if needed 4. User triggers the submit button 5. The application shows up a success alert and navigates back to the list services screen Alternative Flow Not have Exception Flow 6a. System error during creation/updating process 6a1. The application displays an error message 2.2.3 Description of use case Booking appointment ID and Name UC03 - Booking appointment Description This use case describes the process of a customer booking an appointment for a service offered by a provider through the application.", "label": "human"}
{"ID": "00250052", "file_name": "Mobile application for providing home services", "content": "Actor CustomerTrigger User choose preferred service types according to 6 types displayed on dashboard screenPre-condition The customer has logged into their account on the appli cation.", "label": "human"}
{"ID": "00250053", "file_name": "Mobile application for providing home services", "content": "Basic Flow 1. User opens app 2. The customer clicks on the \"Services\" icon, showing six service types on the dashboard.", "label": "human"}
{"ID": "00250054", "file_name": "Mobile application for providing home services", "content": "Once the appointment details are chosen, the user clicks Processed.\" 10. The app presents a popup confirming all appointment information for the customer to review.", "label": "human"}
{"ID": "00250055", "file_name": "Mobile application for providing home services", "content": "Alternative Flow 2a. User navigates to list services screen3a.User chooses a service and applies filters for refine ment.Exception Flow 1. System error during creation process 2. Transaction encountered an error while processing with a third party.", "label": "human"}
{"ID": "00250056", "file_name": "Mobile application for providing home services", "content": "Description of use case Accept/Dec Appointment ID and Name UC04 - Accept/Decline AppointmentDescription This use case outs the process of a service provider ac cepting or declining an appointment request received from a customer through the application.", "label": "human"}
{"ID": "00250057", "file_name": "Mobile application for providing home services", "content": "Actor Provider Trigger User navigates to Booking section( the second one from the left in navbar) Pre-condition User has logged into their account on the application.", "label": "human"}
{"ID": "00250058", "file_name": "Mobile application for providing home services", "content": "The customer receives a notification confirming the appointment acceptance or regarding the decd appoint ment Basic Flow 1. User opens app 2. User navigates to the booking screen by choosing the second icon in the navbar 3. User selects button pending to view a list of pending request booking 4. User has the option to click the \"Accept\" or \"Dec\" button based on their choice.", "label": "human"}
{"ID": "00250059", "file_name": "Mobile application for providing home services", "content": "Alternative Flow Not have Exception Flow 5a. System error during update process2.2.5 Description of use case Transaction ID and Name UC05 - Transaction with Two Payment Options (Cash and Bank Transfer) Description This use case describes the process of a customer makinga payment for a booked appointment through the applica tion. The customer has two payment options: cash or bank transfer.", "label": "human"}
{"ID": "00250060", "file_name": "Mobile application for providing home services", "content": "Actor Customer Trigger User reachs the payment stage during the appointment booking process Pre-condition User has logged into their account on the application.", "label": "human"}
{"ID": "00250061", "file_name": "Mobile application for providing home services", "content": "Alternative Flow Not haveException Flow 1. Something goes wrong during the payment process (e.g., payment failure, connection issues) 2.2.6 Description of use case Appointment Processing ID and Name UC06 - Appointment Processing Description This use case outs the steps involved in processingan appointment when the scheduled date arrives. It involves the interaction between the customer and the ser vice provider during the appointment.", "label": "human"}
{"ID": "00250062", "file_name": "Mobile application for providing home services", "content": "Both the customer and the provider have the option to rate and comment on each other’s performance.Basic Flow 1. Customer successfully creates a new appointment through the application, providing all necessary details.", "label": "human"}
{"ID": "00250063", "file_name": "Mobile application for providing home services", "content": "After completing the service, the provider updates rel evant evidence or details regarding the appointment and clicks the \"Finish\" button in the application.", "label": "human"}
{"ID": "00250064", "file_name": "Mobile application for providing home services", "content": "The customer and the provider have the option to rate and comment on each other’s performance for the service provided.", "label": "human"}
{"ID": "00250065", "file_name": "Mobile application for providing home services", "content": "Security: The app must ensure the confidentiality, integrity, and privacy ofuser data. It should employ robust encryption and secure authentication meth ods to protect sensitive information.", "label": "human"}
{"ID": "00250066", "file_name": "Mobile application for providing home services", "content": "Reliability: The app must be dependable and function correctly under a wide range of conditions. It should also have backup systems in place to prevent data loss or system crashes.", "label": "human"}
{"ID": "00250067", "file_name": "Mobile application for providing home services", "content": "Compatibility: The app should be compatible with a wide range of devicesand operating systems, and it should be able to integrate with other apps and software.", "label": "human"}
{"ID": "00250068", "file_name": "Mobile application for providing home services", "content": "Maintainability: The app should be easy to update and maintain over time, with clear documentation and a streamd development process. It shouldalso be designed with modular components that can be easily replaced or up graded.3.1 React NativeReact Native is an open-source framework for cross-platform mobile app de velopment. It allows developers to create native apps for both iOS and Androidusing JavaScript and React principles. The framework’s code reusability and native component generation ensure efficient development and a smooth user expe rience. With a vast ecosystem of pre-built components and a flexible UI designsystem, React Native has become a popular choice for building high-quality, re sponsive mobile applications. Its continuous improvement and adoption by major companies highlight its significance in modern app development.", "label": "human"}
{"ID": "00250069", "file_name": "Mobile application for providing home services", "content": "Node.js is a robust and versatile server-side JavaScript runtime that utilizesChrome’s V8 engine. Its asynchronous, event-driven architecture allows for non blocking I/O operations, ensuring scalable and high-performance applications. With a vast ecosystem of modules provided by npm, Node.js simplifies development byenabling code reuse and rapid deployment of features. Its lightweight design pro motes modularity, making it well-suited for building scalable web servers, APIs, and real-time applications. Node.js has garnered widespread adoption due to itsability to handle concurrent connections efficiently and cater to modern web de velopment demands, making it a popular choice for building data-intensive and real-time services across various industries.", "label": "human"}
{"ID": "00250070", "file_name": "Mobile application for providing home services", "content": "MongoDB is a leading NoSQL database, designed for modern, data-intensive applications. It stores data in flexible JSON-like documents, allowing for dynamic and schema-less data structures. MongoDB’s scalability and high availability areachieved through horizontal sharding and replica sets, ensuring consistent perfor mance and fault tolerance. Its powerful query language, robust indexing support, and geospatial data capabilities make it a popular choice for developers building feature-rich and scalable applications. With continuous community support and comprehensive documentation, MongoDB remains a versatile and reliable solution for data storage and retrieval in the evolving landscape of modern applications.", "label": "human"}
{"ID": "00250071", "file_name": "Mobile application for providing home services", "content": "Elasticsearch is a high-performance, open-source distributed search engine built on top of the Apache Lucene library. It excels in indexing and searching largevolumes of data with incredible speed and accuracy. Its distributed nature allows seamless scalability and fault tolerance, making it an ideal choice for applications requiring real-time search and analytics capabilities. With its rich set of features and extensive ecosystem, Elasticsearch continues to be a popular choice for various data-intensive projects and big data applications.4.1 Architecture design 4.1.1 Software architecture selection In this project, the client-server architecture serves as the fundamental model for establishing an efficient and robust communication framework. This architecture involves the utilization of interconnected clients and a central server, where clients, such as computers and smartphones, request various services and resources fromthe server. The server, a powerful machine, stores data and applications and re sponds to client requests by providing the necessary information or performing specific tasks. Through well-defined protocols like HTTP and SMTP, seamlessdata exchange occurs between clients and servers, enabling effective resource shar ing, scalability, security, and centralized management within the project.", "label": "human"}
{"ID": "00250072", "file_name": "Mobile application for providing home services", "content": "Model: The Model represents the data and business logic of the application. Itis responsible for managing data, processing user inputs, and performing rel evant computations. The Model component does not directly interact with theuser interface or presentation layer; instead, it communicates with the Con troller to receive user input and updates the View accordingly.•View: The View is responsible for the presentation and user interface of the application. It displays data to the user and provides an interactive interface for user interaction. The View receives data from the Model and renders it in a user-friendly format. However, it does not perform any data manipulation or business logic; it is purely concerned with displaying information to the user.", "label": "human"}
{"ID": "00250073", "file_name": "Mobile application for providing home services", "content": "Controller: The Controller acts as an intermediary between the Model and the View. It handles user input and updates the Model based on user actions. When a user interacts with the View, the Controller receives the input, processes it, and updates the Model accordingly. Similarly, when the Model changes, the Controller notifies the View to update the user interface accordingly.", "label": "human"}
{"ID": "00250074", "file_name": "Mobile application for providing home services", "content": "Overall design The Overall Design subsection holds significant importance within the project’ssoftware architecture. It serves the purpose of organizing and presenting the sys tem’s packages in a manner that is both comprehensive and easy to comprehend.", "label": "human"}
{"ID": "00250075", "file_name": "Mobile application for providing home services", "content": "To offer a visual representation of the various packages and their interactions, theUML Package Relationship Diagram is included below. In this three-tier architec ture, there are three main packages representing distinct layers:", "label": "human"}
{"ID": "00250076", "file_name": "Mobile application for providing home services", "content": "Frontend Package: The package serves as the user interface, connecting theuser to the application. It includes three folders: the Redux Folder, responsi ble for storing global values and managing application state using Redux; the Component Folder, containing reusable components that break down the userinterface into smaller, manageable parts for efficient reuse throughout the ap plication; and the Screen Folder, where each screen is represented with its UI elements and main functions.", "label": "human"}
{"ID": "00250077", "file_name": "Mobile application for providing home services", "content": "Backend layer: implemented using Express.js, the core component handles the application’s logic and user request processing. This layer comprises threemain packages: the Router Package, defining API endpoints and routing incoming requests to the appropriate controllers; the Controller Package, con taining the business logic that orchestrates data flow and interactions betweenthe frontend and the database, processing requests from the Router and communicating with the Model package to perform CRUD operations on atten dance records stored in the database, generating appropriate responses; and the Model Package, representing the data access layer, interacting with thedatabase (e.g., MongoDB) to fetch, update, and store attendance-related information. The Backend Package plays a crucial role in maintaining data in tegrity, ensuring secure access, and supporting the seamless functioning of theFigure 4.4: Overall design Proving Service App.", "label": "human"}
{"ID": "00250078", "file_name": "Mobile application for providing home services", "content": "Data layer: powered by MongoDB, serves as the foundation for storing and managing attendance-related data efficiently and flexibly. As a NoSQL database, MongoDB stores data in JSON-like documents, allowing dynamic schema structures that adapt easily to changes. Within this Data Layer, attendancerecords, student information, and other relevant data are securely stored, en suring reliable and scalable data management.", "label": "human"}
{"ID": "00250079", "file_name": "Mobile application for providing home services", "content": "Detailed package design a, Frontend Detail Package Design The frontend package is a collection of code and resources that make up the user interface of an application. It is responsible for presenting information and interacting with users. Let’s divide this frontend package into four main smaller packages:Figure 4.5: Frontend Detail Package Design Main Layout Package:: This package includes two major screens that appear in every app: the navigation bar and the login page. The navigation bar facilitates easy navigation throughout the app, allowing users to access different sections or features. The login page is where users can authenticate themselves to gain access to the app’s functionality.", "label": "human"}
{"ID": "00250080", "file_name": "Mobile application for providing home services", "content": "Screen Package: Within this package, there are two major screens designed for two types of actors: the provider and the user. Each screen is tailored to the specific needs and interactions of the respective actor. For example, the provider screen might offer tools for managing services or appointments,while the user screen provides features for browsing services or making ap pointments.", "label": "human"}
{"ID": "00250081", "file_name": "Mobile application for providing home services", "content": "Redux Package: Redux is a global state management library that stores and manages the application’s global state. Within this package, there are three main stores:", "label": "human"}
{"ID": "00250082", "file_name": "Mobile application for providing home services", "content": "The components within the \"redux\" package interact with each other througha small page called \"axiosConfig.\" This page contains all the necessary functions and basic details to make API calls using the axios library. Axios is com monly used for making HTTP requests to a backend server, and \"axiosConfig\"ensures that the frontend components can easily communicate with the back end through well-defined API functions.", "label": "human"}
{"ID": "00250083", "file_name": "Mobile application for providing home services", "content": "By organizing the frontend into these smaller packages, the codebase becomes more modular, maintainable, and easier to understand, making it convenient for developers to collaborate and enhance the application’s functionality.", "label": "human"}
{"ID": "00250084", "file_name": "Mobile application for providing home services", "content": "Backend Detail Package Design The backend package is a collection of code and resources that constitute the server-side logic and functionality of an application. Let’s break down this backend package into three major packages:", "label": "human"}
{"ID": "00250085", "file_name": "Mobile application for providing home services", "content": "Router Package: The Router package is responsible for handling incoming HTTP requests and routing them to the appropriate endpoints or handlers. It is divided into four main categories:", "label": "human"}
{"ID": "00250086", "file_name": "Mobile application for providing home services", "content": "–Transaction: Deals with endpoints concerning transactions or financial operations within the application.Figure 4.6: Backend Detail Package Design Elasticsearch Package: This package connects to the Router package and serves as an intermediary between the router and the controller. Elasticsearch is a powerful search engine that is used to efficiently filter and search through large datasets. The Elasticsearch package contains functions to interact with Elasticsearch and perform filtering operations based on user queries or other criteria.", "label": "human"}
{"ID": "00250087", "file_name": "Mobile application for providing home services", "content": "Controller Model Package: The Controller package is responsible for pro cessing business logic based on the data received from the Router. It connects to the Elasticsearch package to apply filtering to the data retrieved from thedatabase, utilizing Elasticsearch’s capabilities for efficient searching and sort ing. The Model package contains the data models and database interactions.", "label": "human"}
{"ID": "00250088", "file_name": "Mobile application for providing home services", "content": "It serves as an abstraction layer between the database and the controller, han dling database operations such as querying, updating, or inserting data.", "label": "human"}
{"ID": "00250089", "file_name": "Mobile application for providing home services", "content": "Within the Controller package, there is a small package called \"utils.\" This package contains utility functions that assist in handling errors when API callsare made from the Router. It ensures that error handling is centralized and consistent across the application.", "label": "human"}
{"ID": "00250090", "file_name": "Mobile application for providing home services", "content": "Additionally, there is another small package called \"View\" that connects to the Router. The View package is responsible for rendering transaction-related pages. It handles generating dynamic content based on data fetched from the database and provides the necessary information to the frontend for displaying the transaction-related pages.", "label": "human"}
{"ID": "00250091", "file_name": "Mobile application for providing home services", "content": "By structuring the backend into these smaller packages, the codebase becomes more organized, maintainable, and easier to scale. The separation of concerns allows developers to work on specific components independently, leading to better collaboration and development efficiency.", "label": "human"}
{"ID": "00250092", "file_name": "Mobile application for providing home services", "content": "User interface design The wireframe is a vital introductory visual representation of the application’s user interface design, specifically tailored for efficient attendance management.", "label": "human"}
{"ID": "00250093", "file_name": "Mobile application for providing home services", "content": "By emphasizing the layout and structure, it serves as a blueprint, outlining key elements and interactions without delving into detailed visual aspects like colorsand graphics. This skeletal framework enables designers and developers to collaboratively define the app’s functionality and flow, ensuring a clear and intuitive ar rangement of essential elements. Through the wireframe, stakeholders can review and iterate on the design before proceeding with full-fledged visual development,facilitating effective communication and decision-making throughout the develop ment process.Figure 4.7: Homepage screen with two actorsFigure 4.8: Search screen Figure 4.9: Detail booking screen 4.2.2 Layer designFigure 4.10: Detail design class diagram for Appointment and Service classFigure 4.10 is the detailed design for the Appointment and Service class including the properties and methods used in these classes. The Appointment class rep resents a booking appointment made between a customer and a service provider. It contains properties such as appointmentId, customerId, providerId, dateTime, and status to track the appointment details. The class provides methods for creating newappointments, updating existing ones, and managing their status. Similarly, the Ser vice class represents service details, including properties like serviceId, providerId, name, description, and price. It allows for creating, updating, and viewing services.", "label": "human"}
{"ID": "00250094", "file_name": "Mobile application for providing home services", "content": "Both classes act as essential entities for the booking system. The AppointmentCon troller class serves as a central controller responsible for managing the interaction between customers and service providers during the booking process. It operates onthe AppointmentEntity, which represents records of appointments. This class en capsulates methods to add new appointments, update existing ones, and facilitatecommunication between customers and providers. Through the AppointmentCon troller, customers can book appointments, while providers can manage and viewtheir bookings. The class ensures a smooth and structured booking environment.", "label": "human"}
{"ID": "00250095", "file_name": "Mobile application for providing home services", "content": "The ServiceController class is responsible for handling service-related opera tions in the booking system. It operates on the Service entity, which contains details of various services offered by providers. The class includes methods for performing CRUD (Create, Read, Update, Delete) functions on services, enabling providers tomanage their service offerings effectively. Additionally, the ServiceController pro vides a viewing mechanism for customers to browse services and apply filters to find suitable options. The class contributes to maintaining a well-organized and streamlined service management environment.", "label": "human"}
{"ID": "00250096", "file_name": "Mobile application for providing home services", "content": "To visually illustrate the interactions between these classes, the following sequence diagrams present some common use cases: booking an appointment, ac cepting/declining an appointment.", "label": "human"}
{"ID": "00250097", "file_name": "Mobile application for providing home services", "content": "The user begins by accessing the \"Service list\" page and applying multiple filters to find the most suitable services. The application then presents a list of services that match the user’s criteria. Next, the user selects their preferred service provider, and the app navigates to the provider’s details, displaying the various services they offer.", "label": "human"}
{"ID": "00250098", "file_name": "Mobile application for providing home services", "content": "On the booking screen, the user selects the desired location and date/time for theappointment. After making these selections, the user clicks the \"Proceed to Pay ment\" button to initiate the transaction process. The app then updates the controller to register the new appointment.", "label": "human"}
{"ID": "00250099", "file_name": "Mobile application for providing home services", "content": "Upon completing the appointment registration, the app notifies both the customer and the service provider about the successful booking. Finally, the app re turns to the booking screen, where the user can view the appointment details and make any necessary changes if needed.", "label": "human"}
{"ID": "00250100", "file_name": "Mobile application for providing home services", "content": "The user accesses the \"Booking\" page to view all the appointments assigned to them. On this page, the provider is presented with a list of appointments.", "label": "human"}
{"ID": "00250101", "file_name": "Mobile application for providing home services", "content": "Next, the provider can choose to perform actions such as accepting or declin ing appointments. However, before any status changes are made, the app verifies whether the provider has the necessary permissions to perform these actions. Once the verification is successful, the app updates the status of the selected appointment according to the provider’s choice.", "label": "human"}
{"ID": "00250102", "file_name": "Mobile application for providing home services", "content": "After updating the appointment status, the app notifies both the provider and the customer about the change that has just been made. This ensures that both parties are informed about any updates or modifications to the appointment status.4.2.3 Database design The entity-relationship diagram is represented as follows:", "label": "human"}
{"ID": "00250103", "file_name": "Mobile application for providing home services", "content": "User: This entity stores values related to login and defines the role of the user, which can be either ’customer’ or ’provider’.", "label": "human"}
{"ID": "00250104", "file_name": "Mobile application for providing home services", "content": "Customer: This entity stores information about users who have the role of a customer. It has a one-to-one relationship with the User entity, meaning each customer is associated with one user account.", "label": "human"}
{"ID": "00250105", "file_name": "Mobile application for providing home services", "content": "Provider: This entity stores information about users who have the role of a service provider. It also has a one-to-one relationship with the User entity, meaning each provider is associated with one user account.", "label": "human"}
{"ID": "00250106", "file_name": "Mobile application for providing home services", "content": "Service: This entity represents the various services offered by providers. It has a one-to-many relationship with the Provider entity, indicating that each provider can offer multiple services, but each service is related to only oneprovider.", "label": "human"}
{"ID": "00250107", "file_name": "Mobile application for providing home services", "content": "Appointment: This entity represents the appointments made by customers with providers. It has a one-to-many relationship with both the Provider andUser entities, signifying that each provider and user can have multiple appoint ments, but each appointment is related to only one provider and one user.", "label": "human"}
{"ID": "00250108", "file_name": "Mobile application for providing home services", "content": "User (one-to-one) Customer User (one-to-one) Provider Provider (one-to-many) Service Provider (one-to-many) Appointment Customer (one-to-many) Appointment Based on the given details, the application has chosen to utilize MongoDB, a NoSQL database, for data storage. The database design consists of five collections, similar to tables in traditional relational databases. Additionally, each collection is enriched with two fields named \"createdAt\" and \"updatedAt,\" both of which have a data type of date. These fields serve the purpose of recording the timestamp for the creation and modification of each individual record. The overall structure of the database is organized in the following manner:Figure 4.14: MongoDB database design The database design consists of several interconnected tables. The \"User\" table holds basic user information, such as name, phone number, and role (admin, user, or provider). The \"Provider\" table extends the \"User\" table and includes additionaldetails specific to providers, such as a description, avatar, offered categories, ap pointment count, individual/provider status, average rating, and address. Similarly, the \"Customer\" table extends the \"User\" table, containing customer-specific data like location, preferred address, level, and appointment count. The \"Appointment\"table contains information about scheduled appointments, including status (con firmed, pending, canceled, completed), price, location, start and end times, notes,evidence, customer rating, and verification status. The \"Service\" table stores de tails about various services, such as title, description, category, tags, picture, price, rating, available time slots, and a unique service number. This database structure facilitates efficient data management, enabling the application to handle user roles,appointments, services, and their related information effectively.", "label": "human"}
{"ID": "00250109", "file_name": "Mobile application for providing home services", "content": "Libraries and Tools Purpose Tool Version IDE coding Microsoft Visual Studio Code 1.80.1 Programing Language Javascript - ES6 6.0.0 Server-side Javascript NodeJS 18.16.0 Database GUI MongoDB Compass 1.37.0 API developement tool Postman 10.15.0 Version control system Git 2.40.1 Domain Access Control cors 2.8.5 Data Security tool crypto 1.0.1 Web Application Framework Express 4.18.2 Password Generator generate-password 1.7.0 JSON Web Token Authentication. express-jwt 7.7.5 Object Data Modeling mongoose 6.6.5 Environment Configuration Management. dotenv 16.0.3 Downloading and storing photos at the server multer 1.4.3 React framework for build app react native 0.71.5 Date Manipulation Library moment 2.29.4 Framework for Javascript react 18.2.0 HTTP Client Library axios 1.2.0 Handle form management formik 2.4.2 React Native State Management reduxjs-toolkit 2.0.27 React Framework Extension native-base 2.10.2 Auto-restart Development nodemon 2.0.20 Render DOM in Backend ejs 7.6.0 Second validation User twillio 7.6.0 Searching Upgrade Methods @elasticsearch 3.7.7 Maps Integration mapbox 0.9.79 Table 4.1: List of libraries and tools used 4.3.2 AchievementDuring the course of this thesis project, I accomplished the creation of a compre hensive and functional app that facilitates customer bookings for various services, empowering freelancers to operate independently without relying on third-partyservice providers. The app comprises several well-integrated components, each serving a distinct purpose, resulting in a seamless and user-friendly experience.", "label": "human"}
{"ID": "00250110", "file_name": "Mobile application for providing home services", "content": "The customer client provides a platform for interacting with multiple service providers, enabling users to easily book services and receive them in the comfort of their own homes, enhancing their overall quality of life. On the other hand, the provider client offers a platform for service providers to expand their reach and reputation, ensuring they are not dependent on third-party intermediaries.", "label": "human"}
{"ID": "00250111", "file_name": "Mobile application for providing home services", "content": "The user interface (UI) was designed with simplicity in mind, ensuring ease of use for all users, including seniors and those less familiar with technology. Through mobile and internet access, services can be easily accessed and availed.", "label": "human"}
{"ID": "00250112", "file_name": "Mobile application for providing home services", "content": "The Business layer comprises three essential packages. The Router package stores API path declarations, while the Controller package handles requests from the frontend (View) side, performing logical calculations, database queries, and data updates. The Modal package contains class data definitions.", "label": "human"}
{"ID": "00250113", "file_name": "Mobile application for providing home services", "content": "In the Data layer, the Data Package plays a vital role in efficiently managing in teractions with the MongoDB database and facilitating seamless connections withthe Modal package. It ensures secure and optimized storage, retrieval, and manip ulation of attendance-related data.", "label": "human"}
{"ID": "00250114", "file_name": "Mobile application for providing home services", "content": "Overall, successfully developing this app has provided me with invaluable ex perience in designing and executing complex software projects from inception to completion. This achievement highlights my ability to adeptly employ and integrate various software tools and technologies to deliver a polished and fully functional end product. The accomplishment of this project represents a significant milestone in my academic and professional journey, demonstrating my capabilities in the realm of software development.4.3.3 Illustration of main functions a, Dashboard Figure 4.15: Customer Dashboard The application consists of two main dashboard screens: one for customers and another for service providers. The customer dashboard (4.15) presents multiple services for users to choose from and highlights top providers and popular services.", "label": "human"}
{"ID": "00250115", "file_name": "Mobile application for providing home services", "content": "On the other hand, the provider dashboard features charts displaying financial and appointment data, including total earnings, appointments, and services provided.", "label": "human"}
{"ID": "00250116", "file_name": "Mobile application for providing home services", "content": "Additionally, it showcases the top-performing provider’s detailed statistics such as total earnings, appointments served, customer satisfaction (houseman), and thenumber of services rendered. These dashboards aim to offer valuable insights and facilitate efficient service management for both customers and providers(4.16).", "label": "human"}
{"ID": "00250117", "file_name": "Mobile application for providing home services", "content": "Search services Figure 4.21: Search services screenThe \"search services\" screen is a user interface where individuals can find specific services by applying multiple filters such as categories, nearest location, dis count offers, and sorting by rating. It typically includes a search bar for enteringrelevant keywords, a dropdown or list for selecting service categories, a location filter to find nearby options, a discount filter to uncover special deals, and a sorting feature based on ratings to prioritize highly-rated services. The screen displays alist of matching results with essential information about each service, and addi tional filters may be available for further refinement. The design and layout may vary, but the screen aims to simplify and enhance the service-searching process for users.", "label": "human"}
{"ID": "00250118", "file_name": "Mobile application for providing home services", "content": "To ensure that the system is working properly as expected according to its original design, the functionality of the developed system needs to be tested. The ob jective is to check if the functions are operating correctly and whether errors occur during the operation or not. The accuracy of the results displayed by the system and the correctness of the error messages will be assessed. Testing of crucial functions will be outlined in the following sections.", "label": "human"}
{"ID": "00250119", "file_name": "Mobile application for providing home services", "content": "For practical deployment of my app, I utilized a single server to host the Node.js backend application, serving as the Business layer, and deployed it on the Render service. Ad ditionally, I employed another server to set up the MongoDB database using MongoDBAtlas.", "label": "human"}
{"ID": "00250120", "file_name": "Mobile application for providing home services", "content": "The Render service proved to be highly beneficial, offering features like continuous deployment, which automatically updates the app whenever changes are pushed to the repos itory. Its user-friendly UI allowed for easy setup of environment variables, while built-inanalytics and monitoring tools provided valuable insights into the app’s performance, us age, and error tracking.", "label": "human"}
{"ID": "00250121", "file_name": "Mobile application for providing home services", "content": "After configuring the backend and data system, I proceeded to build the app as an IPA file for testing on iOS devices. The build process was seamless and didn’t require complex infrastructure.", "label": "human"}
{"ID": "00250122", "file_name": "Mobile application for providing home services", "content": "During the testing phase, I actively collected user feedback on the app’s functionality and user experience. The response was overwhelmingly positive, with users praising the app’s accurate attendance session tracking and intuitive interface. Additionally, I gathered valuable statistical data on user activity, requests, and response times, providing insights into usage patterns and areas for potential improvement.", "label": "human"}
{"ID": "00250123", "file_name": "Mobile application for providing home services", "content": "Overall, the testing deployment of the app was highly successful, showcasing its robust capabilities and receiving positive user feedback. As I continue to develop the app, I will utilize the insights gained from the testing deployment to optimize its performance and further enhance its functionality.The Solution Contribution chapter serves as the core of this report, delving into the comprehensive implementation of attendance within the family services app. This pivotal chapter explores the significant challenges encountered during the app’s development and the systematic approach taken to overcome them. By navigating this section, readers will gain profound insights into the app’s design and construction, elucidating the intricate process of transforming conceptual ideas into a functional application. Moreover, this chapter offers a detailed account of the seamless integration of cutting-edge technology to breathe life into the app, thereby realizing its full potential.", "label": "human"}
{"ID": "00250124", "file_name": "Mobile application for providing home services", "content": "MotivationIn this subsection, we explore the motivation behind implementing a chart track ing money received in the provider dashboard. The primary objective is to provide an enhanced experience for service providers, enabling them to efficiently tracktheir performance, including earnings and appointments. By offering valuable insights into their financial and appointment metrics, providers can assess their con tributions and better understand the value they bring to their customers.", "label": "human"}
{"ID": "00250125", "file_name": "Mobile application for providing home services", "content": "Solution This subsection outs the proposed solution to address the motivation stated earlier. The primary approach involves introducing a visualized solution that presentsdata to the providers in an easily comprehensible format. The implementation re volves around integrating a user-friendly bar chart that displays two key factors: the number of appointments and the corresponding earnings for each service provider.", "label": "human"}
{"ID": "00250126", "file_name": "Mobile application for providing home services", "content": "This chart will serve as a central component of the provider dashboard, allowing them to access crucial performance data at a glance.", "label": "human"}
{"ID": "00250127", "file_name": "Mobile application for providing home services", "content": "The chart’s design prioritizes clarity and simplicity, ensuring that providers of all ages, including the elderly, can effortlessly interpret the information presented.", "label": "human"}
{"ID": "00250128", "file_name": "Mobile application for providing home services", "content": "Additionally, the dashboard will offer an export chart feature, enabling providers to download and save their financial and appointment data for further analysis or reporting purposes.", "label": "human"}
{"ID": "00250129", "file_name": "Mobile application for providing home services", "content": "Result In this subsection, we discuss the tangible outcomes of implementing the chart tracking money received in the provider dashboard. By introducing this visual-ized representation of appointment and earnings data, providers will experience a significant improvement in their ability to monitor and assess their performance.", "label": "human"}
{"ID": "00250130", "file_name": "Mobile application for providing home services", "content": "The clear and concise presentation of information will enhance their understand ing of their customer interactions and financial gains, empowering them to make informed business decisions.", "label": "human"}
{"ID": "00250131", "file_name": "Mobile application for providing home services", "content": "The visualization of data through the chart will save time and effort for providers, as they can quickly grasp key metrics without the need for complex data analysis.", "label": "human"}
{"ID": "00250132", "file_name": "Mobile application for providing home services", "content": "This will foster a sense of empowerment among service providers, increasing their engagement and dedication to delivering quality services to customers.", "label": "human"}
{"ID": "00250133", "file_name": "Mobile application for providing home services", "content": "In conclusion, the implementation of a chart tracking money received in the provider dashboard is a pivotal step toward providing an optimal user experience for service providers. By visualizing appointment and earnings data, the solution enables providers to gain valuable insights into their performance and reinforces their role as valuable contributors to their customers’ well-being.", "label": "human"}
{"ID": "00250134", "file_name": "Mobile application for providing home services", "content": "Motivation This subsection highlights the motivation behind implementing multiple providertypes, ranging from freelancers to companies, in the application. The primary ob jective is to enhance the provider’s experience by allowing them the flexibility to define their identity as either individual freelancers or as part of a company. This dynamic feature ensures that the application caters to a diverse range of service providers, accommodating both sole practitioners and larger organizations.", "label": "human"}
{"ID": "00250135", "file_name": "Mobile application for providing home services", "content": "Solution This subsection outs the proposed solution for incorporating multiple provider types. The backend of the application will be equipped with an additional fieldcalled \"isIndividual\" that distinguishes whether a provider is an individual free lancer or part of a company.", "label": "human"}
{"ID": "00250136", "file_name": "Mobile application for providing home services", "content": "In the front-end registration process, new providers will be presented with a default checkbox where they can indicate whether they are an individual freelancer or part of a company. After registration, providers can update their personal details, and a dedicated tab will be available to change their provider type or add additional members if they are part of a company.", "label": "human"}
{"ID": "00250137", "file_name": "Mobile application for providing home services", "content": "Result In this subsection, we discuss the positive outcomes of implementing multiple provider types. By allowing providers to choose their identity accurately, the appli-cation can attract a broader range of service providers, satisfying the needs of both individual professionals and organizations seeking to offer family services.", "label": "human"}
{"ID": "00250138", "file_name": "Mobile application for providing home services", "content": "This feature enhances the user experience, providing a seamless and person alized onboarding process. Providers can now express their identity accurately, leading to better matching between service providers and customers. Additionally, companies with multiple members can efficiently manage their workforce throughCRUD (Create, Read, Update, Delete) functions, allocating tasks and responsibili ties with ease.", "label": "human"}
{"ID": "00250139", "file_name": "Mobile application for providing home services", "content": "In conclusion, the implementation of multiple provider types in the application, ranging from freelancers to companies, is a strategic move that fosters inclusivity and diversity within the platform. The flexibility offered to providers in definingtheir identity ensures a more personalized experience, leading to improved satis faction and a thriving ecosystem of family service providers.", "label": "human"}
{"ID": "00250140", "file_name": "Mobile application for providing home services", "content": "MotivationThe motivation behind implementing a time filtering mechanism for individ ual providers is to enhance the overall experience for these providers. By allowingthem to specify their available time slots accurately, the application aims to prevent scheduling conflicts and optimize the appointment booking process. This fea ture is designed to ensure that customers can only choose appointments within the provider’s designated working hours, leading to better scheduling and increased customer satisfaction.", "label": "human"}
{"ID": "00250141", "file_name": "Mobile application for providing home services", "content": "SolutionThe proposed solution for filtering available time for individual providers in volves several key steps. When individual providers register or update their profiles, they will be required to specify their daily time range of availability. This includes setting their working hours and any possible breaks or periods of unavailability.", "label": "human"}
{"ID": "00250142", "file_name": "Mobile application for providing home services", "content": "To prevent customers from selecting unavailable time slots, the application will perform a real-time check during the appointment booking process. If a customer attempts to schedule an appointment outside the provider’s designated available time range or within two hours before the end of the available time, the application will display a notification on the screen. Additionally, all service selection buttons will be disabled to prevent customers from proceeding with an unavailable time slot.", "label": "human"}
{"ID": "00250143", "file_name": "Mobile application for providing home services", "content": "Furthermore, the provider’s available time range will be dynamically adjusted toaccount for existing appointments. After every appointment is made, the time slot of the appointment will be subtracted from the provider’s daily time range. This ensures that customers can only select from the remaining available time slots, reducing the risk of overbooking and potential conflicts.6.1 ConclusionIn conclusion, the primary objectives of the graduation thesis have been accom plished successfully. The developed application offers several advantages when compared to similar native apps, as it provides multiple services from variousproviders. Essential basic flows, such as booking, transaction handling, and ser vice management, have been implemented effectively.", "label": "human"}
{"ID": "00250144", "file_name": "Mobile application for providing home services", "content": "Throughout the project, I have gained invaluable knowledge and skills in software development, including learning new architectures and programming languages. The experience of designing and developing a system has been enlightening, providing insights into constructing efficient systems following proper pro cedures. This learning journey will undoubtedly prove beneficial when tackling more extensive projects in the future, as it allows for time-saving and minimizes errors by adhering to essential principles.", "label": "human"}
{"ID": "00250145", "file_name": "Mobile application for providing home services", "content": "However, the project was not without its challenges. Time management was cru cial in ensuring the successful completion of the product. Designing a user-friendly interface, especially one that is easily understandable for elderly and middle-aged users, required careful consideration and adjustments. Moreover, handling multiplealgorithms and integrating third-party components presented significant complex ities and demanded extensive effort.", "label": "human"}
{"ID": "00250146", "file_name": "Mobile application for providing home services", "content": "In conclusion, the app’s focus on an easy-to-use UX, meaningful user experi ence, and addressing real-world challenges has been its cornerstone. As technology continues to evolve, this application stands as a valuable contribution to the field of home services, promising convenience and reliability to users in the current and future years. The completion of this thesis marks a significant milestone in my academic journey, shaping my skills and knowledge to excel in future endeavors.", "label": "human"}
{"ID": "00250147", "file_name": "Mobile application for providing home services", "content": "In order to enhance the application providing family services and improve its overall user experience and efficiency, three essential features can be introduced.", "label": "human"}
{"ID": "00250148", "file_name": "Mobile application for providing home services", "content": "The first key feature to integrate into the application revolves around offeringenhanced service customization options for users. By allowing individuals to tai lor each service according to their specific needs and preferences, the application can empower its users with more control over the services they avail. Through auser-friendly interface, customers will have the flexibility to select various serviceparameters, including service duration, add-ons, and other personalized require ments. This level of customization fosters a greater sense of user satisfaction, asclients can receive services that precisely align with their unique preferences, lead ing to increased engagement and fostering long-term relationships.", "label": "human"}
{"ID": "00250149", "file_name": "Mobile application for providing home services", "content": "Furthermore, to support service providers and stream their business operations, the application can benefit from the implementation of an advanced fi nancial tracking system. This comprehensive system would empower providers to efficiently manage their appointments and finances with ease. By incorporating automated appointment scheduling and reminders, service providers can optimize their time and avoid potential conflicts. Additionally, real-time financial reporting and analysis would enable providers to gain insights into their revenue streams and financial performance. Moreover, a pricing model that factors in essential variablessuch as service duration, prevailing market rates, and desired profitability will en able providers to set competitive prices while ensuring their financial viability and competitiveness.", "label": "human"}
{"ID": "00250150", "file_name": "Mobile application for providing home services", "content": "The third crucial feature to incorporate into the application is a diversified payment system. Recognizing that users have varying payment preferences, the application should offer a range of payment options to accommodate all needs. Inte grating popular digital payment platforms like Momo and other mobile paymentmethods, alongside traditional cash payments, will ensure a seamless and hassle free transaction process for customers. This not only improves accessibility but also reinforces user trust and encourages a broader user base to avail of the services. By catering to a diverse range of payment preferences, the application can expand its reach and position itself as a user-friendly platform for family services, fostering stronger customer loyalty and satisfaction.", "label": "human"}
{"ID": "00250151", "file_name": "Mobile application for providing home services", "content": "By implementing these three pivotal features, the application can elevate its offerings, improve the overall user experience, and foster a thriving ecosystem for both users and service providers in the family services domain. NodeJS Ltd, Introduction to NodeJS . [On]. Available:  js.org/en/docs/ (visited on 23/07/2023)  Meta Platforms, Inc., Introduction React Native . [On]. Available: http s://reactnative.dev/docs/getting-started (visited on 23/07/2023) Mongoose Core Concepts . [Online]. Available:  .com/docs/guides.html (visited on 23/07/2023)", "label": "human"}
{"ID": "00260001", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "On news outlets have become an integral part of our modern society, primarily due to their ease of access and often free availability. The news plays a cru cial role in shaping public discourse and informing individuals about significant events, trends, and societal issues. Their influence on public opinion and behavior has raised concerns among various groups, including legislators, content creators, and marketers. Aside from the effects, what are being written on the news should be a good reflection of people’s will, attention and even cultural standard.", "label": "human"}
{"ID": "00260002", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "In Vietnam, even though journalists have received a lot of criticisms, and facing competition for people’s attention from a myriad of other sources of informa tion , especially in recent years, news outlets still receive a large amount of traffic (27%) compared to other methods to receive information.", "label": "human"}
{"ID": "00260003", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "From the defined objectives in section 1.2, the primary focus would be on ad dressing two specific problems: monitoring topics and keywords on on news sites and conducting basic analysis on the collected data. To tackle these challengeseffectively, two key components need to be developed: a robust data collection sys tem capable of operating reliably 24/7 and real-time or near-instantaneous basic analysis capabilities.", "label": "human"}
{"ID": "00260004", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "The first step would involve constructing an efficient data collection system that can reliably gather information from on news sites. This system would need to handle the high velocity of incoming data and operate continuously without interruptions. By ensuring its reliability and uninterrupted operation, the system can gather the most up-to-date data, capturing the latest articles and information from the targeted news sites.", "label": "human"}
{"ID": "00260005", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Once the data collection system is in place, the next focus would be on per forming basic analysis on the collected data in real-time or with minimal delay.", "label": "human"}
{"ID": "00260006", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "This analysis could involve tasks such as identifying trending topics, extracting key information and sentiment analysis. By conducting these analyses in real-timeor near-instantaneously, the system can provide users with timely insights and up dates.", "label": "human"}
{"ID": "00260007", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "The subsequent sections of the reports would delve into the detailed process ofdesigning, building, and operating the project. Additionally, a brief overview of po tential future improvements would be provided. The following chapter would focus on the first required actions that needed to be done after an idea was lit - analyzing how the public and target users would react and what are their real requirements.", "label": "human"}
{"ID": "00260008", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "After that would be the Methodology section, where all the analysis and surveys are then converted into the project’s structural and detailed designs. Chapters 4 and 5 would focus on the construction and assembly of the project components. It wouldprovide an in-depth exploration of how these components were developed and integrated to form a cohesive system. Additionally, experimental assessments would beconducted to evaluate the performance and effectiveness of the implemented com ponents. The final chapter would present the conclusions drawn from the project’s execution. This reflective section would highlight the achievements, successes, and areas for improvement. It would provide an opportunity to learn from any mistakes made during the project’s development, as well as identify opportunities for futureenhancements or advanced practices.This chapter focuses on the process of documenting, and analyzing the func tional and non-functional requirements for the development of the project. The study aims to provide basic understandings about users’ needs to make the success possibilities of Trendz higher.", "label": "human"}
{"ID": "00260009", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "General use case diagram The General Use Case Diagram in Figure 2.1 would provide a representation of the system’s core functionalities and the actors involved in its operation.", "label": "human"}
{"ID": "00260010", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Register: A regular user may sign up for a new account using different methods, including social networks or using Google email.", "label": "human"}
{"ID": "00260011", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Login: A registered user may sign in using his existing account View Hot Keywords: Hot keywords are basically what users would encounterafter visiting trendz.vn homepage. Every users, no matter whether they have reg istered or not should be able to retrieve basic information about ongoing trends.", "label": "human"}
{"ID": "00260012", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Advanced Features: A feature that serve registered users, exclusively. Those include detailed statistics about one keyword (sentiment, related keywords...), anal ysis about news sites and authors, receive notifications about topics, sites...", "label": "human"}
{"ID": "00260013", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Edit data manually: No matter how good the models are, there would be anoma lies or special cases that may affect the rankings. Trendz would also need to keeptrack about news sites’ components UI updates, which may affect the final out puts of the data collecting systems.", "label": "human"}
{"ID": "00260014", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Accessibility Trendz aims to support real users, and most of them may not possess high-tech expertise, so a friendly user-interface is a must. The webpage should be responsive, users’ flows of actions should be intuitive and APIs that directly serve users should response in acceptable time intervals. The requirement can be divided into smaller ones, which are:", "label": "human"}
{"ID": "00260015", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Clarity: Easy to understand/interpret icons and buttons. Users should be able to easily understand how to perform tasks and navigate through the application without confusion or frustration.", "label": "human"}
{"ID": "00260016", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Consistency: There should be no significant changes of components throughout the application: buttons should be in similar size, fonts should not be changedtoo often and components should follow one color palette.", "label": "human"}
{"ID": "00260017", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Predictablity: Buttons, forms and functions should be predictable. An example for this is that a button with trash can icon should behave as a \"DELETE\" button.", "label": "human"}
{"ID": "00260018", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Error handling: Avoid \"UNKNOWN ERROR\" as much as possible. Whenever there is an anomaly in users’ inputs or behaviors, the UI should be able to instruct users to review and correct those mistakes.", "label": "human"}
{"ID": "00260019", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "ReliabilityEach component within the system should possess the capability to operate con tinuously and autonomously, without the need for human intervention. The systemmust be able to serve as many users as possible concurrently and smoothly. Addi tionally, it should be equipped to promptly notify the system administrator in the event of an outage, and ideally, possess the ability to recover automatically.", "label": "human"}
{"ID": "00260020", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "ScalabilityThere are two types of scales: vertical and horizontal. Normally, every applica tions should be vertically scalable, which means they would perform better after hardware upgrades. However, vertical scaling require downtime as it is impossible to achieve a smooth transition while having to turn the machines off. Horizontal scaling is when you increase the total capabilities of the system by adding more computers to an existing network. This approach allows for seamless expansionwithout the need to power off any nodes in the existing clusters, resulting in min imal disruptions and only small changes in requests distribution between nodes.", "label": "human"}
{"ID": "00260021", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Therefore, components should be designed to scale horizontally to mitigate sys tem downtime during updates or traffic spikes. To achieve that, they should be asstateless as possible, which means that a component’s behavior should remain con sistent regardless of its current internal status. With this approach, components can be easily replicated and distributed across multiple nodes without concerns about maintaining synchronization or data consistency.", "label": "human"}
{"ID": "00260022", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Extensiblity The journey of the project would not be stopped after graduation day, since other useful and fancy features are still being queued. Those components should be able to integrated easily with the existing ones. It requires existing components to be loosely coupled together and can be easily broken down into isolated groups that can perform without requiring the other ones. Also, changes that applied to one module should not affect the performance or break compatibility of any othermodules.In the second chapter, I have analyzed and listed required features and other non functional requirements using use case diagrams and personal experiences. From those analysis, I would introduce and explain the technologies that were used and fundamental reasons about why I chose them. Detailed implementations of those technologies within the system would be further clarified in chapter 4.", "label": "human"}
{"ID": "00260023", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Spring Boot Framework Spring Boot is a framework that is written in Java - the programming languagethat was taught in many courses during the time I studied in HUST. Despite in heriting most weaknesses of Java (boilerplate code, large memory consumption...),I have to give credits to Spring Boot for being one of the most powerful frame works to develop an API server. It supports a multitude of features, even more than I could ask for, from natively support JPA queries, caching capabilities and evensecurity functions. Also, the strict convention of Java helps developing and main taining processes a lot as the code can be self-explained and intuitive (most of the time) without significant efforts to document them.", "label": "human"}
{"ID": "00260024", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "ReactJSReactJS is a widely-used JavaScript library for frontend development. Devel oped by Facebook, it benefits from the collective expertise of a team working within one of the largest technology companies globally. ReactJS encompasses arange of built-in features and functionalities, making it a valuable tool for develop ers.", "label": "human"}
{"ID": "00260025", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "This community provides a wealth of reusable modules and libraries, allowing developers with limited experience to quickly learn and integrate them into their projects. These readily available resources significantly expedite the development process, enabling developers to leverage pre-existing solutions and reduce the need for building complex components from scratch.", "label": "human"}
{"ID": "00260026", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Without having to understand JavaScript, HTML and CSS to their cores, I was still able to construct a functional UI thanks to ReactJS’ rich features and supported libraries.3.1.3 Material UI Material UI is one of the most popular React JS Frameworks. Inspired by Google’s Material Design, Material UI offers a vast collection of well-crafted and visuallyappealing components. These components adhere to the established design guide s, ensuring a consistent and intuitive user experience across applications. The framework’s flexibility, extensive toolset, and active community contribute to its widespread adoption and utility in accelerating React JS frontend development.", "label": "human"}
{"ID": "00260027", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Gensim library Gensim is an open-source library, developed by RARE Technologies Ltd. and continuously updated since 2009. The library is famous for its usage in natural language processing domain, especially for unsupervised topic modeling (which has been integrated into Trendz), retrieval by similarity and implementations for algorithms such as tf-idf, latent semantic analysis  (LSA, LSI, SVD) and latent Dirichlet allocation (LDA).  3.2.2 VnCoreNLP library VnCoreNLP is amongst the fastest and most accurate NLP annotation pipe for Vietnamese, providing rich linguistic annotations through key NLP componentsof word segmentation, POS tagging, named entity recognition (NER) and depen dency parsing. Users do not have to install external dependencies. Users can runprocessing pipes from either the command- or the API. ) VnCoreNLP is reused in Tokenizer module to segment an article’s title and content into separated meaningful words.", "label": "human"}
{"ID": "00260028", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Pickle libraryPickle - a library that helps saving and loading Python’s objects is used frequently during training and integrating machine learning models into the applica tion. It allows for the serialization and deserialization of various Python objects, including arrays, lists, dictionaries, and more. The ability to save and reuse objects facilitates the seamless integration of trained models across different computing environments and microservices.", "label": "human"}
{"ID": "00260029", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "By employing Pickle, I was able to train machine learning models on one com puter and subsequently integrate them into inference services without the need to retrain the models. This capability significantly streams the development and deployment processes, as it eliminates the necessity of duplicating training efforts and allows for efficient knowledge transfer between different components of the application.", "label": "human"}
{"ID": "00260030", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "It provides a reliable method to acknowledge tasks from publishers and distribute them between workers. It serves as a fundamental component within the Trendz project, providing crucial functionality for the distribution and processing of tasks between publishers and workers.", "label": "human"}
{"ID": "00260031", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "By leveraging RabbitMQ as the message queue protocol broker, Trendz bene fits from a robust and reliable messaging system. It provides a solid foundation for the implementation of intensive processes, allowing for efficient task distribution, reliable task acknowledgment, and scalable capabilities. This ensures that machinelearning inference and data standardization services within Trendz can operate ef fectively and accommodate the system’s evolving requirements.", "label": "human"}
{"ID": "00260032", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "By leveraging Docker, you can create lightweight containers that encapsulate all the necessary components required to run your application, removing the need to rely on specific dependencies or configurations present on the host system. With Docker containers, you can easily share your application with others, ensuring that everyone has access to the same containerized environment. This ensures that yourapplication functions consistently across different systems, regardless of the under lying host configurations.  Figure 3.5: Docker’s position In this project, Docker is used for creating uniform environments between de velopment PC and deployment servers to avoid any conflicts caused by operating systems or libraries while running applications.", "label": "human"}
{"ID": "00260033", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Jenkins is a popular open-source software-as-a-service (SaaS) which can beused as a server to automate various stages of the software development lifecy cle, including building, testing, and deploying applications. By leveraging Jenkins,developers can automate repetitive tasks, reducing the potential for errors and in creasing overall productivity. With Jenkins handling these tasks, developers can dedicate more time and effort to building and optimizing features, enhancing the project’s growth and quality.", "label": "human"}
{"ID": "00260034", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Prometheus - Grafana stack Prometheus and Grafana form a powerful monitoring stack that is commonlyused to monitor active systems. Together, they provide comprehensive metrics col lection and visualization capabilities, enabling operators to gain valuable insights into system performance and identify anomalies promptly.", "label": "human"}
{"ID": "00260035", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Prometheus is a widely adopted monitoring system that offers a broad rangeFigure 3.8: Example of a Jenkins pipe (sensitive details omitted)of collectable metrics. It can monitor various aspects of the system, such as up time, downtime, CPU usage, memory utilization, and more. Moreover, Prometheus has a growing community that contributes additional metrics exporters tailored forspecific frameworks and applications. This extensibility allows operators to col lect fine-grained metrics from various components, including the ones that were already deployed in Trendz: MySQL Databases or web applications built on the Spring Boot framework.", "label": "human"}
{"ID": "00260036", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Grafana, on the other hand, serves as a robust and flexible visualization tool for these collected metrics. With its user-friendly interface, Grafana enables operators to create insightful and intuitive dashboards that present the metrics in a visually appealing manner. This makes it easier to understand system behavior and identify any performance issues or trends. Another notable feature of Grafana is its alertingfunctionality. Operators can set up alert rules based on defined thresholds or pat terns in the metrics data. When an anomaly or critical event occurs, Grafana can trigger notifications and send alerts through popular messaging applications likeTelegram, Slack, or email. This timely alerting capability enables operators to ac knowledge and respond to anomalies promptly, facilitating faster incident response and minimizing system downtime.Figure 3.9: Grafana UI (omitting sensitive details such as server’s IP address) Figure 3.10: Prometheus UI (omitting sensitive details such as server’s IP address)3.3.5 Nginx Webserver Nginx - a web server that can be used as a reverse proxy, load balancer, or even a Content Delivery Network  thanks to its features. Nginx helps hiding real locations of API servers and provides straightforward syntax to apply TLS protocol for trendz instead of having to reconfigured for each microservices. Its provided features also help restrict accesses to private services, such as system monitoring user interface (Grafana UI) Figure 3.11: Nginx as a Reverse Proxy With the architecure above, users would not communicate directly with backend APIs, which partially alleviate possible vulnerabilities from direct API calls  (e.g: DDoS  would not harm the actual API providers).", "label": "human"}
{"ID": "00260037", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Nginx also provides caching functions for both static files (JS, CSS and im ages) and HTTP APIs. This caching functionality serves two important purposes:", "label": "human"}
{"ID": "00260038", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "By caching static files, Nginx effectively stores copies of these files in memory or on disk, closer to the end-user. This means that subsequent requests for the same files can be fulfilled directly from the cache, eliminating the need to fetch them from the backend server. As a result, the webpage loading time is significantly reduced, improving the overall user experience.", "label": "human"}
{"ID": "00260039", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Furthermore, Nginx’s caching feature extends to HTTP APIs, allowing responsesfrom these APIs to be cached as well. This means that if a particular API responseis requested multiple times, Nginx can serve the cached response instead of for warding the request to the backend server. This reduces the computational load on the backend server, enabling it to handle higher traffic loads more efficiently.", "label": "human"}
{"ID": "00260040", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Software architecture selectionInherits the characteristics of Separation of Concerns principle , Microservices architecture is becoming widely applied in the industry because of its ele gant characteristics. By decomposing an application into smaller, loosely coupled services, microservices enable organizations to achieve a range of benefits. Thearchitecture paves the way for horizontal scaling, automated testing, continuous in tegration and deployment and above all, it provides the base for minimal downtime applications. Compare to the old monolithic architecture, microservies have their own strengths and weaknesses that can be listed in Table 4.1.", "label": "human"}
{"ID": "00260041", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "[*] A monolithic application can only be written in one single codebase, so it hasto be written in one single programming language, which means it can not use state of-the-art technologies if those techs are written in other programming languages.", "label": "human"}
{"ID": "00260042", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "[*] Microservices usually use communication via network interfaces while Mono liths application functions communicate internally. Read/Write speed of hardware (CPU cache, RAM or SSD) should always be faster than communication over the Internet.", "label": "human"}
{"ID": "00260043", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "[*] Even though deployment for monoliths is easier, it requires downtime for the whole system for an update. Rolling updates can be performed, but still a larger portion of computing power needs to be \"down\" for an update. E.g: With 4 identicalservers, we only have 75% computing power left during update time with mono lithic structure, while for microservices, it would only affect one single service and one single server at a time with rolling updates.", "label": "human"}
{"ID": "00260044", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "[*] If we take opportunity cost into consideration, it would be favourable for microservices. Although monoliths are easier to deploy, that does not mean those applications can be deployed frequently as each redeployment requires a longer testing process. Faster updates mean more new features come out and more bugs are fixed.Monoliths Microservices Single codebase Multiple services multiple codebases Scaling by adding replica nodes with the whole applicationEach service can be scaled independently Difficult to understand for new team membersEasier for new members to start working on a small service Barrier to new technologies* Newer technologies Faster communication between functionsSlow communication between services* Usually use only one programming languageFlexible in terms of language Easy for testing Difficult to test (needs to create mock services to test one service) Easy to trace errors and exceptions Tracing errors and exceptions is difficult Easier deployment (single packaged application)*Difficult to deploy (have to run all microservices to make the system function as expected) Updating a function requires redeploying again the whole applicationOnly need to redeploy the updated service Lower initial costs Higher initial costs* Table 4.1: Microservices and Monoliths architecture comparison4.1.2 Overall design Figure 4.1: Trendz’s Component DiagramThe system has eight core components, each of them has their own responsibil ities, and together serve as an automated and realtime system for users.a, URL Crawler URL crawler scans through HTML documents of the main pages of the news sites, watch for elements that contain suitable ’href’ attributes - articles/news link.", "label": "human"}
{"ID": "00260045", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "It then takes those URLs and sends them to message queue and let the queue system perform the job distribution process.", "label": "human"}
{"ID": "00260046", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Parser Parser receives URLs of news articles as inputs and returns objects that contain detailed information of those articles, including:", "label": "human"}
{"ID": "00260047", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "It would then push those results to the main API server for further processing c, Message Queue Message Queue system acts as a coordinator between tasks’ publishers and tasks’ workers. It has the responsibility to ensure the background components can perform smoothly. The publishers do not need to wait until the workers finish their jobs to perform the next requests, they can leave the messages, and the broker would distribute those messages to workers based on custom configurations. In that way, publishers and workers won’t be coupled together and can \"mind their own business\".", "label": "human"}
{"ID": "00260048", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Main API Server Acting as a buffer between database and other actors, including microservices and users, API server handles most of the workloads on a regular basic.", "label": "human"}
{"ID": "00260049", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Machine Learning System Including both training and inferencing modules, machine learning system is responsible for producing outputs for \"advanced\" features. However, only inference service would be deployed with the live system for now.", "label": "human"}
{"ID": "00260050", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Authentication and Authorization ServiceThe service helps authorizing requests and differentiate them from other unauthorized ones. It also has its own database, which stores users’ information, sub scriptions for registered users and confirmation tokens used in registration and forget password use cases.", "label": "human"}
{"ID": "00260051", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Website UI The final component is the public trendz.vn website, which helps visualizing data and directly serves regular users.4.2 Detailed design 4.2.1 User interface design The design would aim at serving most popular users’ screen resolution: FullHD (1920x1080). To ensure an uniform and intuitive user interface, most compo nents inherit characteristics from the most popular ReactJS library - Material UI’s elements, including buttons, tables and lists.", "label": "human"}
{"ID": "00260052", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Detailed design for important screens Figure 4.4: Designed wireframe for keyword cluster detail screen using Figma Figure 4.5: Designed wireframe for Site statistics screen using Figma4.2.2 Database designSimilar to other elements within the system, the database structures have under gone numerous reconfigurations, resets, and updates in order to attain their presentstate. The Trendz system consists of four distinct components, each necessitating its own dedicated databases. These components encompass an authorization authentication service, a statistical API service, and a service dedicated to handling sites’ metadata.", "label": "human"}
{"ID": "00260053", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Main Database All information that was dedicated to Trendz would be stored here, including crawled data, machine learning models outputs and generated data by users during their experience with Trendz.", "label": "human"}
{"ID": "00260054", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Content: Stores crawled articles from websites, contains their metadata and re quired data for other modules, including authors’ name, url, title,... and the time the record was written to the database (crawled_at) MainContentEntity: Stores intepretable outputs of Named Entity Recognition module EntitySentiment: Stores intepretable outputs of Sentiment Analysis module KeywordFollowingCluster & KeywordFollowingClusterKeyword: Store keyword clusters that users followDailyTopKeywords & DailyOverallSentiment: Aggregated results, update rou tinely by cronjobs, used for accelerating frequent requested queries.", "label": "human"}
{"ID": "00260055", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Site: Store news sites basic metadata: domain, popular name and elo (derived from their traffic, measured by webrank.vn)SiteElement: Store CSS selector paths of important fields that need to be ex tracted from each site article.", "label": "human"}
{"ID": "00260056", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "IgnoredKeyword: Store keywords that should be ignored after inference process (e.g: ’VnExpress Thể thao’ on VnExpress) FrequentKeyword: Keywords that appear too often and in a wide range of topics but have no significant meaning about ongoing trends (e.g: ’Việt Nam’)Figure 4.6: Main Database Entity Relationship Diagramb, Users Database Users’ information was stored in a separated database not because it has to or it was separated for the sake of making Authorization and Authentication an isolated service. It was separated instead because it was a layer that could be reused for other projects as well. The structure of the Users’ Info Database can be described as below:", "label": "human"}
{"ID": "00260057", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "User: Stores users’ basic information, including email to identify, encrypted ver sion of their passwords and their accounts’ current statuses: disabled or activeMailConfirmationToken: Stores one-time tokens for special cases - registering ac counts and resetting passwords requests since those can not performed with access tokens.", "label": "human"}
{"ID": "00260058", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Backup Strategy Current approach to tackle backup problems of Trendz is relatively simple. A scheduled script (cronjob) would be triggered daily to dump the database and pushit to a storage bucket on cloud provided by Google Cloud Platform (GCP). However, the solution would eventually become insufficient as the database will con tinue to grow. Current script would look like this:", "label": "human"}
{"ID": "00260059", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "#!/bin/bash # Dump database to an SQL file mysqldump -u <username> -p<password> \\ -port <mysql_port> -h <mysql_host> \\ -single-transaction --quick <database_name> > <database_filename>.sql # Push the output SQL File to a Google Cloud Storage Bucket gcloud storage cp <database_filename>.sql \\ gs://<desired_bucket_name>/<desired_folder>/$(date +%Y-%m-%d).sql # Remove local output file rm <database_filename>.sql Figure 4.8: Backup Bucket on GCP (28/06)4.3 Application Building 4.3.1 Libraries and Tools This small section would be dedicated to list all tools and libraries that were used during development with their versions.", "label": "human"}
{"ID": "00260060", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Purpose Name Version URL Programming IDE Visual Studio Code ”  Programming Language Python 3.8  Programming Language Java 11  Programming Language Javascript ES6 ” API Server Framework Spring Boot 2.7.0  boot UI Framework ReactJS 17.0.2  Database Engine MySQL 8.0.28  Containerizing engine Docker ”  Containerizing engine Docker Compose ”  Webserver Nginx 1.24.0  Monitoring stack Grafana 9.0.0  Monitoring stack Prometheus ”  Load test Apache JMeter 5.5  Table 4.2: List of tools and libraries 4.3.2 Achievement Component Number of files Lines of code Main Language API Service 171 5732 Java Authentication Service 60 1834 Java Crawler 2 92 Python Parser 5 238 Python Frontend 113 16000 JavaScript Machine Learning Training 14 745 Python Machine Learning Integrations 7 399 Python Other Platform Services 7 190 YAML Table 4.3: Detailed statistics about Trendz’s codebase4.3.3 Illustration of main functions Home screen is the first thing users would encounter every time they access trendz.vn, and since first impressions are amongst the important factors that decide whether users would continue using the website, it should be carefully developed and optimized.", "label": "human"}
{"ID": "00260061", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Python 3.8: Since the module was written in Python and test on local machine with Python 3.8 installed, it is safe to say that Python 3.8 would be a suitable version.", "label": "human"}
{"ID": "00260062", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Python Torch for CPU library: Since the cloud server that is being used for the project does not have GPU, I have to choose specific version for Torch library Python libraries: Defined in requirements.txt file as usual Those dependencies would be translated into a Dockerfile as below:", "label": "human"}
{"ID": "00260063", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "# Define the base image FROM python:3.8.10 WORKDIR /absa # Install Torch libraries RUN pip install torch torchvision torchaudio --index-url \\  --no-cache-dir # Add requirements.txt file first and # install other required libraries COPY requirements.txt requirements.txt RUN pip install -r requirements.txt # Copy the code into the image COPY . .", "label": "human"}
{"ID": "00260064", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "# Define the command that would be executed # when the container starts CMD [\"python\", \"absa_inference.py\"]4.4.2 Continuous Integration and Continuous DeliveryContinuous Integration (CI) is the process of building and unit testing an appli cation before releasing a new version of a software application to detect possible deploying errors as soon as possible.", "label": "human"}
{"ID": "00260065", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Continuous Delivery (CD) is the whole process from a revision to production, including: building, testing and deploying. Those methods shorten the process of integrating a new feature or a bug fix into products. “For successful software, the first release is just the beginning of the delivery process.”  Together, continuous integration (CI) and continuous delivery (CD) make the deployment and operation process from the environment on developers’ machines to production reliable, stable, predictable and largely automated. Those techniques,despite appearing as a solution for large-scale applications only, still show their val ues with small to medium projects, and who knows, maybe Trendz would become large one day.", "label": "human"}
{"ID": "00260066", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Every active servers in the system has a docker container built from nodeexporter image, which provides overall metrics, including CPU, memory, IO usages. To integrate microservices monitoring, each of them needs to public an end point so that Prometheus can collect necessary metrics from.", "label": "human"}
{"ID": "00260067", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Prometheus server also needs to be configured properly so that the collecting steps would not become a significant overhead for the system.", "label": "human"}
{"ID": "00260068", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "With a robust monitoring system, any anomalies (a spike in systems’ load, slow queries,...) would be tracked, so I could notice and fix them as soon as possible (despite the reality that those changes were not that soon with only one developer).Figure 4.17: Prometheus endpoints in Trendz’s microservices and servers Figure 4.18: Monitoring databases’ healthFigure 4.19: Monitoring crawler and tokenizer services5.1 SolutionsThe Solution chapter in this thesis presents the detailed design and implemen tation of the proposed methodologies based on the requirements identified in the previous chapters. This section aims to showcase how the theoretical concepts and insights gained from requirement analysis are translated into a concrete application.", "label": "human"}
{"ID": "00260069", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Apart from a comprehensive overview of the solution, this chapter also demon strates the effectiveness and practicality of the developed software system.", "label": "human"}
{"ID": "00260070", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Data Collecting System a, RequirementsTrendz’s primary objective is to deliver an application capable of tracking, ex tracting, and analyzing information from the latest articles published on on news sites. Consequently, the foremost requirement for the data collection system is to ensure that the data being gathered at any given moment is as up-to-date aspossible. This ensures that the application operates with the most current informa tion available. The next requirement would be that there is a constant data flow so that other modules, such as inference and standardize services can also process continuously. Both would require the module to run smoothly and can perform without any human interventions.", "label": "human"}
{"ID": "00260071", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Anti-DDOS policies: News sites are usually developed and by experienced de velopers and operated on reliable cloud platforms, so they should be capable to detect abnormal requests. In fact, my crawlers were blocked a few times by almost all of the sites before applied a more specific approach.", "label": "human"}
{"ID": "00260072", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "There was a significant drop from 08-07-2022 to 12-07-2022 which was caused by the Anti-DDOS service of those sites that blocked my VPS from crawling articles.", "label": "human"}
{"ID": "00260073", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Restricted accesses: There are several sites that only serve requests from Viet namese users only, which means that I could not utilize the \"strongest\" machine for the data collecting processes. Also, as most of the sites have their servers located in Vietnam, abroad accesses to those would be slower compared to the domestic ones.Figure 5.1: Crawled articles count by date (chart) Low memory resources: Despite having 5 virtual machines, those machines don’t have impressive computing power each, so simulating users’ requests on browsers with multiple tabs using libraries such as Selenium would not be a viable solution as browsers would eat up a significant amount of memory.", "label": "human"}
{"ID": "00260074", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Heterogeneous HTML structures: Every news sites have their own HTML struc tures - different class name for articles’ titles, content, which requires different variables for crawling process of each sites.", "label": "human"}
{"ID": "00260075", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Similar content structures: In constrast to the previous obstacle, news articles usually share similar content structure. A news article, no matter where it was written or who wrote it, after the standardizing process would contain similar data fields including title, content, author, published time..", "label": "human"}
{"ID": "00260076", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Difference in terms of significance: Sites cannot be treated equally as each site has different amount of users, traffics, which affect their abilities to \"lead thetrend\". For example: an article on vnexpress.net should be considered more ef fective than the one from docbao.vn.Figure 5.3: Similar content structure between two articles on vnexpress.net and 24h.com.vn (title is marked red, published time is marked blue, topic is marked green and body is marked orange) Figure 5.4: Vietnamese news sites ranking (12-07-2023)c, Solutions Each requirements and obstacles require separated solutions. Those solutions can be carefully designed ones or workarounds and sometimes they include tricks.", "label": "human"}
{"ID": "00260077", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "To tackle anti-DDOS policies of news sites, instead of iterating through each site and parsing all of its articles at once, I would append those URLs into a listand then shuffle the list of URLs randomly before sending each of them to parser so that consecutive requests from parser would not come to the same news site.", "label": "human"}
{"ID": "00260078", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Cumass =2 N.(N−1)NX i=2−1X j=1log(P(wi, wj) +ϵ P(wj)) P(wi)is the probability that token ithappears in the whole set of documentsP(wi, wj)is the probability that token ithandjthappear within the same doc ument in the whole set of documents Coherence based on pointwise mutual information cuci:", "label": "human"}
{"ID": "00260079", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Cuci=2 N.(N−1)n−1X i=1NX j=i+1PMI (wi, wj) PMI (wi, wj) =logP(wi, wj) +ϵ P(wi)·P(wj) Coherence measured by normalized pointwise mutual information cnpmi , the function is the same as cuci, except for the new PMI function:", "label": "human"}
{"ID": "00260080", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "NPMI (wi, wj) = (log(P(wi,wj)+ϵ P(wi)·P(wj)) −log(P(wi, wj)) +ϵ) Coherence combines the indirect cosine measure with the NPMI and boolean sliding window cv. With boolean sliding window, P(wi, wj)is no longer just theprobability that wiandwjappear in the same document but is the probability thatthese two words appear together but not further than the window’s size. For exam ple, with the already segmented sentence “Manchester_City thành_công chiêu_mộ Erling_Haaland”, “Erling_Haaland” and “Manchester_City” may appear in the same document, but they would not appear in the same window if the window’s size is smaller than 4.", "label": "human"}
{"ID": "00260081", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "The dataset which was used for testing process has 200,000 data points and were taken randomly from the whole table named “Content” in the database (around 1,000,000 records) Testing Parameters:", "label": "human"}
{"ID": "00260082", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Dataset Size: Show the number of documents that were used for training process of the model. Typically in a machine learning problem, larger dataset size would return a better result with the same approach.", "label": "human"}
{"ID": "00260083", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "If the number of iterations has reached the value, the training process would be halted and return the model immediately.", "label": "human"}
{"ID": "00260084", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Threshold: Show the minimum threshold about whether a word is considered gen eral enough to represent a topic. If a word only appears few times across the whole dataset, it may have a significant weight, which is something we do not want (e.g:", "label": "human"}
{"ID": "00260085", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "we rarely mention “Yoweri Museveni” in “Thế giới” topic, but 100% articles that have “Yoweri Museveni” in them would belong to “Thế giới” topic even though not everyone knows that he is the president of Uganda)IDKeywords Labeled topic 0việt nam, chồng, việt, mẹ, đẹp, gái, đẹp, vợ, đi, phim, hoa hậu, du lịch, trai, nữ, mạngGiải trí 1thi, trường, việt nam, hà nội, học sinh, đại học, 10, tổ chức, 2023, kỳ, giáo dục, quốc tế, học, thí sinhGiáo dục 2tp, tỉnh, công an, hcm, vụ, chủ tịch, hà nội, huyện, tổ chức, điều tra, dự án, phó, công tác, giao thông, đấtChính trị - Xã hội 3covid-19, y tế, bệnh, ca, mắc, sức khỏe, bệnh viện, giúp, trẻ, thuốc, dịch, bệnh nhân, ung thư, nguy cơY tế 4nga, mỹ, ukraine, trung quốc, tổng thống, châu âu, thế giới, dân trí, đức, ngoại giao, tấn công, tuyên bố, quân sự, tên lửa, máy bayThế giới 5xe, đi, đường, vụ, biển, chết, tử vong, cháy, miền, phát hiện, nam, ô tô, mưaBỏ qua (khó xác định) 6trận, việt nam, world cup, 2022, vòng, bóng đá, hlv, giải đấu, đội, vs, bảng, thắng, thái lanThể thao 7giá, đồng, tiền, triệu, vàng, tỷ, usd, mua, thị trường, doanh nghiệp, hàng, hôm nay, việt nam, đầu tư, công tyKinh tế Table 5.1: Topic Modeling best model outputs Results Despite having trained and selected best possible models in a pool of around 2800 different sets of parameters, I have to admit that the results of topic modeling is still not concretely persuasive. “Characterizing topics is hard”, “Naming topics is hard” , and trusting both topic modeling output and my own intuition is voluntarism to some extent. Using quantitative evaluation may help, but labeling them later after having “well-trained” models is also not easy.", "label": "human"}
{"ID": "00260086", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "The final model that was used in inferencing process was the one that has the parameter set of 200000 data points, went through 10 passes, has the threshold of 0.01 and divides its given dataset into 8 topics and can be represented in an understandable way in table 5.1Figure 5.8: Final results with 4 most popular metrics from models that appear in the top 85% percentile in all 4Figure 5.9: Correlation matrices derived from all models Figure 5.10: Correlation matrices derived from models that in the top 85% in all metricsb, Aspect-based sentiment analysisEmploying aspect-based sentiment analysis helps Trendz provide a deeper un derstanding of the public’s sentiments and perceptions surrounding the targeted keyword, enabling more comprehensive and insightful analysis for users.", "label": "human"}
{"ID": "00260087", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Definition Aspect-based sentiment analysis (ABSA) is a machine learning task that is used for identifying and assigning sentiment to a subject within a sentence or paragraph.", "label": "human"}
{"ID": "00260088", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "In a sentence like \"The weather is good today\", ABSA would ideally extract the sentiment towards the weather is positive.", "label": "human"}
{"ID": "00260089", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Data labeling The model that was chosen was a supervised one, which means it would require data with labels with the expected format like illustrated below:", "label": "human"}
{"ID": "00260090", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "$T$của Công_an Hà_Nội bày tỏ: \" Tôi rất hạnh_phúc với chiến_thắng hôm_nay của đội_nhà. Hy_vọng các cầu_thủ sẽ tiếp_tục giữ phong_độ trong những trận_đấu khó_khăn sắp tới.", "label": "human"}
{"ID": "00260091", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "HLV Paolo_Foiani Positive Figure 5.11: Required dataset format Each sentence/paragraph would be converted into 3 s: the sentence without the desired keyword (replaced by $T$, the keyword itself and finally the labeled sentiment Figure 5.12: Data labeling process: Green is positive, Red is negative while Gray is neutral The process would be dull and ... boring without an user interface. However,thanks to a tool provided by ABSA team (illustrated in image 5.12), I was able to do it interactively with their provided script.", "label": "human"}
{"ID": "00260092", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Evaluation Metrics For aspect based sentiment analysis, the evaluation metrics are comparatively straightforward compared to Topic Modeling in the previous section. Accuracy and F1 are then used for assesing effectiveness of a model.", "label": "human"}
{"ID": "00260093", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Accuracy =CorrectPredictions Cardinality Precision =TruePositive TruePositive +FalsePositive Recall =TruePositive TruePositive +FalseNegative Precision +Recall Experiments The final dataset has around 3500 labeled sentences/paragraphs (which was much smaller than the given database, but still a large number to label manually).", "label": "human"}
{"ID": "00260094", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "It was tested with 6 different parameters sets. Due to hardware limitations, only learning rate and dropout rate would be changed during the experiments.", "label": "human"}
{"ID": "00260095", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Label # of occurrences in Training set # of occurences in Testing set Positive 1302 203 Negative 1294 182 Neutral 967 102 Table 5.2: Dataset’s labels distributions Results The final result is presented in table 5.3:", "label": "human"}
{"ID": "00260096", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "For smaller learning rate (5e-5), dropout rate has positive impact, while for larger learning rate (1e-4), dropout rate has negative impact. The best parameter set would be: (learning rate of 5e-5, 10 epochs, batch size of 50 and dropout rate of 0.1).Learning rate # of Epoch(s) Batch size Dropout rate Accuracy F1 5e-5 10 50 0.02 63.47 63.07 5e-5 10 50 0.05 64.67 63.64 5e-5 10 50 0.1 73.65 72.41 1e-4 10 50 0.02 62.57 61.45 1e-4 10 50 0.05 43.11 31.81 1e-4 10 50 0.1 42.81 31.61 Table 5.3: Aspect based Sentiment Analysis results with different sets of parameters 5.1.3 Machine Learning Inference Services a, Requirements Since there is an active data flow that required to be processed immediately, all inference services need to provide answers in short intervals. They should also be able to provide sufficient level of correctness amongst important modules such as sentiment analysis, topic modeling,... which outputs would be visible to end users. There is another special requirement for those modules: they should be able to perform well enough on limited resources as its owner could not invest a large amount of money for now - no cloud GPUs and limited number of cloud virtual machine instances.", "label": "human"}
{"ID": "00260097", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "CPUs friendly: As the instance group does not have any GPUs, integrated models should be able to perform at a reasonable speed on CPU-only systems despite most of them were trained on GPUs.", "label": "human"}
{"ID": "00260098", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Acceptable throughputs: In order to meet the requirements of providing timelyand responsive outputs, the integrated models should strive to achieve an accept able level of throughput. The processing of data should be performed as quickly as possible to ensure that the generated insights and outputs are up-to-date andrelevant. It is considered unacceptable to provide sentiment analysis or other re sults for a keyword that was extracted an hour ago, as this would render the information outdated and less useful.", "label": "human"}
{"ID": "00260099", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Solutions Containerize modules The output models of the training phases would be packaged with the inference codebase using Docker. For the models that were trained with Torch, CPU versionshould be declared in Dockerfile for compatiblity. This ensures that the inference codebase runs smoothly on systems that may not have access to GPU resources or require CPU-based computations.import os import pika # DECLARE CONNECTION PARAMETERS pika_credentials = pika.PlainCredentials( os.environ[\"RABBIT_MQ_USER\"], os.environ[\"RABBIT_MQ_PASSWORD\"]) pika_connection = pika.BlockingConnection(pika.ConnectionParameters( host=os.environ[\"RABBIT_MQ_HOST\"], port=5672, credentials=pika_credentials, heartbeat=0, connection_attempts=20, retry_delay=1)) pika_channel = pika_connection.channel() def predict_sentiment(data):", "label": "human"}
{"ID": "00260100", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "traceback.print_exc() ch.basic_ack(delivery_tag=method.delivery_tag) # DEFINE QUALITY OF SERVICE PARAMETER pika_channel.basic_qos(prefetch_count=25) # START CONSUMING THE MESSAGES pika_channel.basic_consume( queue=\"absa_queue\", on_message_callback=callback, auto_ack=False) pika_channel.start_consuming() Figure 5.13: Message Queue integration (detailed implementation omitted) Integrate message queueTo further reduce dependencies between components in machine learning in ference services, message queue implementation was integrated into the codebase.", "label": "human"}
{"ID": "00260101", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "This integration aimed to improve the communication and interaction between dif ferent components, allowing for more efficient and scalable processing of tasks.", "label": "human"}
{"ID": "00260102", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "There is a coding example of message queue integrations in figure 5.13.5.1.4 Realtime API Server and Internal Standardizer a, Requirements Most of the visible features on Trendz are results of aggregated queries. Since those queries are expensive for database servers, it is a requirement to offload those results using other mechanisms including caching and aggregated tables.", "label": "human"}
{"ID": "00260103", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Problems There is no free lunch\", additional and unexpected challenges are still a part of those modules, they include:", "label": "human"}
{"ID": "00260104", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Different data format: SQL database and Java have different ways to represent and store data, and Redis instance also has different representations and data structures. They may include: datetime, arrays and sets format between Java andRedis, rows of records in SQL and keys - values structures in Redis. Those con flicts should be reconciled so that we can utilize each strengths and mitigate each weaknesses.", "label": "human"}
{"ID": "00260105", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Limited accesses for internal data processing requests: Apart from regular users, there are also internal services that have to make requests to the API server.", "label": "human"}
{"ID": "00260106", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Those requests should restrict accesses from any sources that do not belong to the granted group services. One example is that regular users should not be able to perform a write operation to crawled contents or extracted entities table.", "label": "human"}
{"ID": "00260107", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Solutions Apart from traditional database system, API server would connect to another Redis caching instance and queries’ results would then be cached there. This caching mechanism aims to improve performance and reduce the response time for queries by storing and retrieving frequently accessed data.", "label": "human"}
{"ID": "00260108", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Authentication and Authorization Service a, Requirements The Authentication and Authorization service plays a critical role in the Trendzsystem, providing essential APIs for user-related use cases and facilitating interac tions with other microservices. These APIs encompass functionalities such as user login, sign-up, token refreshing, and user identity verification.", "label": "human"}
{"ID": "00260109", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "As the central authentication and authorization component, these APIs are vi tal for verifying the authenticity and access privileges of users. Other componentswithin the system rely on these APIs to determine whether incoming requests originate from suitable clients or not. Given their pivotal nature, these APIs often be come prime targets for potential cyberattacks.Figure 5.14: Login API (omitting email and password from picture)To ensure the security and integrity of the Authentication and Authorization ser vice, it is imperative to implement a carefully-designed solution that incorporatesbest practices and stays updated with the latest security measures. This entails following industry standards and adopting proven security protocols to mitigate com mon vulnerabilities and address potential attack vectors.", "label": "human"}
{"ID": "00260110", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "There are two different types of storage used in authentication and authorization processes: local storage for access token and httpOnly cookie - which provides additional security protection  - for refresh token. The reason for this difference is executable code (JavaScript) in UI App would not be able to manipulate or even read refresh token - which has longer lifespan . Access token could also be stored that way for a higher level of confidentiality, but I chose to store it in local storage of the clients just for easier development process - where my local app could also use access token that was generated by auth service for a closer-to-production environment. Also, as access token has relatively short lifespan (less than 1 hour), the risk of losing it would not be as significant as losing a refresh token - where the attacker could use it as a way to continuously (even eternally) use a real user’s identity to make API calls that he/she does not have permissions to.", "label": "human"}
{"ID": "00260111", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Despite being labeled as an Artificial Intelligence and Applications thesis, what Trendz has been focusing on and doing well were not only the machine learning and natural language processing models. It is essential to acknowledge that Trendz has not introduced any machine learning or natural language processing models that can be considered groundbreaking or revolutionary. Instead, the emphasis has been placed on effectively integrating and fine-tuning existing popular models within the system.", "label": "human"}
{"ID": "00260112", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "The contributions that I feel proud of is constructing a reliable and scalable system that can collect, process and give end-users desired outputs real-time and 24/7. Instead of being a researcher, I chose the journey of an engineer with Trendz.", "label": "human"}
{"ID": "00260113", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "It was a matter of choice, of course, and on the path that I chose, I am still able to practice a multitude of skills with a myriad of problems.", "label": "human"}
{"ID": "00260114", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Talking about reliability , the internal modules (Machine Learning Inference Models, Data Collecting System and Scheduled Standardizer) have shown that they can be trusted, especially after Message Queue component was integrated. I could not recall a system outage caused by those components in the last three to four months. Also, despite their reliability (until now), I still apply the motto \"Trust but verify\", which means that those components are still closely monitored. However,for external modules - UI Web application and API servers - both Statistical server and Users’ server, there has not been enough workload to push them to limit so that I can observe how would they behave with real users.", "label": "human"}
{"ID": "00260115", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Talking about scalability , I can confidently say that every modules in this project can be scaled horizontally with ease - which means instead of having to turn off themachine, add more or replace with better hardwares, we can increase the computa tional of the system by adding more nodes to it. This approach has zero downtime since no hardware needs to be turned off during the process and end-users will not even notice that there was an upgrade. With sufficient resources and investments, those microservices can be integrated into state-of-the-art cloud solutions such as Kubernetes in a matter of days.", "label": "human"}
{"ID": "00260116", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "So to conclude this section, the most important contribution that I made was assembling components with different programming languages, different develop systems together, especially the natural language processing modules to create a scalable, reliable and realtime data processing system that can serve users days in and days out if it has a chance.6.1 Conclusion 6.1.1 Starts with small steps In the pursuit of finding an optimal solution, it can be tempting to prioritize perfection from the outset. However, it is crucial to recognize that striving for an optimal\" solution without ensuring basic functionality is nonsensical. At first, I also fell into that trap while constructing the crawling system. I kept thinking about how to make it reliable and how to avoid the DDoS detection system of those news sites and did not realize that my approach was not sufficient to even crawl required data at first.", "label": "human"}
{"ID": "00260117", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "This experience served as a valuable lesson, highlighting the importance of es tablishing a solid foundation before focusing on fine-tuning and optimization. It is essential to prioritize functional viability before pursuing advanced features and optimizations.", "label": "human"}
{"ID": "00260118", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "A wide range of technology in the first days would not help, also. It is recom mended from my experience that a narrow stack but all of them are cohesive and easy to assemble together so we can accelerate in developing first usable features,after that moment, we would know what are really needed and what are just pe ripherals.", "label": "human"}
{"ID": "00260119", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Suitable technology stack After designing process, each project would need to choose its own technology stack. The stack, in another words, can be described as the skeleton of a project, whereas the codebase and the idea is the soul. This step sometimes seems to be the most exciting one of the whole process since it is the step where developers are free (more than usual, at least) to choose what suits best for their product. However, they tend to eventually pick the flashiest or coolest ones, instead of the ones that really fit.", "label": "human"}
{"ID": "00260120", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "An example of \"cool\" technologies that had not been applied into Trendz wasElasticsearch - Logstash - Kibana stack. This combination would bring a tremen dous amount of value to the current project with its full text search capabilities a currently poorly performed module. However, as those components require a significant amount of memory and CPUs, they have not yet been integrated into Trendz to leave rooms for other vital modules.", "label": "human"}
{"ID": "00260121", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "If you look at Trendz core technology stack, you may find that those are notthe newest, or the most trendy ones in the market. MySQL Database, Spring Boot API server and ReactJS frontend, all of them have been players in the market for a long time. Choosing what you are already familiar with and can start working immediately to build a prototype, and then you can learn new technologies with less-important modules to keep yourself up-to-date instead of starting with zero experiences and 5-10 steep learning curves ahead. While selecting cutting-edge technologies might be enticing, prioritizing familiarity and productivity in the early stages of a project can lead to quicker results and increased confidence after getting something done\".", "label": "human"}
{"ID": "00260122", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Machine Learning models are not always expensive Recent advances in artificial intelligence, especially in neural networks models are very promising, with the likes of ChatGPT, Bard,... that have demonstrated impressive capabilities in natural language understanding and generation. However, there are concerns surrounding the accessibility of these models - those models can only be trained and operated by the massive companies such as Google, Microsoft or OpenAI, not startups or casual developers as the costs are inhibitly high. For instance, the operational costs for OpenAI’s ChatGPT model are reported to be as high as 700K USD per day ). Trendz, until now can prove the opposite, that there are possibilities for small companies or projects to integrate automated and smart data processing pipe into their systems (Trendz requires 5 relatively small virtual machines to operate every modules 24/7 for the last year) 6.1.4 Microservices journey Along with the development in cloud computing, microservices architecturenow becomes more and more trendy than ever before, and to a level where peo ple in the industry now may be confident enough to say that it is a must for every software products. From my own experience, I have nothing to go against that viewpoint, but as usual, things are easier said than done.", "label": "human"}
{"ID": "00260123", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Deciding to follow microservices journey is a promise, applying it is in fact aburden. At first, you may feel really excited since you are now \"free\" to apply what ever programming language or any framework to start coding - NodeJS for socket server, Java Spring Boot for backend, Python for machine learning services,... and cool new tools around: Jenkins for CI/CD, RabbitMQ, Kafka for message-queue, Grafana and Prometheus for monitoring. However, the more you dive into it alone, it would become more and more complex for a single person to handle all of them.", "label": "human"}
{"ID": "00260124", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Yes, having a dashboard that shows how your system is behaving is cool, having your code deployed on a public server right after your last commit is also very cool,but for a small/canonical span of time (one semester), it would be your nightmare.", "label": "human"}
{"ID": "00260125", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Trendz is a product that was built with microservices motto from the moment it was just an idea, but it does not mean that the designed solutions are all good from start. They have to be reviewed, redesigned and even rebuilt a multitude of times to reach a stable state, not fantastic, not incredible, but stable . A product does not become usable only because it has an incredible idea behind or applies what are so-called \"best practices\", its own problems must be solved with tailor-made solutions and by people who at least understand what they are solving. \"Apply my solution for Trendz blindly would lead a project to nowhere\", said by its author.", "label": "human"}
{"ID": "00260126", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Social Media tracking A product that declares itself as a \"trend monitor\" would reach nowhere if it cannot offer users comprehensive insights into the ongoing trends and activities preva lent on popular social media platforms, including Facebook and TikTok. News sites are good places to start and test the viabilities of the project, but neglecting socialmedia platforms would make the product unusable for real users since they repre sent the most widely accessed sources of information nowadays.", "label": "human"}
{"ID": "00260127", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "This improvement would also not be as easy as switch an \"on/off\" button. Dealing with social media also means a whole new set of problems - handling uncanon ical text data from Facebook and extracting meaningful information from TikTok videos, to name just a few examples. However, by surmounting these challenges, the product can position itself as a valuable tool for users seeking real-time insights into the trends and happenings across the mass media.", "label": "human"}
{"ID": "00260128", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Real-time notificationsDespite having already put much efforts into the project, it is important to ac knowledge that Trendz has yet to attain a state where it can be widely and optimally utilized by its intended user base. While several features are still missing, real-time notifications emerge as a prominent requirement that remains unaddressed.", "label": "human"}
{"ID": "00260129", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Real-time notifications is not a \"nice-to-have\" feature, it is instead a must. Users would need to know whether the topics that they are following are being mentioned or not, and what kind of public sentiment is being tied with them immediately.", "label": "human"}
{"ID": "00260130", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "The existing implementations of notification systems often fall short in terms of complexity and functionality. Typically, users are compelled to manually reloadthe website to retrieve the latest messages, which is not only inconvenient but also hinders their ability to stay up-to-date in real-time. To address this limitation, a more sophisticated and responsive notification system should be implemented.", "label": "human"}
{"ID": "00260131", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Admin UIIn spite of the automated nature of the majority of components within the sys tem, certain tasks still necessitate manual intervention, including check for newssites’ updates in UI components or policies. There are also machine learning models that should be semi-supervised to ensure the quality of the output and con tinuous improvement. Through periodic human intervention and feedback, those models can adapt and refine their performance over time, resulting in enhanced accuracy and efficacy.", "label": "human"}
{"ID": "00260132", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Database Read-Only Replicas If Trendz has the honour to serve real users in the future, new problems aboutsystem’s scalability would eventually emerge, and foremost among these chal lenges would invariably revolve around the capabilities of the database. Existing strategy that involves consolidating all types of queries into a single database nodewould prove suboptimal, as it would transform the node into a single point of failure. To address this issue and ensure enhanced scalability and resilience, the implementation of slave nodes becomes imperative. These slave nodes would not only as sist in distributing the read workloads from the master node but would also serve as reliable backups in the event of system blackout or failure. By incorporating slave nodes into the system architecture, the workload can be effectively distributed and redundancy can be introduced to mitigate the risk of mentioned adverse scenarios.", "label": "human"}
{"ID": "00260133", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Full text search engineThe existing approach employed by Trendz for keyword searching lacks con sideration for the aspect of \"relevance\". A query that retrieves latest articles about Hà Nội\" should be performed on the articles table instead of the current approach that extract results from derived tables such as main content entities. This approach fails to prioritize fully matched records, and misses records that match the queries partially, which leads to suboptimal search results. By giving precedence to articles that precisely match the query terms, users will be presented with more pertinent and targeted search results.Figure 6.1: API Server deployment with Read-only database replica Figure 6.2: Full text search and SQL comparison on search queries6.2.6 Streaming Users’ Access and Error LogsCurrent monitoring approaches are not sufficient for disaster analysis and re covery. Tracing the root causes of a downtime incident should be a task that can be done in a short period of time, or at least, able to be performed easily. To addressthese limitations, the implementation of the Elastic stack, which comprises Elas ticsearch, Filebeat, and Kibana, appears to be a viable solution. Not only would the adoption of the Elastic stack prove suitable for the aforementioned purposes, but it would also yield additional benefits by simultaneously resolving challenges related to full-text search functionality. In this sense, the utilization of the Elasticstack can be considered a dual-purpose approach that efficiently tackles both dis aster analysis and recovery requirements, as well as the aforementioned full-text search capabilities.", "label": "human"}
{"ID": "00260134", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Pricing models and Payment methods After an usable version of Trendz goes into action, it will be time to think about how to make it becomes a valuable product so that users would not be hesitate to pay a small price to use it. Without pricing models and integrating on payment methods, it would be impossible to generate any revenue from the project.", "label": "human"}
{"ID": "00260135", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "Pricing models also come with more fine-grained access control matrices for APIs. Users would then have different permissions to features, from able/not able to use to perform maximum X requests per days for a feature. J. Str ¨omb¨ack, Y. Tsfati, H. Boomgaarden, et al. , “News media trust and its impact on media use: Toward a framework for future research,” Annals of the International Communication Association , vol. 44, no. 2, pp. 139–156, 2020.", "label": "human"}
{"ID": "00260136", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "J. Aspin, Facebook less newsworthy in 2020, but still Vietnam’s most popular platform overall , 2020. [Online]. Available: co/blog/facebook-less-newsworthy-in-2020-but-still vietnams-most-popular-platform-overall .", "label": "human"}
{"ID": "00260137", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "T. K. Landauer, P. W. Foltz, and D. Laham, “An introduction to latent se mantic analysis,” Discourse processes , vol. 25, no. 2-3, pp. 259–284, 1998.", "label": "human"}
{"ID": "00260138", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "S. Gupta and B. B. Gupta, “Cross-site scripting (xss) attacks and defense mechanisms: Classification and state-of-the-art,” International Journal ofSystem Assurance Engineering and Management , vol. 8, pp. 512–530, 2017. IAB, M. J. Handley, and E. Rescorla, Internet Denial-of-Service Considerations, RFC 4732, Dec. 2006. DOI:10.17487/RFC4732 . [On]. Avail able: .", "label": "human"}
{"ID": "00260139", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "J. Humble and D. Farley, Continuous delivery: reliable software releases through build, test, and deployment automation . Pearson Education, 2010, pp. 13–14.", "label": "human"}
{"ID": "00260140", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "N. Aletras and M. Stevenson, “Evaluating topic coherence using distribu tional semantics,” in Proceedings of the 10th international conference on computational semantics (IWCS 2013)–Long Papers , 2013, pp. 13–22.", "label": "human"}
{"ID": "00260141", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "L. AlSumait, D. Barbará, J. Gentle, and C. Domeniconi, “Topic significance ranking of lda generative models,” in Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2009, Bled, Slovenia, September 7-11, 2009, Proceedings, Part I 20 , Springer, 2009, pp. 67–82.", "label": "human"}
{"ID": "00260142", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "J. Chang, S. Gerrish, C. Wang, J. Boyd-Graber, and D. Blei, “Reading tea leaves: How humans interpret topic models,” Advances in neural information processing systems , vol. 22, 2009.", "label": "human"}
{"ID": "00260143", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "J. C. C. D. M. Daniel Ramage Evan Rosen and D. A. McFarland, “Topic modeling for the social sciences,” 2009.", "label": "human"}
{"ID": "00260144", "file_name": "TRACKING SYSTEM FOR ONLINE NEWS SITES IN VIETNAM", "content": "A. Mok, ChatGPT could cost over $700,000 per day to operate. Microsoft is reportedly trying to make it cheaper. [On]. Available: businessinsider.com/how-much-chatgpt-costs-openai to-run-estimate-report-2023-4 .", "label": "human"}
{"ID": "00270001", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "This chapter will discuss the thesis’ overview topic as well as the factors that influenced the decision to focus this graduation study on these issues. Additionally, this section chapter the topic’s goal and solution as well as an introduction to the report’s structure.", "label": "human"}
{"ID": "00270002", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "In the modern world, with the rapid evolution of information technology, mobile phone has become an essential electronic equipment in our daily life. The usage of mobile device ranges widely form phone calls, texting, browsing, entertaining, and in recent years, gaming. Gaming on mobile phones has become one of the most viral trending among the youth.", "label": "human"}
{"ID": "00270003", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Gaming on mobile phone is entertaining, easy to start, and available almostanywhere when user has a mobile device with them, therefore, the demand for mo bile game has grown rapidly. Many studios around the world are publishing games which target different range of users and platforms. With the rise in the sale of tablets and mobiles, game app download has increased immensely, and with the introduction of cloud gaming and real money games, the mobile gaming industry has taken a take-off, and the future of mobile gaming looks very bright indeed.", "label": "human"}
{"ID": "00270004", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The mobile gaming market has grown so much that it is now ahead of computer gaming. The success of a game depends on many factor, which can include, but not restricted to game theme, market trending, target users and game engine. Behind the development phase of every game is a game engine, a tool which simplifiedmany aspects in game development and support developer code and manage re source more easily and efficiently.", "label": "human"}
{"ID": "00270005", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "From the growing trend mentioned, in this project, we will use Unity to create a hyper casual mobile game - Funny Zoo.", "label": "human"}
{"ID": "00270006", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Nowadays, in the video game industry, there are many different groups of videogames which target different types of gamers and platforms. Typically, they’re categorized by their size, budget and development time. Some common game cate gories can be listed as (i) AAA games, (ii) mid-core games and (iii) casual games.", "label": "human"}
{"ID": "00270007", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "AAA games (pronounced “triple A games”) are video games most distinguished by their massive development and marketing budgets. They are meant to be a game development company’s best work and provide a high quality video gameexperience-comparable to a summer blockbuster. Aside from budget, there are a number of other common features that these games posses. Though there is no limit on genre, unifying qualities among these games are typically photo-realisticgraphics, game worlds of massive scale, cross-platform releases, and violent con tent. There are certain exemptions for each of these qualities, but on the whole,these trends hold. However; money is by far the most important factor in determin ing whether a game is AAA or not, and equally important to these games’ massive budgets is their massive expected revenue and profit.", "label": "human"}
{"ID": "00270008", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Mid-core games are more complex than hyper-casual and casual games, requiring players to make time to play, rather than playing opportunistically or sporadi cally. Mid-core games require skill and strategy to progress and as a result, requireplayers to be more invested than a typical casual game. Mid-core games often fea ture multi-player experiences, side quests, and resource management, unlike casualgames where your goal is to solve a puzzle or complete a repetitive action. Mid core games often distill an AAA game down to simpler elements in order to have a broader appeal. Think of a hardcore racing game on mobile distilled down to swipe gestures, which are far less punishing and easier to learn than motion controls.", "label": "human"}
{"ID": "00270009", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Casual games are video games targeted at a mass market audience, as opposed to a hardcore game, which is targeted at hobbyist gamers. Casual games may exhibitany type of gameplay and genre. They generally involve simpler rules, shorter ses sions, and require less learned skill. They don’t expect familiarity with a standardset of mechanics, controls, and tropes. Countless casual games have been devel oped and published, alongside hardcore games, across the history of video games.", "label": "human"}
{"ID": "00270010", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Most casual games have fun, simple gameplay that is easy to understand. They have simple user interface, operated with a mobile phone tap-and-swipe interfaceor a one-button mouse interface. Besides, casual game tends to have short ses sions, so a game can be played during work breaks, while on public transportation,or while waiting in a queue anywhere. Casual games generally cost less than hard core games, as part of their strategy to acquire as many players as possible. Any game monetization method can be used, from retail distribution to free-to-play to ad-supported. Also, they are easier to develop and publish.", "label": "human"}
{"ID": "00270011", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "From the problem mentioned above, along with the researches carried out, we decided to create a casual game. The main reasons are that this type of game hasshort development times and suitable for a solo developer. It also has a lower stan dard than other game gernes, so the game assets can be collected from the internet and free asset store. In this project, we also want to do research on and apply new technologies and methods on game development process to produce a mobile gamewith high quality, attractive to users and on trend with the market. The game will also be designed with unique gameplay and proper monetization.", "label": "human"}
{"ID": "00270012", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "To achieve the objectives mentioned above, in this project, several researches must be carried out. The first aspect to create a complete game is game design. In game design, game creators must study the trending of the market, as well as gamegenres and types in order to decided the main theme and play style of the game be ing created. Additional information about development time, budget and viabilityof the project should also be taken into account during this phase. From the infor mation mentioned in section 1.2, the target game genre for this thesis project will be hyper casual, which has a short development time, small development cost and can easily be published to google store, but still be competent to other game genres on google store. Next, a game engine must be chosen for the development process.", "label": "human"}
{"ID": "00270013", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The game engine chosen should be able to balance between the development aspect and the game design aspect, in other words, the game engines should have enough features and can be utilized to speed up the development process and guarantee the quality and content of the game at the same time. Unity Game Engine is by far the most suitable game engine for this project due to its excellent mobile support for game development phase. Detailed explanation for choices of the game engine willbe discussed in section 3.1. The final products will be a casual game with aver age content, interactive gameplay and high engagement time, which mainly target young audience, and expected to have five millions downloads on google store.", "label": "human"}
{"ID": "00270014", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "In chapter 2, requirements of the software are first described through use case diagrams. Brief description as well as specification of some important use cases of the system are then presented. These include activities that a player can do in on as well as off game sessions. Finally, chapter 2 lists some non-functional requirements of the system.", "label": "human"}
{"ID": "00270015", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Chapter 3 will mainly focus on the technology stack used for application de velopment. The chapter begins by explaining the need for a game engine. With the objectives of building a game targeting mobile platforms, some of the popular game engines are put on comparison for their advantages and disadvantages. We then give reasons for why Unity is the ultimate choice for this project. The process of choosing a suitable multiplayer framework is showed in a similar fashion.", "label": "human"}
{"ID": "00270016", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "After a technology stack is determined, chapter 4 dives into the details of appli-cation development and deployment. Design elements are identified and analyzedto implement the system’s functional requirements. These elements include archi tecture design, package and class design, interface design, application testing and deployment.", "label": "human"}
{"ID": "00270017", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Chapter 5 exhibits solutions to a few problems encountered in game develop ment such as object synchronization and reactive UI architecture.", "label": "human"}
{"ID": "00270018", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Chapter 6 summarizes achieved results and presents orientation for future de velopment. Remaining limitations of the application are also briefly discussed.This chapter includes information about current top trending game genres on the market, their strength and weakness and general users’ opinion toward those games.", "label": "human"}
{"ID": "00270019", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "For mobile games, Google Play and App Store are the two most popular on stores for mobile app at the moment. With millions of games on these store, one can expect to come across a large numbers of game categories with different themesand play styles. For dedicated gamers who want to show their high skill when com peting other players in a realtime battle, MMORPG and MOBA games are at the highest preferences. These games often require strategy, skill and dedication and in return, they provide the player with satisfaction and the feeling of achievement.", "label": "human"}
{"ID": "00270020", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Though being high-rated by both players and reviewer, MMORPG and MOBA game are not of the top games ranking due to their high dedication requirements and long game sessions, which are not quite suitable in a modern busy society.", "label": "human"}
{"ID": "00270021", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Also, the performance of the games, though being highly optimized, is not quite acceptable for the majority of the mobile devices on the market today.", "label": "human"}
{"ID": "00270022", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Hyper casual games, in contrast, have a short game session and easy to catch up game play. Their fast and highly interactive style fit almost all sort of player.", "label": "human"}
{"ID": "00270023", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Kids are attracted by the color full themes, juicy effects and haptic the hyper casual game bring back. Adults can try out some of those interactive and easy-to understand gameplays when they are on the train or at break time to kill time.", "label": "human"}
{"ID": "00270024", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Teenagers are also into hyper casual game when they expect something fast and relaxing to entertain during their free time, or they just want to try something new after experiencing other categories of games. From all the reasons above, hyper casual games have become the top trending game category on the on mobile app store. Player can come across a variety of top trending hyper casual genres on store such as runner, shooter, 2d puzzle, simulation and tycoon.", "label": "human"}
{"ID": "00270025", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Though being the top trend on the market, hyper casual games also have theirown problems. As the competition rise, many hyper casual games are mass pro duced without detailed designed and refinement. There are also a great amount of games cloned from top trending game on the market, which distract the users and lower the quality of this game genres. And finally, most of the low-rating commentof hyper casual games are about the disturbing ads during the game session, which significantly affects players’ experience and felling about the game.", "label": "human"}
{"ID": "00270026", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "In order to compete in such a competitive market, the final product this project must be carefully designed in various aspects: concept, game play, main theme andmost important, player experience. Funny Zoo, as the name suggest, is a tycoon like game where player becomes the owner of a small zoo. The player is in charge of feeding the animals, cleaning the cages, collect the fee and some other interest actions. The game is designed with single touch controller, which is easy to catch up even for no-experience player. The main concept of the game is a toony world with cute, low poly characters and bright, colour full environments, which brings player relaxation and chilling time while keeping them busy doing the zoo stuff.", "label": "human"}
{"ID": "00270027", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The game is also designed to extend the normal engagement time by sub-dividingthe game progress into multiple phase, where player can make progression and dis cover new hidden contents of the game, thus keeping them staying longer. Funny Zoo is also designed with proper monetizing to aid player in progressing the game,which in return, provide some profit to the developers. Structured coding and op timization also need to be applied into the game development in order to ensure that the game can be extended with more feature in the future, while can still run smoothly on even low-end devices.", "label": "human"}
{"ID": "00270028", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "All use case of the system are generally described by an overall use case diagram as shown in figure 2.1 There are 1 actor in the system that is the player.", "label": "human"}
{"ID": "00270029", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Use case diagramFigure 2.1: Overall use case diagram Player is an actor that directly plays the game. The people who play the game first need to choose a playing mode, off or on mode.", "label": "human"}
{"ID": "00270030", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Decomposition of use case \"Play offline\" Figure 2.2: Play offline use case diagram Figure 2.2 describes all functions that a player can do in an off game session.", "label": "human"}
{"ID": "00270031", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "This is including, but not limited to manage the staffs, manage the zoo sites and control the main character of the game.2.2.3 Decomposition of use case \"Play on\" Figure 2.3: Play online use case diagram Figure 2.3 describes all functions that a player can do in an on game session.", "label": "human"}
{"ID": "00270032", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Player first needs to set up the connection for the game session and can then later plays against an opponent through the internet.", "label": "human"}
{"ID": "00270033", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Specification for use case \"Manage zoo sites\" Use case code UC001 Use case name Manage zoo sites Actor Player Description Player do actions to manage zoo sites Precondition Player chooses offline mode Post condition No Activation No Main flow of event (success)1. Player goes to the food containers or food production sites to get the food items for zoo animals.", "label": "human"}
{"ID": "00270034", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Player cleans up the zoo sites by picking up the poos of the zoo animals and throw them into the trash bin.", "label": "human"}
{"ID": "00270035", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Alternative flow of eventNo Table 2.1: Specification for use case \"Manage zoo sites\"2.3.2 Specification for use case \"Hire staffs\" Use case code UC002 Use case name Hire staffs Actor Player Description Player do actions to hire more staffs for the zoo Precondition Player chooses offline mode Post condition No Activation No Main flow of event (success)1. Player enters staff manage region.", "label": "human"}
{"ID": "00270036", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Alternative flow of event4a. No available staffs to hire. The system notifies that max number of staff has been reached.", "label": "human"}
{"ID": "00270037", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "a. Not enough money to spend. The hire-with-money button is grayed out, indicating that there is not enough money to hire the staff.", "label": "human"}
{"ID": "00270038", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Alternative flowof event4a. Max upgrade reached. The system notifies that max up grade of the staff type has been reached.", "label": "human"}
{"ID": "00270039", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "a. Not enough money to spend. The upgrade-with-money button is grayed out, indicating that there is not enough money to upgrade the staff type.", "label": "human"}
{"ID": "00270040", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Purchase success. The gloves or boots of the main charac ter changed color, indicating the stat has changed.Alternative flowof event3a. Max upgrade reached. The system notifies that max up grade of the main character stat has been reached.", "label": "human"}
{"ID": "00270041", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "a. Not enough money to spend. The upgrade-with-money button is grayed out, indicating that there is not enough money to upgrade the main character.", "label": "human"}
{"ID": "00270042", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The system display a waiting popup indicating that the connection is in progress. 4. Connect success.The system display a form to configure the display name and the color of the main character for the game session.", "label": "human"}
{"ID": "00270043", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Along with the requirements about business, the system needs to satisfy non functional requirements such as performance and ease of use.", "label": "human"}
{"ID": "00270044", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The system needs to be stable and run smoothly on both low-end devices and high-end devices with low latency and energy consumption. The system should also be well designed so that it can be extended later in order to fulfill future userrequirements. While data schema changes should be avoided, player’s off ses sion data should be capable of migrating to new version.", "label": "human"}
{"ID": "00270045", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The user interface and user experience is also need to be detailed examine for the sake of users’ experience. The control of the game and the core game play should be user friendly and easy to catch up even with no experience player. In addition, visual effects, sounds and haptics feedback also need to be carefully designed so asto maximize players’ experience during the game session.Chapter 2 analyzes the basic functional, non-functional requirements and crite ria that the game Funny Zoo need to satisfy. In the following chapter, theoretical background of game engine and multiplayer framework that are used to develop the game will be discussed, as well as the reason for which they are used in this project.", "label": "human"}
{"ID": "00270046", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "A game, at the very least, needs a way to draw stuffs on the screen. The standard solution includes a component for loading and managing textures and 3D models, a component for handling shaders and another one for GPU rendering. Other gamesalso needs to take input from players, do simulate physics, play sounds, do network ing, run animations. Doing everything from scratch is costly and prone to errors so developers often reuse systems that have already been developed and battle-tested.", "label": "human"}
{"ID": "00270047", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "A game engine is a software framework primarily designed for the development of video games, and generally includes relevant libraries and support programs.", "label": "human"}
{"ID": "00270048", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The core functionality typically provided by a game engine may include a ren dering engine (\"renderer\") for 2D or 3D graphics, a physics engine or collisiondetection (and collision response), sound, scripting, animation, artificial intelli gence, networking, streaming, memory management, and localization support. In many cases, game engines provide a suite of visual development tools that are built on top of reusable software components. These tools are generally provided in an integrated development environment to enable simplified, rapid development of games in a data-driven manner. Game engines arise as a need for all the corefunctionality needed, right out of the box, to develop a game application while re ducing costs, complexities, and time-to-market - all critical factors in the highly competitive video-game industry.", "label": "human"}
{"ID": "00270049", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "For mobile game development, the list of game engines currently available on the market is vast. Some of the most popular choices are Unity1, Unreal Engine2, GameMaker Studio3, Godot4. Each platform has its own set of features that is better suited to different requirements. The merits and downsides of those 4 game engines can be summarized in table 3.1.", "label": "human"}
{"ID": "00270050", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "4 Unreal GameMaker Godot Supported platformsMobile, desktop, web, console, VRMobile, desktop, web, console, VRMobile, desktop, web, consoleMobile, desktop, web, console AdvantagesEasy to use for beginner developers Many platform supported Great support for mobile developmentOpen-sourced Has more tools and functionalities Suitable for AAA gamesBuilt-in plug and play system Focused on 2D gamesOpen-sourced Use node-based interface Cross-platform development environment Popular developed gamesPokémon Go, Monument Valley, Call of Duty: Mobile, Beat Saber, CupheahFortnite, Werewolf: The Apocalypse – Earthblood, The Matrix AwakensSamurai Gunn 2, Webbed, Super Hiking League DXKingdoms of the Dump, Haiki, Until Then PricingFree for personal useFree for creators, educators and publishersMultiple tiers including freeEntirely free Scripting languagesC# C++ GMLGDScript, C++ and C# Table 3.1: Game engines comparison.With the objectives of building a small-sized game targeting mobile platforms, Unity comes ahead as the first choice for game developers. There are 2.8 billion5 monthly active users involved with content operated or made by Unity game enginein 2020. In the same year, applications built with Unity generated 5 billion down loads per month. These statistics can be attributed to a collection of features and technologies that Unity gaming solution has to offer.", "label": "human"}
{"ID": "00270051", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Perhaps, one of the biggest reasons Unity is preferred amongst game developers worldwide is the ability to build, manage and deploy games cross-platform. Unity provides platform abstraction, allowing the same game to run on various platforms with few, if any, changes made to the game source-code. With this advantage inmind, our mobile game can be built and tested on development environment (Win dows/Mac) and then deployed to mobile platforms (Android/IOS) with ease.", "label": "human"}
{"ID": "00270052", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "A GameObject can have many Components attached. Each Component defines a particular behavior (e.g. \"Renderer\" renders graphics on the screen, \"Rigidbody\" takes care of physics simulation). Developers can also define custom Components in forms of scripts to create complex interactions and logic. The editor windows(scene, game, hierarchy and inspector) provide quick access to all object’s proper ties without the need to dive into the code all the time.", "label": "human"}
{"ID": "00270053", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Apart from robust built-in architecture and tooling, Unity also features its large asset store that comes with a variety of paid and free assets ready for any game project. While Unity does develop some of these, many of them are also made by the community, meaning developers have numerous options to choose from.", "label": "human"}
{"ID": "00270054", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "When developing a multiplayer game, one has to account and solve for inher ent network-related challenges that impact the game experience, such as latency, packet loss and scene management. Criteria for choosing the right solution includes a game’s genre, the scale of its players and networked objects, competitiveness and feature breadth. There is hardly a perfect, one-size-fits all solution for all kinds of games and experiences. For example, a MOBA game implemented upon a P2P5 with deterministic rollback like Heroes Strike6will have completely dif ferent netcode requirements than a FPS game running on a dedicated game server with server authority for cheat prevention, such as Fortnite7. Our choice of network solution was made by identifying the correct netcode type that fits our game and a corresponding network framework implementing that netcode type.", "label": "human"}
{"ID": "00270055", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Netcode type Unlike a local game where the inputs of all players are processed and executed instantly in the same simulation or instance of the game, an on game containsseveral parallel simulations (one for each player) where the inputs from their re spective players are received instantly, while the inputs for the same frame from other players arrive with a certain delay. The goal of video game networking is to create the illusion that two or more players are sharing a single environment . It is the job of network engineers to ensure these simulations stay in sync and create a overall responsive and crisp experience for players under various internet conditions. The extend to which desynchronize resolutions are enforced dependson genres of game. Generally, there are 2 solutions to the netcode problem: delay based and rollback. Definitions and advantages of each techniques will be briefly discussed below.", "label": "human"}
{"ID": "00270056", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Delay-based netcode is the extension of a simpler and classic solution calledLockstep\". In lockstep model, the game progress is paused until all inputs are col lected. Turn-based games are generally implemented this way since the strategic nature of them requires players to think for a few moments. A half-second delay in this case is not very noticeable. To successfully apply lockstep netcode to fightinggames, however, we need to add what is called input latency. Input latency effec tively creates a delay between inputs and their corresponding actions and ensures both players have received the other’s input before the simulations proceed. The end result is that all local game versions are in sync. A combination of lockstep model and input latency is commonly known as “Delay-Based Networking” and has been used for decades in video games such as \"Age of Empires\". A developer can implement a delay-based on mode with little or no change to the core game loop. Delay-based networking, while simple, comes at the cost of responsiveness and flexibility. If there is a spike or variance in latency (due to a poor connection), the game can be paused for a long time until it receives all the inputs.", "label": "human"}
{"ID": "00270057", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Rollback networking approaches the synchronization problem in a much different angle. Rollback removes the need for both player’s inputs to continue the simu 6 7 At each loop, the game predicts what the remote player will input and render the game accordingly. When the real input arrives, rollback checks if the predictionit made was correct. An inconsistency between predicted and real input will “roll back” the game state to a previous committed state, simulate the new inputs, and render the correct game state. Rollback is quite effective at concealing lag spikes or other issues related to latency in the users’ connections, as any correction made in successive frames is small and unobtrusive. A downside of rollback model is that its implementation is more complicated than its delay-based counterpart. Tony Cannon, creator of GGPO8, writes that a game wishing to implement rollback networking must meet three criteria: The game must be deterministic , the game must update the game state independently of input sampling and visual rendering, and the game must be able to save and load the game state on demand.", "label": "human"}
{"ID": "00270058", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Funny Zoo, being a real-time fighting game, incorporates ideas borrowed from both networking techniques. To synchronize players’ movement under real-time constraints, we build a predictor component similar to what rollback netcode has.", "label": "human"}
{"ID": "00270059", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Other events and triggers in the game that happen infrequently are processed with delay-based approach. The last step in creating multiplayer solution is to select a framework that satisfies these requirements.", "label": "human"}
{"ID": "00270060", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Netcode framework Unity, since version 5.2, has been offering a first-party netcode solution calledUNet9. UNet is composed of 2 parts: HLAPI (high-level API) and LLAPI (low level API). HLAPI lets developer build game with ready-to-use components and provides access to Unity engine and editor integration. On the other hand, LLAPI is a real-time transport layer that is built upon optimized UDP based protocol.", "label": "human"}
{"ID": "00270061", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "LLAPI is for those who need to build network infrastructure or advanced multi player games. While being deprecated and currently in maintenance mode, UNet has created a strong foundation on which Unity’s next first-party netcode solution is built.", "label": "human"}
{"ID": "00270062", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "MLAPI10(mid-level API) is a open-source solution being developed (at the time of writing) to become the new Unity netcode foundation. It is customizable and adaptable for the needs of many multiplayer game types. MLAPI offers a greatbreadth of mid-level features like NetworkedVars, scene management, remote pro cedure calls (RPCs), messaging, and more. This solution offers an abstraction layerto enable the swapping of different transports depending on the topology and plat 8 910 that the game is shipped to. The solution assumes some form of client server topology – either a dedicated game server (DGS, where clients connect and interact with the game on a central server) or a listen server (where one client hosts the server for the match).", "label": "human"}
{"ID": "00270063", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Photon PUN11(Photon Unity Networking) is a third-party Unity package for multiplayer games. Its key features include RPCs, serialization, hosted relay and simple matchmaking. Higher-level features like prediction and delta compression is not availble. Photon PUN uses a mesh topology solution (direct P2P), in whicheach client synchronizes everyone else’s data. PUN is suitable for developers mak ing a 2–4 player game that is cooperative or very casual. While having simple interfaces, it struggles with scale in any implementation and may not be viable for very fast-paced games.", "label": "human"}
{"ID": "00270064", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "DarkRift 212is a fast and highly performant low-level networking solution. Itsfeature set contains bi-channel TCP and UDP, serialization, and customizable logging. DarkRift requires a dedicated server topology and the entire solution is mul tithreaded by default. While it does not offer any of the mid- or high-level features, the solution was highly rated for performance. DarkRift targets developers who are in need of full control over networking and are comfortable building additional netcode.", "label": "human"}
{"ID": "00270065", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "After careful consideration, MLAPI was selected as our primary framework to handle the multiplayer part of Funny Zoo. MLAPI’s tight integration with Unityleads to low learning curve and fast iterations. MLAPI being fully free and open sourced is another key attribute leading to the final decision.", "label": "human"}
{"ID": "00270066", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "2 3 provides an insight over the game engine and the multiplayer frame work used in the project. This chapter will go into details of the architecture design for the system as well as some class design and deployment characteristics.", "label": "human"}
{"ID": "00270067", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Software architecture selection Game development is different from traditional software engineering in thatthere are no real functional requirements and the customers buy and use the software only because it is engaging and fun. One of software engineering challenges in game development has been identified as Diverse Assets - game de velopment is not simply a process of producing source code, but involves assets such as 3D modes, textures, animations, sound, music, dialog and video. In Funny Zoo, software elements are grouped into 3 major components in which common software architectures are applied.", "label": "human"}
{"ID": "00270068", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Game architectureA common technique that is typically shown in beginner-level game develop ment is to organize game objects in a hierarchical manner. While this approachworks for small game, the practice of organizing game objects in a hierarchy in troduce inflexibility and maintenance problem. A good game object system mustbe scalable such that game object types can be added easily to the system regard less of the number of types already defined. Unity engine, amongst numerousother game engines, provides developers with component-based game object sys tem which uses composition, rather than inheritance, to define game object typesand their behaviors. Game objects are the fundamental objects in Unity that repre sent the actors of the game world (characters, props and scenery). A game objectdefines their functionalities and behaviors through a list of components. For exam ple, a solid cube object has a MeshFilter andMeshRenderer component, to draw the surface of the cube, and a BoxCollider component to represent the object’s solid volume in terms of physics.", "label": "human"}
{"ID": "00270069", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "In figure 4.1, a player is represented as a game object accompanied by a list of components. The Transform component is used to store a GameObject’s position, rotation, scale and parenting state and is thus very important. Rigidbody enablesphysics-based behaviour such as movement, gravity, and collision. CharacterCon troller component gives the character a simple, capsule-shaped collider and pro-Figure 4.1: Player object in component-based system vides special functions to set the object’s speed and direction. Input handling andextra behaviors are handled inside PlayerController , which is a custom script writ ten in C#. Since the behaviors are decoupled from game objects, the game object system not only becomes much more maintainable, but also very flexible.", "label": "human"}
{"ID": "00270070", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Network architecture Client hosted (Listen server) is selected as the primary network topology for multiplayer experience in Funny Zoo. In this architecture, a player will host the game server (own the game world) and other players will connect to it (see figure 4.2). Client hosted model does not require any special infrastructure or forward planning to set up, which makes it common at LAN parties where latency and bandwidth issues are not a concern. MLAPI framework (mentioned in 3.2.2) alsosupports other setup such as Relay Server andNAT Punchthrough though its mod ular transport system.", "label": "human"}
{"ID": "00270071", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "User interface architecture For user interfaces, MVP pattern is used to structure all screens and popups in our game. Model–view–presenter (MVP) is a derivation of the model–view–controller (MVC) architectural pattern. The model is an abstraction defining the data to be displayed. The view is a passive interface that displays data (the model) and routesinvocations (from user) directly to the presenter. The job of the presenter is to re trieve data from repositories (the model) and format it for display in the view.", "label": "human"}
{"ID": "00270072", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "In Funny Zoo, the view part of MVP is implemented with the help of uGUISource: Unity multiplayer docs Figure 4.2: Player object in component-based system package. uGUI (Unity UI) is a set of tools for developing user interfaces for games and applications. It is a GameObject-based (see a) UI system that uses Components and the GameObjects to arrange, position and style user interfaces. A presenter is a custom defined component talking to the view and the model . Visual components in uGUI exposes setter properties that the presenter uses to set the data. The model is a global state container enhanced with reactive data streams that presenters can subscribe to. A detailed explanation of this architecture will be presented in section 5.2.", "label": "human"}
{"ID": "00270073", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Overall design One advantage of using Unity engine as the primary developing environment is that the entire code base is generally enclosed in a single project. The overall code structure is depicted in package diagram 4.4.", "label": "human"}
{"ID": "00270074", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Config anddata are the foundational packages of the project. Config package contains game related information such as properties of game objects, level layoutsand game design parameters. These configs are typically implemented as Script ableObjects - Unity data containers that support creating, editing and saving inside Unity editor. The data package provides models that the game depends on to saveSource:  Figure 4.3: MVP pattern Figure 4.4: General package designand load data. Game data is stored as a single JSON blob on PlayerPrefs. Play erPrefs is an Unity interface for storing preferences between game sessions. This interface is handled differently based on which platform the application runs on.", "label": "human"}
{"ID": "00270075", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Gameplay package is the core package defining behavioral components for all elements in the game. Some of these components are player and character con-trollers which are grouped and defined inside sub-packages such as staff,player andvisitor .Gameplay package also involves game manager and controllers for other interactable entities.", "label": "human"}
{"ID": "00270076", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Multiplayer package extends some behaviors described in gameplay package to handle multiplayer scenario. It is composed of a multiplayer game manager and custom controllers for player that interact with the network system.", "label": "human"}
{"ID": "00270077", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "UIpackage is dedicated to building all user interfaces in the game. As a mo bile game, Funny Zoo’s UI mainly consists of a main screen screen and several popups. UIpackage contains presenter components (in MVP pattern) that bind to corresponding uGUI objects (see previous section c).", "label": "human"}
{"ID": "00270078", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Last but not least, utility package provides helpful routines and methods that make game development easier. Built on top of Unity API, utility contains helper functions for math (vector) calculation as well as game object and components manipulation.", "label": "human"}
{"ID": "00270079", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Detailed package design A substantial portion of the code base is related to the player. Figure 4.5 showsa list of main classes and packages that handle player behavior as well as their relationship to each other. PlayerControllerBase provides common functionalities such as handling user’s input and controlling player game object. Play erControllerBase refers to PlayerConfig for predefined paramters andPlayerData for run-time information. PlayerController andNetwork PlayerController can then define additional or custom behaviors on top of the base implementation for off and on cases respectively.", "label": "human"}
{"ID": "00270080", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Regarding user interfaces, UIPanel andGUIManager are the 2 main classes that make up the UI system. UIPanel provides common functionalities for UI elements in the game: transition animations and life cycle hooks. GUIManager isresponsible for arranging these UIPanel s and display them on the screen. Generally, screens inherit directly from UIPanel while popups extends UIPopup Panel - a subclass of UIPanel that has extra convenient methods for creating and managing popups. An overview of the UI system is presented in figure 4.6Figure 4.5: Detailed package design for player behavior Figure 4.6: Detailed package design for UI4.2 Detailed design 4.2.1 User interface design a, Screen configuration standardization Display Screen resolution: 720 x 1280px Number of colors supported: 16,177,216 colors Screen Size: 720 x 1280px Location of buttons: Located on the sides of the screen Main color theme: #72FFFF, #FFE59D, #3CCF4E Location of messages: Located on the bottom of the screen Text: Lilita One, size at most 72pxb, Screen specifications for Play Screen Figure 4.7: Play screen template No. Control Operation Function 1 Setting button Click Show setting popup 2 No ads button Click Show no ads popup 3 Map button Click Show map popup 4 Sites button Click Show sites popup 5 Beginner gift Click Show beginner gift popup 6 Buffs button Click Apply a buff to the game 7 Movement zone Drag Control main character movement Table 4.1: Play screen specificationsc, Screen specifications for Manage Staffs Screen Figure 4.8: Manage staffs screen template No. Control Operation Function 1Hire staffs tab buttonClick Show hire staffs tab 2Upgrade staffs tab buttonClick Show upgrade staffs tab 3Money upgrade buttonClick Upgrade staffs using money 4Ads upgrade buttonClick Upgrade staffs by watching ads 5 Close button Click Close manage staffs popup Table 4.2: Manage staffs screen specificationsd, Screen specifications for Setup Connection Screen Figure 4.9: Setup connection screen template No. Control Operation Function 1Local IP address input fieldInput Contain local IP address 2Host IP address input fieldInput Contain host IP address 3 Host button Click Host a game 4 Join button Click Join a game 5Player name input fieldInput Contain player display name 6Player color buttonClick Choose player display color 7 Ready button Click Mark state as ready Table 4.3: Setup connection screen specifications4.2.2 Class design As previously stated in section 4.1.2, the PlayerController class and its accompanying components play an essential part in interfacing between player and the game. A detail design is demonstrated in figure 4.10. Adhering to \"component over hierarchy\" architecture previously outd in section \"Game architecture\", theplayer game object is comprised of several components: ItemContainer ,Character Controller ,CharacterAnimationController andCharacterAccessoriesController .", "label": "human"}
{"ID": "00270081", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "All of these components are specially designed to ensure high reusability and low coupling - they can be added to other character-like entities (e.g. staffs and visitors) without any modification. A brief explanation of each component is given in table 4.4.", "label": "human"}
{"ID": "00270082", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "OnTriggerEnter andOnTriggerExit are also Unity message methods invoked whena collision with another object start and stop. Figure 4.11 illustrates how Play erController uses these 2 messages to detect if player enter an interactable region.", "label": "human"}
{"ID": "00270083", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "An demonstration of the above design is showed in diagram 4.14. MLAPI supports exchanging messages by invoking Remote procedure call (RPC). NetworkGame playManager uses this feature to inform clients of various game events such as game started event and game ended event. In sequence diagram 4.15, a machineacts as a host and the other tries to join as a client. The order in which players initiate connection does not matter as Unity transport layer transparently handles low level UDP networking. In client hosted model, both players are treated as clients and only one of them need to run additional server-side logic to handle incoming connections and setup the game.", "label": "human"}
{"ID": "00270084", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "//github.com/Unity-Technologies/ com.unity.netcode.gameobjects Creating and managing animation sequencesDotween V1.2.632 Create tools and utilities in Unity EditorOdin Inspector 3.1 Handle reactive programmingUniRx 7.1.0  Build, test and deployAndroid SDK 26.0.2 udio/releases/sdk-tools TestingNoxPlayer 7.0.3.2 Version control GitHub  Table 4.5: List of libraries and tools4.3.2 Achievement A typical build output is an APK file. Table 4.6 shows uncompressed asset usage by category in Funny Zoo. Graphics (textures, meshes and animations) take up a substantial part of the total project asset bundle. While the uncompressed size is around 100 mb, Unity managed to produce a optimized build of 78.2 mb as the final product.", "label": "human"}
{"ID": "00270085", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Category Size Percentage Textures 64.2 mb 64.3% Meshses 4.9 mb 4.9% Animations 1.6 mb 1.6% Sounds 1011.7 kb 1.0% Shaders 1.2 mb 1.2% Other Assets 2.4 mb 2.4% Levels 2.4 mb 2.4% Scripts 8.4 mb 8.4% Included DLLs 13.6 mb 13.6% Total User Assets 99.9 mb 100.0% Table 4.6: Uncompressed asset usage by category4.3.3 Illustration of main functions This section will focus on the main features of the game Funny Zoo.", "label": "human"}
{"ID": "00270086", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The player can buy food at the production sites, feed the animals by bringing the food to the trough, collect money on the checkout table, buy more animal and open more production sites.Figure 4.17: Single player scenes where players manage their own zoos Figure 4.18: Minimap popup As the map of the single player mode is quite large, in order to aid the player in navigation and locating objectives, the game provides a minimap which can be accessed though a button on the play screen. When the button is pressed, the minimap popup appears and displays the minimize version of the scene.", "label": "human"}
{"ID": "00270087", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Another feature of the game is the ability to upgrade main character and staffsby entering the corresponding upgrade region, as illustrated on figure 4.19.", "label": "human"}
{"ID": "00270088", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "There are two characters in this scene, which are the player and his opponent. Theplayer needs to move to the floating popup to purchase the food with the price labeled below to use as bait, and then move to the animal to catch it. There is also an upgrade button on the left for the player to spend money on upgrading main character’s stats.", "label": "human"}
{"ID": "00270089", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Automated testing is integrated directly into the build process. Unity provides callbacks into the build pipe and executes pre-build and post-build scripts.", "label": "human"}
{"ID": "00270090", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "These scripts make sure application properties (e.g. version code, bundle code and other setting constants) are correct. After the final output artifact is produced, we useMonkey to stress-test application. Monkey is a program included in Android SDK that runs on emulators or devices and generates pseudo-random streams of user events such as clicks, touches, or gestures, as well as a number of system-level events. The game is expected to function well under these synthesized constraints.", "label": "human"}
{"ID": "00270091", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "While automated tests are robust and reliable, manual testing is still required to collect in-depth functional and performance metrics. Table 4.7 and 4.8 summarize 2 test suits that are done in person, by clicking through and interacting with the software.No.Setup Output Conclusion Step by step Expectation Manage main character: Control main character and move main character to main character upgrade region to upgrade it 1•Step 1: Chose single player mode Step 2: Move main character to main character upgrade region Step 3: Click on upgrade button to spend money to upgrade main characterThe gloves or boots of the main character change color (colors presents levels of the corresponding upgrade)The color of the shoes and gloves of main character changedPASS Hire staffs: Control main character and move main character to staffs manage region to hire more staffs 2•Step 1: Chose single player mode Step 2: Move main character to HR site Step 3: Move main character to staff manage region Step 4: Click on hire staff button to hire staffsThe newly hired staff appears on the map and automatically moves to working placeOne new staff shows up and starts workingPASS Data saving: Player makes changes in single-player session, exits the game and then comes back 3•Step 1: Chose single-player mode Step 2: Spend an amount of money on arbitrary item Step 3: Exit the game Step 4: Open the game again in single-player modeThe amount of money player has before quitting the game is preservedPlayer’s money is saved across sessionsPASS Table 4.7: Single-player test suiteNo.Setup Output Conclusion Step by step Expectation Test connection: A game has already been hosted on the local network, the player has the correct host IP address and use it to connect to the hosted game 4•Step 1: Chose multiplayer mode Step 2: Fill in the local IP address Step 3: Fill in the correct host IP address Step 4: Click on the join button to attempt to join the gameThe waiting popup disappears and the character configuration pop up shows up, meaning the player has successfully joined the gameThe character configuration popup shows up for the player to customize the main character before the game startsPASS Test connection: A game has already been hosted on the local network, the player has the wrong host IP address and use it to connect to the hosted game 5•Step 1: Chose multiplayer mode Step 2: Fill in the local IP address Step 3: Fill in the wrong host IP address Step 4: Click on the join button to attempt to join the gameThe waiting popup appears and the application hangs here, waiting for the connection to be establishedThe waiting popup shows up and do not disappear, indicating that the application is trying to establishing the connection, but not yet succeededPASS Test connection: When two players are in the game, one player disconnected, the other player is automatically disconnected by the system and returned to the main screen 6•Step 1: A player connect to a hosted game Step 2: The host start the game Step 3: A player disconnected from the gameThe other player get disconnected from the game and returned to the main screenThe player whose opponent suddenly disconnected is returned to the main screenPASS Table 4.8: Multi-player test suite4.5 Deployment For testing purposes, APK (Android Package) is used as the target build format.", "label": "human"}
{"ID": "00270092", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "APKs can either be installed on a emulator or a physical device. A different package format is required to deploy the game to end users. Google Play mandates that application be bundled in AAB format (Android App Bundles), while Apple app store permits the use of IPAs (iOS App Store Package) - application archive files which stores an iOS app.", "label": "human"}
{"ID": "00270093", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "After the first month, the game has been rated 4.0 stars over more than 1.2 thou sand reviews, with quite many positive feedbacks from the community. It also gets downloaded for over 1 million time, which is a pretty impressive number for a casual game.Chapter 4 has discussed over the design, implementation and deployment of the system. In the following chapter, the contribution of this project will be proposed.", "label": "human"}
{"ID": "00270094", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Problem description One of many targets that we aimed for when building Funny Zoo’s multiplayerfeature is a stable and smooth gameplay. A multiplayer game operating over the in ternet has to deal with several adverse factors that are not present when developing a single-player one. Latency, which in the context of games means the amount of time between a cause and it’s visible effect, often shows up as the primary adversefactor. An example of latency can be a button press on joystick and the fighter char acter moves in response to said button press. For some game genres, the real-time nature implies that response times are important, and in a networked environment this means that round-trip delays must be kept to a minimum. However, in case of Funny Zoo, RTT is hardly the principal source of latency as the game is mainly played over LAN setup. Still, the impact of jitter (the rate at which ping changes over a period of time) and packet loss has be taken into account.", "label": "human"}
{"ID": "00270095", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Solution A naive approach to synchronize object’s position or any value between serverand client would be turning off all simulation logic in the client and rendering re ceived states from the server as is. This approach will cause some unresponsiveness as the world simulation depends entirely on state packets sent from server. Jitter and packet loss have full control over how choppy gameplay experience is for the client. The overall effect is that the game would only run at sub-optimal framerateregardless of what potential framerate that the client could achieve. Character ob jects standing at a position in this tick could randomly teleport to another position next tick. A simple and conservative approach that makes no attempt to mitigate delay is referred to as \"dumb terminal\". Figure 5.1 shows a simplified structure of a dumb terminal client. Note that only the latest state from the server is kept.Figure 5.1: \"Dumb terminal\" client design In the first iteration of implementing client-side interpolation, instead of just snapping objects to their positions that are transmitted from the server we smoothly interpolate to this state over time. Interpolation is the process of constructing an intermediate data point from few sampled data points. The ultimate goal of doing interpolation is to approximate complicated function (positions of a object) by asimple function. One of the simplest methods is ar interpolation (will be re ferred to as \"lerp\"):", "label": "human"}
{"ID": "00270096", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "lerp(a, b, t ) =a∗(1−t) +b∗t, where t∈[0; 1] If we plugging in current position and server’s new position for aandb, the client would be able to catching up to the most recent state passed to us from the server.", "label": "human"}
{"ID": "00270097", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Using lerp with this setup provides some improvement to the choppiness problem, but it still does not handle jittering well. Another problem with this implementation is that if an object teleports to a new position, the player will incorrectly see a rapid movement in that object rather than an instant jump. We could work around this by sending a flag in addition to the state packet to instruct a \"reset\", but there is a better way to do synchronization.Instead of only storing the latest state, we buffer all incoming changes from the server. This provides the client with more data to produces even smoother gameplayat the cost of added processing. A state update packet now includes a timestamp  the time in which the state was snapshotted (see figure 5.2). At each client game loop, we try to read from the buffer and pick out a newest snapshot that is due (i.e. its sent time is less than reference time) as the end target for interpolation. The reading process can consume multiple snapshots from the buffer. The next step will be applying lerp on the last interpolation target and the new one:", "label": "human"}
{"ID": "00270098", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "In the context of user interface (UI), contents of visual elements should be up to date with the application state changes. The goal of adding reactivity to UI is to eliminate elusive bugs of unsynchronized view and application state, when one forgets to update the view when updating the data. On the language layer, C#/.NET has a built-in event model1that follows the observer design pattern, which enables a subscriber to register with and receive notifications from a provider. However, this design pattern is often too complex and requires a significant amount of boilerplate code. On the application layer, Unity offers proper data binding with the advent of UI Toolkit package. Nevertheless, at the time of writing UI Toolkit is still missing features found in uGUI - the UI package that Funny Zoo uses.", "label": "human"}
{"ID": "00270099", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Solution Instead of building a binding layer to bring data binding mechanism to uGUI , weopted for reactive extensions with UniRx library. In reactive programming, applica tion state is converted to data streams and changes are propagated from producersto consumers. Rather than constantly pulling data sources to update content, recip ients await for the arrival of incoming changes. This means that we can design datasource in isolation without needing to worry about how UI accesses data. To illus trate the final design, the rest of this section will focus on an example of updatingand displaying player’s money. Listing 1 displays a small section of Gameplay Data (the global application data store) that is related to money.", "label": "human"}
{"ID": "00270100", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "public class GameplayData : IGameData public IObservable< int> MoneyObservable => moneySubject; private readonly BehaviorSubject< int> moneySubject; Listing 1: Example of a data source Using UniRx, the value of money is wrapped in a mechanism for retrieving and transforming the data in the form of an \"Observable\". BehaviorSubject is a special implementation of an Observable that immediately emits the most recent item and then continues to emit any other items emitted later. This is the desiredbehavior for data sources as observers should receive the latest state upon sub 1 Rather than using GameplayData as the concrete implementation of the data source, we use dependency injection to provide UI layers with an abstract implementation - IGameData . Dependency injection allows gameplay data to be unit-tested without much effort.", "label": "human"}
{"ID": "00270101", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "To display current money value on a label, the UI presenter need to subscribe toMoneyObservable . Listing 2 demonstrates how PlayScreen presents a up-to-date money label on screen. For an overview of the UI layer’s structure, refer to package diagram 4.6 and section c.", "label": "human"}
{"ID": "00270102", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "public class PlayScreen : UIPanel private TMP_Text moneyLabel; private IGameData gameData; private CompositeDisposable eventSubscriptions; protected override void RegisterEvent() gameData.MoneyObservable .SubscribeToText(moneyLabel) .AddTo(eventSubscriptions); protected override void UnregisterEvent() eventSubscriptions.Clear(); Listing 2: Example of a data consumer Reactive extensions provided by UniRx integrate seamlessly with FunnyZoo’s UI system. By placing subscription calls inside RegisterEvent , subscriptionlifecycle is automatically managed. Data recipients should only be consuming re sources when they are active rather than listening all the time. Nevertheless, apart from convenient lifecycle management, Observables seems like just another way to do event handling. The real power comes with the \"reactive extensions\" - operators that allow one to transform, combine, manipulate, and work with the sequences of items emitted by Observables. These operators allow composing asynchronoussequences together in a declarative manner with all the efficiency benefits of call backs but without the drawbacks of nesting callback handlers that are typically associated with asynchronous systems. For instance, we can add a smooth updateanimation to the money label by applying a custom operator to MoneyObserv-able before subscribing. In another example, the buy button associated with a pur chasable item is usually made conditionally enabled depending on whether player has enough money. The same MoneyObservable can be transformed to a \"has enough money\" stream with Select operator and then applied to the button’s state. The end result is exhibited in figure 5.4.", "label": "human"}
{"ID": "00270103", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "The Funny Zoo game was born with the aim to entertain mobile players in theirfree time. Built on top of Unity game engine, the development process was ac celerated with the presence of a visual development environment, cross-platform support, and a modular system of components. Featuring an attractive gameplay and a colorful theme, Funny Zoo has been published on Google Play and received a lot of good feedbacks from the community. This is also attributable to an in-depth game flow and contents that some of the casual games on the store lack. Finally, the game comes with a multiplayer competitive game mode for players and their friends to enjoy the game together.", "label": "human"}
{"ID": "00270104", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Aside from successfully delivering the final product, we gained some valu able experiences in the process of doing Graduation Thesis. The project openeda chance to come into contact with game design inside and out. Developing mul tiplayer functionality also gives us a deeper understanding of network architecture in the context of a real-time fighting game.", "label": "human"}
{"ID": "00270105", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Within the graduation scope, the project has been developed and published suc cessfully to serve the basic need of the players and acquired the target proposed.", "label": "human"}
{"ID": "00270106", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Still, there are many to improve in the project. Firstly, regarding the game design, the average time to unlock all the contents of the game is not very long, about forty five minutes. This is due to the constraint of development time and can be solved by adding more content in the future. The game is expected to have at least 2-hour length game sessions to bring back more profit. Secondly, the multiplayer game should be extended to serve more than just two players at the same time. Also, a lobby service or a match making system should be integrated into the game in order to make the game more competitive. This target could be achieved by a redesign of the multiplayer game mode, and a more in-depth researching in networking system.", "label": "human"}
{"ID": "00270107", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "There are some events where the FPS drop slightly such as when the player inter acts with a large amount of objects, or when there are more than 15 visitors in thescene. Performance optimization requires interacting with low level interfaces of the game engine, as well as applying a more efficient algorithm for solving currentproblems. Boualem Benatallah, Fabio Casati, and Farouk Toumani. “Web service conversation modeling: a cornerstone for e-business automation”. In: IEEE In ternet Computing 8 (2004).", "label": "human"}
{"ID": "00270108", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Paul Bettner and Mark Terrano. “1500 archers on a 28.8: Network program ming in Age of Empires and beyond”. In: GDC . Vol. 2. 2001. 2001, 30p.", "label": "human"}
{"ID": "00270109", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Tony Cannon. “Fight the Lag: The Trick behind ggpo’s Low-Latency Net code”. In: Game Developer Magazine 19.9 (2012), pp. 7–13.", "label": "human"}
{"ID": "00270110", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Christopher M Kanode and Hisham M Haddad. “Software engineering chal lenges in game development”. In: 2009 Sixth International Conference on Information Technology: New Generations . IEEE. 2009, pp. 260–265.", "label": "human"}
{"ID": "00270111", "file_name": "Funny Zoo - A Casual Game Built With Unity", "content": "Alf Inge Wang and Nj ˚al Nordmark. “Software architectures and the creativeprocesses in game development”. In: International Conference on Entertain ment Computing . Springer. 2015, pp. 272–285.", "label": "human"}
{"ID": "00280001", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "This chapter serve as a introductory to the thesis. In here, you will find the motivation behind the thesis, the contribution of the thesis and its structure.", "label": "human"}
{"ID": "00280002", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Video has become an increasingly popular and pervasive medium in the digital age due to its captivating and dynamic nature. As a visual and auditory form of communication, video possesses a unique ability to convey information, emotions,and narratives in a compelling and engaging manner. Its multi-sensory appeal al lows audiences to immerse themselves in content, making it an ideal medium for storytelling, educational purposes, entertainment, and marketing. Moreover, thewidespread availability of high-speed internet and the proliferation of mobile de vices have facilitated seamless video consumption, enabling users to access a vast array of content anytime and anywhere.", "label": "human"}
{"ID": "00280003", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "As users’ appetite for video content grew, a demand emerged for platforms that could efficiently host, stream, and share videos with a global audience. Platforms like YouTube, Vimeo, and Dailymotion were born out of this necessity, offering creators and users a space to upload, share, and discover an extensive range of videos. As users sought to connect, engage, and express themselves through video, these platforms evolved into massive digital ecosystems that revolutionized content consumption, entertainment, and on social interaction.", "label": "human"}
{"ID": "00280004", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "However, the fact that almost all of these platforms are centralized causes them to face considerable difficulties, which has sparked worries about content control and censorship. These platforms’ centralization makes it possible to remove or limit information based on arbitrary standards, raising concerns about the repression of free speech and different viewpoints.", "label": "human"}
{"ID": "00280005", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Solving this problem will greatly benefit content creators, journalists and ac tivists as they can freely create the content they want and openly express their opinion without worrying that it will be taken down. And so the solution I have chosen for this thesis is for the platform to be decentralize. This solution can also be apply across other platforms involving information sharing like as social media, news, file sharing...", "label": "human"}
{"ID": "00280006", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "By adopting decentralized technologies, my website offer a censorship-resistant environment that empowers content creators and users to freely express themselveswithout fear of arbitrary removal or suppression. This commitment to free speech promotes a diverse range of ideas, perspectives, and artistic expressions, fostering a vibrant and open digital space for creativity and dialogue. Moreover, by beingdecentralized, my platform prioritize true data ownership, ensuring that users re tain control over their content. This emphasis on data ownership aligns with the growing demands for greater transparency and user empowerment..", "label": "human"}
{"ID": "00280007", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The next chapter, Chapter 2, will introduce the background knowledge of thetechnology that is used in this thesis such as blockchain, smart contract and espe cially Eueno, our decentralize storage method. Then it will discuss the approaches that has been made with the given objective.", "label": "human"}
{"ID": "00280008", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In Chapter 3, I will present the overview of the website. Afterward, I will go into great detail about the website architecture.", "label": "human"}
{"ID": "00280009", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Chapter 4 will be used to discuss the technical difficulty I have met when making the website and the solution I have employed to solve them. Then I will intro duce the website interface.", "label": "human"}
{"ID": "00280010", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Chapter 5 is the evaluation of my website such as the API calling speed and video loading time. These will then be compare with other solution such as dTube or BitChute.", "label": "human"}
{"ID": "00280011", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "With all of the above, Chapter 7 will summarize the thesis and list my contribu tion to the project. I will also provide some of my insight on what I have achived, what can be improve in the futureThe background portion of this thesis gives a thorough discussion of the major ideas and concepts that form the basis of the solution I provide. The fundamentalproperties of blockchain technology are covered in this chapter, along with a defi nition of a smart contract, a synopsis of the development of a decentralized videosharing network, a basic analysis of Eueno, the decentralized storage solution uti lized for this project, and a discussion of alternative strategies. Understanding these ideas is essential for understanding the motivations behind our approach and its possible effects on the decentralized digital ecosystem.", "label": "human"}
{"ID": "00280012", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Blockchain technology has emerged as a ground-breaking breakthrough that has the power to alter entire industries and the way in which digital transactions arecarried out. It offers a decentralized, open, and transparent platform for safe, per manent record-keeping, doing away with middlemen and promoting peer-to-peerinteractions. This chapter offers a succinct overview of blockchain technology, emphasizing its historical background, the issue it tries to address, and the main con tributions of its initial author.", "label": "human"}
{"ID": "00280013", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The idea of blockchain was first suggested in 2008 by an unidentified individual or group going by the alias Satoshi Nakamoto . The essential ideas and designof blockchain technology were detailed in the seminal essay \"Bitcoin: A Peer-to Peer Electronic Cash System\" written by Satoshi Nakamoto as a response to theproblems of trust and decentralized digital currency. Blockchain was first intro duced with Bitcoin, marking a crucial turning point in the development of digital currencies and decentralized networks. The problem blockchain aims to solve is the lack of security and trust in traditional centralized systems. There is possibility for manipulation, deceit, and censorship because centralized systems depend on asingle trusted authority to confirm and authenticate transactions. By creating a de centralized network of nodes where consensus mechanisms ensure the legitimacy and integrity of transactions without the need for a central authority, blockchain technology tackles these problems.", "label": "human"}
{"ID": "00280014", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Blockchain technology was founded on the safe and decentralized foundation for digital currency transactions introduced by the original author, Satoshi Nakamoto.", "label": "human"}
{"ID": "00280015", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Nakamoto’s most important contribution was to combine distributed ledger tech nology with already existing cryptographic methods, such as hash functions and digital signatures. This development made it easier to create a visible and impene-trable transaction ledger, guaranteeing the immutability and integrity of blockchain data. Blockchain technology has developed since Nakamoto’s original work and now goes beyond digital currencies like Bitcoin. It affects a wide range of sectors,including healthcare, supply chain management, and finance. Due to the decentralized nature of the blockchain, these industries can benefit from increased trans parency, efficiency, and trust, which opens the door for creative solutions and fresh business models.", "label": "human"}
{"ID": "00280016", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Transactions Transactions are fundamental elements of blockchain technology, serving as the building blocks for the transfer and exchange of digital assets. Each transaction is a public entry in bitcoin’s blockchain, the global double-entry bookkeeping ledger.", "label": "human"}
{"ID": "00280017", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Transactions play a critical role in the security and reliability of blockchain net works. They are designed to provide a visible and auditable trail of all blockchain activities and to be verifiable and immutable. Participants may track the history and origin of digital assets by documenting each transaction on the distributed ledger, promoting accountability and eliminating double spending.", "label": "human"}
{"ID": "00280018", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "A transaction is created throughout the course of several steps. By providing therecipient’s address and the specified transfer amount, the sender starts the trans action. The transaction is then authenticated and integrity is guaranteed by the originator using their private key. The transaction is distributed to the network for verification and included in a block after being digitally signed. Using the sender’s public key, the validation process verifies the transaction’s digital signature to make sure it hasn’t been altered with and that the originator has enough money to finishthe transfer. After validation, the transaction is added to a pool of pending transac tions that are awaiting confirmation. Selected transactions from the pool are added to a new block by miners, who are in charge of maintaining the blockchain. Thetransaction is then added to the blockchain via a consensus process, such as proof of-work or proof-of-stake.", "label": "human"}
{"ID": "00280019", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Participants can transmit digital assets in an open, secure, and intermediary-freemanner by creating transactions on the blockchain. By using cryptographic algo rithms to authenticate and approve transactions, it ensures the system’s integrity and makes the process tamper-proof and fraud-resistant.", "label": "human"}
{"ID": "00280020", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Blocks In a blockchain, a block is a key component that is essential to the organizationand operation of the network. It serves as a storage facility for a variety of trans actions and other important information. Each block consists of a block pream-ble, which establishes a chronological sequence and contains metadata such as the block’s unique identification, timestamp, and a reference to the prior block. Theblock consists of transactions, which are a collection of various blockchain network operations. Sender and destination addresses, digital signatures for authen tication, and other relevant data are all included in these transactions. The block also has a Merkle tree root, which offers a quick way to confirm the accuracy of the transactions it includes. In addition, a cryptographic hash function generates a unique block hash for each block. This block hash guarantees the immutability ofthe block’s content and acts as a digital fingerprint for it. For instance, in proof of-work consensus algorithms, miners compete to find a nonce value that, whenpaired with the block header, satisfies particular criteria, adding a layer of secu rity by solving computational puzzles. The block serves as the essential building element of the blockchain, making it possible to store and verify transactions in a safe, open, and effective manner.", "label": "human"}
{"ID": "00280021", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Wallet a, Key and address In the context of blockchain technology and cryptocurrencies, key and address are fundamental notions for user identity and transaction security. A key, also calleda cryptographic key, is a piece of data used in cryptographic algorithms for vari ous tasks like encryption, decryption, and digital signatures. Keys are typicallyemployed in the context of blockchain to authenticate transactions and secure ac cess to digital assets. Private and public keys are just two examples of the many key categories with mathematical connections. A user-secret, randomly generated number is referred to as a private key. It is employed to produce digital signaturesthat serve to confirm the validity and integrity of transactions. Never share the pri vate key with anyone and keep it in a safe place. The linked digital assets could be taken over by a third party if they manage to get their hands on the private key. On the other hand, a user’s public key is represented cryptographically by an address.", "label": "human"}
{"ID": "00280022", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "It is a string of alphanumeric characters that serves as a special identification for receiving transactions or communications in a blockchain network. They do notprovide any information about the private key, but the public key is utilized to cre ate addresses. The recipient’s address is used as the destination when sending a transaction to a specific user on a blockchain network. The address serves as a pseudonymous identity and offers protection and anonymity. Using their private key, the recipient can then manage and gain access to the digital assets linked to that address.b, Wallet A cryptocurrency wallet is a piece of hardware or software that enables usersto securely store, manage, and interact with their digital assets. Wallets are essen tial for both users’ acceptance and use of cryptocurrencies, improving the wholeexperience with a number of benefits. An easy-to-use interface for managing dig ital assets is offered by wallets. They offer a safe way to keep private keys, whichare needed to access and manage bitcoins. By securely keeping private keys, wal lets let users to send and receive money, keep track of their past transactions, and check their account balances. Wallets often offer customers a complete set of tools for managing their cryptocurrency holdings, including features like address book management, transaction history, and real-time market data.", "label": "human"}
{"ID": "00280023", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The use of industry standards, such as the BIP39 protocol, in the creation andadministration of mnemonic phrases or seed phrases is a crucial component of wal let security. The BIP39 protocol guarantees that wallets follow a consistent process for producing mnemonic phrases, which are human-readable collections of words.", "label": "human"}
{"ID": "00280024", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "You can use these words to generate the cryptographic keys required to access and control bitcoin funds. By implementing the BIP39 specification, wallets give users a dependable and consistent means to backup and restore their wallets, adding an extra layer of security and usability.", "label": "human"}
{"ID": "00280025", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "ConsensusIn the context of blockchain technology, the idea of consensus is of utmost im portance because it ensures the agreement and validity of transactions across the network. This method includes a procedure through which decentralized nodes inthe network come to consensus on the blockchain’s present state. This study com pares and contrasts Proof of Work (PoW) and Proof of Stake (PoS), two popular consensus techniques.", "label": "human"}
{"ID": "00280026", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The PoW consensus method, which was first introduced by Bitcoin , acts as the primary mechanism for verifying transactions and upholding the reliability of the blockchain network. The participants in PoW are referred to as miners, and they compete in order to solve challenging mathematical riddles. In the world ofblockchain technology, the first miner who correctly solves the challenging challenge receives due recognition and a payment, adding a new block to the already existing chain of transactions. The aforementioned procedure requires a significant quantity of computational power and uses a significant amount of energy. The use of PoW maintains the security of a blockchain system by successfully discouraging malevolent parties from interfering with earlier transactions. This is accomplishedby making any attempts to change the blockchain’s historical records extremely computationally expensive.", "label": "human"}
{"ID": "00280027", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The PoS  consensus method serves as a strong substitute for the PoW mecha nism with the main goal of addressing the energy consumption issues that are often associated with PoW. In the Proof-of-Stake (PoS) consensus process, validators are chosen based on their bitcoin holdings and willingness to \"stake\" their holdings as collateral. The choice of validators is often made through a deterministic process, which frequently takes into account elements like the size of the stake and the length of time it has been held. Because PoS relies less on powerful computing resources than PoW does, it is commonly known that PoS’s consensus process is more energy efficient than PoW’s.", "label": "human"}
{"ID": "00280028", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Both PoW and PoS consensus procedures have advantages and drawbacks that are distinct from one another. Strong security precautions are a hallmark of the PoW consensus process, but at the expense of high resource consumption. On the other hand, while the PoS protocol has advantages in terms of energy efficiency, it may also be vulnerable to certain types of assaults. The choice between PoW and PoS depends on the different requirements and aims of a blockchain network.", "label": "human"}
{"ID": "00280029", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Smart contracts are contracts that, because they are written in code, fulfill their duties automatically. These contracts automatically execute and enforce themselvesby doing away with the need for middlemen and providing a secure and decentral ized platform to conduct and enforce agreements or transactions. The concept of smart contracts has been known since the 1990s; the name \"smart contract\" is attributed to computer scientist Nick Szabo. However, smart contracts were notwidely used or given much attention until the development of blockchain technol ogy, especially after Ethereum  was introduced in 2015.", "label": "human"}
{"ID": "00280030", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The decentralized blockchain network Ethereum introduced a Turing-complete programming language that enables the development and execution of advanced smart contracts. This invention opened the door for the creation of decentralized applications (DApps), which have the potential to employ smart contracts to secureand automate a range of processes, including voting systems, supply chain man agement, and financial transactions. Since then, smart contracts have increased in popularity and are being researched in a number of fields and businesses for their potential to revolutionize current business practices. Their immutability and transparency, as well as the capacity to automate procedures and do away with middlemen, hold the promise of enhancing workflow, increasing productivity, andlowering expenses.", "label": "human"}
{"ID": "00280031", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Decentralized video streaming platforms are a new paradigm that are begin ning to replace the traditional centralized video streaming platforms that have longdominated the market. The idea of decentralized video streaming platforms is thor oughly examined in this section, along with its benefits, drawbacks, and potential effects on the development of internet video streaming.", "label": "human"}
{"ID": "00280032", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "It governs how a decentralized video streaming platform functions, allowing users to both watch and produce content. Users can directly exchange videocontent with one another using P2P architecture, in contrast to typical stream ing systems that rely on centralized servers. This makes a centralized authority unnecessary and allows for a more decentralized, robust network.", "label": "human"}
{"ID": "00280033", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "P2P architecture has a number of benefits for streaming video. The first benefit is that it relieves pressure on central servers, enabling effective and scalable content distribution. By utilizing the resources of numerous peers, it enhances video streaming performance and enables quicker and more depend able streaming experiences.", "label": "human"}
{"ID": "00280034", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Platforms for decentralized video streaming are constructed on a distributed network in which numerous peers or nodes work together to transmit content.", "label": "human"}
{"ID": "00280035", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Because of the network structure, the platform is less vulnerable to censorship, outages, and other types of disruption because no one party has total control over it.", "label": "human"}
{"ID": "00280036", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "A decentralized network improves reliability by spreading content among several nodes. The network may carry on operating even if certain nodes malfunc tion or become inaccessible, guaranteeing consumers of uninterrupted videostreaming. Additionally, distributed networks optimize content delivery by uti lizing the resources that are available across the network to achieve effective bandwidth usage.", "label": "human"}
{"ID": "00280037", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Using the technology discussed in section 2.1, the video streaming platform’sinteractions and transactions are recorded and verified using blockchain, which functions as a decentralized ledger. It guarantees equitable compensation forcontent creators, strengthens copyright protection, and makes transparent revenue sharing models possible. Additionally, by encrypting video data and offering a tamper-proof record of transactions and interactions, blockchain tech nology improves content security.", "label": "human"}
{"ID": "00280038", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Platforms for decentralized video streaming use a variety of distribution techniques. While some systems choose a hybrid strategy that combines central ized and decentralized elements, others only use peer-to-peer networks.", "label": "human"}
{"ID": "00280039", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Using central servers for the initial material distribution and peer-to-peer con nections for the later streaming are both examples of hybrid systems. This strategy keeps the benefits of decentralized networks while enabling effective content delivery. Fully decentralized platforms, on the other hand, only usepeer-to-peer connections to transmit content, offering high resilience, scala bility, and user control over the streaming procedure.", "label": "human"}
{"ID": "00280040", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In comparison to its centralized equivalents, decentralized video streaming systems offer more resilience and reliability. These platforms decrease thepossibility of service interruptions by doing away with single points of fail ure and use a distributed network. Other nodes in the network can step in to make up for any lost or malfunctioning nodes, guaranteeing uninterrupted video streaming.", "label": "human"}
{"ID": "00280041", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "As content is spread across numerous nodes, the network can still serve the video content even if one or more nodes fail, preserving a seamless streaming experience for users.", "label": "human"}
{"ID": "00280042", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In the digital age, privacy and security issues are crucial. Platforms for decen tralized video streaming address these issues by supplying improved privacyand security features. These platforms give users the ability to maintain con trol over their personal data and viewing preferences by utilizing blockchain technology. The blockchain stores personal data, maintaining transparencyand enabling users to stay anonymous if they so want. This stops centralizedorganizations from collecting and making use of user data for things like tar geted advertising.", "label": "human"}
{"ID": "00280043", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "By encrypting video data and offering an immutable record of transactions,blockchain technology also improves content security. This safeguards the in tegrity of the video streaming process and prevents illegal modification of thecontent. Users who use decentralized platforms can watch content with confi dence, knowing that their personal information is safe.", "label": "human"}
{"ID": "00280044", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Comparatively to centralized systems, decentralized video streaming networksare more scalable and cost-effective. To manage rising user demand, tradi tional streaming services frequently need to make significant infrastructure investments. Decentralized platforms, in contrast, make use of the resourcesof network users to cut down on the need for expensive centralized infrastruc ture.", "label": "human"}
{"ID": "00280045", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Decentralized platforms make advantage of peer-to-peer networks to spread the streaming load among a number of nodes, thereby scaling the network asthe user base expands. Even during times of high demand, its scalability guar antees a flawless video streaming experience. In the long run, decentralized systems are more economically viable due to the less reliance on centralized infrastructure and cheaper operational costs.", "label": "human"}
{"ID": "00280046", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Challenges Decentralized video streaming systems have many advantages, but there are also some issues and problems that must be taken into account if they are to be widely used and successful.", "label": "human"}
{"ID": "00280047", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Decentralized platforms rely on peer-to-peer networks, so securing scalablenetworks and enough bandwidth might be difficult. Users’ willingness to contribute resources to the network, such as processing power and bandwidth, de termines the platform’s performance. To motivate users to engage and support the scalability of the network, appropriate resource management techniques and incentive mechanisms are crucial.", "label": "human"}
{"ID": "00280048", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Removing censorship is a double edge sword, while it can indeed promote free speech and expression, it also green light toxic contents such as hate speech,misinformation, conspiracy theory,...", "label": "human"}
{"ID": "00280049", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "A decentralized video streaming platform’s success depends on encouraging user uptake and involvement. Users must be encouraged to share their material and give their resources.", "label": "human"}
{"ID": "00280050", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "EUENO  is a decentralized data storage designed for Web3 which provides end-to-end encryption, huge data storage, dynamic access management, and simple sharing. Eueno will especially provide a way forward to engage with data in termsof file encryption, storage, and sharing between peer for users who frequently cre ate or use dApps.", "label": "human"}
{"ID": "00280051", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "With the development of numerous peer-to-peer data storage methods and protocols, decentralization has progressed significantly. EUENO, like many other stor age services, is built for both the mobility of data exchange and its permanence over time, with a primary focus on the fundamental discip of data privacy.", "label": "human"}
{"ID": "00280052", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Blockchain embrace the transparency of transaction data by design, but theymay fall well short of that capability when it comes to storing information according to one’s preferences, especially in huge amounts. In addition, rather than main taining constant transparency, these kinds of data should be made public, private, or just accessible to chosen people.", "label": "human"}
{"ID": "00280053", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "EUENO revolutionizes a variety of ways we can work with data for the better through end-to-end encryption using cryptography, including freely contributing to a peer-to-peer network of encrypted files without putting one’s ownership at risk, sparing oneself from using up a lot of storage space exclusively, broadcasting encrypted data to different networks, and many more.", "label": "human"}
{"ID": "00280054", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "There have been multiple decentralized video sharing systems that have arisenduring the last few years, using different technologies to accomplish their decen tralization objectives.2.5.1 BitChute Figure 2.1: BitChute Home PageBitChute emerged as a video hosting platform that presented itself as a champion of free speech and an alternative to mainstream video-sharing sites. By posi tioning itself as a platform that prioritized freedom of expression, BitChute soughtto provide content creators with a space where they could share their videos with out fear of censorship or removal based on political or ideological reasons. The platform’s emphasis on free speech resonated with content creators who felt stifled or restricted on other popular video-sharing platforms.", "label": "human"}
{"ID": "00280055", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "At the core of BitChute’s technology was its utilization of WebTorrent, a peer-to peer (P2P) technology. WebTorrent allowed videos to be distributed and delivered through a decentralized network of users rather than relying solely on centralized servers. When a video was uploaded, it was broken into smaller pieces, which were then distributed and hosted by various users who had the BitChute application installed. As a result, when someone wanted to watch a video, their device wouldretrieve these pieces from other users’ devices, making the content delivery process more resilient and less reliant on traditional server infrastructure.", "label": "human"}
{"ID": "00280056", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "BitChute’s commitment to decentralization extended beyond its content distri bution approach. The platform’s community-driven moderation system allowed users to flag potentially inappropriate content for review. Instead of relying solely on a centralized moderation team, BitChute entrusted the community to activelyparticipate in keeping the platform’s content in check, fostering a sense of owner ship and responsibility among its user base.", "label": "human"}
{"ID": "00280057", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "To support the platform’s operations and continued commitment to free speech,BitChute introduced a subscription-based membership known as \"BitChute Pre mium.\" This user-funded initiative offered subscribers access to additional features and benefits while contributing to the financial sustainability of the platform.", "label": "human"}
{"ID": "00280058", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Odysee Figure 2.2: Odysee Home PageOdysee is a video-sharing and content publishing platform that embodies the principles of decentralization and blockchain technology. Operating on the LBRY protocol, Odysee is an upgraded and rebranded version of the previous LBRY.tv platform. Its primary mission is to provide content creators with an environmentfree from censorship, allowing them to share their videos and digital content di rectly with their audience without interference from centralized authorities.", "label": "human"}
{"ID": "00280059", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Built on the LBRY protocol, Odysee benefits from the decentralized and blockchain based system that enables direct peer-to-peer transactions between creators andconsumers of content. The blockchain records ownership details, content meta data, and transaction history, ensuring transparency and security throughout the platform.", "label": "human"}
{"ID": "00280060", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Integral to the functioning of Odysee is the use of LBRY Credits (LBC), thenative cryptocurrency of the LBRY protocol. Content creators earn LBC by pub lishing their work, and users can use this cryptocurrency to show support for their favorite creators through tips or by accessing premium content. LBC plays a pivotal role in incentivizing content creation and fostering community engagement.", "label": "human"}
{"ID": "00280061", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Odysee proudly upholds the ethos of decentralized content publishing. Creatorsare empowered to publish their content directly to the platform, bypassing interme diaries and centralized content moderation. This approach allows creators to retain full ownership and control over their content, ensuring that it remains accessible and uncensored for their audience.", "label": "human"}
{"ID": "00280062", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "To enhance user experience, Odysee provides a user-friendly interface for content discovery. Users can explore a diverse range of media, and the platform em ploys its blockchain-based system to offer personalized content recommendations based on individual preferences and viewing history.", "label": "human"}
{"ID": "00280063", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Community governance is a crucial aspect of Odysee’s ethos. Utilizing the LBRY Improvement Proposal (LIP) system, users and stakeholders actively participate in decision-making, shaping the platform’s development and direction.", "label": "human"}
{"ID": "00280064", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Odysee’s use of blockchain technology and decentralization creates a robust, censorship-resistant content-sharing platform. By providing creators with greatercontrol over their work and enabling users to access diverse and uncensored content, Odysee aims to foster a thriving community of content creators and con sumers.2.5.3 DTube Figure 2.3: dTube Home Page dTube stood as a decentralized video-sharing platform that sought to offer a censorship-resistant alternative to mainstream video-sharing sites. Operating on the STEEM blockchain and leveraging IPFS (InterPlanetary File System), dTube combined the power of blockchain technology and decentralized content storage to create an ecosystem where users could share and discover videos without fear of censorship or content removal.", "label": "human"}
{"ID": "00280065", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "At the heart of dTube’s infrastructure was the STEEM blockchain, a decen tralized social media platform that rewarded users with STEEM tokens for theircontent creation and curation efforts. This incentivized content creators and en couraged community engagement, fostering an environment where original and valuable content thrived.", "label": "human"}
{"ID": "00280066", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Complementing the STEEM blockchain was the use of IPFS for content storage and distribution. By storing content on multiple nodes across the network, dTube minimized reliance on traditional centralized servers. This approach ensured thatcontent remained available and resilient, even in the face of potential server outages or attempts to suppress information.", "label": "human"}
{"ID": "00280067", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Embracing the principles of decentralization, dTube empowered content creators to publish their videos directly to the platform without intermediaries or cen tral authorities. This approach granted creators full ownership and control over their content, contributing to a platform where diverse perspectives could be freely shared and accessed.", "label": "human"}
{"ID": "00280068", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Moreover, dTube’s design aimed to enhance censorship resistance, making it challenging for external entities to take down or restrict content. By utilizing blockchain technology and decentralized content storage, the platform stood as a bastion of free expression and information dissemination.", "label": "human"}
{"ID": "00280069", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In addition to content creation, dTube offered a unique monetization model for creators and users alike. Content creators could earn rewards in the form of STEEM tokens based on the popularity and engagement of their videos, while users whocurate and upvote content could also be rewarded with STEEM tokens. This selfsustaining system created a thriving ecosystem where quality content was incen tivized and rewarded.This chapter will provide a thorough look at the system as a whole and how it interact with each of its function. It will also show the work flow of each important function in the project.", "label": "human"}
{"ID": "00280070", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The user’s access to the platform is made easier by the web browser, which also acts as the user’s interface for interacting with other system parts.", "label": "human"}
{"ID": "00280071", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The web browser works with a designated signer, in this case Owallet, to ensure safe and dependable access. Users may log in to the website with ease and trust because to the platform’s strong authentication system, which makes advantage of Owallet’s strong capabilities. By confirming the user’s credentials and securely managing authentication methods, Owallet serves as the platform’s trusted identity provider, ensuring that only authorized users have access to its services.", "label": "human"}
{"ID": "00280072", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Depending on the nature of the particular activity at hand, the website orches trates its interactions with the blockchain after a successful login. Because of the platform’s seamless connection with the blockchain, users can easily conduct tasks like uploading videos, making transactions, and managing content thanks to the quick and effective blockchain interactions made possible by this.", "label": "human"}
{"ID": "00280073", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In contrast, the website may also work with Eueno provider, utilizing its scal ability and security capabilities to communicate with the database that is home to the enormous collection of films and related metadata. The core of the content repository is Eueno provider, which effectively manages the storage and retrieval of video data to give viewers a seamless and engaging viewing experience.", "label": "human"}
{"ID": "00280074", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Actor a, UserUsers, who serve as the project’s principal actors, are vital to and indispens able to the beginning and advancement of all interactions within the decentralizedvideo-sharing system. Users operate as the main initiators and players in the plat form’s dynamic ecology, serving as the major catalysts for the platform’s activities in each and every use case.", "label": "human"}
{"ID": "00280075", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Eueno Provider Our decentralized video-sharing platform’s supervision of the API, which forms its foundation, is crucial to guaranteeing smooth and effective operations. These governance actors are the API’s custodians, in charge of handling user requests and organizing the retrieval and storage of video data, which is essential to the plat-form’s efficient operation. They serve as the mediators, ensuring the smooth flow of data between users and the underlying system with their sophisticated function in administering the API.", "label": "human"}
{"ID": "00280076", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Owallet ProviderThe players in charge of overseeing the API used for user wallet login play a sig nificant part in the decentralized video-sharing network in addition to the EuenoProvider. Their main duty is to manage user identification and authorization proce dures so that users’ wallets may be accessed easily and securely. They are crucial infacilitating user logins and giving the system the required user addresses for iden tification and transactional purposes because they are the gatekeepers to the wallet API.", "label": "human"}
{"ID": "00280077", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Main Flow a, User login Users are effortlessly steered through a user-centric login procedure once theyarrive at the decentralized video-sharing platform’s main screen, improving secu rity and access management. Owallet, a blockchain-based wallet renowned for its strong security and user-friendly design, is required to be used as part of the loginprocess. By utilizing Owallet to enable secure user identification, the platform em braces the decentralized ethos and makes sure that only authorized users may take part in the thriving video-sharing community.", "label": "human"}
{"ID": "00280078", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The Owallet login method is simple for users who already have an account. They are prompted to enter their Owallet credentials after choosing the \"Login\" option, which are then securely transmitted to Owallet’s servers for validation. Users aregiven access to the platform’s wealth of features and personalized content recom mendations after properly authenticating.", "label": "human"}
{"ID": "00280079", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "However, the platform asks users to start a short and simple account setup pro cess if they do not already have an Owallet account or have not downloaded the Owallet app. Users are guided through the Owallet download and account creationprocess with an easy-to-use interface, ensuring a smooth entry into the decentral ized video sharing world. Users may confidently create their accounts with Owallet because of its reputation as a trustworthy and secure blockchain wallet, knowing that their digital assets and personal information are protected.", "label": "human"}
{"ID": "00280080", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "User search videoUsers can look for particular videos on the decentralized video-sharing plat form. A smart contract receives the request from the system and quickly locatesvideos that satisfy the search criteria. The smart contract collects pertinent videocontent using blockchain technology and provides it to the consumer. By ensur ing accurate and objective recommendations, this approach gives users access to tailored content discovery experiences.", "label": "human"}
{"ID": "00280081", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "User upload video Users must enter at least a title for the video and the video itself in order to start the upload process, which gives them the opportunity to include a succinct description that summarizes their content. In addition to streamlining the upload procedure, this modest criterion encourages users to present their movies succinctly and interestingly, improving the overall user experience.", "label": "human"}
{"ID": "00280082", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The platform effectively processes the video file after starting the upload, tak ing into account both its size and the user’s available bandwidth. Smaller videosmight be uploaded in a matter of seconds, giving users a smooth and nearly imme diate experience. The upload process could take hours, though, for larger videos or situations where the user’s internet is constrained.", "label": "human"}
{"ID": "00280083", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "User watch video When a user chooses a video to view, the platform immediately gets to work, deftly exploring the on world to find the requested content. Utilizing Eueno’s powerful capabilities, the platform interacts with the decentralized storage system without a hitch, reliably and efficiently obtaining the selected video.", "label": "human"}
{"ID": "00280084", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "A trustworthy repository, Eueno, known for its scalability and security, houses a variety of intriguing movies from content producers all around the world. Theplatform’s interaction with Eueno illustrates the fundamentals of decentralized co operation while showing the seamless interplay of cutting-edge technologies.", "label": "human"}
{"ID": "00280085", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The system shows the viewer the chosen film and immerses them in an engaging viewing experience with a user-friendly interface that promotes intuitive design.3.3 Functional Overview 3.3.1 General use case diagram Figure 3.2: General Use Case Diagram A thorough visual representation of the major use case is shown in Figure 3.2, with an emphasis on the core flow covered in section 3.2.2. The major player in the use case diagram is the user, who stands in for the main ways that users interact with the decentralized video-sharing platform. Later sections will elaborate on the employment of additional actors to represent other user roles and functionalities, ensuring a complete and in-depth understanding of the platform’s operation.", "label": "human"}
{"ID": "00280086", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The introduction of additional actors like Eueno Provider and Owaller Providerwill be covered in detail in the sections that follow. The inclusion of these players in later sections will provide readers a more thorough knowledge of how the platform functions internally and the teamwork required to create a flawless and interesting user experience.", "label": "human"}
{"ID": "00280087", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Use Case Login Specification Usecase Id UC1 Usecase name Login Actor User, Owallet Provider Precondition None Postcondition None Main flowStep By Action 1 User Click connect wallet 2 System Send request to enable Owallet 3 Owallet Provider Render login form 4 User Enter credentials 5 Owallet Provider Authenticate 6 System Redirect user to home Alternate flow2a System Show error user hasn’t install Owallet 5a Owallet Provider Show error authenticate failed Table 3.1: Use Case Login Specification.3.4.2 Use Case Watch Video Specification Usecase Id UC2 Usecase name Watch Video Actor User, Eueno Provider Precondition User must have logged in Postcondition None Main flowStep By Action 1 User Click on a video 2 System Query the video from the blockchain 3 System Send request to get video to Eueno 4 Eueno Provider Return video 5 System Render video Alternate flow 2a System Show error can’t find said video Table 3.2: Use Case Watch Video Specification.", "label": "human"}
{"ID": "00280088", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Use Case Upload Video Specification Usecase Id UC3 Usecase name Upload Video Actor User, Owallet Provider Precondition User must have logged in Postcondition None Main flowStep By Action 1 User Click upload video button 2 System Render upload video form 3 User Fill in form 4 User Press upload 5 System Send request to upload video to Eueno 6 Eueno Provider Store video 7 Eueno Provider Return file id 8 System Save video detail to the blockchain 9 System Success notification Alternate flow4a System Show error fill in the required field 6a Eueno Provider Not enough space error 8a System Transaction failed Table 3.3: Use Case Upload Video Specification.3.4.4 Use Case Search Video Specification Usecase Id UC4 Usecase name Search Video Actor User Precondition User must have logged in Postcondition None Main flowStep By Action 1 User Input search title in to search box 2 System Call smart contract to find video 3 System Get list of video match the search title 4 System Render the list on screen Alternate flow 2a System No match found Table 3.4: Use Case Search Video Specification.", "label": "human"}
{"ID": "00280089", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Working EnviromentThe Decentralized Video Sharing Website was built with the goal of provid ing consumers with a seamless and streamd experience across various web browsers. The platform was carefully created and optimized to operate steadily on popular browsers, including, but not limited to, Mozilla Firefox, Microsoft Edge, and Google Chrome.", "label": "human"}
{"ID": "00280090", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "One of the most frequently used browsers, Chrome, has gotten extra attention in order to give consumers a fast and feature-rich experience. Video streaming and interaction are improved because to the platform’s seamless integration withChrome’s cutting-edge capabilities which makes for a more interesting user expe rience.", "label": "human"}
{"ID": "00280091", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Users of Microsoft Edge will also have a faultless experience on the platform because Edge’s integration with Chromium has been tuned for it. Because of this compatibility, Edge users may easily view and engage with video content.", "label": "human"}
{"ID": "00280092", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "For those who favor Mozilla Firefox, the platform follows web best practices and standards, producing a seamless and uniform experience that is compatible with Firefox’s open-source ethos.", "label": "human"}
{"ID": "00280093", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "ScalabilityThe inherent scalability of the Decentralized Video Sharing Website is a funda mental part of its design philosophy. It was meticulously developed to adapt and accommodate the future, dynamic growth of users and operations. The platform’sarchitecture has been painstakingly designed to manage the influx of users andexpanding content repositories without compromising performance or user experi ence in anticipation of the always growing demand for video content and a thriving user base.", "label": "human"}
{"ID": "00280094", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I used cutting-edge technology and industry best practices to accomplish thisscalability, building a solid and elastic architecture that can easily extend both vertically and horizontally. No matter how many users or movies are stored on the plat form, the distributed nature of the platform, supported by blockchain technology and decentralized storage solutions like Eueno, ensures that content distribution and retrieval remain effective and scalable.", "label": "human"}
{"ID": "00280095", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "User FriendlyThe Decentralized Video Sharing Website’s user interface has been carefully de signed to offer users a high degree of convenience, intuitiveness, and engagement, guaranteeing they have an extraordinary experience when navigating the website.", "label": "human"}
{"ID": "00280096", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The interface, which is fundamentally user-centric, embodies a harmonious union of attractive design and smooth functioning. It has been painstakingly designed toaccommodate users with various backgrounds and levels of technological knowl edge.", "label": "human"}
{"ID": "00280097", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "From the minute users arrive at the home screen, it is clear that the platform is committed to simplicity and clarity. Users are welcomed by a straightforward layout that leads them smoothly through the available features and content. Even new users can easily browse, search, and find compelling videos thanks to the site’s user-friendly design, which promotes an initial sense of familiarity and comfort.", "label": "human"}
{"ID": "00280098", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Privacy The end-to-end encryption offered by Eueno has been carefully integrated into the Decentralized Video Sharing Website to maximize user data and asset security.", "label": "human"}
{"ID": "00280099", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The platform adopts a fully decentralized architecture and makes use of Eueno’s powerful encryption capabilities to safeguard all user interactions, video metadata, and private data from the uploading stage through content retrieval.", "label": "human"}
{"ID": "00280100", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Each video’s information and user interactions are securely saved and transported across the blockchain network with Eueno’s cutting-edge end-to-end en cryption, making them resistant to tampering, illegal access, or data manipulation.", "label": "human"}
{"ID": "00280101", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The technology avoids the need for centralized user data storage by adhering toa completely encrypted structure, protecting users’ private information from poten tial data breaches or outside attacks. Users can feel secure knowing that their data is secure since encryption makes sure that only those with the appropriate decryption keys and authorization can access and decipher the encrypted data.With the overall design mention above, in this chapter I will dwell deeper into the design of our website from the interface to the technology used. I will also present some problems that I have met when making this thesis and how I choose to solve them.", "label": "human"}
{"ID": "00280102", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "How a video is stored a, Problem In order to handle the astonishing volume of videos, video-sharing websites must build a strong infrastructure that can handle the ever-increasing stream ofdata from user uploads. Traditional storage systems are being strained by the ex ponential growth in video uploads as consumers actively submit their material to these platforms. To solve this problem, a number of strategies have been developed, each with its own set of benefits and cons.", "label": "human"}
{"ID": "00280103", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "One method that provides the highest level of data resilience and tamper-proofsecurity is to store data directly on the blockchain. However, it has a significant lim itation in that it has little room for big video files. As videos get bigger, it becomes more expensive to split them up into smaller pieces and distribute them throughout the blockchain. For video sharing platforms that value seamless user experiences for both uploading and watching videos, this restriction presents a hurdle.", "label": "human"}
{"ID": "00280104", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The InterPlanetary File System (IPFS), on the other hand, represents a more well-liked substitute and provides a practical answer to the size issue. A distributed file system is used by IPFS to store and retrieve content, making it possible to handle larger video files effectively. The lack of end-to-end encryption inherent in IPFS, however, may expose user data to unwanted access or security breaches.", "label": "human"}
{"ID": "00280105", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Another choice is Webtorrent, which makes use of peer-to-peer technology toenable user-to-user data exchange, reducing the need for centralized storage. Webtorrent and IPFS are similar in several ways, however Webtorrent lacks built-in end to-end encryption, raising similar security issues.", "label": "human"}
{"ID": "00280106", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Data security, scalability, and performance must be carefully balanced in order to navigate the trade-offs among different storage options. The best course of action depends on the unique needs and priorities of each video sharing site.b, Solution After researching, I choose to use Eueno for this project as it enables Web3projects to build large-scale dApps, providing end-to-end encryption, big data stor age, dynamic access control, and easy sharing. Eueno aim to achieve four things:", "label": "human"}
{"ID": "00280107", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "EUENO provides a large storage capacity beyond that of blockchain. Still de centralized – totally – and sharing instantly through a scalable network of data shared between P2P nodes. Each user (permission-ed or permissionless) shares a portion of his storage capacity to complement the decentralization of the network storage and data recovery by design.", "label": "human"}
{"ID": "00280108", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The disadvantage of limited storage on the blockchain leads to EUENO’s solu tion to change the way of storing and broadcasting data to different blockchains.", "label": "human"}
{"ID": "00280109", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "EUENO is chain-agnostic and complements every blockchain in data storage capacity for DApps development. Store at Eueno and stream to all chains with end-to-end data encryption.", "label": "human"}
{"ID": "00280110", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "EUENO encrypts data by default and deploys strong security in each process related to any data. Encryption and decryption are completely on the user side,directly through non-custodial wallet services like OWallet, with a combina tion of AES-GCM symmetric encryption technology and asymmetric Elliptic curve cryptography to ensure security and improve encryption performance.", "label": "human"}
{"ID": "00280111", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Eueno is built based on web-torrent protocol and practically optimized for users to become a hosting node (client browser, computer node) and increase bandwidth when downloading data. Hosting data is done on the client side of each dApp. This ensures the security and ownership of data.", "label": "human"}
{"ID": "00280112", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "How to store the detail of a video a, Problem We used Eueno, a decentralized storage technology, to successfully address the problem of storing the video content itself in Section 4.1.1. The requirement to store extra metadata, such as video titles, descriptions, thumbnails, and categories, alongside the videos, was another crucial difficulty that we ran into as the platform developed. Creating a separate database to hold this information is required bya traditional centralized approach, which runs counter to the idea of a genuinely serverless and decentralized website.", "label": "human"}
{"ID": "00280113", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The decentralized character of our platform would be jeopardized and its fundamental principles would be undermined by storing the video information in a con ventional database. Exploring alternatives to standard databases in order to safelyand effectively store metadata was necessary in order for us to achieve a truly de centralized solution.", "label": "human"}
{"ID": "00280114", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "However, we ran into problems with query efficiency. Reading every file on Eueno would be necessary to retrieve a video’s details, which would take a lot of time and resources, especially if the platform’s video library grew.", "label": "human"}
{"ID": "00280115", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "We started a thorough investigation of alternative remedies to address this issue in order to achieve a balance between decentralization, data efficiency, and query performance. Our objective was to come up with a simple solution that upheld the decentralization ideals while preserving the responsiveness and scalability of the platform.", "label": "human"}
{"ID": "00280116", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "SolutionAfter days of thorough investigation, I came up with a straightforward but in credibly efficient method for storing video metadata: using the blockchain. The blockchain’s inherent immutability makes it the perfect choice for securely and openly capturing and archiving video data. As explained in Section 2.2, I used thepower of smart contracts, a ground-breaking technology that enables code execu tion on the blockchain, to accomplish this strategy.", "label": "human"}
{"ID": "00280117", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "A robust and decentralized database was created by designating video as an entity within the smart contract and implementing it onto the blockchain. The decentralized video storage solution offered by Eueno and the demand for quick metadata search and retrieval are connected via the smart contract. By enabling this interface, I have replicated the capabilities of a conventional database while upholding the decentralization principles, allowing easy and transparent access to video details.", "label": "human"}
{"ID": "00280118", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The smart contract functions as a distrustless middleman, offering a user inter face for video data querying without the requirement for a central database. Theblockchain ensures the integrity and permanence of each video’s metadata, pro tecting it from any data manipulation or tampering. I have used smart contract technology to turn the blockchain into an immutable repository for video data, en-abling quick access to information similar to a traditional database.", "label": "human"}
{"ID": "00280119", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In addition to enhancing Eueno’s decentralized storage capabilities, the use of smart contracts for video metadata management also opens up a wide range ofpossibilities for improved transparency, security, and trust within the video shar ing platform. Users’ interactions with the platform are securely recorded on the blockchain as they happen, leaving a permanent and unchangeable record of user interactions and content contributions.", "label": "human"}
{"ID": "00280120", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Additionally, the implementation of smart contracts perfectly complements theplatform’s overarching decentralization and data sovereignty philosophy. By incor porating this technology, I have given consumers full ownership and control over their video information, fostering a sense of pride and trust among platform users.", "label": "human"}
{"ID": "00280121", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "How to efficiently query the blockchain a, ProblemThe procedure’ efficiency is one of the primary issues with using smart con tracts to query data. On blockchain platforms like Ethereum, smart contracts are primarily made for processing data updates and carrying out transactions. Despitetheir ability to store data, they may not be as effective at retrieving it as conven tional databases or other types of data storage solutions.", "label": "human"}
{"ID": "00280122", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Executing a smart contract includes interacting with the blockchain network,which calls for consensus among network nodes, transaction verification, and con tract code execution. Data retrieval from smart contracts is comparably slower and more resource-intensive than regular database queries due to the additional delay and overhead introduced by these procedures.", "label": "human"}
{"ID": "00280123", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Executing smart contracts on blockchain networks like Ethereum uses gas, a met ric for the computing effort necessary to complete a transaction. The cost of gas increases with query complexity and with the size of the data being requested. This can make it economically impossible to run complicated queries or query massive datasets.", "label": "human"}
{"ID": "00280124", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Furthermore, network scalability and congestion issues affect smart contracts on open blockchains. The transaction costs may rise and the processing times maylengthen during times of intense network activity. The effectiveness of data retrieval from smart contracts may be further impacted by this, particularly for appli cations that require real-time data or large query rates.b, Solution The difficulty of efficiently requesting data from smart contracts has given rise to products like The Graph (GRT). In order to index, arrange, and efficiently query data from blockchain networks, including data contained in smart contracts, The Graph offers a decentralized protocol and network.", "label": "human"}
{"ID": "00280125", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Developers can use The Graph to establish subgraphs, which function as openAPIs and index and provide data from smart contracts in a well-organized and user friendly way. Due to the fact that they are tailored for particular use cases and data types, these subgraphs offer a more effective and user-friendly way to query data.", "label": "human"}
{"ID": "00280126", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The availability and dependability of data indexing and retrieval are ensured by the decentralized network of Indexers, Curators, and Delegators in the Graph.", "label": "human"}
{"ID": "00280127", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "By staking GRT tokens, curators highlight particular subgraphs as important, en couraging accurate and worthwhile data indexing. Delegators can participate in the network and gain rewards by delegating their GRT tokens to Indexers.", "label": "human"}
{"ID": "00280128", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The Graph makes it quicker, more affordable, and scalable to query data from smart contracts. The decentralized nature of the protocol assures that data is secure and unchangeable, in  with the fundamentals of blockchain technology. The Graph also promotes a dynamic and cooperative ecosystem of data indexers and service providers by using the GRT token as an incentive.", "label": "human"}
{"ID": "00280129", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Now that The Graph has been integrated, developers can more easily obtain datafrom smart contracts and concentrate on creating novel solutions without being hin dered by the difficulties of direct smart contract querying. The protocol simplifies the complexities of interfacing with the blockchain so that programmers can more easily take advantage of the power of decentralized data.4.2 Detailed design 4.2.1 Sequence Diagram a, Login Figure 4.1: Login Sequence Diagram b, Search Video Figure 4.2: Search Video Sequence Diagramc, Watch Video Figure 4.3: Watch Video Sequence Diagramd, Upload Video Figure 4.4: Upload Video Sequence Diagram4.2.2 User interface design a, Welcome Screen Figure 4.5: Welcome Screen When the user arrive at the the website, the user will be greeted with a welcome screen that require the user to connect to their Owallet to continue using the website and actually watch videos.b, Login Popup Figure 4.6: Login popup When clicking the connect wallet button, a popup of Owallet will appear and require the user to input their password to connect to their walletc, Home Screen Figure 4.7: Home Screen After successfully logged in, user will be redirect to the home screen where all the video on our website will be shown. The user can also use the category icon on the side bar to filter out video belongs to a certain category.d, Watch Video Figure 4.8: Watch Video If user choose a video to watch, they will be led to watch video screen where the video will be fetch from Eueno then shown to the user. The user can choose the speed of the video, watch in full screen and get to any part of the video they desire.e, Search Video Figure 4.9: Search Video Screen As shown in figure 4.9, when the user enter the title of the video they want to find, the website will filter out the matched videos and show them on the screen.", "label": "human"}
{"ID": "00280130", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Category Screen Figure 4.10: Category Screen Similar to search video, the website will filter the video arccording to category when user click on the category they like.g, Upload Video Figure 4.11: Upload Video Screen If user click the plus button on home screen, they will be taken to the upload video screen. Here, user will have to fill out the upload video form. In this form, only the title and the video itself is required.4.2.3 Database design Figure 4.12: Video Entity As we have discussed in section 4.1.2, to maintain the serverless property of the project, I choose to use the blockchain as the database and smart contract to query.", "label": "human"}
{"ID": "00280131", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In this project, I only have one entity so save which is the video detail shown in figure 4.12. There are two attribute that need further explaining that is the fileId and thumnailId. When saving theo video on Eueno, that video will be assign an id which is what we use when we request video from Eueno. ThumnailId is similar, it is the file id of the thumnail that get save in Eueno. Another notable thing is that the entity doesn’t have update_at attribute. This is because the blockchain is immutable so we can’t update a record on the blockchain, we can only create a new one.4.2.4 Libraries and Tools Purpose Tool URL IDE Visual Studio Code 1.80.0  Package Manager Node Package Manager 8.5.5  Frontend Framework Nextjs 12.3.0  GraphQL Library @apollo/client 3.6.9,  Eueno API library @eueno/lib-browser 0.1.8  Video Player library plyr-react 5.1.0  Web3 Development Framework Hardhat 2.17.0  Web3 Library ethers 5.7.1  Code Formatter Library eslint 8.23.1  Css Library tailwindcss 3.1.8  Eueno suppliment library @ethereumjs/util 8.1.0  TypeScript bindings for smart contract @typechain/ethers-v5  Promise-based HTTP Client axios 0.27.2  Smart contract testing library chai 4.2.0  Table 4.1: Libraries and Tools4.2.5 Programming Language Language Purpose URL Javascript Code Frontend  TypeScript Code Frontend and smart contract  Html Code Frontend  Css Code Frontend  Solidity Code smart contract  Table 4.2: Programming Language 4.2.6 Achievement The Decentralized Video Sharing Website Using Eueno and Smart Contract isproof of my enthusiasm, commitment, and skill in designing an original and user focused platform. I adopted a proactive and research-driven strategy throughout the development process, carrying out extensive surveys and market assessments to pinpoint the best solutions and address the actual problems encountered by existing video-sharing platforms.", "label": "human"}
{"ID": "00280132", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "My careful selection of solutions, based on my thorough knowledge of the blockchain ecosystem and relevant technology, was one of my major contributions.", "label": "human"}
{"ID": "00280133", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I carefully compared different solutions, taking into account their scalability, se curity, and user-friendss. I was able to give a unified and efficient solution to consumers by utilizing this data-driven decision-making approach to ensure that the platform’s design matched perfectly with the project’s vision.", "label": "human"}
{"ID": "00280134", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I also undertook the challenging task of creating and putting the FrontEnd sys tem into place, using Smart Contracts to communicate with the blockchain network in real-time. This included developing a user-friendly and intuitive interface usingmy expertise in web development, user experience design, and blockchain integra tion. By incorporating Smart Contracts, the platform made sure to take advantage of the decentralized nature of blockchain technology, enabling tamper-proof and transparent transactions.", "label": "human"}
{"ID": "00280135", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Eueno’s integration into the project served as proof of my flexibility and open ness to adopting cutting-edge technologies. Eueno was the best option for handling the platform’s video storage and retrieval because of its reputation for scalabil-ity and security, enabling quick and effective content distribution. I tapped intoEueno’s potential through this integration to build a decentralized, censorshipresistant ecosystem that gave consumers control over their video content and safeguarded their privacy.This chapter presents the testing and evaluation of critical functions in the Decentralized Video Sharing Website, focusing on response speed and overall perfor mance. Then we will look deeper into the result and analyse them.", "label": "human"}
{"ID": "00280136", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "In this section, I will test the response speed of two of the most important func tion in this thesis: upload video and watch video. These request are crucial as they are the backbone of my website and they will also decide the satisfaction of the user when using the website.", "label": "human"}
{"ID": "00280137", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Processor: Intel Core i7-9750H(2.6 GHz) 12 CPU RAM: 20GB It is wise to repeat each test ten times in light of the erratic bandwidth conditions in order to guarantee accurate and trustworthy results. This repeat will lessen the effect that potential network fluctuations may have on the test results and give a more thorough insight of the system’s performance under various circumstances.", "label": "human"}
{"ID": "00280138", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The indeterminacy of the time required to save a record onto the blockchain makes determining the effectiveness of the platform extremely difficult. Before a transaction can be permanently stored on the blockchain and made searchable, it must first undergo verification. The verification procedure requires the dispersed network of nodes coming to a consensus, which can cause variation in the amount of time it takes for a transaction to be confirmed and added to the ledger.", "label": "human"}
{"ID": "00280139", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Upload Video The goal of this extensive testing work is to evaluate the platform’s view video capabilities in a variety of situations. The study team will run tests on not just one, but six different videos, each exhibiting various material and characteristics, to ensure a thorough examination.", "label": "human"}
{"ID": "00280140", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Furthermore, I will use six various video formats, ranging from 100KB to asizeable 2GB, because I recognize the importance of video size in real-world us age circumstances. The researchers may assess the platform’s capacity to managemovies of various sizes by testing throughout this range of sizes, modeling scenar ios that reflect user experiences while gaining access to videos of various quality and length.I have painstakingly developed a trustworthy metric to determine the upload video function’s response time in order to emulate a real-world user experience.", "label": "human"}
{"ID": "00280141", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The amount of time that passes between the user pressing the \"upload video\" but ton and the success notification popup thereafter appearing will be precisely timedand used to calculate the reaction time. This careful method makes sure that the re sponse time accurately reflects the time it actually took for the platform to process and properly upload the video, giving a reliable indication of the effectiveness of the upload function.", "label": "human"}
{"ID": "00280142", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "100KB Average response time: 3.29s Biggest response time: 4.12s Smallest response time: 3.02s b, 10MB Average response time: 10.21s Biggest response time: 13.37s Smallest response time: 9.07s c, 230MB Average response time: 50.72s Biggest response time: 1m5s Smallest response time: 40.28s d, 512MB Average response time: 1m58s Biggest response time: 2m45s Smallest response time: 1m30s e, 1GB Average response time: 5m36s Biggest response time: 7m02s Smallest response time: 4m44s f, 2GB Average response time: 12m12s Biggest response time: 14m03s•Smallest response time: 11m54s I noticed something important about the upload video function’s response time compared to the watch video function throughout the thorough evaluation process.", "label": "human"}
{"ID": "00280143", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "As was to be expected, the uploading of a video took noticeably longer as the file size increased. This observation is consistent with the inherent difficulties in managing and processing bigger video files, which call for more time and resources for successful uploads.", "label": "human"}
{"ID": "00280144", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Watch videoI will continue to use the six previously chosen videos in this extensive analy sis to evaluate the platform’s upload video feature in great detail. I can guarantee consistency and comparability between test results by using the same collection of movies, which enables a thorough evaluation of the platform’s effectiveness in many facets of its video-sharing capabilities.", "label": "human"}
{"ID": "00280145", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I have carefully selected a trustworthy statistic in light of the complexities in volved in determining response time for video playing. The accurate measurement of the time elapsed between the user starting video playing and the point at which the watch video page has fully loaded will be used to determine the reaction time.", "label": "human"}
{"ID": "00280146", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "This careful technique makes sure that the reaction time accurately reflects the time it takes for the video to start playing, rather than just the time it takes for the page to load.", "label": "human"}
{"ID": "00280147", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "100KB Average response time: 0.75s Biggest response time: 0.89s Smallest response time: 0.61s b, 10MB Average response time: 2m1s Biggest response time: 2m15s Smallest response time: 1m45s c, 230MB Average response time: 5m23s Biggest response time: 5m59s Smallest response time: 4m55sd, 512MB Average response time: 10m15s Biggest response time: 11m12s Smallest response time: 9m58s e, 1GB Average response time: 23m46s Biggest response time: 25m56s Smallest response time: 20m45s f, 2GB Average response time: 49m35s Biggest response time: 52m43s Smallest response time: 47m12s The fundamental nature of decentralization can be blamed for the prolongedloading times for video content on our decentralized video sharing platform. Decentralization creates special difficulties in data distribution and retrieval, but pro viding unmatched advantages in terms of data ownership, security, and resistance to censorship. Each video in our system is dispersed throughout a network of nodes, combined from many sources, and its component portions arrive at random and asynchronous times.", "label": "human"}
{"ID": "00280148", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Users can access video content from a variety of sources thanks to this decen tralized method of video distribution, which guarantees the absence of a single point of failure. However, before the film can be played seamlessly, all of the video portions must be downloaded and integrated. As a result, loading times may be longer than on centralized video streaming services that use centralized content servers and optimal delivery systems.", "label": "human"}
{"ID": "00280149", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I reach wise conclusions about the platform’s overall performance based on thethorough testing and analysis done on the platform’s video-watching and video upload functions.", "label": "human"}
{"ID": "00280150", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The longer loading times for videos on our decentralized platform are inherent to decentralization’s nature. Videos are combined from multiple sources, ar riving asynchronously and randomly, necessitating complete downloading before playback. The video-upload feature, on the other hand, demonstrated excellentresiliency and dependability. Response times rose proportionally with video size as was to be expected, reflecting the difficulties in processing bigger video files.", "label": "human"}
{"ID": "00280151", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The response times, however, consistently stayed within an acceptable range. This shows that the platform effectively manages video uploads, ensuring that content creators may distribute their work seamlessly with the least amount of lag time.", "label": "human"}
{"ID": "00280152", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Overall, the platform performs admirably in both the watching and uploading ofvideos. Its emphasis to user pleasure is highlighted by its commitment to low la tency, rapid response times, and seamless content delivery. The platform performs exceptionally well, making it a powerful competitor in the video-sharing marketbecause to its use of decentralized technology, blockchain integration, and effec tive content distribution systems.", "label": "human"}
{"ID": "00280153", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "These results offer insightful information for future improvement and optimiza tion. The platform may capitalize on its advantages to improve its offerings andconsistently cater to the changing demands of its user base. The platform can main tain its position as the top option for content producers and viewers looking for adependable, censorship-resistant, and pleasant video-sharing platform by prioritiz ing user experience and utilizing the data-driven feedback.", "label": "human"}
{"ID": "00280154", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The platform’s dedication to excellence and ongoing development will assure its relevance and longevity in a cutthroat market for digital content as technology and user expectations continue to advance. If the platform embraces innovation and user-centric design, it can continue to draw a lively community of creators and viewers, building a thriving ecosystem where diverse content thrives and user experiences are continuously top-notch.This chapter, which summarizes the process of creating the Decentralized VideoSharing Website, acts as the thesis’s conclusion. It draws attention to the plat form’s emphasis on user privacy, security, and autonomy, which is made possibleby blockchain technology and Eueno’s end-to-end encryption. The chapter exam ines the knowledge gained, the technical skills mastered, and the value of user input and teamwork. Additionally, it addresses potential improvements, such as a personalized recommendation system and token-based incentivization. The chapterheralds the start of a revolutionary project with the intention of improving decen tralized video sharing.", "label": "human"}
{"ID": "00280155", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The domination of video content has developed as a potent tool for communi cation, education, and entertainment in the constantly changing digital ecosystem.", "label": "human"}
{"ID": "00280156", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Video has become a crucial part of on experiences as a result of the grow ing use of high-speed internet and the pervasiveness of smartphones. However, asthe popularity of user-generated material increased, centralized video-sharing plat forms came under fire for their censorship and information control, raising worries about the suppression of free speech and different viewpoints.", "label": "human"}
{"ID": "00280157", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I started the challenging project of creating a decentralized video-sharing web site in order to solve these issues and promote a culture that cherishes freedom of expression. This platform aims to give users and artists a place where they can share, upload, and view a wide variety of movies without worrying about beingarbitrarily removed or having their material restricted. The website aspires to empower content producers and viewers by utilizing decentralized technologies, giving them control over their content and promoting the expression of multiple opin ions.", "label": "human"}
{"ID": "00280158", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I made the decision to use Eueno for website storage in my effort to build a de pendable and secure infrastructure. The platform’s flexibility to scale and its strong security features, which protect user data while handling an increasing volume of video uploads, proved to be essential. Adopting a decentralized storage solution improves platform resilience while also adhering to the fundamental ideas of data privacy and security.", "label": "human"}
{"ID": "00280159", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I also looked at the field of smart contracts as a novel way to strengthen theplatform’s decentralized character. With the help of smart contracts, I made surethat some of the video content would be safely kept on the blockchain, increas ing transparency and offering unchangeable proof of who owns what data. This novel strategy increases user confidence and reassures content creators that their intellectual property rights are safeguarded.", "label": "human"}
{"ID": "00280160", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I’ve run across a lot of obstacles while creating the website, but also had somegreat opportunity to learn. I was a student who found myself bridging the gap between academic study and real-world application by putting the theoretical knowledge I had learned in university courses to a project. I explored lesser-known li braries and tools in addition to more common ones, broadening my skill set and capacity for problem-solving.", "label": "human"}
{"ID": "00280161", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Eueno’s pick served as an example of why certain choices aren’t always the most popular choice for a given endeavor. By experimenting with various methods, I came to understand the value of thoughtful analysis and specialized decisions when creating complicated systems.", "label": "human"}
{"ID": "00280162", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Deploying smart contracts requires understanding the complexities of blockchaintechnology, which posed another steep learning curve. By overcoming these obsta cles, I was able to boost my proficiency with complicated tools and methods and gain knowledge that would be useful on future projects.", "label": "human"}
{"ID": "00280163", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "Without a doubt, each step of this journey has increased my knowledge and abilities and given me a deeper appreciation for decentralized technologies and how they are used in the real world. These newly discovered skills will surely come in handy for my future development projects and help me succeed in the industry.", "label": "human"}
{"ID": "00280164", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The knowledge acquired while creating this decentralized video-sharing plat form is proof of the value of experimentation and hands-on learning. As my career develops, I am optimistic that the information and abilities I have gained will helpme advance, enabling me to spur creativity, develop worthwhile projects, and advance both technology and society as a whole. I am excited to take on new chal lenges and continue my path of lifelong learning and development.", "label": "human"}
{"ID": "00280165", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "It is clear that there are exciting opportunities for additional development andexpansion to elevate the platform’s capabilities and user involvement as the De centralized Video Sharing Website using Eueno and Smart Contract approaches acritical stage. The use of a token-based incentive system is one of the main enhanc ing tactics. The platform can transform the world of content sharing by introducing a native token, encouraging users to post material more regularly and developing avibrant and engaged community.", "label": "human"}
{"ID": "00280166", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "By encouraging content creators to contribute frequently and rewarding them for their significant efforts, the token-based incentive mechanism has the potential to completely alter the dynamics of the platform. This strategy is completely in with the decentralization tenets, according to which users are crucial in determin ing the success and growth of a platform. The inherent worth of the token can be correlated with a number of variables, including the popularity of the content, user engagement, and community involvement. Content producers will be encouraged to share their creativity and knowledge more frequently if they can earn tokens for posting entertaining and high-quality videos, creating a thriving and constantly changing video-sharing ecosystem.", "label": "human"}
{"ID": "00280167", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "The creation of a sophisticated website recommendation algorithm representsanother interesting area for progress. The ability to offer tailored content suggestions becomes increasingly important as the video collection expands for improv ing user experiences and encouraging content discovery. A robust recommendation system can take the platform’s user engagement and happiness to a new level.", "label": "human"}
{"ID": "00280168", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "To comprehend user preferences, habits, and interests, the recommendation sys tem might make use of machine learning techniques and data analysis. The system may automatically adapt content recommendations to each user’s preferences byexamining user interactions, viewing history, and feedback. This degree of per sonalisation allows users to explore and discover new content that matches theirinterests, keeping them interested in the platform and establishing a sense of be longing.", "label": "human"}
{"ID": "00280169", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "By encouraging content variety, the recommendation algorithm can also help build a welcoming and inclusive community. The platform may highlight creativity and innovation by exhibiting a variety of viewpoints and genres, drawing in a varied audience and promoting an environment of open expression and inclusivity.", "label": "human"}
{"ID": "00280170", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "As I complete my Decentralized Video Sharing Website Using Eueno and Smart Contract thesis, I take stock of the enormous amount of learning that has gone into it. I struggled with the limits brought on by time restraints and my own degree of skill throughout the creation process. I firmly believe that this project is a stepping stone to larger successes and advancement in my development career, even though the website’s current status may fall short of my early aspirations.", "label": "human"}
{"ID": "00280171", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "I am humbled by the chance to get advice from seasoned mentors, even as I anxiously anticipate the lecturers’ comments and observations. Their assistancewill not only enable me to finish this assignment but also help me gain additionalworthwhile experience for ongoing professional growth. Their knowledge and ex perience will be a priceless advantage, influencing how I develop as a developerand pointing me in the direction of professional excellence. S. Nakamoto, Bitcoin: A peer-to-peer electronic cash system . [On]. Avail able: (visited on 06/10/2023).", "label": "human"}
{"ID": "00280172", "file_name": "Decentralized Video Sharing Website Using Eueno and Smart Contract", "content": "V. Buterin and G. Wood, Ethereum: A next-generation smart contract and de centralized application platform . [On]. Available:  org/whitepaper/ (visited on 06/10/2023).", "label": "human"}
{"ID": "00290001", "file_name": "Building a social media application for sharing image and video", "content": "The 21st century is considered as the development era of information technol ogy (IT). Along with the globalization process, the explosion of smart electronic devices such as tablets and smartphones, the participation of individuals on thenetwork is increasingly active, leading to the need to share information, connect ing with friends is a necessary need to promote the birth and development of social networks. Today, with just a smartphone device connected to the internet, users can exchange and contact anyone anywhere through social networks.", "label": "human"}
{"ID": "00290002", "file_name": "Building a social media application for sharing image and video", "content": "Social networks develop widely and prove their attraction and role in most as pects of social life from information exchange, learning, entertainment to business and commerce. appear and take place easily through social networks. It can be said that social networks have really become close and popular, or even have become an indispensable part of today’s modern society.", "label": "human"}
{"ID": "00290003", "file_name": "Building a social media application for sharing image and video", "content": "According to statistics by April 2023  of NapoleonCat (a tool to measure social network indicators), the total number of Facebook social network users in Vietnam is nearly 85 million people, accounting for more than 83% of the country population, an increase of 30 million users compared to 2019 . Instagram social network with nearly 11 million people (June 2021), of which the audience is mainly young people, the age group 18-24 accounts for more than 30% of the total. In addition, it is impossible not to mention social networks with a huge number of users such as TikTok, Twitter, Telegram, etc.", "label": "human"}
{"ID": "00290004", "file_name": "Building a social media application for sharing image and video", "content": "With the number of users of social networks as above, Vietnam is currently ranked 7th in the number of social network users in the world. On average, young Vietnamese users spend about 7 hours per day using social networks. Photos andvideos are highly preferred content types because they are highly interactive, enter taining, and intuitive. Thus, I decided to choose the topic \"Building a social media application for sharing image and video\" for the thesis.", "label": "human"}
{"ID": "00290005", "file_name": "Building a social media application for sharing image and video", "content": "The objectives and scope of the project are to design and build a social network that can run on the web platform, meeting the basic functions of users such as posting images and videos, following other users, and interacting with other users through functions such as messaging, commenting on posts, on calling, and video calling. Users can also edit personal profiles, and manage posts.1.3 Tentative solution To accomplish the objectives stated in the above section, I choose to create a webapp that user can access from anywhere with the internet. To help building such an app, I choose the MVC as the main architecture. The webapp will be built with single page application architecture in the frontend to give user a better experience while using the app. The backend will be hosted on a serverless cloud to enable seamlessly scaling. To enable realtime communication features, I choose some very popular solutions such as SocketIO and WebRTC.", "label": "human"}
{"ID": "00290006", "file_name": "Building a social media application for sharing image and video", "content": "Chapter 2 focuses on the system requirements analysis. In the chapter, I analyze the functional and non-functional requirements of the app. The use cases of the app will also be provided.", "label": "human"}
{"ID": "00290007", "file_name": "Building a social media application for sharing image and video", "content": "In chapter 3, I will go into the technologies used to build the app, and how that technology is used to solve the functional requirements stated in chapter 2.", "label": "human"}
{"ID": "00290008", "file_name": "Building a social media application for sharing image and video", "content": "In chapter 4, the architecture of the app will be introduced. It consists of the interface design, the package design, the class design and the database design. It will also include the testing of the app, the data flow of some important use case and the installation of such a system.", "label": "human"}
{"ID": "00290009", "file_name": "Building a social media application for sharing image and video", "content": "In the last chapter, I will give the conclusion about the thesis: what has been done and what not, what can be improved, difficulties I faced while building the app, and how I overcame them. I will also give future develop orientation for the application.2.1 Functional Overview 2.1.1 General use case diagram The figure 2.1 shows the general use case of the application.", "label": "human"}
{"ID": "00290010", "file_name": "Building a social media application for sharing image and video", "content": "The application has three actors. User is the main actor of the application. Guest is the actor that is not in the database, and they can signup to become a User. There is one Admin actor in the application, and they can see and manage all the User accounts in the system.", "label": "human"}
{"ID": "00290011", "file_name": "Building a social media application for sharing image and video", "content": "Extends UserGuestSignupSocial Media Manage postsManage comments in a post Edit personal infoFollow/Unfollow other users Search for other usersGet suggestion about other usersGet suggestion about other usersSee oher users's profileLogin LogoutManage users Admin Figure 2.1: General use case diagram2.1.2 Use case detail: Manage posts The figure 2.2 shows the detailed use case of Manage posts diagram. User can create post, edit and delete their posts, and interact with posts from other users.", "label": "human"}
{"ID": "00290012", "file_name": "Building a social media application for sharing image and video", "content": "UserSee list of posts from following users Discover posts Create post Edit postDelete post See post details Save post Like/Unlike post Figure 2.2: Use case detail: Manage posts diagram 2.1.3 Use case detail: Manage comments in a postThe figure 2.3 shows the detailed use case of Manage comments in a post di agram. User can create post, edit and delete their comments, and interact with comments from other users.", "label": "human"}
{"ID": "00290013", "file_name": "Building a social media application for sharing image and video", "content": "UserSee list of comments in a post Comment a post Edit commentDelete comment Like/Unlike comment Reply to comment Figure 2.3: Use case detail: Manage comments in a post diagram2.1.4 Use case detail: Message other users The figure 2.4 shows the detailed use case of Message other users diagram.", "label": "human"}
{"ID": "00290014", "file_name": "Building a social media application for sharing image and video", "content": "User Other userOnline call Send text, image and video messages Video call Figure 2.4: Use case detail: Message other users diagram 2.1.5 Use case detail: Manage users The figure 2.5 shows the detailed use case of Manage users diagram. These use cases are for the Admin actor only.", "label": "human"}
{"ID": "00290015", "file_name": "Building a social media application for sharing image and video", "content": "This app is for most of users to use, so the interface needs to be easy to be clean, intuitive, modern and encourages users to interact. In addition, it is also necessary to adhere to basic design principles, easy navigation. In addition, the interface has responsive support, and is suitable for variety of screen sizes on different devices.", "label": "human"}
{"ID": "00290016", "file_name": "Building a social media application for sharing image and video", "content": "The system must be deployed in an on environment, has a domain name that can be easily accessed on a browser, and an SSL certificate for the website.", "label": "human"}
{"ID": "00290017", "file_name": "Building a social media application for sharing image and video", "content": "Security requirement User passwords hashed with SHA-256 as of 2023 are secure enough and can be used to store passwords in a database. Since this hash is one-way, it can only be used to compare user-entered passwords, if the password information in the database is exposed, this information only contains the hashed value, so users’spasswords are safe.", "label": "human"}
{"ID": "00290018", "file_name": "Building a social media application for sharing image and video", "content": "The system implements JWT (JSON Web Token) for each user login. JWT token constructed of1. The header contains information about the token format, the signing algo rithm, and the base64 encoded header 2. Payload is any data container, usually used to store publicly identifiable user information in the form of JSON, the payload is base64 encoded.", "label": "human"}
{"ID": "00290019", "file_name": "Building a social media application for sharing image and video", "content": "Signature is an encrypted string. It is signed on the header and payload of the token by the encryption algorithm specified on the header (usually SHA-256 or RS256). Signature is the part that ensures the JWT is not changed over the network, this part is signed from a combination of header, payload and a secret string located on the server side.", "label": "human"}
{"ID": "00290020", "file_name": "Building a social media application for sharing image and video", "content": "So only valid tokens will be validated and processed, and tokens that are randomly generated or have changed payload, header after signing will create a differ ent signature than before. In addition, people often add expiredAt information to the token to check if the token has expired or not 2.3.2 Performance requirementThe application must not be too heavy, do not consume too much CPU re sources, meet the needs of many users. Response time and data retrieval time must be not too long. Ideally, the response time of all requests is less than 2s 2.3.3 Extensibility requirementThe source code needs to be clean, clear. Furthermore, it needs to follow a cer tain coding convention. This is necessary to make the source code easy to read and follow, from which it is easy to add features, limit errors, and fix errors when the system has problems. Some common rules like writing separate functions into small functions, each function only performing a single task, encapsulating them into a class module to inherit and use in other classes.3.1 ReactJS Figure 3.1: ReacJS Logo  ReactJS is a declarative, efficient, and flexible JavaScript library for building reusable UI components. It is an open-source, component-based front end library responsible only for the view layer of the application. It was created by Jordan Walke, who was a software engineer at Facebook. It was initially developed andmaintained by Facebook and was later used in its products like WhatsApp & In stagram. Facebook developed ReactJS in 2011 in its newsfeed section, but it was released to the public in the month of May 2013.", "label": "human"}
{"ID": "00290021", "file_name": "Building a social media application for sharing image and video", "content": "Today, most of the websites are built using MVC (model view controller) archi tecture. In MVC architecture, React is the ’V’ which stands for view, whereas the architecture is provided by the Redux or Flux.", "label": "human"}
{"ID": "00290022", "file_name": "Building a social media application for sharing image and video", "content": "A ReactJS application is made up of multiple components, each component responsible for outputting a small, reusable piece of HTML code. The components are the heart of all React applications. These Components can be nested with other components to allow complex applications to be built of simple building blocks.", "label": "human"}
{"ID": "00290023", "file_name": "Building a social media application for sharing image and video", "content": "ReactJS uses virtual DOM based mechanism to fill data in HTML DOM. The virtual DOM works fast as it only changes individual DOM elements instead of reloading complete DOM every time.", "label": "human"}
{"ID": "00290024", "file_name": "Building a social media application for sharing image and video", "content": "React uses Redux for building the user interface. It was first introduced by Dan Abramov and Andrew Clark in 2015.", "label": "human"}
{"ID": "00290025", "file_name": "Building a social media application for sharing image and video", "content": "React Redux is the official React binding for Redux. It allows React components to read data from a Redux Store, and dispatch Actions to the Store to update data.", "label": "human"}
{"ID": "00290026", "file_name": "Building a social media application for sharing image and video", "content": "Redux helps apps to scale by providing a sensible way to manage state through a unidirectional data flow model. React Redux is conceptually simple. It subscribes to the Redux store, checks to see if the data which your component wants have changed, and re-renders your component.", "label": "human"}
{"ID": "00290027", "file_name": "Building a social media application for sharing image and video", "content": "With a lot of interaction in the application frontend, application states could get convoluted if not handle correctly. To address the issue, I use Redux as the state management library in the frontend.", "label": "human"}
{"ID": "00290028", "file_name": "Building a social media application for sharing image and video", "content": "Bootstrap is an HTML, CSS and JS library that focuses on simplifying the de velopment of informative web pages (as opposed to web applications). The primary purpose of adding it to a web project is to apply Bootstrap’s choices of color, size,font and layout to that project. As such, the primary factor is whether the develop ers in charge find those choices to their liking. Once added to a project, BootstrapFigure 3.3: Bootstrap Logo  provides basic style definitions for all HTML elements. The result is a uniform appearance for prose, tables and form elements across web browsers. In addition,developers can take advantage of CSS classes defined in Bootstrap to further cus tomize the appearance of their contents. For example, Bootstrap has provisioned for light- and dark-colored tables, page headings, more prominent pull quotes, and text with a highlight.", "label": "human"}
{"ID": "00290029", "file_name": "Building a social media application for sharing image and video", "content": "Bootstrap also comes with several JavaScript components which do not require other libraries like jQuery. They provide additional user interface elements such as dialog boxes, tooltips, progress bars, navigation drop-downs, and carousels. Each Bootstrap component consists of an HTML structure, CSS declarations, and in some cases accompanying JavaScript code. They also extend the functionality of some existing interface elements, including for example an auto-complete function for input fields.", "label": "human"}
{"ID": "00290030", "file_name": "Building a social media application for sharing image and video", "content": "In the application frontend, I use Bootstrap as the UI library to create and style most of the React components.", "label": "human"}
{"ID": "00290031", "file_name": "Building a social media application for sharing image and video", "content": "Node.js is a cross-platform, open-source server environment that can run onWindows, Linux, Unix, macOS, and more. Node.js is a back-end JavaScript run time environment, runs on the V8 JavaScript Engine, and executes JavaScript code outside a web browser.", "label": "human"}
{"ID": "00290032", "file_name": "Building a social media application for sharing image and video", "content": "Node.js lets developers use JavaScript to write command  tools and for server-side scripting. The ability to run JavaScript code on the server is often used to generate dynamic web page content before the page is sent to the user’s web browser. Consequently, Node.js represents a \"JavaScript everywhere\" paradigm, unifying web-application development around a single programming language, as opposed to using different languages for the server- versus client-side program-Figure 3.4: NodeJS and ExpressJS Logo  ming.", "label": "human"}
{"ID": "00290033", "file_name": "Building a social media application for sharing image and video", "content": "To faster develop a NodeJS server, I use the ExpressJS framework. Express.js, or simply Express, is a back end web application framework for building RESTfulAPIs with Node.js, released as free and open-source software under the MIT Li cense. It is designed for building web applications and APIs. It has been called the de facto standard server framework for Node.js. Express is a minimal and flexible Node.js web application framework that provides a robust set of features for web and mobile applications.", "label": "human"}
{"ID": "00290034", "file_name": "Building a social media application for sharing image and video", "content": "Socket.IO primarily uses the WebSocket protocol with polling as a fallback option, while providing the same interface. Although it can be used simply as a wrapper for WebSockets, it provides many more features, including broadcasting to multiple sockets, storing data associated with each client, and asynchronous I/O.", "label": "human"}
{"ID": "00290035", "file_name": "Building a social media application for sharing image and video", "content": "Socket.IO provides the ability to implement real-time analytics, binary streaming, instant messaging, and document collaboration. Notable users include Microsoft Office, Yammer and Zendesk. Socket.IO handles the connection transpar ently and will automatically upgrade to WebSocket if possible. This means that the developer does not need to know how to use the WebSocket protocol in order to use Socket.IO.", "label": "human"}
{"ID": "00290036", "file_name": "Building a social media application for sharing image and video", "content": "PeerJS is a WebRTC framework that abstracts away all of the ice and signallinglogic so that you can focus on the functionality of your application. PeerJS simpli fies WebRTC peer-to-peer data, video, and audio calls. PeerJS wraps the browser’s WebRTC implementation to provide a complete, configurable, and easy-to-use peer-to-peer connection API. Equipped with nothing but an ID, a peer can create aP2P data or media stream connection to a remote peer.", "label": "human"}
{"ID": "00290037", "file_name": "Building a social media application for sharing image and video", "content": "MongoDB is used for high-volume data storage, helping organizations storelarge amounts of data while still performing rapidly. Organizations also use Mon goDB for its ad-hoc queries, indexing, load balancing, aggregation, server-side JavaScript execution and other features.", "label": "human"}
{"ID": "00290038", "file_name": "Building a social media application for sharing image and video", "content": "In the application, I use Cloudinary as the CDN for fast accessing the static content like images and videos, which the application is expected to have a lot.", "label": "human"}
{"ID": "00290039", "file_name": "Building a social media application for sharing image and video", "content": "It is actually an enhanced version of ’Borg’ for managing the long-running pro cesses and batch jobs. Nowadays, many cloud services offer a Kubernetes-based infrastructure on which it can be deployed as the platform-providing service. This technique or concept works with many container tools, like docker, and follows the client-server architecture.", "label": "human"}
{"ID": "00290040", "file_name": "Building a social media application for sharing image and video", "content": "Google Cloud Platform (GCP) is a suite of cloud computing services providedby Google. It is a public cloud computing platform consisting of a variety of ser vices like compute, storage, networking, application development, Big Data, and more, which run on the same cloud infrastructure that Google uses internally forFigure 3.10: Google Cloud Logo  its end-user products, such as Google Search, Photos, Gmail and YouTube, etc.", "label": "human"}
{"ID": "00290041", "file_name": "Building a social media application for sharing image and video", "content": "The services of GCP can be accessed by software developers, cloud administrators and IT professionals over the Internet or through a dedicated network connec tion.", "label": "human"}
{"ID": "00290042", "file_name": "Building a social media application for sharing image and video", "content": "Google Kubernetes Engine (GKE), which is a management and orchestration system for Docker container and container clusters that run within Google’s public cloud services. Google Kubernetes Engine is based on Kubernetes, Google’s open source container management system.", "label": "human"}
{"ID": "00290043", "file_name": "Building a social media application for sharing image and video", "content": "I use Google Cloud as the hosting platform for the application. I also use their Google Kubernetes Engine (GKE), to help quicky deploying a kubernetes cluster.", "label": "human"}
{"ID": "00290044", "file_name": "Building a social media application for sharing image and video", "content": "I used JMeter to perfomance testing the deployed application website.4.1 Architecture design 4.1.1 Software architecture selectionFor this app, we use the Model-View-Controller (MVC) which separates an application into three main logical components: the model, the view, and the con troller. Each of these components are built to handle specific development aspects of an application. MVC is one of the most frequently used industry-standard web development architecture to create scalable and extensible projects.", "label": "human"}
{"ID": "00290045", "file_name": "Building a social media application for sharing image and video", "content": "The View component is used for all the UI logic of the application. For ex ample, the Customer view will include all the UI components such as text boxes, dropdowns, etc. that the final user interacts with.", "label": "human"}
{"ID": "00290046", "file_name": "Building a social media application for sharing image and video", "content": "Controllers act as an interface between Model and View components to process all the business logic and incoming requests, manipulate data using the Model component and interact with the Views to render the final output. For example, the Customer controller will handle all the interactions and inputs from the Post View and update the database using the Post Model. The same controller will be used toview the Post data.", "label": "human"}
{"ID": "00290047", "file_name": "Building a social media application for sharing image and video", "content": "The app will be deployed with Kubernetes and hosted in Google Cloud. Using Kubernetes allows the app to scale as it needs. By hosting the app in Google Cloud,we enable the serverless architecture. Serverless computing is a method of provid ing backend services on an as-used basis. A serverless provider allows users towrite and deploy code without the hassle of worrying about the underlying infras tructure. Serverless has many benefits such as: lower costs, simplified scalability, simplified backend code, etc.", "label": "human"}
{"ID": "00290048", "file_name": "Building a social media application for sharing image and video", "content": "Overall design For the MVC architecture design, I used 3 packages: View package, Controllerpackage, Model package. The View package represents the app front end. Con troller package represent the app backend. Model package represents a model in database and we will be working with the databases.", "label": "human"}
{"ID": "00290049", "file_name": "Building a social media application for sharing image and video", "content": "For the realtime communication, we use socket IO in both backend and fron tend (View and Controller package); and WebRTC (by the peer.js library) in the frontend.", "label": "human"}
{"ID": "00290050", "file_name": "Building a social media application for sharing image and video", "content": "Deploying Platform (Kubernetes Google Cloud) View ReactJSSocketIO Client WebRTC (peer .js)Controler NodeJS ExpressJSSocketIO Server MongoDB ORMAPI request API response MongoDB Atlas Model (MongoDB)Cloundinary CDN (images and videos)Request DataStore Data Request Static Image/V ideoStore Static Image/V ideo Figure 4.2: Overall architecture design4.1.3 Detailed package design In this section, I will go through packages, different components in a package:", "label": "human"}
{"ID": "00290051", "file_name": "Building a social media application for sharing image and video", "content": "View Home Page Message Page User Profile Page Post Dicovery PageLogin Page Post Detail Page General-purpose ComponentsPage-specific ComponentsAdmin Page Figure 4.3: Detailed design of view packageFigure 4.3 is the detailed design of View Package. There are two types of sub packages inside the view package. Subpackages with ‘Page‘ as prefix represent a whole seperated page with user can route to. ‘Component‘ subpackages represents the ReactJS components, which is reusable components throught the application.", "label": "human"}
{"ID": "00290052", "file_name": "Building a social media application for sharing image and video", "content": "Post Discovery Page: This page shows all the post from users that current user does not follow User Profile Page: This page displays the detail information about a user.•Message Page: This page displays the chat panel between current user and other user Admin Page: This page will only be displayed to the admin when he/she logins to the application with admin account There are 2 kinds component:", "label": "human"}
{"ID": "00290053", "file_name": "Building a social media application for sharing image and video", "content": "These components will be deeper separated into different folders which name is the page it belongs toGeneral-purpose: These are the reusable component that are used across dif ferent pages in the app. These components will be deeper separated into small and big components, like the header(every page uses) and the model(to display a success or error message) Model Comment Post User NotifyConversation Message Figure 4.4: Detailed design of model package Figure 4.4 is the detailed design of Model Package. We have 4 main models which is User, Post, Comment, Conversation, Message and Notify. Each model is a mapping of an object to a document in the database. Model package also provides an ORM layer to work with the database safely. I will go into each model in detail:", "label": "human"}
{"ID": "00290054", "file_name": "Building a social media application for sharing image and video", "content": "User Model: represent an application user and their detail information Post Model: represent a post a user creates Comment Model: represent a comment in a post and created by a user Conversation Model: represent a conversation between 2 users Message Model: represent a message in a conversation Notify Model: represent a notification to a userController Comment Controller Notify ControllerUser Controller Post ControllerAuth Controller Message ControllerAdmin Controller Figure 4.5: Detailed design of controller package Figure 4.5 is the detailed design of Controller Package. The controller is the bridge between the View and the Model. A Controller provides APIs related to the corresponding Model. It handles any API request sent to the controller and also work with the model and the database. I will go into each controller in detail:", "label": "human"}
{"ID": "00290055", "file_name": "Building a social media application for sharing image and video", "content": "User interface designTo standardize the screen configuration, the app is responsive and should sup port multiple screen sizes. For the best experience, we strongly recommend the screen size 1920x1080 pixels. Number of colors supported: 16,777,216 colors. The main screen will be using the white background to best support readability.", "label": "human"}
{"ID": "00290056", "file_name": "Building a social media application for sharing image and video", "content": "The following figures are some of the screens from the app.Figure 4.6: Interface design of Login screen This is the screen you will see when you first visit the app. Login requires your email address and password. If you don’t have an account, you can go to the next screen to register for one.Figure 4.7: Interface design of Signup screen This is the screen for signing up your account. It asks for some basic user info and then if those info is valid, a new account will be created, and user will be taken to the next screen.Figure 4.8: Interface design of Home screen This is the main screen for user who has logged in. In the home screen, list of posts from user and following people of users are listed. User can interact with those posts by like/unlike, comment, save and share. At the right side, there is a section that list some users that the current user does not follow. The list can be refreshed by click on the loop icon. The header presents for all the pages after user login. In the header, user can search for other users, and navigate between screens.", "label": "human"}
{"ID": "00290057", "file_name": "Building a social media application for sharing image and video", "content": "Click on the heart icon will show all the notifications for the current user. Finally, at this home screen, they can post what they want by click on the top section of the posts list. The popup dialog for user posting is as below.Figure 4.9: Interface design of Create post dialog popup Before posting, user can see all the selected media for their post. They can choose media from their device by click on the image icon, or using the current device’s webcam to capture new image by click on the photograph icon.", "label": "human"}
{"ID": "00290058", "file_name": "Building a social media application for sharing image and video", "content": "In the header navigation bar, next to the notification button, is the button to the discovery page. Below is what the discovery page looks like.", "label": "human"}
{"ID": "00290059", "file_name": "Building a social media application for sharing image and video", "content": "The final button in the header navigation bar, next to the home icon, is the button to the message page. Below is what the message page looks like.", "label": "human"}
{"ID": "00290060", "file_name": "Building a social media application for sharing image and video", "content": "On the header of the conversation details, you can choose to call, video call other user, or delete the current conversation. You can also send text and media message to other user using the input on the bottom of the pages. The message will not be loaded all at one, you can scroll up and the application will load more old messages.", "label": "human"}
{"ID": "00290061", "file_name": "Building a social media application for sharing image and video", "content": "This is the screen when one user on call or video call other user.Figure 4.14: Interface design of Begin call screen When the caller calls, his/her popup dialog will have the option to cancel the call. From the callee’s screen, he/she can choose to cancel or pickup the call. If the callee chooses to pickup the call, then the video call screen will be displayed.", "label": "human"}
{"ID": "00290062", "file_name": "Building a social media application for sharing image and video", "content": "Layer designIn this section, I will describe the detailed design of all the controllers in the ap plication. Controllers handle every requests from user, and also work with objects from database models.", "label": "human"}
{"ID": "00290063", "file_name": "Building a social media application for sharing image and video", "content": "Auth Controller function signupThis function handles the request when user signups. It checks for all the re quired fields, if there is empty required field then it will return error to the client. It then checks for the uniqueness of username and email. The password length must be longer than 6 characters. It then hashes the password, It createsa new User document in the database. After that, it creates new access token and refresh token for the client. The refresh token is stored in the client cookie and will expired after 30 days. The access token is stored in the client local storage and will be expired after 1 day. The access token is required to be sentwith every request from the application. If the access token is expired, the re fresh token will be used to generate new access token. If the refresh token is expired, user must login again.", "label": "human"}
{"ID": "00290064", "file_name": "Building a social media application for sharing image and video", "content": "function login This function handles the login requests. User will send to server the email and password. The server will find the User document in the database and if there is a match, it will compare the hash of the inputed password to the hashed password stored in the found User document. If all good, it then generated the access token and refresh token pair like in the signup function.", "label": "human"}
{"ID": "00290065", "file_name": "Building a social media application for sharing image and video", "content": "function logout This function is called when user clicks logout. The frontend code must clear the access token in the local storage. The backend code will clear the refresh token in the cookie function generateAccessToken This function is called when the user access token is expired. The request sends the refresh token to the server. The server checks for the validation of the token. If the token is valid and has not been expired, then the server will send back an access token to the client.", "label": "human"}
{"ID": "00290066", "file_name": "Building a social media application for sharing image and video", "content": "User Controller function searchUser This function handles the search user request. It will try to return at most 10 results or 10 users from the database based on the inputed keyword and the username of these user.", "label": "human"}
{"ID": "00290067", "file_name": "Building a social media application for sharing image and video", "content": "function getUser This function helps with the user detail information retrieval request. It takes and user_id, find the User document in the database and send back the result if such an user exists function updateUser This function handles the edit personal info request of the user.•function followUser This function handles the request when user click to follow other users. It will then update the following and followers field of respective User document in the database.", "label": "human"}
{"ID": "00290068", "file_name": "Building a social media application for sharing image and video", "content": "function unfollowUser This function handles the request when user click to unfollow other users. It will then update the following and followers field of respective User document in the database.", "label": "human"}
{"ID": "00290069", "file_name": "Building a social media application for sharing image and video", "content": "function suggestUsers This function handles the suggestion users function of the application. It will try to find at most 10 users which the current user is not following.", "label": "human"}
{"ID": "00290070", "file_name": "Building a social media application for sharing image and video", "content": "Post Controller function createPost This function is called when user wants to create a posts. If the text content is empty and there are no uploaded images or videos, then it will return errors.", "label": "human"}
{"ID": "00290071", "file_name": "Building a social media application for sharing image and video", "content": "function getPosts This function returns a list of posts from the users that the current user is following, to be displayed in the current user’s home page. The results is sorted by created timestamp and support pagination.", "label": "human"}
{"ID": "00290072", "file_name": "Building a social media application for sharing image and video", "content": "function getPost This function handles the request to retrive the detail information of a post•function discoverPosts This function returns all the posts from the users that the current user does not follow function deletePost This function helps when the current user required to delete one of his/her posts function savePost This functions is called when user clicks to save a post.", "label": "human"}
{"ID": "00290073", "file_name": "Building a social media application for sharing image and video", "content": "Comment Controller function createComment This function handles the request to create a new comment in post. If the post is not valid then it returns error. If the comment is reply to other comment and the other comment does not exist, then it also returns error. It creates new Comment document in the database and also update the corresponding Post document.", "label": "human"}
{"ID": "00290074", "file_name": "Building a social media application for sharing image and video", "content": "function deleteComment This function handles the requests when user want to delete his/her comment from a post. The corresponding Comment document is deleted in the database, and the Post document is also updatede, Message Controller function createMessage This function will be called when there is a message from a user to anotheruser. If there is no conversation between two users, a new Conversation docu ment will be created and saved to the database. The Message document is then created and saved.", "label": "human"}
{"ID": "00290075", "file_name": "Building a social media application for sharing image and video", "content": "function getMessages This function is called to show all the messages in a conversation that involved current users. It support pagination, which means the messages will not be loaded at once, but in batch.", "label": "human"}
{"ID": "00290076", "file_name": "Building a social media application for sharing image and video", "content": "function deleteMessages This function helps with the request from user that want to delete a specific message in a conversation.", "label": "human"}
{"ID": "00290077", "file_name": "Building a social media application for sharing image and video", "content": "function deleteConversation This function handles the request from users who want to delete the whole conversation. It deletes all the messages in the conversation also.", "label": "human"}
{"ID": "00290078", "file_name": "Building a social media application for sharing image and video", "content": "Notify Controller function createNotify This function creates new notify, handles such request when the front end of the application calls the API.", "label": "human"}
{"ID": "00290079", "file_name": "Building a social media application for sharing image and video", "content": "function getNotifies This functions will return all the notifies of the current user, and sort them by createdAt timestamp function readNotify This function marks a notify from the notification board of the current user as read.•function deleteAllNotifies This function will be called when user clicks remove all notifications from the app frontend g, Admin Controller function getUsers This function gets the list of user account in the application, with pagination.", "label": "human"}
{"ID": "00290080", "file_name": "Building a social media application for sharing image and video", "content": "Database design After analyzing the required functions of the system, I will proceed with thedatabase design for the system. I will use NoSQL as the data could be semistructured, and unstructured. I choose MongoDB as the database management system. Note that the ‘_id‘ field in each schema is the unique id MongoDB auto gen erates for a document. Each document also comes with 2 defaults field which is ‘createdAt‘ meaning the Unix timestamp at which the document was created and ‘updatedAt‘ meaning the Unix timestamp at which the document was last updated.", "label": "human"}
{"ID": "00290081", "file_name": "Building a social media application for sharing image and video", "content": "Libraries and Tools The table 4.7 lists all the tools and libraries I used in the process of building the application.", "label": "human"}
{"ID": "00290082", "file_name": "Building a social media application for sharing image and video", "content": "Purpose Tool/Library Name Version Url AddressIDE program mingVisual Studio Code1.68  Frontend FrameworkReactJS 17.0.1 Frontend UI Li braryBootstrap 4.5.3  Frontend State Management LibraryRedux 7.2.2  Frontend Socket LibrariesSocketIO-Client 3.1.2 Frontend We bRTC LibrariesPeerJS 1.3.2 Backend Pro gramming LanguageNodeJS 16.00 Backend Pro gramming FrameworkExpressJS 4.17.1  Backend SocketLibrariesSocketIO 3.1.2  We bRTC LibrariesPeer 0.6.1  Database MongoDB 6.0.8  CDN server Cloudinary latest  DeploymentplatformGoogle Kuber netes EngineLatest  kubernetes-engine API testing Postman Latest  Performance testingJMeter 5.6.2  Development Operating SystemWindow 10 Latest us/software download/windows10 Version Control Git Latest  Table 4.7: List of Tools and Libraries used in the app development process 4.3.2 Achievement The achieved result is a web application, deployed on a google cloud kubernete cluster, using a domain with valid SSL certificate. Users can access the web fromanywhere as long as they have the Internet. After login, user can create post; in teract with other user’s posts through like, comment; follow/unfollow/search for other users; get suggestion about other users and posts. User can edit their personal info, get realtime notification. Post, comment, like is public for everyone to view,but users can interact with each other in secret by sending text and media mes sages, on calling and video calling each other. For admin, they can manage all the users in the application by create new account, edit existing account’s info and enable/disable user accounts.", "label": "human"}
{"ID": "00290083", "file_name": "Building a social media application for sharing image and video", "content": "Single-page architecture with ReactJS is implemented in the frontend for better user experience. Backend uses NodeJS which is very powerful and can handle lots of requests. For database, MongoDB offers the flexibility for the unstructured data.", "label": "human"}
{"ID": "00290084", "file_name": "Building a social media application for sharing image and video", "content": "For realtime service, SocketIO is implemented and WebRTC with PeerJS is a com mon solution for the on call stream problem.4.4 Testing 4.4.1 Feature Testing Feature Script Expected Result Result Signup User fills in the signupform completely and ac curatelyUser signups successfully and go to the homepagePass Signup User does not fill in one or more required fieldsAn error is displayed PassSignup User signups with an ex isting emailAn error is displayed Pass Login User fills in the loginform completely and ac curatelyUser logins successfully and go to the homepagePass Login User does not fill in one or more required fieldsAn error is displayed Pass Login User fills in the wrong email or passwordAn error is displayed Pass Login User fills in the correct email or password but the account is disable by adminAn error is displayed PassLogout User chooses to logout User is logged out of the applica tion and move to the login pagePass Edit personalinfoUser chooses to edit per sonal info and fill in allfieldsSuccessfully updated informa tion and display that update on personal pagePassSee notificationsUser clicks on the notifi cation buttonList of notification is displayed PassSee a post cor responding to anotificationUser clicks on a notification about a postUser is moved to the post corre sponding to the notification, the notification status is changed to seenPass See a comment correspondingto a notificationUser clicks on a notification about a commentUser is moved to the post containing the comment in the noti fication, the notification status is changed to seenPassSee a follower correspondingto a notificationUser clicks on a notifica tion about a followerUser is moved to the follower’s personal page, the notification status is changed to seenPass Create a new postUser chooses to create text-based only postA post is create successfully and showed in the home pagePass Create a new postUser chooses to create post with mediaA post is create successfully and showed in the home pagePass Create a new postUser chooses to create post without text and mediaAn error is displayed Pass Edit a post User chooses to edit post The post content is updated and the list of posts is updatedPass Like a post User clicks like on a post A notification is sent to otheruser and the number of like is up datedPass Unlike a post User clicks like on a post The number of like in the post is updatedPass Comment a post User clicks to load all comments of a postShow a list of comments in a post Pass Like a comment User clicks like on a commentA notification is sent to otheruser and the number of like is up datedPassUnlike a com mentUser clicks like on acomment they liked beforeThe number of like in the com ment is updatedPass Comment a post User comments a post and clicks sentA notification is sent to other user and the list of comments is updatedPassReply a com mentUser reply a comment in a post and clicks sentA notification is sent to other user and the list of comments is updatedPass Delete a post User chooses to delete a postThe post is deleted and the list of post in the home page is updatedPassDelete a com mentUser chooses to delete a commentThe comment is deleted and thelist of comment in the post is up datedPassSearch for users User types in the searchbar in the header the key wordDisplay the search result Pass See other user infoUser clicks on other user avatar or nameUser is moved to the other user’s personal pagePass Follow other userUser choose to follow other userA notification is created for the other users, the following list of the current user and followers of other user is updatedPass Unfollow other userUser choose to unfollow other userThe following list of the current user and followers of other user is updatedPass Search for user in message pageUser choose to searchfor other user in the mes sage pageDisplay the search result Pass Send message User chooses to send text-based messageA notification is sent to the other user and the message list in both users’s screen are updatedPass Send message User chooses to send empty messageThe application does not send the messagePass Online call User chooses to online call and the other user pickups the callIf the microphone permission is not granted, then the application will ask the user. Both users are then able to hear each otherPass Online call User chooses to online call and the other user does not pickup the callA message is displayed in the message lists that the call is failedPass Online call User chooses to online call and the other user pickups the call but doesnot grant the micro phone permissionThe other user is able to hear what the current user says but not the other wayPassVideo call User chooses to video call and the other user pickups the callIf the microphone permission and webcam permission are not granted, then the application will ask the user. Both users are then able to hear and see each otherPass Video call User chooses to video call and the other user does not pickup the callA message is displayed in the message lists that the call is failedPass Video call User chooses to video call and the other user pickups the call but doesnot grant the micro phone permissionThe other user is able to hear what the current user says but not the other wayPass Video call User chooses to video call and the other user pickups the call but does not grant the webcam permissionThe other user is able to see the current user but not the other wayPassManage user ac countAdmin chooses to seethe list of current usersThe list of current user in the ap plication is displayedPassManage user ac countAdmin chooses to createnew user account, full fills all the required fieldA new user account is created,and the list of user account is up datedPassManage user accountAdmin chooses to cre ate new user account,omits one or more re quired fieldAn error is displayed PassManage user ac countAdmin chooses to editinfo of a user accountA successful message is displayed and the list of user is up datedPassManage user ac countAdmin chooses to editpassword of a user account, the password satisfies all the rulesA successful message is displayedPassManage user ac countAdmin chooses to editpassword of a user ac count, the password’s length is shorter than orequals 6 charactersA successful message is dis playedPassManage user accountAdmin chooses to enable or disable an accountA successful message is displayed and the list of user is up datedPass Table 4.8: Testing Result Table 4.4.2 Performance Testing For perfomance testing the application, I will use the tool JMeter to simulate requests coming to the server. We will try to send 50, 100, 500, 1000 requests to the server. For each test, we will run 5 loops, and calculate the average throughput, which is the number of requests the server handles in a second, and the response time. Because the application is single page, the get request to the website’s url is also the path to the frontend. So for the frontend test, I will continuously send GET requests to the default path of the website. The following table is the testing results of GET request:", "label": "human"}
{"ID": "00290085", "file_name": "Building a social media application for sharing image and video", "content": "Numberof LoopNumber of Re quests per LoopRamp-Up Period (second)Throughput Average Time (miliseconds) 5 50 10s 22.0/sec 316ms 5 100 20s 23.4/sec 309ms 5 500 100s 24.7/sec 317ms 5 1.000 200s 24.8/sec 314ms Table 4.9: Performance Testing with GET Requests For the backend test, I will send multiple POST requests to the api path which is the default backend url. The result is as follow:", "label": "human"}
{"ID": "00290086", "file_name": "Building a social media application for sharing image and video", "content": "The application is first deployed by the google kubernetes engine. First, we cre ate a new cluster. The cluster on the engine will be the autoscaling one. GKE’s cluster autoscaler automatically resizes the number of nodes in a given node pool,based on the demands of your workloads. When demand is low, the cluster au toscaler scales back down to a minimum size that you designate. This can increase the availability of your workloads when you need it, while controlling costs. You don’t need to manually add or remove nodes or over-provision your node pools.", "label": "human"}
{"ID": "00290087", "file_name": "Building a social media application for sharing image and video", "content": "If resources are deleted or moved when autoscaling your cluster, your workloads might experience transient disruption. For example, if your workload consists of a controller with a single replica, that replica’s Pod might be rescheduled onto a different node if its current node is deleted. Before enabling cluster autoscaler, design your workloads to tolerate potential disruption or ensure that critical Pods are not interrupted.", "label": "human"}
{"ID": "00290088", "file_name": "Building a social media application for sharing image and video", "content": "After the cluster has been created, open the Cloud Shell. To working on the clus ter, you must set the current project name and connect to the cluster. For example, connect to the ‘linhpn‘ cluster on the project ‘bkc-learning-hub‘:", "label": "human"}
{"ID": "00290089", "file_name": "Building a social media application for sharing image and video", "content": "gcloud config set project bkc-learning-hubgcloud container clusters get-credentials linhpn - region asia-southeast1 --project bkc-learning-hub After connecting to the cluster, pull the code and change into the directory. Thecode is ready to be packaged in a Docker container and uploaded to Artifact Reg istry. Artifact Registry is a single place for your organization to manage container images and language packages (such as Maven and npm). It is fully integrated with Google Cloud’s tooling and runtimes and comes with support for native artifact protocols.", "label": "human"}
{"ID": "00290090", "file_name": "Building a social media application for sharing image and video", "content": "To containerize the sample app, create a new file named Dockerfile in the same directory as the source files, and its content could be like the following:# Use the official lightweight Node.js 16 image.", "label": "human"}
{"ID": "00290091", "file_name": "Building a social media application for sharing image and video", "content": "CMD [ \"npm\", \"run\", \"start\" ]Add a further .dockerignore file to ensure that local files do not affect the con tainer build process:", "label": "human"}
{"ID": "00290092", "file_name": "Building a social media application for sharing image and video", "content": "Dockerfile README.md node_modules npm-debug.log You will store your container in Artifact Registry and deploy it to your cluster from the registry. The following command will create a repository named smt-repo in the same region as your cluster:", "label": "human"}
{"ID": "00290093", "file_name": "Building a social media application for sharing image and video", "content": "gcloud artifacts repositories create smt-repo \\ -project=bkc-learning-hub \\ -repository-format=docker \\ -location=asia-southeast1 \\ -description=\"Docker repository\"To verify that the repository is created correctly, you can use the following com mand gcloud artifacts repositories listNext, build your container image using Cloud Build, which is similar to running docker build and docker push, but the build happens on Google Cloud:", "label": "human"}
{"ID": "00290094", "file_name": "Building a social media application for sharing image and video", "content": "A Deployment to define your app. A Deployment provides declarative updates for Pods and ReplicaSets. You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or toremove existing Deployments and adopt all their resources with new Deploy ments.", "label": "human"}
{"ID": "00290095", "file_name": "Building a social media application for sharing image and video", "content": "A Service to define how to access your app. In Kubernetes, a Service is a method for exposing a network application that is running as one or more Pods in your cluster.", "label": "human"}
{"ID": "00290096", "file_name": "Building a social media application for sharing image and video", "content": "To deploy the app, create the deployment.yaml file in the same directory as your other files. The sample content of the file could be like:", "label": "human"}
{"ID": "00290097", "file_name": "Building a social media application for sharing image and video", "content": "The Deployment is complete when all of the AVAILABLE deployments are READY. If the Deployment has a mistake, run kubectl apply -f deployment.yaml again to update the Deployment with any changes.", "label": "human"}
{"ID": "00290098", "file_name": "Building a social media application for sharing image and video", "content": "After that, we must deploy a service. Services provide a single point of access to a set of Pods. While it’s possible to access a single Pod, Pods are ephemeral and can only be accessed reliably by using a Service address. In the app, the Service defines a load balancer to access the Pods from a single IP address. This service is defined in the service.yaml file.", "label": "human"}
{"ID": "00290099", "file_name": "Building a social media application for sharing image and video", "content": "port: 443 targetPort: 3001 The Pods are defined separately from the Service that uses the Pods. Kubernetes uses labels to select the Pods that a Service addresses. With labels, you can have a Service that addresses Pods from different replica sets and has multiple services that point to an individual Pod.", "label": "human"}
{"ID": "00290100", "file_name": "Building a social media application for sharing image and video", "content": "kubectl get services It can take up to 60 seconds to allocate the IP address. The external IP address is listed under the column EXTERNAL-IP for the Service.", "label": "human"}
{"ID": "00290101", "file_name": "Building a social media application for sharing image and video", "content": "for port 80 or  for port 443 To use video call function of the web, user must grants the website with the video and microphone permission. Browser only lets web application to ask forpermission if the application has a domain name with valid SSL certificate. Using the external IP can let user access the application from anywhere, but can not use some features like notification and video call. So the next step is to get a SSL certificate and deploy the app to a domain. After buying a domain withvalid certificate, in the setting of the domain, create a new A record that points to the external IP address of the app. We successfully deploy the application to the internet with full features available. The application is available at the url:", "label": "human"}
{"ID": "00290102", "file_name": "Building a social media application for sharing image and video", "content": "Conclusion Stemming from the desire to build an application for users to interact through different kinds of media, I have carried out the project \"Building a social media application for sharing image and video\". The process of researching, surveying, analyzing as well as problem solving has been fully presented in this graduation project.", "label": "human"}
{"ID": "00290103", "file_name": "Building a social media application for sharing image and video", "content": "The project has met the main tasks and objectives set out initially. Specifically, the project has built a social networking website running on the web platform. First, I conducted a survey and assessed the user’s demand for using social networks on some major social networking sites such as Facebook, Instagram, and Tiktok.", "label": "human"}
{"ID": "00290104", "file_name": "Building a social media application for sharing image and video", "content": "From there, I conduct analysis and indicate functional and non-functional require ments. Based on the requirements, I conduct detailed design and build the database.", "label": "human"}
{"ID": "00290105", "file_name": "Building a social media application for sharing image and video", "content": "The website is built according to the MVC model and uses the MongoDB databasemanagement system. Currently the website is deployed in the Google Cloud Plat form and anyone with internet access can see the website.", "label": "human"}
{"ID": "00290106", "file_name": "Building a social media application for sharing image and video", "content": "During the working process, the graduation project has achieved all the basic features for three actors: guest, user and admin. Guest can go into the website and signup for an account to be come a user. After successful account creation, guests can log in and use user functions. Users in the system can perform the following main functions: Edit personal information, search for other users, see other user’s info, see list of posts, post media, comment a post, message other user, on call, video call and see realtime notification. Admin can manage all the user accounts.", "label": "human"}
{"ID": "00290107", "file_name": "Building a social media application for sharing image and video", "content": "While designing, developing and implementing this project, I have a better un derstanding of the process of life cycle of making an IT based product in generaland a website to be specific. In a real life situation there would be separated mem bers for each steps, but developing by myself helped me a lot in understanding each and every steps in making a product.", "label": "human"}
{"ID": "00290108", "file_name": "Building a social media application for sharing image and video", "content": "As a fullstack developer, the process of designing the database, making mockups, implementing APIs and building the UI/UX has given me great opportuni ties to learn cutting edge programming languages, frameworks and development tools. For example, I’m now used to developing APIs using NodeJS with ExpressJS Framework in the backend, and for the frontend part I can now easily use modernJS frameworks like React.js and UI framework like Bootstrap for making beautiful user interfaces.", "label": "human"}
{"ID": "00290109", "file_name": "Building a social media application for sharing image and video", "content": "Moreover, I also learned the way to handle real-time events using Socket.io library. For the video call and on call which requires the instantanious data stream, I learn about WebRTC and implement it in the app using PeerJS library.", "label": "human"}
{"ID": "00290110", "file_name": "Building a social media application for sharing image and video", "content": "Last but not least, I have learned the way to deploy a website and register a valid do main for the website with SSL certificate. For the app development, I used Docker locally and in the production environment, which is hosted in a GKE cluster.", "label": "human"}
{"ID": "00290111", "file_name": "Building a social media application for sharing image and video", "content": "First is to improve the UX/UI. Visual attraction is very important for an ap plication such as social media website. To attract more user, the UI must be very appealing and the UX must be very smooth. The web application needs to completethe functions and have the optimal interface for the phone. Next, some features re lated to the group like user groups, group message channel or group on/videocall could also need to be carried out to increase the interaction of the users. Fi nally, website load time and API response time could also be improved by usingadvanced deploy techniques like load balancer or API gateway. The above prob lems need to be overcome and added in the future for the purpose of improving the website as well as improving the user experience.", "label": "human"}
{"ID": "00290112", "file_name": "Building a social media application for sharing image and video", "content": "The above is the full content of the thesis. Due to the limited time and limited skills and experience, it is difficult to avoid shortcomings in the process of working on my thesis. I look forward to receiving the guidance and suggestions of teachers so that the system can be improved in the future. [On]. Available:  users-in-viet_nam/2023/04/ .", "label": "human"}
{"ID": "00300001", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "In the face of the rapid development of the field of Information Technology, accompanied by the strong development of services and utilities, especially on shopping services, are proving to be effective for people and gradually becoming more and more popular. become a basic human need.", "label": "human"}
{"ID": "00300002", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Shopify e-commerce platform helps new users who do not need to be familiar with programming languages to use it. Shopify is a cloud computing platform so store owners don’t need to buy a server to put it on. In addition, Shopify packs many features such as payment support, product management support, product sets, support for many different sales styles, and more. Especially, if the store owner sells on, Shopify supports the website’s interface pages.", "label": "human"}
{"ID": "00300003", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "However, with the available interfaces, users cannot add editing or create filters on the search page. To be able to customize an interface to their liking, customers must learn about the Liquid language, as well as the languages to program apps for shopify, and find a way to rewrite the code to suit their interface. The problem requires creating an application so that the user can change the filters or the interface of their search page.", "label": "human"}
{"ID": "00300004", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Although there are now a lot of applications or themes to change the interface or operating mechanism of the search page, a part of customers can’t afford the price or don’t know how to use it due to too many layers. and attributes. so this project will solve the problems mentioned above.", "label": "human"}
{"ID": "00300005", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "With this app, store owners can start editing and updating search page characteristics and SEO-related settings. then the buyer’s website will be customized to the specifics of the buyer’s With this app, store owners can start editing and updating search page characteristics and SEO-related settings. then the buyer’s website will be customized to the specifics of the buyer’s site.", "label": "human"}
{"ID": "00300006", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "many apps are too expensive, or the app uses many technologies that make users unable to access the application.1.3 Research Objectives and Conceptual FrameworkBased on the objectives of the presented topic, the \"search page application  Shopify Ecommerce\" system is developed on the web platform using the MVC model. With the use of this model, the separate components of the application will be clearly separated, which is convenient for the management, upgrade and maintenance of the application, and can help the application’s processing flow to be clear.", "label": "human"}
{"ID": "00300007", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Based on the above challenges and issues, the following chapters will focus on problem solving and results, organized as follows:", "label": "human"}
{"ID": "00300008", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Chapter 2 presents about surveying the types of lockers on the market to choose the most appropriate model, thereby building the system’s operations and requirements.", "label": "human"}
{"ID": "00300009", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "From the identification of the necessary requirements in chapter 2, the technologies to be selected and used are summarized in the next chapter 3.", "label": "human"}
{"ID": "00300010", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Chapter 4 presents project design options, briefly describes how the system works, design interfaces, databases, etc. The results achieved, test work, project implementation, etc also be briefly described Chapter 5 will present the contribution, the process of making the thesis and the results achieved, including the difficulties encountered, how to overcome the problem.", "label": "human"}
{"ID": "00300011", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Chapter 6 summarizes what has been learned through the project, what has been and has not been done, thereby giving conclusions and future development directions.2.1 E-commerce Due to the field of information technology’s quick development, together with the significant growth of services and utilities, particularly e commerce services, these services are proving to be beneficial to people and are steadily gaining popularity.", "label": "human"}
{"ID": "00300012", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "What is E-commerce E-commerce, often known as electronic commerce, is the exchange of goods and services as well as the sending of money and data through an electronic network,most commonly the internet. These business dealings can be either B2B (business to-business), B2C (business-to-consumer), C2C (consumer-to-consumer), or C2B.", "label": "human"}
{"ID": "00300013", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "E-business and e-commerce are frequently used interchangeably. The transactional procedures that make up on retail shopping are also occasionally referred to as e-tail.", "label": "human"}
{"ID": "00300014", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The widespread use of e-commerce sites like Amazon and eBay over the past 20 years has significantly boosted the growth of on retail. According to the U.S.", "label": "human"}
{"ID": "00300015", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Type of E-commerce Business-to-business (B2B) e-commerce refers to the electronic exchange of products, services or information between businesses rather than between businesses and consumers. Examples include on directories and product and supply exchange websites that let businesses search for products, services and information and initiate transactions through e-procurement interfaces. A Forrester report published in 2018 predicted that by 2023, B2B e-commerce will reach $1.8 trillion dollars and account for 17% of U.S. B2B sales.", "label": "human"}
{"ID": "00300016", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Business-to-consumer (B2C) is the retail part of e-commerce on the internet.It occurs when companies offer goods, services, or information to customers directly.", "label": "human"}
{"ID": "00300017", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The phrase gained popularity in the late 1990s dot-com boom, when on stores and sellers of goods were still a novelty.", "label": "human"}
{"ID": "00300018", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Consumer-to-consumer (C2C) is a type of e-commerce in which consumers trade products, services and information with each other on.These transactions are often carried out through a third party that offers an internet platform for theirexecution.", "label": "human"}
{"ID": "00300019", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Consumers offer their goods and services for sale to businesses on through a sort of e-commerce known as consumer-to-business (C2B). This goes against the conventional B2C business paradigm.", "label": "human"}
{"ID": "00300020", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Advantages and disadvantages of e-commerce E-commerce has many advantages, including round-the-clock accessibility, quick access, a wide range of products and services, ease of accessibility, and global reach.", "label": "human"}
{"ID": "00300021", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Availability.E-commerce sites are accessible 24/7, allowing users to explore and shop at any time, with the exception of outages and scheduled maintenance.", "label": "human"}
{"ID": "00300022", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Speed of access.While crowds can slow down customers in a physical store, e-commerce sites run rapidly due to considerations regarding computing and bandwidth on both the consumer device and the e-commerce site. The loading time of the product and shopping cart pages is under a second. An on purchase can be made in a few clicks and within five minutes.", "label": "human"}
{"ID": "00300023", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "It was able to make this assertion because it was an on store rather than a brick and mortar establishment that needed to stock every book on its shelves.", "label": "human"}
{"ID": "00300024", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "With the use of e-commerce, businesses may provide a wide range of goods, which are subsequently sent from one or more warehouses when a customer makes a purchase. Customers will probably find what they’re looking for more easily.", "label": "human"}
{"ID": "00300025", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Easy accessibility. Customers looking in a real store could have trouble finding a specific item. Website users can instantly search for a product using the site’s search feature and explore product category pages in real time.", "label": "human"}
{"ID": "00300026", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "International reach.Businesses with physical stores sell to clients who come into their locations. Businesses can sell to everyone who has access to the internet through e-commerce. E-commerce has the potential to increase a company’s clientele.", "label": "human"}
{"ID": "00300027", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Lower cost.Pure-play e-commerce companies do not have to pay rent, stock, or payroll costs associated with operating physical storefronts. However, they can be responsible for shipping and storage fees.", "label": "human"}
{"ID": "00300028", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Personalization and product recommendations.A visitor’s browsing, search,and purchase history can be tracked on e-commerce websites. They can gather information about target markets and give customised product recommendations using this data. Examples are the \"Frequently bought together\" and \"Customers who viewed this item also viewed\" sections on Amazon product pages.", "label": "human"}
{"ID": "00300029", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The alleged drawbacks of e-commerce include occasionally poor customer service, the inability for customers to physically touch or view a product before making a purchase, and the lengthy shipment wait times.", "label": "human"}
{"ID": "00300030", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Limited customer service.Customers can ask a clerk, cashier, or store manager for assistance if they have a query or problem in a physical store. Customer service in an on store may be restricted: The website might only offer support during defined hours, and its on service options might be confusing to use or fail to address a particular query.", "label": "human"}
{"ID": "00300031", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Limited product experience.Although looking at product photographs on a website can give you a good idea of what it is like, it’s not the same as actually using the object, such as when you play a guitar, evaluate the picture quality of a television, or try on clothes. On shoppers may wind up purchasing goods that fall short of their expectations and need to be returned. In some circumstances, the cost of shipping a returned item to the merchant is borne by the customer. The capacity of customers to inspect and test e-commerce goods is anticipated to improve with augmented reality technology.", "label": "human"}
{"ID": "00300032", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Wait time.Customers purchase items in stores, pay for them, and then take them home. Customers who shop on must wait for the merchandise to be delivered to them. Shipping windows are getting smaller even while next-day and even same-day delivery are becoming more popular.", "label": "human"}
{"ID": "00300033", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Security.Hackers with the right skills may make websites that look real and sell well-known products. Instead, the website either takes credit card information from customers or sends them bogus or copycat versions of such things. Even legitimate e-commerce websites have risks, particularly when customers save their credit card details with the merchant to facilitate future purchases. Threat actors might steal that credit card information if the retailer’s website is breached.", "label": "human"}
{"ID": "00300034", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "E-commerce applications On marketing strategies are used by several retail e-commerce apps to entice users to the platform. Email, on shopping carts and catalogs, file transfer protocol, web services, and mobile applications are some of these.Security is issue on which e-commerce enterprises are concentrating. When creating e-commerce systems and apps, developers and administrators should take into account consumer data privacy and security, data governance-related regulatory compliance demands, personally identifiable information privacy laws, and information protection measures. While some security protections are incorporated into an application’s architecture, others need to be updated often to handle growing threats and discovered vulnerabilities.", "label": "human"}
{"ID": "00300035", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Alibaba 2. Amazon 3. EBay 4. Walmart Marketplace 5. Newegg 6. Paypal 7. SlideShare 8. Lazada 9. Facebook The following vendors provide e-commerce platform services for customers hosting their own online shop websites:", "label": "human"}
{"ID": "00300036", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Software applications will be deployed on this cloud space. Instead of buying a license for the software, the user will buy a service that uses it.In other words, a fixed piece of software will be made by the software seller.", "label": "human"}
{"ID": "00300037", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Afterward, this website platform’s software will be maintained. Customers from all over the world can access that software on. The price is not paid all at once but rather on a regular basis (monthly, quarterly or annually).", "label": "human"}
{"ID": "00300038", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The global adoption of cloud computing is making it one of the most cutting edge 4.0 technology platforms. It predominates mostly in the technological sector.", "label": "human"}
{"ID": "00300039", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Advantages of SaaS 1. Increase managerial and operating expenses.Businesses must make sure the infrastructure platforms are in place before installing traditional software. For instance, the computer must guarantee the setup, or the expenses of routine upkeep and upgrades. Alternatively, the entire computer must be reinstalled if it is broken or needs to be replaced. Businesses will maximize these costs with SaaS. Quick turnaround, affordable conversion, and excellent conversion possibility everywhere and anytime.", "label": "human"}
{"ID": "00300040", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Constantly updated program with the newest features.Businesses don’t require a maintenance team or a technical team on call when using internet-based software. This component will be the supplier’s responsibility. Businesses will profit from the software’s frequent updates and new feature additions.In contrast to customary installation programs. Install the updated version and pay an extra license price if you want to upgrade.", "label": "human"}
{"ID": "00300041", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "when there is internet, simple to use.SaaS applications are used with unique accounts for each user. You can utilize it somewhere except in the company, then. You can sign in and access it from anywhere, possibly with just a phone, and it has limitless functionality. This is a significant benefit of this program.", "label": "human"}
{"ID": "00300042", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Integration with external applications capability.Software with traditional copyrights is frequently isolated and unconnected to external programs. For a business to manage and run efficiently, various links are required. Customer service and marketing, for instance, will get user feedback. However, the product division also requires this information to plan enhancements or develop fresh concepts for the product. The best option for corporate operations will be to integrate software so that both departments may view client feedback rather than having to transmit information back and forth.5. Can expand without compromising current infrastructure.You can fully scale your SaaS cloud data as your business expands. can increase the number of existing accounts by more than n times without compromising the infrastructure or business data. This is a tremendous and useful advantage for growing enterprises.", "label": "human"}
{"ID": "00300043", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Shopify overview Shopify is a SaaS (Software as a Service) e-commerce system that enables you to build an on sales website with all of the capabilities of a shopping cart and checkout, order processing, omnichannel selling, and marketing automation.", "label": "human"}
{"ID": "00300044", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Advantages and disadvantages of Shopify Shopify is a modern and cutting-edge e-commerce platform with a number of distinguishing benefits over rivals, including:", "label": "human"}
{"ID": "00300045", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "If you have questions about using Shopify and the supporter hasn’t gotten back to you right away, you may join their Shopify Vietnam community and post to discuss. Shopify also includes video tutorials on using Shopify categorized by level from basic to advanced.", "label": "human"}
{"ID": "00300046", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Along with the aforementioned benefits, Shopify sales are subject to a few restrictions. What are Shopify’s drawbacks then? 1. Limited capabilities for major businesses 2. does not yet support domestic cards for Vietnam.", "label": "human"}
{"ID": "00300047", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "PHP language A server-side programming language called PHP is used to create either static or dynamic webpages or on apps. PHP, which formerly stood for Personal Home Pages, is now known as Hypertext Pre-processor. Only servers with PHP installed can interpret PHP scripts. Only a web browser is needed on the client machines to view the PHP scripts. A PHP file has the \".php\" suffix and contains PHP tags.2.4.2 Advantage of PHP language Despite having access to a variety of scripting languages, including CGI, ASP, JSP, and Perl, the majority of web developers favor PHP. This programming language is at the forefront of website creation for a number of reasons.", "label": "human"}
{"ID": "00300048", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Simple and Easy to Learn. One of the simplest programming languages is PHP. PHP is less labor-intensive than other web languages in that it doesn’t call for extensive manual study. The syntax in PHP is clear and orderly. Even command functions are simple to comprehend because they explicitly state to the developer what action is taken. As a result, the creation and optimization of the application is relatively simple for web developers.", "label": "human"}
{"ID": "00300049", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Exceptionally Flexible. Whether a project is in progress or has been finished, PHP is incredibly adaptable. A scripting language’s flexibility is essential since functionality might change at any time while a project is ongoing. The nicest thing about PHP is that it allows for changes to be made even after the project has begun, which helps to save time.", "label": "human"}
{"ID": "00300050", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Easy compatibility and integration. With the vast majority of OS systems, PHP is compatible. It may easily be used with UNIX, Solaris, and Linux, among other platforms. Existing software doesn’t need to be developed from scratch because it can easily be integrated with other technologies, like Java. This reduces waste and costs.", "label": "human"}
{"ID": "00300051", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Performance Efficiency.PHP has the potential to be an effective language, depending on how the web developer programs. It may be used to create a huge number of apps and is scalable when used to write codes. It is the preferred programming language for websites with numerous web pages.", "label": "human"}
{"ID": "00300052", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Buying pricey licenses or software doesn’t cost anything. It functions well with a variety of databases, including MySQL, Apache, and PostgreSQL.", "label": "human"}
{"ID": "00300053", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Increases Control for Web Developer.PHP offers more control to the website developer than other programming languages. In contrast to other programming languages, PHP is not slowed down by lengthy, intricate scripts. The code only has to be a few s long. Additionally, PHP permits tags, thus website developers can add and/or mix HTML elements to create incredibly dynamic content.2.4.3 Laravel Overview Taylor Otwell developed the free, open-source Laravel PHP On Framework, which is built on the Symfony PHP Framework and designed for the creation of web applications with an MVC pattern architecture. The use of the module packaging system, package management (Composer), support for numerous relational database management systems (MySQL, MariaDB, SQLite, PostgreSQL,...), and application deployment and maintenance are only a few of Laravel’s capabilities.", "label": "human"}
{"ID": "00300054", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The most recent PHP features 2. The MVC design pattern (Model - View - Controller) 3. Outstanding Authentication and Authorization System 4. Possesses a thorough and understandable documentation system 5. Massive community of supporters 6. Command  management tool integrated with artisan tool 7. To control PHP packages, use composer.", "label": "human"}
{"ID": "00300055", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Perfection of the interface. The interface needs to be complete, easy to use, fully functional. The management web interface as well as the android app do not need to be too picky, but still ensure aesthetics high performance. Also need to support different screens and devices with different configurations.", "label": "human"}
{"ID": "00300056", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "User-friendly. The application should limit errors as much as possible, in order to create a good experience for users.High availability. Built-in features need to be practical, and actually solve certain problems. Avoid building unnecessary features, burdening the system without solving any problems.", "label": "human"}
{"ID": "00300057", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Optimal algorithm. The system will later need to be maintained and upgraded to complete and add new features, so the code needs to be organized scientifically, avoiding confusing for the maintainers.3.1 Front-end technologies 3.1.1 Vuejs A versatile framework for creating user interfaces is called vue.js (original English:", "label": "human"}
{"ID": "00300058", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "progressive). Vue was created from the bottom up to support and promote step-by step application development, in contrast to monolithic frameworks. Users simply need to use the core library of Vue when creating the view layer; it is simple to learn and easy to incorporate into other projects or libraries. At the same time, Vue also readily satisfies the requirements of constructing single-page applications (SPA Single-Page Applications) with significantly higher complexity when combined with contemporary approaches like SFC (single file components) and support libraries.", "label": "human"}
{"ID": "00300059", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "A JavaScript object called Virtual DOM in Vue represents the Document Object Model (DOM). Instead of directly updating the DOM, the application updates the Virtual DOM.Before talking about virtual DOM we need to understand DOM.", "label": "human"}
{"ID": "00300060", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "For traditional web models, the interaction and interface processing mainly use pure JavaScript. These interactions will be performed on the DOM1, accessing and manipulating structured HTML or XML documents. Figure 3.1 will displays the structure of HTML DOM.", "label": "human"}
{"ID": "00300061", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Applications that run on both the client-side (Angular2) and server-side can be created using TypeScript (NodeJS). TypeScript makes use of all the ECMAScript 2015 (ES6) features, including classes and modules. Prior to the creation of TypeScript, Google also created CoffeScript and Dart, libraries that supported the aforementioned ideas but made use of a whole different syntax. Thus, despite its later birth, TypeScript continues to get favorable reviews from programmers.", "label": "human"}
{"ID": "00300062", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Laravel Laravel is a free and open source PHP framework, built to support the development of software and applications, following the MVC2architecture. MVC is a computer’s user interface creation template for its software architecture. The MVC system, which separates the user interface from the business concepts, is composed of three interconnected pieces. These are the three components:", "label": "human"}
{"ID": "00300063", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Controller: Takes responsibility for receiving instruction requests from users 2Model-View-Controller, defined by the World Wide Web Consortium - W3Cand calling the correct methods to handle them.", "label": "human"}
{"ID": "00300064", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Model: A component that contains all business logic, processing methods, database access, data describing objects such as classes, processing functions, etc.", "label": "human"}
{"ID": "00300065", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "It’s quick and simple.Since Laravel is the most popular PHP framework, most web developers are already familiar with it. There’s also a wide selection of built-in templates, which makes development simpler and easier for developers.", "label": "human"}
{"ID": "00300066", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "In light of this, a skilled Laravel developer might create a five- or six-page website in a day or two. Rapid development translates into cheaper expenses and faster outcomes for the company.", "label": "human"}
{"ID": "00300067", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Security is key.The majority of organizations’ top concern is security. Most websites may easily be configured with Laravel’s strong security capabilities to improve security and defend against hackers and cybercriminals. Technically speaking, Laravel never stores any passwords in the database since it employs the Bcrypt hashing method. When compared to other PHP frameworks, Laravel also includes excellent user authentication and simple-to-create limited access capabilities. This safeguards the data of both you and your clients.", "label": "human"}
{"ID": "00300068", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Better website performance.Laravel offers caching for your website out of the box, which is wonderful for accelerating the pace of your site, unlike manyother frameworks available. Other performance optimization strategies, such memory utilization reduction and database indexing, are made simple to apply by Laravel to further improve the efficiency of your website. If site speed and SEO friendss are part of your needs, this makes Laravel an ideal alternative for your company.", "label": "human"}
{"ID": "00300069", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Great for Traffic-Handling.The amount of visitors to your website will increase as your firm expands. Laravel-built websites may process requests significantly more quickly than those made using other frameworks. Because Laravel employs a special message queue structure, you may postpone doing some website operations, like sending emails, until later. Your website will be able to complete jobs more quickly if you have control over time-consuming processes. In addition to keeping your website’s server in good shape, this can ultimately cut your hosting fees.", "label": "human"}
{"ID": "00300070", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Really Flexible.Laravel offers the ability to create both a straightforward and expert B2B website and a full-featured eCommerce website. It has the capacity to design and support a number of complex features for your site, such password reset and encryption, because of the comprehensive pre-installed authorization libraries it contains. There are also a ton of third-party packages that you can utilize to provide your website a variety of features and functionality, including Socialite, which lets people to sign in to your site using their social network profiles if you decide to incorporate that feature.", "label": "human"}
{"ID": "00300071", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Easy third-party integrations.Almost all websites require some kind of integration with a third-party program. This might be a tool your business utilizes for marketing or a payment system like Stripe or Paypal. Whatever the integration, Laravel’s straightforward APIs for integration make connecting third-party programs simple. So Laravel is a good candidate whether your website has a payment system in place or an automated tool to handle your marketing.", "label": "human"}
{"ID": "00300072", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Simple Website Maintenance.In general, Laravel-built websites are simple to update over time. So, let’s say you want to add some new features to your site (which was already constructed using Laravel) after a few years. A new developer may easily continue where your previous developers left the site. It is incredibly simple to maintain a Laravel site over time because of its unique characteristics, such as clean code, MVC design (which separates functionality and presentation), and OOP concepts.", "label": "human"}
{"ID": "00300073", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The cost of a Laravel Site.Laravel is an open-source framework in contrast to some other ones out there. This indicates that you can use it without payinga dime for any project you want. Of course, there will be a fee for hiring a skilled Laravel developer to create your website (especially if you know very little about coding). A Laravel project might be more cost-effective in the long term since development expenses are further decreased and the time to construct and maintain is less than with certain competing frameworks.", "label": "human"}
{"ID": "00300074", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "API A collection of specifications and protocols known as an API3are used to create and integrate application software. It’s also referred to as a contract between a supplier of information and a user of that information, outlining the content that the consumer (the call) and the producer (the producer) are obligated to deliver (the response). For instance, the API architecture for a weather service would need the user to provide their zip code and the producer to respond with two parts: the high temperature and the low temperature.", "label": "human"}
{"ID": "00300075", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "APIs let your product or service communicate with other products and services without having to know how they’re implemented.For making app development simpler, time and money may be saved. APIs provide you freedom, make design, administration, and usage simpler, and open up options for creativity when you’re creating new tools and products—or managing ones that already exist.", "label": "human"}
{"ID": "00300076", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "With documentation that serves as a representation of a contract between parties, APIs are frequently compared to contracts: This is how party 2’s program will react if party 1 submits a structured remote request.", "label": "human"}
{"ID": "00300077", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "APIs facilitate communication between business and IT teams by making it easier for developers to incorporate new application components into an existing architecture. In reaction to constantly evolving digital markets where new rivals might completely transform an industry with a new app, business demands frequently change swiftly. Supporting the quick development and deployment of innovative services is crucial for remaining competitive. A recognizable method of accelerating development speed is cloud-native application development, which depends on linking a microservices application architecture through APIs.", "label": "human"}
{"ID": "00300078", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Cloud-native app development makes it easier to link your own infrastructure, but APIs also let you share your data with clients and other outside users. Because they may stream and broaden how you engage with your partners and perhaps monetize your data, public APIs have special business value (the Google Maps API is a popular example).Figure 3.4 displays how the API functions.", "label": "human"}
{"ID": "00300079", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "API-Application Programming Interface , defined by the World Wide Web Consortium - W3CFigure 3.4: how the API functions a, Rest API An application programming interface (API) that adheres to the REST architectural standards and limitations used in client-server communication is known as a REST API (also known as a RESTful API). The acronym REST stands for REpresentational State Transfer, and Roy Fielding, a computer scientist, developed it.", "label": "human"}
{"ID": "00300080", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "A RESTful API transmits a representation of the resource’s state to the requester or endpoint when a client request is made through it. One of various forms, including JSON (Javascript Object Notation), HTML, XLT, Python, PHP, or plain text, is used to send this information or representation through HTTP. Despite its name, JSON is the most widely used file format because it can be read by both people and machines and is language-independent.", "label": "human"}
{"ID": "00300081", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Additionally, the HTTP methods of a RESTful API HTTP request since they contain data about the request’s metadata, authorisation, unified resource identifier (URI), caching, cookies, and more. There are headers for requests and responses, and each one contains information about the HTTP connection and a status code.Instead of having to use one URL to process some user information, Rest will make HTTP requests like: GET, POST, DELETE,PUT to with any URL to be used. Figure 3.5 below shows how to divide the UI into components in React.Figure 3.5: Restful API 3.2.3 PostgreSQL The Faculty of Computing at the University of California in the United States created PostgreSQL, an object-relational database management system, based on Postgres version 4.2. Many later commercial data management system ideas were inspired by this application.", "label": "human"}
{"ID": "00300082", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "PostgreSQL was then modified to be adaptable and run on other systems, including Windows, Mac OS X, and Solaris, with many exceptional capabilities and characteristics.", "label": "human"}
{"ID": "00300083", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Data type: primitives (integers, booleans, numbers, strings); structure (UUID, Range, Array, Date/time); Geometry; Custom; Document.2. Data integrity: Word type constraints, Primary Keys, Foreign Keys, UNIQUE, NOT NULL, Recommendation Locks/ Advisory Locks, Function Locks/ Explicit Locks, etc.", "label": "human"}
{"ID": "00300084", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Performance, convergence: multiple instances concurrency control (MVCC), table partitioning, parallel read queries, advanced cataloging, scheduling, complicatedaccess optimizer, multi-column statistics, index-only scanning, transaction transaction test format, and disaster recovery Replication, Score-ahead Logging (WAL), and Restore Score - Time, Table.", "label": "human"}
{"ID": "00300085", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Scalability: stored methods, procedural languages (PL/PGSQL, Python, Perl, and many more), PostGIS, other threading or database connectivity with standard SQL interfaces, and many other extended features.", "label": "human"}
{"ID": "00300086", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "More features: Ability to manage the number of users working at the same time, suitable for production environments that manage multiple terabytes and petabytes.4.1 Architecture design 4.1.1 Software architecture selection The project uses the Client - Server architecture model, combined with interceptors to intercept and check the request before sending it to the server for processing to develop the project.", "label": "human"}
{"ID": "00300087", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "On the Server side, the code will be organized into controller, model and service, using Laravel Framework Core. The controller is responsible for receiving and processing data, while the management model handles the data. Service acts as an interceptor, intercepting and examining the request before confirming it is a valid request and submitting it to the controller for further processing.", "label": "human"}
{"ID": "00300088", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Class name Purpose Auth Storage roles of managers User Storage details of User Search Storage details of Search parameter Tenm Storage details about Search record Table 4.1: List of models\" b, Controller Controller is the place to receive requests and then process them and call models to get, create, update, or delete data. Finally, it will return the result to the client, which is the status code, message and response data. These operations are called API.", "label": "human"}
{"ID": "00300089", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "API for back-end:Route Function Purpose getConfig GetAllConfig() Get all config postToken PostToken() post new token gethge getHGE() Get data from hasura putconfig PutConfig() Update config data postlog PostLog() Post new log Table 4.2: Back-end API c, View In this part, the application will have 2 main interfaces:", "label": "human"}
{"ID": "00300090", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "In the interface, there will be 2 main users, merchant and user. Here the merchant will be the one to decide what the user will see in the search page.", "label": "human"}
{"ID": "00300091", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Overall design a, Package diagram for server The figure below will display the package diagram for server.Figure 4.3: Package diagram for server side Reference to Fig. 4.3 above,Model takes the role of an interceptor, intercepting and checking the request before the controller continue to processing and handling to respond.", "label": "human"}
{"ID": "00300092", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Package Controller takes care of receiving request data, first checking it using the service in Service package, then processing it in conjunction with getting orupdating data by working with Model package, and returning results to the front end.", "label": "human"}
{"ID": "00300093", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The package Model represents the data in the table, connecting to the database so that the controller can perform query operations with the tables.", "label": "human"}
{"ID": "00300094", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Package diagram for web client The figure below will display package diagram for merchant view.Figure 4.4: Package diagram for merchant view Reference to Fig. 4.4 above, package Component contains all the UI of the website. This package contains sub-packages, which contain components that have been classified into packages based on properties and functionality. Some components interact with each other, which will be present in next part. Components in this package use other packages to render the final interface. Component packages include:", "label": "human"}
{"ID": "00300095", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Package diagram for User view The figure below will display package diagram for app client.Figure 4.5: Package diagram for user view This part is quite simple when there is only 1 file used to replace the search page after catching the click event on the search button.", "label": "human"}
{"ID": "00300096", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Detailed package design The diagram in Fig. 4.6 below shows the detailed package design.Figure 4.6: Detail package diagram The activity flow will be carried out as per my concept. The program will first be installed into the store, following which it will proceed immediately to the page where the search page’s parameters and the page where searches are stored may be edited. A successful save message appears after changing the parameter values and saving. The modified search page will show once we click the search button on the store’s homepage.", "label": "human"}
{"ID": "00300097", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "User interface designWith desktop interface for web application, the system is capable of support ing screen sizes such as 1360x768 (HD screen), 1440x900 (Macbook screen), 1920x1200 (Full HD wide-screen).", "label": "human"}
{"ID": "00300098", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Login interface for website The login interface will be designed with the login form on the right. The left side will be the decoration, showing the organization’s logo as well as the message or introduction of the organization, etc.", "label": "human"}
{"ID": "00300099", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Fig. 4.7 illustrates the interface design of login for merchant function.Figure 4.7: login for merchant function b, Setting interface This page will be divided into 1 main section, the left part will be tabs to select the page including setting page and term. on the right will be the display of the changeable elements of the search page.", "label": "human"}
{"ID": "00300100", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Fig. 4.8 illustrates the interface design of setting page.Figure 4.8: Design of setting page c, Term interface This page will be divided into 1 main section, the left part will be tabs to select the page including setting page and term. on the right will be the display of the data table of searches.", "label": "human"}
{"ID": "00300101", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Fig. 4.9 illustrates the interface design of term page .Figure 4.9: Detail term page d, Save setting page A successful save message will be displayed by the program after making changes to the properties and tapping save.", "label": "human"}
{"ID": "00300102", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Fig. 4.10 illustrates the interface design of Save setting page.Figure 4.10: Detail save Save setting page e, Design of search page Fig. 4.11 illustrates the interface design of Design of search page.", "label": "human"}
{"ID": "00300103", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Libraries and Tools Table 4.3 below will display list of libraries, tools, and API that I used to develop and maintain this project.Purpose Tool/Library/API URL address IDE for web Visual Studio  front-end Code Front-end framework Vuejs  Web call API REST API  docs/Web/API/REST_API Language for building PHP  android application App call API Retrofit  IDE for back-end Visual Studio  om Back-end framework Laravel Framework  Core core Database SQL Server  /sql-server Database management SSMS  /sql/ssms Test API Postman  Manipulated with json Newtonsoft  son Deploy server digitalocean  Draw diagram draw.io  Table 4.3: List of used libraries and tools 4.2.2 Achievement There will be 23 primary tables in this database part, including user, term, and search setting. Users are managed via the user table. The term table is in charge of keeping track of the terms that the user has looked up. The store owner’s data configured for his search bar will be saved in the search configuration panel.", "label": "human"}
{"ID": "00300104", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "I installed my app for shops and built two stores on Shopify with enough inventory to test it. The final findings demonstrate that the program functions flawlessly and without any bugs.", "label": "human"}
{"ID": "00300105", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The testing process of server is divided into two steps. The first step was to conduct a test using the student’s computer as a server, with the help of Ngrok.", "label": "human"}
{"ID": "00300106", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Ngrok allows demo web projects to the internet without deploying, so it makes system testing more realistic than using localhost. The second step is to conduct the test with the lab’s server. My back-end contri- bution will be merged with the back-end code available in the lab and tested. For android application, I export code to .apk file and install the app to my phone for the most authentic experience.", "label": "human"}
{"ID": "00300107", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "The system application is also installed on a lab android device. Finally, proceed to connect, test both the android app and the management web and conduct the test.This chapter will detail my contribution to the project, about problems need to be solved, approach, difficulties encountered, final solution, etc.", "label": "human"}
{"ID": "00300108", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Problem The two dominant players in the e-commerce industry, shopify and amazon, are now engaged in a vigorous battle for market share. While shopify allows store owners to utilize and build up their own stores on the shopify platform, amazon is an e-commerce site that allows consumers to post their purchases and sales immediately on amazon.com. In comparison to shopify, the ahnfg stores on Amazon have a lot of useful features already built in. However, shopify can adjust the features based on the shop. The search page on Shopify is one of them. Shopify’s default search page is currently only partially supported. In contrast, it is challenging for new users to use Shopify’s search page changing applications since they are too pricey and sophisticated.Shopify’s default search page is currently only partially supported. On the other side, new Shopify customers find it challenging to obtain and utilize the search page changing applications since they are too pricey and complex. Therefore, the major objective of this project is to develop a straightforward search page that is more user-friendly than Shopify’s default search page.", "label": "human"}
{"ID": "00300109", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Requirement The solution must first be financially feasible. The second is having strong connections to the present system. Next, check for space difficulties and try to conserve as much space as you can. Additionally, it must guarantee that the problem is manageable and convenient.", "label": "human"}
{"ID": "00300110", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Approach The approach given is,Using three stores as an example, you might deploy the app there and compare how well it performs based on how many searches are made using it and well it is integrated into the consumer search page.", "label": "human"}
{"ID": "00300111", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Difficulties encountered In this application, I’m primarily concerned with the back-end, where I obtain the data and adjust the search page’s required settings. Therefore, the program will need to be divided into numerous separate parts. Additionally, Shopify supports a wide range of languages and programming languages. Consequently, working was not without its challenges.Firstly,The choice and application of languages and techniques presented a significant challenge in finishing this project. Shopify may employ several different languages and methodologies, the most of which are foreign to me. I dedicated two months to learning everything there is to know about Shopify, including its apps, themes, languages, and usage options.", "label": "human"}
{"ID": "00300112", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Secondly,the capacity to integrate methods and project components. After the procedures were chosen based on the criteria (simple, simple to learn, and simple to use), a significant issue—the adaptability between the parts—arose. When data is sent from the front end to the back end (post error), or when the back end saves data to the database, there are several problems that show up. The application’s need to merge the admin page with the user’s search page was the biggest issue. It took me a long time to figure out the address to replace and the event to use every time a user clicks on the search page because of the inconsistencies between the technologies.", "label": "human"}
{"ID": "00300113", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Finally,Although this is not the most complete product and more features will need to be developed in the future, after the last three months, my application has been finished and is usable, and I have met the criteria I laid out at the project’s commencement.", "label": "human"}
{"ID": "00300114", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Final solution and result Following the approach I outd above,This software will add settings that the store owner can define to the search page of Shopify to make it easier to use, such as \"most searched terms,\" \"color direct the items,\" and \"color price of the sought product.\" This allows the shop actively alter in accordance with the products it owns, making the monetization page more user-friendly and giving the business better access to techniques. SEO initiative.", "label": "human"}
{"ID": "00300115", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Problem The program has to include an admin edit page so that the search page may be as user-friendly as feasible and can be altered in accordance with the store owner’s sales plan.", "label": "human"}
{"ID": "00300116", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Requirement The requirement is,use shopify’s available api to install apps based on shopify’s available resources 5.2.3 ApproachWe must separate the admin page into the admin front-end and the admin back end in order to develop it. The information that has to be altered for the search page is on the front-end admin page. I decided to utilize vuejs for the front-end in order to reduce the amount of code and deliver the best speed. In addition, I choose the Laravel framework for my back-end in order to effectively employ the MVC approach. Following the shop owner’s selection, the data to be installed for the search page is then transferred to the back-end and stored to the database before being retrieved and installed there.", "label": "human"}
{"ID": "00300117", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Difficulties encountered The admin page will be the primary component of this project as opposed to the search page. These are the challenges in this section: First off, there are issues with receiving and sending data between the front end and the back-end since theauthentication components of Shopify and Laravel are not synced. As a result, while sending and receiving data between the back-end and front-end, The time it takes to send and receive data grows when more tokens are attached at the top.", "label": "human"}
{"ID": "00300118", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Secondly,Given that it may reload instantly after saving the code, vuejs is a simple language to learn and use and has the capacity to minimize page refresh times as much as feasible. I took a lot of effort to identify and correct those problems because I don’t know what caused them.", "label": "human"}
{"ID": "00300119", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Final solution and result Following the approach I outd above,I’ve successfully created a front-end admin page with key features including web and Shopify logins, as well as the ability to update data in accordance with the store owner’s preferences. Figure 5.2 illustrates login page from URL.", "label": "human"}
{"ID": "00300120", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "In addition, doing the assigned tasks also helps me a lot in improving my programming skills, learning new technologies, especially problem solving skills. I realized that a problem does not have only one solution, should not be stubbornly going in a predetermined direction. I need to be more flexible, map out possible directions and then choose the most suitable one. Exposure to a huge amount of code helps me to have a more open and confident attitude, so that I don’t get overwhelmed by similar tasks in the future.", "label": "human"}
{"ID": "00300121", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "Currently, although the system is working well, there are still some points that can be improved.First,To assist clients in finding the right goods as quickly as possible, the application needs to provide a number of additional search fields, such as price, address, color, ship, etc. Additional technology is required for the application, such as fuzzy search, synonym search, etc.", "label": "human"}
{"ID": "00300122", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "In addition, I need to work on a number of other things, like how I approach and learn new technology. the capacity to recognize issues and identify issues that require solving.hovy1993automated E. H. Hovy, “Automated discourse generation using discourse structure rela- tions,\" Artificial intelligence , vol. 63, no. 1-2, pp. 341–385, 1993 <Sách: Tên tác giả, tên sách, volume (nếu có), lần tái bản (nếu có), nhà xuất bản, năm xuất bản> peterson2007computer L. L. Peterson and B. S. Davie, Computer networks: a systems approach . Elsevier, 2007.", "label": "human"}
{"ID": "00300123", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "<Tập san Báo cáo Hội nghị Khoa học : Tên tác giả, tên báo cáo, tên hội nghị, ngày (nếu có), địa điểm hội nghị, năm xuất bản> poesio2001discourse M. Poesio and B. Di Eugenio, “Discourse structure and anaphoric accessibil- ity,\" in ESSLLI workshop on information structure, discourse structure and discourse semantics , Copenhagen, Denmark, 2001, pp. 129–143.", "label": "human"}
{"ID": "00300124", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "<Đồ án tốt nghiệp, Luận văn Thạc sĩ, Tiến sĩ : Tên tác giả, tên đồ án/luận văn, loại đồ án/luận văn, tên trường, địa điểm, năm xuất bản> knott1996data A. Knott, “A data-driven methodology for motivating a set of coherence relations,\" Ph.D. dissertation, The University of Edinburgh, UK, 1996.", "label": "human"}
{"ID": "00300125", "file_name": "Study research and create a saas-based search engine for e-commerce websites. Quế Hoài Vũ vu.qh176914@sis.hust.edu.vn Major: Information technology Specialization: Global ICT Supervisor: Master of Science Lê Tấn Hùng Signature Department: Information", "content": "<Tài liệu tham khảo từ Internet : Tên tác giả (nếu có), tựa đề, cơ quan (nếu có), địa chỉ trang web, thời gian lần cuối truy cập trang web> BernersTim T. Berners-Lee, Hypertext transfer protocol (HTTP) . [On]. Available:", "label": "human"}
{"ID": "00310001", "file_name": "Building a software system for teaching and learning English", "content": "Multilingualism is becoming increasingly important in today’s world. Aside from expanding job options, knowing a foreign language allows you to interact with people and learn about different countries, places, and lifestyles. The more skilled you are, the more effectively you can express yourself. Although it ranks second behind Mandarin in terms of total speakers, English is the most frequently used language, as it is spoken in more nations than any other.", "label": "human"}
{"ID": "00310002", "file_name": "Building a software system for teaching and learning English", "content": "English is the language of technology, particularly high-tech subjects such as computer science, genetics, and medicine. If you want to read documents in such discips, you’ll generally have to do so in English. In other words, English is a necessary instrument for broadening and illuminating your worldview. Your accessto the world of information will be limited if you do not speak English. Further more, once you have mastered English, you will have more opportunity to learn about other cultures through literature, as most popular international works are translated into English rather than other languages. The majority of material on the Internet is also in English.", "label": "human"}
{"ID": "00310003", "file_name": "Building a software system for teaching and learning English", "content": "More and more individuals are investing time to learning English as a second language these days. Many nations integrate English in their education systems, and children are learning English at an earlier and earlier age. Traditional methodsof learning English have their importance, but they are geographically and chrono logically limited, and also usually pricey.", "label": "human"}
{"ID": "00310004", "file_name": "Building a software system for teaching and learning English", "content": "Learning English has been influenced by technological advancements throughout the years. The emergence of the Electronic Dictionary in the early 2010s trans formed the way individuals learn English. Replacing a bulky paper dictionary witha compact device that contains hundreds of thousands of words and includes capa bilities like pronunciation allows students to be considerably more versatile. Theincreasing in availability of smartphones and laptops and telecommunication tech nology technologies let learner access English learning resources wherever andwhenever they want. Since then, many applications for learning English on all plat forms have been developed and introduced to the market.", "label": "human"}
{"ID": "00310005", "file_name": "Building a software system for teaching and learning English", "content": "Although each product has its own pros, very few of them can combine effec tively between letting people freely choosing what to learn and guiding them to grow properly. Some products only focus on the dictionary features, while otherstry to tie them strictly to lessons. For that reasons, the idea was to built an all-in-one English learning platform where people can access with a competitive pricing.", "label": "human"}
{"ID": "00310006", "file_name": "Building a software system for teaching and learning English", "content": "As mentioned in the section 1.1, products for English education are widely available on the market today. With over 1.75 billion  learner worldwide and the mar ket size of 1.95 billion USD , it’s not surprising that so many companies want to break into this market.", "label": "human"}
{"ID": "00310007", "file_name": "Building a software system for teaching and learning English", "content": "One of which is Duolingo, the biggest platform in 2022 for multilingual learn ing according to Statista . With its popularity, its effectiveness in learning a new language is undeniable. Its multilingual aspect, although a huge plus, unfortunatelydraws the platform away from some essential student necessities, such as the dic tionary feature. Since it is a product aimed at a global market, the contents and pricing are also not completely appropriate for Vietnamese people.", "label": "human"}
{"ID": "00310008", "file_name": "Building a software system for teaching and learning English", "content": "Looking into the domestic market, there are also English learning platforms from local companies. These products compete on lower pricing, however they fall short in terms of features. TFlat dictionary could be seen as an honorable mentions.", "label": "human"}
{"ID": "00310009", "file_name": "Building a software system for teaching and learning English", "content": "While it is one of the richest dictionary for Vietnamese, its features are mostly focus on its own name \"dictionary\".", "label": "human"}
{"ID": "00310010", "file_name": "Building a software system for teaching and learning English", "content": "In this thesis, we design and build a web application for users to teach and learn English. Our web application features word games, dictionary, flashcards, lessons and exercises; administration.", "label": "human"}
{"ID": "00310011", "file_name": "Building a software system for teaching and learning English", "content": "As mentioned in the previous section, our orientation to resolve the business issues is to build a web-based system for learning English.", "label": "human"}
{"ID": "00310012", "file_name": "Building a software system for teaching and learning English", "content": "The system can be divided into two parts: (i) Client-side application with whichthe users interact, (ii) Server-side application which stores data and executes busi ness logic. For the characteristics of the data, which are tightly linked, a relational database is chosen to be our main database. There are also data not suitable for storing in relational database. In this case, a NoSQL database will be used to store them as form of documents. The detailed design for the system will be described in 3 and 4 The functions oriented for this project are as follow:", "label": "human"}
{"ID": "00310013", "file_name": "Building a software system for teaching and learning English", "content": "Authentication : The system will let learners create accounts and track their progress. The accounts will be divided into different roles, and each role has itsown permissions.Dictionary : Dictionary is one of the features that many English learning sys tem are lacking. Having a dictionary integrated into the application prevent user switching to another platform.", "label": "human"}
{"ID": "00310014", "file_name": "Building a software system for teaching and learning English", "content": "Flashcards : Flashcards system are built for users to memorize their words of choice. The flashcards are tied heavily to the dictionary and the lessons that the platform provides.", "label": "human"}
{"ID": "00310015", "file_name": "Building a software system for teaching and learning English", "content": "Lessons exercises : Users can learn lessons and do exercises attached to them, therefore have a clearer route to growth.", "label": "human"}
{"ID": "00310016", "file_name": "Building a software system for teaching and learning English", "content": "Upgrade account : The system provides basic functionalities with free tier, and also let people access special contents with a competitive pricing subscription.", "label": "human"}
{"ID": "00310017", "file_name": "Building a software system for teaching and learning English", "content": "Administration : There will also be a page for administration with the ability to manage users, lessons and exercises. The page also provides current statistics of the platform.", "label": "human"}
{"ID": "00310018", "file_name": "Building a software system for teaching and learning English", "content": "To tackle this problem, the solution we came up with is to crawl the data from dif ferent sources on the internet, then transform the data and store it in our relational database. Therefore, the system might have more control over the data and be easier to get new feature related to those data.", "label": "human"}
{"ID": "00310019", "file_name": "Building a software system for teaching and learning English", "content": "Chapter 2: Surveying will offer specifics about the current situation, evaluate various popular programs operating in the same sector that are already accessible on the market, and analyze business requirements.", "label": "human"}
{"ID": "00310020", "file_name": "Building a software system for teaching and learning English", "content": "Chapter 3: Methodology will present the topic’s primary technologies as well as the environment that technology provides to the system.", "label": "human"}
{"ID": "00310021", "file_name": "Building a software system for teaching and learning English", "content": "Next, in Chapter 4: Experiment and Evaluation, we will study and develop each system function based on the needs assessed, as well as how to implement the system.", "label": "human"}
{"ID": "00310022", "file_name": "Building a software system for teaching and learning English", "content": "Chapter 5: Project Solution ContributionsFinally, Chapter 6 Conclusion will compare our application to the products dis cussed in Chapter 2, providing conclusions and orientations for future development areas.In Chapter 2, surveys will be provided on how English learning systems andplatforms are currently being utilized. These surveys will include user and cus tomer demands as well as a review of the various English learning products used in Vietnam and overseas. The functional and non-functional requirements for our platform in general will be covered later on.", "label": "human"}
{"ID": "00310023", "file_name": "Building a software system for teaching and learning English", "content": "In this day and age, anybody may effortlessly learn any language at any time and from any location using a web or mobile application. On language learning has properly dominated the industry in recent years. There are several websites on the internet that may help you get started. Among the various options for learning a new language, Duolingo, British Council Learn English are a well-known platforms. There are also competitors from the domestic market, one of which is Monkey Junior. We investigated these applications as the foundation for our project.Duolingo Monkey Junior The British Council AppCharacteristics Easily accessi ble, all contents can be accessed for free, allowslearning multi ple languages simultaneouslyWide variety of contents, focusmostly on chil dren from the age of 6 to 10This popular app is solely dedicated toteaching En glish grammar.", "label": "human"}
{"ID": "00310024", "file_name": "Building a software system for teaching and learning English", "content": "Disadvantages Beginners ori ented, provides support best forEnglish speak ers, focus on vocabulary andphrases onlyOnly recom mended for children, focusonly on vocabu lary and phrasesNot suitable fornewcomers, fo cus heavily on courses, lack ofinteractive con tents Dictionary supportNo No No Flashcard Yes No NoVietnamese UI Partially sup portedYes No Pricing Plus:", "label": "human"}
{"ID": "00310025", "file_name": "Building a software system for teaching and learning English", "content": "$69/month Table 2.1: Comparing 3 platforms for learning English From our survey, each platforms has their own strengths and weaknesses. Duolingo, despite being one of the most downloaded language learning apps in the world, still has its own drawbacks. Duolingo focus heavily on games and interactive contents, guiding learners toward phrases and vocabulary, which is very fun and suitable for beginners, but it lacks contents for more intermediate users. As a free-to-use platform, its approach to the market is still undeniably effective.", "label": "human"}
{"ID": "00310026", "file_name": "Building a software system for teaching and learning English", "content": "In contrast, British Council Learning English App provides mostly on courses and traditional English learning, focus on English grammar. With this platform, it is possible for learners to go from beginner to advanced level. It even provides courses for international English test like the IELTS. However, this product lacks the fun and enjoyment compared to Duolingo, and the pricing also on the heavier side. This site is also not suitable for Vietnamese to start learning English, since it has no support for Vietnamese language.Monkey Junior is a good platform for children to learn English from Vietnam.", "label": "human"}
{"ID": "00310027", "file_name": "Building a software system for teaching and learning English", "content": "With the wide variety of contents, creativeness, friendly UI, and appropriate one time payment, it became one of the top choices when it comes to teach English to children. As much good as it is, the platform only stick with its young set of users.", "label": "human"}
{"ID": "00310028", "file_name": "Building a software system for teaching and learning English", "content": "While researching, we found out that all 3 platforms do not integrate dictionar ies to their platform. Although there are many dictionary out there already in the market, integrate one inside our learning application will create a more cohesiveexperience. Therefore, letting people have access to everything in only one plat form is our main priority.", "label": "human"}
{"ID": "00310029", "file_name": "Building a software system for teaching and learning English", "content": "To summarize, to provides best English learning experience for Vietnamese peo ple, we will create our system navigating toward the Vietnamese market. Which means (i) the user interfaces should be in Vietnamese, (ii) the contents should be suitable for Vietnamese culture, and (iii) the pricing should be competitive. For the scope of this thesis, below are the features desired to be implemented:", "label": "human"}
{"ID": "00310030", "file_name": "Building a software system for teaching and learning English", "content": "Learn courses and do exercises Managing users, courses and more.2.2 Functional Overview 2.2.1 General use case diagram Figure 2.1: General use case diagram of the application The system contains of 4 main actors.", "label": "human"}
{"ID": "00310031", "file_name": "Building a software system for teaching and learning English", "content": "User is the most basic actor, which represent a general person accessing our sys tem. An user is able to search for words using the system dictionary, and memorizethem through flashcards. The actor also have access to lessons, exercises, and can upgrade account to unlock new contents and features.", "label": "human"}
{"ID": "00310032", "file_name": "Building a software system for teaching and learning English", "content": "Teacher acts as a supporter for students and manages the contents uploaded to the system, which includes exercises and lessons. Teacher also has all the ability of a User.", "label": "human"}
{"ID": "00310033", "file_name": "Building a software system for teaching and learning English", "content": "Administrator is in charge of decentralization and system management. Ad ministrator can manage both User and Teacher, and has all the abilities.", "label": "human"}
{"ID": "00310034", "file_name": "Building a software system for teaching and learning English", "content": "Detailed use case \"Use Dictionary\" Figure 2.2: \"Use Dictionary\" detailed use case diagram The use case \"Use Dictionary contains of 3 main functions: (i)Looking for wordtranslation, (ii)Add current word to a flashcard collection, and (iii)Assessing pro nunciation. To use feature (ii) and (iii), user must be authenticated by the system.2.2.3 Detailed use case \"View Flashcard Collection\" Figure 2.3: \"View Flashcard Collection\" detailed use case diagram People can access the flashcard collections and their details anonymously, with only the permission to view. Once an user is logged in, he/she will be able to make changes to the flashcard collections which they created or are following.", "label": "human"}
{"ID": "00310035", "file_name": "Building a software system for teaching and learning English", "content": "Detailed use case \"Learn Lesson\" Figure 2.4: \"Learn Lesson\" detailed use case diagram The \"Learn Lesson\" use case always require user to be authenticated. This use case provides the functions to view lessons in list or by category. From there, users can access the lesson content, comment their questions. Once the lesson is finished, exercise section for that lesson will be unlocked, and user will be able to fill andsubmit the exercise. After finishing exercise, it is able to see attempts history, and redo the exercise.", "label": "human"}
{"ID": "00310036", "file_name": "Building a software system for teaching and learning English", "content": "Detailed use case \"Upgrade Account\" Figure 2.5: \"Upgrade Account\" detailed use case diagram Similar to 2.4, this use case also require users to be logged in. The use case includes (i)selecting package, (ii)selecting package duration, (iii)making payment, and (iv)redeeming the codes.", "label": "human"}
{"ID": "00310037", "file_name": "Building a software system for teaching and learning English", "content": "Detailed use case \"Manage Lesson\" Figure 2.6: \"Manage Lesson\" detailed use case diagram Manage lesson\" is the use case specified for the actor Teacher . The teacher actor’s function in this use case is managing the list of lesson, creating, modifying, and deleting lessons. Login required.2.2.7 Detailed use case \"Manage Exercise\" Figure 2.7: \"Manage Exercise\" detailed use case diagram This use case is nearly identical with the section 2.2.6, with the functions ofviewing exercise list and doing CRUD operations. The actor could also view exer cises’ statistics, which provide detail insight of the selected exercise.", "label": "human"}
{"ID": "00310038", "file_name": "Building a software system for teaching and learning English", "content": "Detailed use case \"Manage Members\" Figure 2.8: \"Learn Lesson\" detailed use case diagram s Administrator has the permission to manage members. An administrator can change privilege of a specific member, making it a Teacher or an Administrator.", "label": "human"}
{"ID": "00310039", "file_name": "Building a software system for teaching and learning English", "content": "The actor can also change package information of each account, which related to contents and features unlocking or limitation.2.3 Functional description 2.3.1 Description of use case \"Login\" Brief Description: As a user, I want to login to the system to access more features and contents.", "label": "human"}
{"ID": "00310040", "file_name": "Building a software system for teaching and learning English", "content": "Input data: None Output data: None Use case ID 001 Use case name Login Actor User Pre-condition User is not logged in Main flowNo. Actor Action 1 User Click \"Login\" 2 System Show login form 3 User Fill in username and password 4 User Click \"Confirm\" 6 System Verify inputs 5 System Verify account 6 System Generate token for user 7 System Notify user 8 System Redirect to home page Alternative flowNo. Actor Action 6a System Alert invalid inputs 7a System Alert invalid account Post-condition System recorded lesson progress for user Table 2.2: Description of use case \"Login\" 2.3.2 Description of use case \"View Lesson Content\" Brief Description: As a user, I want to view lesson available on the website.", "label": "human"}
{"ID": "00310041", "file_name": "Building a software system for teaching and learning English", "content": "Input data: None Output data: NoneUse case ID 002 Use case name View Lesson Content Actor User Pre-condition User is logged in and currently in lesson preview page Main flowNo. Actor Action 1 User Click \"Start lesson\" 2 System Check package permission 3 System Get lesson contents 4 System Bind lesson to view 5 User Click \"Finish lesson\"6 System Check if lesson has flashcard col lection 7 System Ask user if they want to add to their collections 8 User Click \"Yes\" 9 System Add lesson flashcard collection to user’s collections 10 System Record user lesson progress11 System Redirect to lesson preview and al low doing exercise Alternative flowNo. Actor Action 7a User Click \"No\" 7a1 System Record user lesson progress7a2 System Redirect to lesson preview and al low doing exercise Post-condition System recorded lesson progress for user Table 2.3: Description of use case \"View Lesson Content\" 2.3.3 Description of use case \"Do Exercise\" Brief Description: As a user, I want to do exercises after finishing a lesson.", "label": "human"}
{"ID": "00310042", "file_name": "Building a software system for teaching and learning English", "content": "Input data: None Output data: NoneUse case ID 003 Use case name Do Exercise Actor User Pre-condition User is logged in and had finished lesson Main flowNo. Actor Action 1 User Click Begin2 System Get Exercise and Questions infor mation 3 System Binding questions to view 4 User Choose answer 5 System Record all answers 6 User Click “Submit” 7 System Calculate exercise result and save attempt 8 System Announce result 9 User Press Confirm 10 System Redirect to lesson preview and show history Alternative flow Post-condition System recorded attempt history for each submission Table 2.4: Description of use case \"Do exercise\" 2.3.4 Description of use case \"Upgrade Account\" Brief Description: As a user, I want to upgrade my account so I can have more contents and features.", "label": "human"}
{"ID": "00310043", "file_name": "Building a software system for teaching and learning English", "content": "Input data: None Output data: NoneUse case ID 004 Use case name Upgrade account Actor User Pre-condition User is logged in Main flowNo. Actor Action 1 User Click \"Upgrade account\" 2 System Redirect user to upgrade page 3 User Choose package and period 4 System Show payment popup 5 User Fill in payment card details 6 User Click “Submit” 7 System Send request to payment system to make purchase 8 Payment System Verify purchase and send result 9 System Send email with redeem code to user 10 System Show result 11 User Press Confirm 12 System Redirect to redeeming screen 13 User Redeem code 14 System Verify code 15 System Show result and redirect to login screen.", "label": "human"}
{"ID": "00310044", "file_name": "Building a software system for teaching and learning English", "content": "To deliver a smooth and speedy user experience, the system must fulfill the following non-functional criteria in addition to the business requirements: (i) The application’s interface should be well-designed and get feedback from the system fast. (ii) Application components on the user’s site must be operated without logical errors or compromising the original user interface. (iii) The program must provide good performance as the number of users in the system grows, constantly ensuring that the system is not overloaded.", "label": "human"}
{"ID": "00310045", "file_name": "Building a software system for teaching and learning English", "content": "Chapter Summaries Preliminary surveys on English Learning solutions from Vietnam and around the world were provided in Chapter 2. We had a better understanding of whatneeded to be done to create a platform fit for the Vietnamese market as a result of the survey, and we drew out the functional and non-functional needs for our application. We will look at what was used to construct such a platform in the following chapter 3.Chapter 2 looked at the application requirements and the specific requirements that the application must fulfill. In chapter 3, we will describe the technologies implemented in Front-end and Back-end and services used in the project.", "label": "human"}
{"ID": "00310046", "file_name": "Building a software system for teaching and learning English", "content": "A good architecture is essential for developing scalable, modular, and main tained programs. Different architectures may differ in their features, but they always strive for the same goal: separation of concerns. And they all attempt to establish this separation by layering the application.", "label": "human"}
{"ID": "00310047", "file_name": "Building a software system for teaching and learning English", "content": "Clean ArchitectureClean Architecture is a software architecture designed to keep code under con trol while avoiding the tidiness that prevents anybody from modifying code once it has been released. The basic idea behind Clean Architecture is that applicationcode/logic that is unlikely to change should be developed without any direct de pendencies. So if we alter our framework, database, or user interface, the core of the system (Business Rules/ Domain) should not change. It means that external dependencies can be fully replaced.Figure 3.1: Clean architecture The Domain and Application layers remain in the base of the design, known as the Core of the system, in Clean architecture. Enterprise logic is contained in thedomain layer, whereas business logic is included in the application layer. Enter prise logic can be shared across several systems, however business logic is often employed just within the system. The core will be unaffected by data access or other infrastructure issues. And we can accomplish this by utilizing interfaces and abstraction within the Core and having other layers outside of the Core implement them.", "label": "human"}
{"ID": "00310048", "file_name": "Building a software system for teaching and learning English", "content": "All dependencies flow inwards in Clean Architecture, and Core is independent on any other layer. And the Infrastructure and Presentation layers are dependent on the Core.", "label": "human"}
{"ID": "00310049", "file_name": "Building a software system for teaching and learning English", "content": "The Advantages of Clean Architecture Database and framework independence Unrelated to the presentation layer. We may alter the UI at any moment without affecting the rest of the system or business logic. Highly testable, particularly the fundamental domain model and associated business rules.", "label": "human"}
{"ID": "00310050", "file_name": "Building a software system for teaching and learning English", "content": "Database and framework independence•Unrelated to the presentation layer. We may alter the UI at any moment with out affecting the rest of the system or business logic.", "label": "human"}
{"ID": "00310051", "file_name": "Building a software system for teaching and learning English", "content": "Microservices Architecture A Microservices architecture, known as Microservices, is an architecturalparadigm based on a collection of independently deployable services. These ser vices are self-contained, with their own business logic and database, and they servea specific function. Each service is updated, tested, deployed, and scalable. Microservices isolate critical business challenges into discrete code bases. Microservices do not reduce complexity, but they do make it visible and controlled by breaking operations down into tiny processes that operate independently while contribut ing to the overall system. As a result, developers may focus on one microservicewithout worrying about the others. This centralized model implies that develop ment cycles for several teams are shorter, and firms can get goods to market faster.", "label": "human"}
{"ID": "00310052", "file_name": "Building a software system for teaching and learning English", "content": "Microservices are usually associated with DevOps because they serve as the foundation for continuous delivery methodologies that allow teams to respond to changing customer requirements quickly. More businesses are moving away from monolithic approaches and toward microservices.", "label": "human"}
{"ID": "00310053", "file_name": "Building a software system for teaching and learning English", "content": "A REST API  (also known as a RESTful API) is an API (a set of definitions and protocols for developing and integrating application software) that follows tothe constraints of the REST architectural style and allows interaction with REST ful web services. When a client uses a RESTful API to request a resource, theresource’s REST is sent to the requester or endpoint. This information, or repre sentation, is sent via HTTP in one of several formats: JSON (Javascript Object Notation), HTML, XML, Python, PHP, or plain text. This is a well-known mode of communication in web applications.", "label": "human"}
{"ID": "00310054", "file_name": "Building a software system for teaching and learning English", "content": "Basic technologies for web programming The World Wide Web, the most popular platform utilized by 4.9 billion people worldwide, is the foundation around which our application is built. Therefore, we should have a fundamental grasp of the components that make up a web applicationbefore delving further into the program’s core.", "label": "human"}
{"ID": "00310055", "file_name": "Building a software system for teaching and learning English", "content": "HTML HTML (Hyper Text Markup Language)  is a standard markup language for web pages established by the W3C (World Wide Web Consortium) that aids in the definition of a page’s text structure. HTML elements are represented by tags, which are often expressed in pairs. HTML is something that a browser can comprehend and present to the user as an interactive interface.", "label": "human"}
{"ID": "00310056", "file_name": "Building a software system for teaching and learning English", "content": "CSS is a language that specifies the style of an HTML document. It makes the website more colorful and appealing. We may modify the font style, font size, color, and many other aspects of the webpage using CSS.", "label": "human"}
{"ID": "00310057", "file_name": "Building a software system for teaching and learning English", "content": "SCSS is a CSS superset used for client-side styling. SCSS is essentially a more advanced version of CSS that enables cleaner, more manageable style as well as a major increase in capability. Variables, operators, nested syntax, functions, andmany more capabilities are available in SCSS. SCSS is our tool of choice for de veloping and styling the web client.", "label": "human"}
{"ID": "00310058", "file_name": "Building a software system for teaching and learning English", "content": "JavaScript & TypeScriptJavaScript  is a scripting language for creating interactive web pages. It fol lows client-side programming standards, meaning it operates in the user’s web browser without requiring any resources from the web server.", "label": "human"}
{"ID": "00310059", "file_name": "Building a software system for teaching and learning English", "content": "TypeScript  is a JavaScript programming language from the current era. It is a statically built language for writing concise JavaScript code. TypeScript has static typing, classes, and an interface. Adopting Typescript for a big JavaScript project can result in more robust software that is readily deployed alongside a standard JavaScript application. TypeScript was also officially supported by the framework that we used, which will be described in the next section.", "label": "human"}
{"ID": "00310060", "file_name": "Building a software system for teaching and learning English", "content": "AngularEven though a web application can be build by using only web vanilla technolo gies, it might be cumbersome to manage and maintain as your application grows.", "label": "human"}
{"ID": "00310061", "file_name": "Building a software system for teaching and learning English", "content": "Therefore, many web framework and libraries, like React, Vue and Angular, has been developed to solve these issues, speed up the developing process, and also optimize performance of your applications.", "label": "human"}
{"ID": "00310062", "file_name": "Building a software system for teaching and learning English", "content": "Google’s Angular is a JavaScript framework for creating Single Page Appli cations (SPAs) with JavaScript, HTML, and TypeScript. Angular offers built-incapabilities for animation, http service, auto-complete, navigation, toolbar, menus, and so on. The code is written in TypeScript and compiles to JavaScript before being shown in the browser.", "label": "human"}
{"ID": "00310063", "file_name": "Building a software system for teaching and learning English", "content": "The core building elements of the Angular framework are Angular components ar ranged into NgModules. NgModules organize related code into functional groups;an Angular application is defined by a collection of NgModules. An application al ways contains at least one root module that facilitates bootstrapping, and it usually has many more feature modules.", "label": "human"}
{"ID": "00310064", "file_name": "Building a software system for teaching and learning English", "content": "Components make use of services, which provide functionality that is not directlyconnected to views. Service providers can be injected as dependencies into com ponents, making your code modular, reusable, and efficient.", "label": "human"}
{"ID": "00310065", "file_name": "Building a software system for teaching and learning English", "content": "Material UIMaterial UI is the most powerful and efficient tool for developing an appli cation by incorporating designs and animations, as well as combining technological and scientific innovation. It is essentially a design language created by Google in 2014. It includes additional design and animations, a grid system, and shadows and lighting effects.", "label": "human"}
{"ID": "00310066", "file_name": "Building a software system for teaching and learning English", "content": "It can be used with any JavaScript frameworks and libraries, such as Angular and VueJS, to make the application more fantastic and responsive. Material UI is one of the leading React User Interface frameworks, with over 35,000 stars onGitHub.", "label": "human"}
{"ID": "00310067", "file_name": "Building a software system for teaching and learning English", "content": "By using Material UI, the application user interface will be more elaborate and consistent, and provides better experience to users.", "label": "human"}
{"ID": "00310068", "file_name": "Building a software system for teaching and learning English", "content": "NET 6.0Microsoft .NET  is a software framework and development ecosystem de signed to facilitate application engineering for on and desktop environments. Itnow supports the programming environment for most phases of software develop ment, therefore it has a wide range of applications and use cases.", "label": "human"}
{"ID": "00310069", "file_name": "Building a software system for teaching and learning English", "content": "NET is a suitable development option for firms seeking for a variety of capabil ities in their software, such as desktop applications, cloud infrastructure support, and web-based services.", "label": "human"}
{"ID": "00310070", "file_name": "Building a software system for teaching and learning English", "content": "NET is built on the object-oriented programming model (OOP). This technique divides data into objects (data fields) and utilizes class declarations to define the behavior and contents of the objects. This OOP development’s modular structure allows developers to establish object interactions without having to handle their inner characteristics. In the long term, this simplifies development since the code is easier to test, more manageable, and responsive to problems.", "label": "human"}
{"ID": "00310071", "file_name": "Building a software system for teaching and learning English", "content": "Code written using .NET Core can support cross-platform application, which can run on Windows, macOS, and Linux. While the original.NET framework wasnot totally open and did not provide such cross-compatibility, the.NET Core in cludes fully open-source technology to guarantee the proliferation of use cases throughout the developer community. From C to Visual Basic, code created in.NET will operate on any supported operating system, allowing businesses to access a wide range of platforms without leaving the ecosystem.", "label": "human"}
{"ID": "00310072", "file_name": "Building a software system for teaching and learning English", "content": "It is simple to install as part of a program or separately. The platform’s modular architecture incorporates all essential dependencies, making deployment as simple as copying a folder. Additionally, multiple.NET Core versions may operate on the same machine at the same time, making it simple to work on different projects while smoothly executing deployment.", "label": "human"}
{"ID": "00310073", "file_name": "Building a software system for teaching and learning English", "content": "With the latest version, .NET 6.0 simplifies the developing process, and bringsbetter performance at the same time. The version 6.0 also listed as long-term sup port, which is suitable for building a stable system.3.4.2 Authentication - JSON Web Token (JWT)Authentication is the process of ascertaining whether or not someone or some thing is who or what they claim to be. Authentication technology controls systemaccess by determining if a user’s credentials match those in a database of autho rized users or in a data authentication server. Authentication ensures safe systems, secure processes, and organizational information security in this way.", "label": "human"}
{"ID": "00310074", "file_name": "Building a software system for teaching and learning English", "content": "JSON Web Token (JWT) is an open standard (RFC 7519) that offers a con cise and self-contained method for securely sending information between parties as a JSON object. Because it has been digitally signed, this information can bechecked and trusted. JWTs can be signed with a secret (using the HMAC algo rithm) or a public/private key pair (using RSA or ECDSA).", "label": "human"}
{"ID": "00310075", "file_name": "Building a software system for teaching and learning English", "content": "Although JWTs can be encrypted to offer confidentiality between parties, we will concentrate on signed tokens. Signed tokens can validate the claims contained inside them, whereas encrypted tokens conceal those claims from third parties.", "label": "human"}
{"ID": "00310076", "file_name": "Building a software system for teaching and learning English", "content": "When tokens are signed with public/private key pairs, the signature also confirms that only the party with the private key signed it.", "label": "human"}
{"ID": "00310077", "file_name": "Building a software system for teaching and learning English", "content": "A refresh token is used to produce a new access token. If the access token con tains an expiration date, the user must authenticate again to acquire an access token once it expires. This phase can be avoided with a refresh token and a request to the API to obtain a new access token that allows the user to continue accessing the application resources.", "label": "human"}
{"ID": "00310078", "file_name": "Building a software system for teaching and learning English", "content": "Our application use JWT as the main method of authenticating user, with the use of both access token and refresh token.", "label": "human"}
{"ID": "00310079", "file_name": "Building a software system for teaching and learning English", "content": "Database A database is a structured collection of data that is often stored and accessible digitally via a computer system. It allows for data storage and manipulation. In other words, databases are utilized by businesses to store, manage, and retrieve information.", "label": "human"}
{"ID": "00310080", "file_name": "Building a software system for teaching and learning English", "content": "In our application, there were 2 databases that we used - MySQL and MongoDB a, MySQL MySQL is the most popular database in the world, ranking second only to Oracle Database. MySQL is the most common open source database currently in use. It was called after its founder’s daughter My, and is notable for arranging data into one or more data tables in which data kinds are connected to one other. It is one of the most trustworthy and performative databases available. Because SQL is a programming language used to create, modify, and extract data from a relational database, these relationships assist structure data.", "label": "human"}
{"ID": "00310081", "file_name": "Building a software system for teaching and learning English", "content": "MySQL is a structured query language relational database. Relational databasesare a form of database that employs a structure to identify and access data in rela tion to other data within the database.", "label": "human"}
{"ID": "00310082", "file_name": "Building a software system for teaching and learning English", "content": "Multiple storage engines, including InnoDB, CSV, and NDB, can be used with MySQL to store and access data. For improved performance and durability, MySQL is also capable of data replication and table partitioning. Users using MySQL do not need to learn any new SQL commands in order to access their data.", "label": "human"}
{"ID": "00310083", "file_name": "Building a software system for teaching and learning English", "content": "Developed in C and C++, MySQL runs on more than 20 different operating sys tems, including Mac, Windows, Linux, and Unix. Numerous data types, including signed or unsigned integers of lengths 1, 2, 3, 4, and 8 byte(s), FLOAT, DOUBLE, CHAR, VARCHAR, BINARY, are supported by RDBMS, which also supportsmassive databases with millions of records.", "label": "human"}
{"ID": "00310084", "file_name": "Building a software system for teaching and learning English", "content": "For security, MySQL uses an encrypted access and password system that allows server-based verification. MySQL clients can connect to the MySQL Server using a number of protocols, including TCP/IP on any platform. MySQL also supports a number of client and utility programs, command  programs, and administrative tools such as MySQL Workbench. Not simply from a data standpoint, but also from a development one, MySQL is dependable. It is established, regularly updated with patches, and supported by a strong development community. Compared to more recent, less developed RDBMS choices, this makes it a secure option.", "label": "human"}
{"ID": "00310085", "file_name": "Building a software system for teaching and learning English", "content": "MongoDBThe most well-known NoSQL database, MongoDB, is a free, documentoriented database. Non-relational is what \"NoSQL\" refers to. It means that Mon goDB offers a completely alternative mechanism for data storage and retrieval and is not based on the relational database structure that resembles a table. The name of this storage format is BSON ( similar to JSON format).", "label": "human"}
{"ID": "00310086", "file_name": "Building a software system for teaching and learning English", "content": "Tabular data is stored in SQL databases. This data is kept in a preset data model that isn’t very flexible for the modern, rapidly expanding real-world applications.", "label": "human"}
{"ID": "00310087", "file_name": "Building a software system for teaching and learning English", "content": "Due to their architecture, relational database management systems (RDBMS) are not the best option for handling massive data because they are not horizontally scalable. The database will hit a scaling limit if it uses a single server. NoSQLdatabases offer better performance and are more scalable. With its adaptable document model, MongoDB, a NoSQL database, boosts productivity by adding ever more servers.", "label": "human"}
{"ID": "00310088", "file_name": "Building a software system for teaching and learning English", "content": "Document Oriented : MongoDB stores the main subject in the minimal num ber of documents and not by breaking it up into multiple relational structures likeRDBMS. For example, it stores all the information of a computer in a single doc ument called Computer and not in distinct relational structures like CPU, RAM, Hard disk, etc.", "label": "human"}
{"ID": "00310089", "file_name": "Building a software system for teaching and learning English", "content": "Indexing : Without indexing, a database would have to scan every document of a collection to select those that match the query which would be inefficient. So, for efficient searching Indexing is a must and MongoDB uses it to process huge volumes of data in very less time. Scalability : MongoDB scales horizontally using sharding (partitioning data across various servers). Data is partitioned into datachunks using the shard key, and these data chunks are evenly distributed across shards that reside across many physical servers. Also, new machines can be added to a running database.", "label": "human"}
{"ID": "00310090", "file_name": "Building a software system for teaching and learning English", "content": "Replication and High Availability : MongoDB increases the data availabilitywith multiple copies of data on different servers. By providing redundancy, it pro tects the database from hardware failures. If one server goes down, the data can be retrieved easily from other active servers which also had the data stored on them.", "label": "human"}
{"ID": "00310091", "file_name": "Building a software system for teaching and learning English", "content": "Aggregation : Aggregation operations process data records and return the com puted results. It is similar to the GROUPBY clause in SQL. A few aggregation expressions are sum, avg, min, max, etc Because of the flexibility of MongoDB, it was used in our application to store more complex data such as lessons content or exercises’ questions.", "label": "human"}
{"ID": "00310092", "file_name": "Building a software system for teaching and learning English", "content": "Message broker and RabbitMQIn modern cloud architecture, applications are decoupled into smaller, independent building blocks that are easier to develop, deploy and maintain. Message bro kers provide communication and coordination for these distributed applications.", "label": "human"}
{"ID": "00310093", "file_name": "Building a software system for teaching and learning English", "content": "A message broker (also known as an integration broker or interface engine) is an intermediary computer program module that translates a message from the formal messaging protocol of the sender to the formal messaging protocol of the receiver.", "label": "human"}
{"ID": "00310094", "file_name": "Building a software system for teaching and learning English", "content": "Message brokers are elements in telecommunication or computer networks where software applications communicate by exchanging formally-defined messagesRabbitMQ  functions as a message broker, accepting and forwarding mes sages. Consider it like a post office: if you put your mail in a post box, you can be sure that the letter carrier will eventually deliver it to your receiver. RabbitMQ is a post box, a post office, and a letter courier in this example. The primary distinction between RabbitMQ and the post office is that it takes, stores, and forwards binary blobs of data messages rather than paper.", "label": "human"}
{"ID": "00310095", "file_name": "Building a software system for teaching and learning English", "content": "Let assume you now have a web service that must receive a large number of requests every second while ensuring that not a single request is dropped. And instead of being locked because it is processing the previous request, your web service is always ready to take a new request. So the goal is to queue them between the web service and the processing service. This will ensure that the two processes are fully independent of one another. Furthermore, when the number of requests becomes exceedingly enormous, the queue will hold them all without missing any.", "label": "human"}
{"ID": "00310096", "file_name": "Building a software system for teaching and learning English", "content": "Chapter Summaries This chapter outs provided you with chosen technologies, what are they, and why we used them. In chapter 4, we will take a look at our system design.In this Chapter 4, we will show the overall design, detailed design, and method of deploying the application based on the findings of the current condition survey as well as the deep business analysis of all aspects in the application provided in 2.", "label": "human"}
{"ID": "00310097", "file_name": "Building a software system for teaching and learning English", "content": "Software architecture selection Figure 4.1: System architectureOur system architecture is illustrated in figure 4.1. Our web application com municates with server through REST API. For tasks required real-time communi-cations, client will connect to services through network socket.", "label": "human"}
{"ID": "00310098", "file_name": "Building a software system for teaching and learning English", "content": "Our server is based on the simplified version of microservices architecture, in which most of the main business logic will be handled by our main .NET 6.0 server, while specific tasks will be executed by our services (or workers).", "label": "human"}
{"ID": "00310099", "file_name": "Building a software system for teaching and learning English", "content": "Our main server, which is implemented with .NET 6.0, used the Clean Architecture (section 3.1.1). Detailed application for our main server with Clean Archi tecture is describe more in section 4.1.3.", "label": "human"}
{"ID": "00310100", "file_name": "Building a software system for teaching and learning English", "content": "There are two main types of workers in our system, the independent ones, which decides all is logic independently, and the dependent ones, which need to receive informations from other services to be able to do their duties. In order to communi cate with each others, we used RabbitMQ as a message broker which mentioned in section 3.4.4. By using this, our services can send and receive information, without having to deal with others’ business logic.", "label": "human"}
{"ID": "00310101", "file_name": "Building a software system for teaching and learning English", "content": "For storing data, our system used MySQL as the main database, storing most information for our application. Where as MongoDB is used in addition to store document type data. Both databases are described in details in section 4.2.34.1.2 Overall design Figure 4.2: Overall package design Our package design consists of two main components: Client andServer The client application is designed with Angular 14, which divides the app into modules. Each module may contain Angular essential components that compose pages in our application. To connect with the server, the client must send an request using the Services package. Services manage application states and send HTTP requests to the main server.", "label": "human"}
{"ID": "00310102", "file_name": "Building a software system for teaching and learning English", "content": "The ApplicationCore package represents the Application and Domain compo-nent in the Figure ??. The Services package is responsible for executing businesslogic. The Entities package contains all database entities for the whole system. In terfaces defines rules for communication between packages. Interfaces and Entities packages combined become the Domain from the Figure ??, and Services stand for Application component. As the name implies, ApplicationCore is the heart of our server, on which most other packages in the system depend.", "label": "human"}
{"ID": "00310103", "file_name": "Building a software system for teaching and learning English", "content": "API and Infrastructure packages stand at the outer layer of the architecture. Both packages depend on ApplicationCore. Infrastructure is used for communicating with the database, and it use the DBHelper package for establishing connections.", "label": "human"}
{"ID": "00310104", "file_name": "Building a software system for teaching and learning English", "content": "API package handle incoming requests from the client. Beside using Application Core for executing business logic, API package also use the Authentication package to authenticate.", "label": "human"}
{"ID": "00310105", "file_name": "Building a software system for teaching and learning English", "content": "Finally, QueueHelper package is used for accessing the MessageBroker of the system. The package also used by others subsystem in order to communicate with the main server.", "label": "human"}
{"ID": "00310106", "file_name": "Building a software system for teaching and learning English", "content": "For specific tasks, there will be independent services, also known as workers, to support the main server. These workers will be described more in the Chapter 5.4.1.3 Detailed package design Figure 4.3: Detailed package design diagram In the section 4.1.3, we have describe about how the system will depend on the ApplicationCore package. The Interfaces package contains 2 packages IService and IRepository, each of which contains interfaces for corresponding classes.", "label": "human"}
{"ID": "00310107", "file_name": "Building a software system for teaching and learning English", "content": "ApplicationCore implements classes for the IService package, while class implementation for IRepository package will be implemented in Infrastructure pack age. By keeping both service and repository interfaces in the same space, all the business logic and actions are controlled by the ApplicationCore. The Entities package contains a BaseEntity class which holds common attributes and actions.", "label": "human"}
{"ID": "00310108", "file_name": "Building a software system for teaching and learning English", "content": "Since both the API package and Infrastructure package refer to ApplicationCore, they can access both the Interfaces and the Entities.", "label": "human"}
{"ID": "00310109", "file_name": "Building a software system for teaching and learning English", "content": "In API packages, request handlers are known as Controllers. In order to commu nicate with ApplicationCore, a controller need to inject the service class instance through interface using DI. The same is true for Infrastructure; in order for servicesto obtain instances of repositories classes, the system will inject the appropriate class instance that corresponds to the repository interfaces. Using DI, a class might be updated or replaced without requiring the entire system to be fixed.", "label": "human"}
{"ID": "00310110", "file_name": "Building a software system for teaching and learning English", "content": "The repository classes use DBHelper package, also by using DI, to get the con nection context instance for the databases. In our system, there are contexts for both MongoDB and MySQL.", "label": "human"}
{"ID": "00310111", "file_name": "Building a software system for teaching and learning English", "content": "Authentication package is similar to ApplicationCore, but only process logic related to the authenticating tasks. It contains Validators and Generators classes for JWT authentication.", "label": "human"}
{"ID": "00310112", "file_name": "Building a software system for teaching and learning English", "content": "User interface design a, Monitor specifications supports resolutions for desktop displays with aspect ratios of 4:3, 16:9, 16:10, or 21:9 with the minimum resolution of 1280x720px. For the scope of the thesis, only desktop screens are supported, there is no native support for mobile screen at the time of this writing. The software can display 8-bit color spectrum, which is standard for a website.", "label": "human"}
{"ID": "00310113", "file_name": "Building a software system for teaching and learning English", "content": "User Interface Illustration Figure 4.4: Dictionary screen mockupFigure 4.5: Flashcard collection list screen mockup Figure 4.6: Flashcard collection details mockupFigure 4.7: Lesson preview screen mockup Figure 4.8: Lesson detail screen mockupFigure 4.9: Do exercise screen mockup Figure 4.10: Exercise overview screen mockupFigure 4.11: List for admin pages mockup 4.2.2 Layer designIn this section, we will have a proper look at three base classes that forms appli cation’s main flow.", "label": "human"}
{"ID": "00310114", "file_name": "Building a software system for teaching and learning English", "content": "sessionData SessionData Contains authenticated user information Table 4.1: Attributes of BaseController class Operations No Name Return Type Description 1 GetById IActionResult Get record by id 2 GetDetailByID IActionResult Get record details by id 3 Post IActionResult Add new record 4 Put IActionResult Edit record 5 Delete IActionResult Delete record 6 MassSave IActionResult Add multiple record 7 UpdateByFields IActionResult Update data of fields 8 QueryList IActionResult Get list data 9 GetTableStruct IActionResult Get table structure for list Table 4.2: Operations of BaseController class ParametersNo Name Description 1 id ID of record 2 entity The information required of type T 3 entities List of entity 4 body Contains information of fields’ name and their new value 5 filterRequest information about filtering a list Table 4.3: Parameters of BaseController class b, BaseService class Figure 4.14: Design of BaseService class Attributes No Name Data Type Description 1 repository IBaseRepository<T> The main repository that communicates with database.", "label": "human"}
{"ID": "00310115", "file_name": "Building a software system for teaching and learning English", "content": "sessionData SessionData Contains authenticated user information 3 serviceResult ServiceResult Response of the service Table 4.4: Attributes of BaseService class OperationsNo Name Return Type Description 1 CreateTask void Create new task with correct context 2 GetById ServiceResult Get record by id 3 GetDetailsById ServiceResult Get record details by id 4 Add ServiceResult Add new record 5 BeforeAdd void Process data before add 6 AfterAdd void Process logic after adding completed 7 AsyncAfterAdd void Process logic after adding completed asynchronously 8 MassAdd ServiceResult Add multiple records 9 Update ServiceResult Update record 10 BeforeUpdate void Process data before update 11 AfterUpdate void Process data before update completed 12 AsyncAfterUpdate void Process data before update completed asynchronously 13 UpdateFields ServiceResult Update fields 14 Delete ServiceResult Delete record 15 ValidateBeforeDelte boolean Check if record can be deleted 16 BeforeDelete void Process data before delete record 17 AfterDelete void Process data after delete record18 AsyncAfterDelete void Process data after delete record asyn chronously 19 Validate boolean Check if entity is valid 20 CustomValidate boolean To be overwritten 21 GetTableStruct ServiceResult Get table structure for list 22 QueryList ServiceResult Get record list Table 4.5: Operations of BaseService class Parameters No Name Description 1 id ID of record 2 entity The information required of type T 3 entities List of entity 4 action Action to be executed 5 oldEntity Entity before updated or deleted 6 fields List of field 7 filters Filter options selected 8 sortBy Field to be sorted 9 sortDirection Sort direction 10 pageNum Page number 11 pageSize Page size Table 4.6: Parameters of BaseService classc, BaseRepository class Figure 4.15: Design of BaseRepository class Attributes No Name Data Type Description 1 repository IBaseRepository<T> The main repository that communicates with database.", "label": "human"}
{"ID": "00310116", "file_name": "Building a software system for teaching and learning English", "content": "sessionData SessionData Contains authenticated user information 3 dbConnection IDBConnection Connection to the database Table 4.7: Attributes of BaseRepository class Operations No Name Return Type Description 1 GetById T Get record by id 2 GetDetailsById T Get record details by id3 GetEnitiesByColumns List<T> Get records by column condi tions 4 QueryList List<T> Get list records 5 QueryListByView List<dynamic> Get list records by DB view 6 Add long Add new record 7 Update int Update record 8 UpdateFields int Update fields 9 Delete int Delete record 10 DeleteByIDs void Delete record by IDs11 MappingDBType DynamicParameters Map query parameters with cor rect types12 MappingDBTypeByField void Map query parameters with cor rect types of selected fields 13 BuildFilterString string Build where clause Table 4.8: Operations of BaseRepository classParameters No Name Description 1 id ID of record 2 ids ID list 3 entity The information required of type T 4 entities List of entity 5 oldEntity Entity before updated or deleted 6 action Action to be executed 7 fields List of field 8 filters Filter options selected 8 formula Formula to combine filters 10 sortBy Field to be sorted 11 sortDirection Sort direction 12 pageNum Page number 13 pageSize Page size Table 4.9: Parameters of BaseRepository classTo have better understanding about classes design, below are two sequence dia grams for the \"Learn lesson\" and \"Do Exercise\" flow.Figure 4.16: \"Learn lesson\" Sequence Diagram Figure 4.16 describes the steps when a member learn a lesson. The data flow will move from client application, through API calls, accessing the server. The server transfers from LessonController to LessonService, then accesses the DB using LessonRepository.Figure 4.17: \"Do exercise\" Sequence Diagram Figure 4.17 describes the steps when a member start doing an exercise.4.2.3 Database design a, Entity Relationship Diagram Figure 4.18: Entity Relationship DiagramThe object organizational structure of the system is represented by the E-R dia gram.", "label": "human"}
{"ID": "00310117", "file_name": "Building a software system for teaching and learning English", "content": "An User can learn multiple Lesson, and vice versa; Each will create a corre sponding record with finished value. A Lesson might contain an Exercise. WhenUser do the exercise, the system also create an attempt record. An User with spec ified roles can create Exercises and Lessons. Users can also comment on multiple lessons.", "label": "human"}
{"ID": "00310118", "file_name": "Building a software system for teaching and learning English", "content": "Flashcard contains one Dictionary Word. A Flashcard can be created by only one User, and must belong to a Flashcard Collection. An user can learn many dif-ferent flashcards, and a Flashcard might be learned by multiple Users. Therefore, the learning status of user with flashcards is stored separately in the system.", "label": "human"}
{"ID": "00310119", "file_name": "Building a software system for teaching and learning English", "content": "Flashcard Collection might be created manually by the User or automatically created when creating a Lesson. User learning Flashcard Collection is n-n relation, with the information of progress status.", "label": "human"}
{"ID": "00310120", "file_name": "Building a software system for teaching and learning English", "content": "Database Design Implementation Figure 4.19: MySQL Database Design Implementation From ER Diagram in figure 4.18, each entity, is given its own table. Each n-n relationship between entities is corresponding to a mapping table in the database,while other relationships are stored as a attributes in either tables.", "label": "human"}
{"ID": "00310121", "file_name": "Building a software system for teaching and learning English", "content": "Source code size 3.5GB Compress size 908MB No. packages of server 11 Table 4.11: Application Information 4.3.3 Illustration of main functions a, Dictionary Figure 4.21: Dictionary screen The Dictionary let user search English word and get result in Vietnamese and English. In addition, there is a float button at right bottom corner for quick adding new flashcard.Figure 4.22: Dictionary pronunciation assessment screenThe system allow all-level user using dictionary pronunciation assessment fea ture. The result will be displayed as in figure above.", "label": "human"}
{"ID": "00310122", "file_name": "Building a software system for teaching and learning English", "content": "FlashcardsFigure 4.23: Flashcard collection list screenThe flashcard collection list screen contains both finished and unfinished col lections. At this screen, users are allowed to create a new collection for themselves.", "label": "human"}
{"ID": "00310123", "file_name": "Building a software system for teaching and learning English", "content": "Exercise Figure 4.30: Do exercise screenDo exercise screen has question palette on the right and the main content of exercise on the left. The system will display a dialog with the result of the exercise after submitting.", "label": "human"}
{"ID": "00310124", "file_name": "Building a software system for teaching and learning English", "content": "Upgrade Account Figure 4.31: Upgrade screenThe upgrade screen displays three packages available in the system: Free, Pre mium and Plus.f, Admin Figure 4.32: Member list screen Member list is displayed in form of a table with search by username, email and full name function.", "label": "human"}
{"ID": "00310125", "file_name": "Building a software system for teaching and learning English", "content": "To illustrate the testing processes, in this section, we will take a look at test cases of upgrading account and doing exercise functions.", "label": "human"}
{"ID": "00310126", "file_name": "Building a software system for teaching and learning English", "content": "Test cases for \"Upgrade account\" Input data No Name Value 1 User01Username: vmhoang Package: Free Free trial used: False 2 User02Username: tthang Package: Plus Free trial used: True Table 4.12: Data for test case \"Upgrade account\"No. Input Expected Result Result T01 Click \"Upgrade account\" Redirect to pricing view PASS T02 User01 click \"Free trial\" Open payment popup PASS T03 User01 typesCard number: 1 EXP: 05/12 CCV: 123Show invalid card warning PASS T04 User01 enters valid card and clickAccept\"Open payment gateway ser vice in new tabFAILED T05 - Show confirmation to the userPASS T06 User02 click \"Free trial\" Show warning trial used PASS T07 User02 select \"Premium 12 months\" open payment popup PASS T08 User02 enters valid card and click Accept\"Show dialog email with code sentPASST09 User02 check emails System sent email with up grade codePASS T10 User02 click \"Redeem code\" Navigate to redeeming code pagePASS T11 User02 types invalid code Show warning PASS T12 User02 types received code Show upgrade success PASS T13 - Redirect to login page PASS Table 4.13: Test cases for \"Upgrade account\" As mentioned in section 4.3.2, the integration with a payment gateway service was not implemented. Therefore, the test case T04 failed.", "label": "human"}
{"ID": "00310127", "file_name": "Building a software system for teaching and learning English", "content": "For server-side, first, we need to start the main server. For email and notifica tion related features, we need to fire up our notifying and emailing workers. In addition, we build the service for checking accounts’ expired date. All the source code for deploying can be found at the server’s repository2. RabbitMQ for message broking message are setup using Docker image following the official RabbitMQ documentation . Queue setup will be done automatically once the workers are started.", "label": "human"}
{"ID": "00310128", "file_name": "Building a software system for teaching and learning English", "content": "–Operating System: macOS Monterey 12.5 –Processor: Apple M1 (ARM) –RAM: 16GB –Storage: 256GB Chapter SummariesThis chapter has covered system architecture, application development, and de ployment in depth. We also presented the components, use cases, user interface, database design, and tools we used during the software development life cycle.", "label": "human"}
{"ID": "00310129", "file_name": "Building a software system for teaching and learning English", "content": "Lastly, we provided the project’s achievements, some test cases, and application deployment information. The following chapter will summarize my contributions to this project, as well as specific challenges and solutions we used to confrontthem.According to the design and development of the application described in Chap ter 4, in this chapter, we would like to discuss some challenging difficulties that we encountered while building the program, as well as the remedies we devised to increase product quality and user experience efficiency.", "label": "human"}
{"ID": "00310130", "file_name": "Building a software system for teaching and learning English", "content": "Problem From the chapter 4, we have mentioned about how the system implements theClean Architecture, and how the interfaces can help our application easy to main tain, thus expandable. As the application grow, there will be similar business logic that needs to be executed similarly, but not in the exact same way. Base classes are used in Object Oriented Programming (OOP) to take advantages of the Inheritance mechanism. Many class can derived from the base class, and inherit all the public and protected properties and methods from the parent class. One question is how we can get base classes that can cover the basic flows, without needing the child classes to overwrite completely the related methods in order to modify the businesslogic. Another one is about how we can optimize and prevent performance penal ties, since the performance of base classes affects heavily to the whole system.", "label": "human"}
{"ID": "00310131", "file_name": "Building a software system for teaching and learning English", "content": "Solution Normal base classes, even though can deal many different cases, are not veryflexible. My system is built on an entity oriented basis. Therefore each class usu ally attached directly to an Entity type. For example, the LessonService class is responsible for executing lesson related business logic. If we use a normal base class, it is nearly impossible to deal with all entity types, which make the class much less useful and inheritable.", "label": "human"}
{"ID": "00310132", "file_name": "Building a software system for teaching and learning English", "content": "Therefore, we decided to implements base classes by using generic class. With this approach, all the methods of base classes now can be abstracted through a generic class T. At this point, our base classes can used with any Entity types, as long as it is inherited from the BaseEntity class.", "label": "human"}
{"ID": "00310133", "file_name": "Building a software system for teaching and learning English", "content": "Below is an example of applying generic principle into implementing the base classes.Figure 5.1: Generic class exampleFigure 5.2: Generic class method example In the example is the Add method of BaseService class. If we want to declare a new service class, LessonService for example, we will let the new class extends BaseService<Lesson>, with the Lesson class is a child of BaseEntity. At this point, the Add method will take Lesson instead of T for executing, which is suitable for our requirements.", "label": "human"}
{"ID": "00310134", "file_name": "Building a software system for teaching and learning English", "content": "Taking in the Add methods again, even though code logic for saving a new in stance to our database might be the same across the application, business logic might be different. For example, validation before adding an lesson and an exercisehave both similarities and differences. The answer is straightforward: inside base class methods, there will be custom methods that allow child classes to override, allowing them to adjust the flow without completely rebuilding those routines.", "label": "human"}
{"ID": "00310135", "file_name": "Building a software system for teaching and learning English", "content": "Child classes can use the BeforeAdd, AfterAdd, and AsyncAfterAdd methods tocustomize the Add record flow. These approaches assist to dramatically boost de velopment speed, when a fully new business requirement can be satisfied simply by customizing and overwriting methods.", "label": "human"}
{"ID": "00310136", "file_name": "Building a software system for teaching and learning English", "content": "Restful APIs are provided by our server to the client application. A request withslow response time not only degrades the user experience, but it also has a signif icant impact on server resources. The longer a request takes to execute, the moreCPU, RAM and other resources will be used, which decreases the number of re quest can be handled at once by the server.", "label": "human"}
{"ID": "00310137", "file_name": "Building a software system for teaching and learning English", "content": "By using caching, server could respond instantly without querying the database or executing slow procedures. Using caching also mean that we have to clear and update the cache properly, ensure the integration of data.", "label": "human"}
{"ID": "00310138", "file_name": "Building a software system for teaching and learning English", "content": "Not every business logic requires real-time execution. Add new tasks for nonreal-time requirements to minimize server response time. For example, after cre ating a lesson, we might wish to make a flashcard collection based on that lesson.", "label": "human"}
{"ID": "00310139", "file_name": "Building a software system for teaching and learning English", "content": "Because the information used to create the flashcard collection is not necessary for the response, this operation may be classified as non-real-time. As a result, performing this in a separate task and allowing the response to be provided to the client significantly increases server response time. Functions like AsyncAfterAdd or AsyncAfterUpdate called inside a separate task, let the child classes to do things outside and not affecting the main flow.", "label": "human"}
{"ID": "00310140", "file_name": "Building a software system for teaching and learning English", "content": "With the addition of generic classes, our system has become entity-centric. A new business flow can be built by simply extending and overwriting the methods of base classes.", "label": "human"}
{"ID": "00310141", "file_name": "Building a software system for teaching and learning English", "content": "Caching and asynchronous processing aid in reducing server response time, particularly for slower queries, resulting in a substantially better experience for con sumers.5.2 Implementing authentication 5.2.1 ProblemIdentifying users across courses is required in a learning system. Json Web To kens (JWT) are one of the most widely used methods of authentication. The systemmay authenticate the user using JWT without storing the token itself. This also implies that once an access token is produced, anyone having that token gets full ac cess to the system as the original user until it is expired. This increases the danger of losing a token to attackers.", "label": "human"}
{"ID": "00310142", "file_name": "Building a software system for teaching and learning English", "content": "SolutionA possible way is to create a blacklist of tokens on the server. The main advan tage of JWTs is that they speed up session verification. We will lose that benefit if we keep a blacklist/deny list and have to query it with every API call.", "label": "human"}
{"ID": "00310143", "file_name": "Building a software system for teaching and learning English", "content": "Another solution, which is implemented in for my system, is to use short life span access tokens and refresh tokens. To overcome the risk of losing access token, they will have short life-spans. Therefore, if an attacker can get access to an user’s access token, it will be invalidated automatically in a very short amount of time.", "label": "human"}
{"ID": "00310144", "file_name": "Building a software system for teaching and learning English", "content": "However, using a short life-span token alone will cause the client application to be unauthorized constantly, and the user will have to re-login over and over again to get new access token.", "label": "human"}
{"ID": "00310145", "file_name": "Building a software system for teaching and learning English", "content": "A refresh token, which is stored in the server, is used for generating new access token. At this point, once the old access token becomes invalid, a refresh token will be sent to the server in order to getting the new access token, and this process will repeat constantly until the user has logged out. Comparing When Comparing storing refresh tokens and the access token blacklist, the blacklist must be accessedfor every request to the server, whereas the refresh token table only needs to be ac cessed for generating new access tokens, retaining all of the advantages in terms of both security and speed of access tokens. A refresh token could also be invalidated easily by deleting it from the server.", "label": "human"}
{"ID": "00310146", "file_name": "Building a software system for teaching and learning English", "content": "Implementing JWT authentication with refresh token, the server generates and returns the access token along with the refresh token when user first login. Refreshtokens are stored inside MySQL database. Client will use the access token to com municate with the server, until it get the response status of 401 - Unauthorized. At this stage, the response goes through a network interceptor. The interceptor take the refresh token, make a request to the server in order to get new access token, then try again with the unauthorized request. If the refresh token is invalid, the server will response with status 401, and user will be logged out.Figure 5.3: Client request interceptor handling 5.2.3 Result I successfully integrated JWT authentication with refresh token to my system,increase the system security, while keeping all the advantages of using access to kens.", "label": "human"}
{"ID": "00310147", "file_name": "Building a software system for teaching and learning English", "content": "ProblemAs mentioned in section 2.1, to overcome the weaknesses of some existing prod ucts on the market, our application will provide an English - Vietnamese dictionary.", "label": "human"}
{"ID": "00310148", "file_name": "Building a software system for teaching and learning English", "content": "Although taking this route is quick and easy, it eliminates our ability to connect our features to the lexicon. The data that is not saved in our system is tough to modify for other features.The ideal situation would be to store all of the structured data for terms in ourdatabase. There are suppliers who will let us use their dictionary data for our ap plication in exchange for a charge. That approach is suitable from a functional and legal standpoint. However, for the scope of this thesis, a workaround would be to collect data from various on sources and use it to create a sample dictionary for the system.", "label": "human"}
{"ID": "00310149", "file_name": "Building a software system for teaching and learning English", "content": "First, we need to collect the list of available English words. After researching, we found a free source code from Github, which give us a list of 370101 English words.", "label": "human"}
{"ID": "00310150", "file_name": "Building a software system for teaching and learning English", "content": "Then, we used Python and Scrapy for getting data for words inside the list. We tried scrapping data on 2 dictionary website: Laban Dictionary and VDict. The common characteristic of this website is that they do not use Restful API to fetch word data requests to the server, but using server-side rendering. Therefore, we can only access the data through the HTML rendered on the browser. The spider using to scrap these 2 website determine words mostly based on HTML classes attached to each elements. By analyzing and experiencing, we gathered words into a JSON file as following.", "label": "human"}
{"ID": "00310151", "file_name": "Building a software system for teaching and learning English", "content": "Our mission is to transform the JSON data that we have into records of these tables. For doing this task, we created a JavaScript project for manipulating the processed input data. For each word, we generate corresponding insert queries into the tables. After inserting, words will become available inside our dictionary.", "label": "human"}
{"ID": "00310152", "file_name": "Building a software system for teaching and learning English", "content": "The reason why we could not hit a higher mark is because the 2 chosen dictionaries lack many words. Moreover, the source file for words was not containing compound words, hence could not cover a bigger range of English.", "label": "human"}
{"ID": "00310153", "file_name": "Building a software system for teaching and learning English", "content": "The number of 75000 words is not ideal, but still perfectly good for developing our demo system.5.4 Pronunciation recognition and assessment 5.4.1 Problem For every language learner, knowing how to correctly pronounce a word is very important. To compete with other products on the market, an indispensable feature for English learning platforms is pronunciation assessing.", "label": "human"}
{"ID": "00310154", "file_name": "Building a software system for teaching and learning English", "content": "Solution With the limitation of this Thesis, we decided to go with a third party service that could help me deal with this problem. There are many paid services like Speechace can provide us with such features. After researching, we found out that Microsoft has the Azure Cognitive Services, which provides many speech-to-text features.", "label": "human"}
{"ID": "00310155", "file_name": "Building a software system for teaching and learning English", "content": "Since, we have free education Azure server, and they also native SDK for C devel opment, we decided to go with it.", "label": "human"}
{"ID": "00310156", "file_name": "Building a software system for teaching and learning English", "content": "First, we have to setup the environment for our Azure Cognitive Services. By following the documentation, we managed to run the service on our Azure server.", "label": "human"}
{"ID": "00310157", "file_name": "Building a software system for teaching and learning English", "content": "ResultThe pronunciation assessment features was successfully integrated to the sys tem, providing users a way to effectively self improve their English skills.", "label": "human"}
{"ID": "00310158", "file_name": "Building a software system for teaching and learning English", "content": "Problem Our system is currently quite monolithic. Too many tasks allowed in one process puts heavy loads on the server, and raises the possibility that one job may crash the entire system.", "label": "human"}
{"ID": "00310159", "file_name": "Building a software system for teaching and learning English", "content": "Solution To improve the system’s reliability and performance, it is a good idea to usemicroservices to handle complex and asynchronous operations. An individual mi croservice is a service that usually exists only for a single purpose, is self-contained and independent of other instances and services.", "label": "human"}
{"ID": "00310160", "file_name": "Building a software system for teaching and learning English", "content": "Microservices or modules are decoupled from each other but still able to com municate. Using message brokers is one way of communication. A message broker acts as a middleman for various services. They can be used to reduce loads and delivery times of web application servers by delegating tasks that would normally take up a lot of time or resources to a third party that has no other job. For our applications, we implemented RabbitMQ as the message broker.", "label": "human"}
{"ID": "00310161", "file_name": "Building a software system for teaching and learning English", "content": "Consider the email sending task: an email will be sent once the user successfully upgrades the account. If we place the sending email code in our main server, it will be sent whenever a user’s account is upgraded. The server’s resources will be diverted to the process of sending email, reducing its ability to handle new requests.", "label": "human"}
{"ID": "00310162", "file_name": "Building a software system for teaching and learning English", "content": "Not to mention, if the email server does not respond, our main server will suffer greatly, even though this is not a real-time operation.", "label": "human"}
{"ID": "00310163", "file_name": "Building a software system for teaching and learning English", "content": "Going toward our solution, we created a worker for sending email only named CrossLang.Worker.Email\".Figure 5.8: CrossLang.Worker.Email class diagramWorker class extends BackgroundService to be able to run as a background service on host machine. The worker calls Syncjob.Start() method to begin dequeu ing the message queue. This worker communicates with our main server using RabbitMQ on a publishing/consuming basis, where our main server will be thepublisher, and the worker will be the subscriber. At this point, instead of send ing the email directly, our main server will publish a structured message to theEmail\" queue on RabbitMQ. The worker, as the subscriber, dequeueing and exe cuting sending email logic on the message received.", "label": "human"}
{"ID": "00310164", "file_name": "Building a software system for teaching and learning English", "content": "Furthermore, one queue can be subscribed by more than one worker. Multiple in stance of the same worker can run at once to speed up the dequeuing process.", "label": "human"}
{"ID": "00310165", "file_name": "Building a software system for teaching and learning English", "content": "We used this approach to manage account subscriptions as another job. The database tables should be routinely checked for expired accounts. This operation should be done in a separate process so as not to interfere with our main server.", "label": "human"}
{"ID": "00310166", "file_name": "Building a software system for teaching and learning English", "content": "Although communicating with the main server is not necessary for this task, it does include sending emails to users notifying them that their accounts have expired. We let this process run as a cron job in a separate worker. With the aid of RabbitMQ, this worker may still publish a message to the \"Email\" queue, allowing the Email worker to carry out its duties. This illustration demonstrates how the Email worker may be used for several processes at once. By incorporating this approach into our system, we can improve both platform scalability and performance.", "label": "human"}
{"ID": "00310167", "file_name": "Building a software system for teaching and learning English", "content": "Result As stated, we were able to effectively implement RabbitMQ into our system as a message broker. Our server was divided up into smaller services that are morequickly scalable and prepared for future growth.", "label": "human"}
{"ID": "00310168", "file_name": "Building a software system for teaching and learning English", "content": "Chapter Summaries My contributions to the thesis are summarized in this chapter. In addition, we highlighted the difficulties we experienced during the process of development, along with my solutions. The final chapter, chapter 6, will include my reflections on the project and future works.6.1 Conclusion The fundamental platform met the requirements for a base service for on English learning, according to the results of implementing Graduation Thesis. We successfully created a system that allows anyone to learn English. The code was designed for ease of maintenance and scalability. At current stage, the system has successfully integrated a simplified version of the microservices.", "label": "human"}
{"ID": "00310169", "file_name": "Building a software system for teaching and learning English", "content": "Our platform currently offers users a dictionary that allows them to search for English words, observe definitions and usage in both Vietnamese and English, and assess their pronunciation. Furthermore, the site has a flashcard system for learningnew words. A user might even learn lessons from other categories and practice ex ercises after finishing a lesson. Teachers and administrators have their own section for managing content and users.", "label": "human"}
{"ID": "00310170", "file_name": "Building a software system for teaching and learning English", "content": "Building a heavy platform like this requires all different kinds of resources. The features that we made are just fundamental compared to the whole picture.", "label": "human"}
{"ID": "00310171", "file_name": "Building a software system for teaching and learning English", "content": "First, our plan was to finish the uncompleted features. For example, the cur rent system lacks a payment gate for making transaction. Without this feature, our system would not be able to earn profits.", "label": "human"}
{"ID": "00310172", "file_name": "Building a software system for teaching and learning English", "content": "Then, the application will update new E-Learning standards, new types of on  learning, and develop in accordance with those features and requirements. In addition, we also had plan to integrate the Notification feature for various functions such as account upgrading notification, expiration date reminder, and so on. Some types of practice will also be incorporated. I’m preparing to build some games tomake learning more fascinating, dynamic, and entertaining. Lastly, we want to im plement a live classroom feature in which students might study face-to-face with teachers according to the schedule they set up. L. Ceci, Language learning apps - statistics facts . [On]. Available: https:", "label": "human"}
{"ID": "00310173", "file_name": "Building a software system for teaching and learning English", "content": "Introduction to json web tokens . [On]. Available:  introduction (visited on 07/20/2022). Mysql documentation . [On]. Available:  doc/ (visited on 06/30/2022).", "label": "human"}
{"ID": "00320001", "file_name": "E-commerce platform: A module for suppliers", "content": "Currently, in the market, according to the trading model, a manufacturer will produce products, and distributors will import and sell to dealers. From there, retailers will bring products to consumers. The management of distributors andagents in practice is quite difficult. Among distributors, dealers have price differ ences, and the appearance of counterfeit goods does not guarantee product quality.", "label": "human"}
{"ID": "00320002", "file_name": "E-commerce platform: A module for suppliers", "content": "In addition, price is increase two or three times because intermediaries make prices, pickpocket\" consumers. Shoppers have few choices and suggestions and can’t tellthe difference between fakes. Solving these problems helps the market become sta ble, suppliers can manage distributors, and buyers are satisfied with the quality and amount of money spent.", "label": "human"}
{"ID": "00320003", "file_name": "E-commerce platform: A module for suppliers", "content": "However, price differences and counterfeit goods have not been taken care of. Most e-commerce platforms aren’t interested in distributors and dealers yet. On the side of customers, users are not concerned about the quality of products when shopping on. Distributors and agents do not have appropriate policies.", "label": "human"}
{"ID": "00320004", "file_name": "E-commerce platform: A module for suppliers", "content": "Therefore, I develop e-commerce that focuses on suppliers, distributors but still brings authentic products to the customer. My E-commerce creates an easy and convenient exchange of purchases. This e-commerce solves management issues of price increment when trading among distributors, maximum cut of intermediaries, bringing quality products to consumers. In addition, the suppliers can manage thedistributors bought their goods. This research focused on the module for the supplier in that e-commerce. The main functions of suppliers are managing their prod ucts, stock inventory, orders, and reports in this project.", "label": "human"}
{"ID": "00320005", "file_name": "E-commerce platform: A module for suppliers", "content": "It is necessary to create an e-commercial to help suppliers manage distributors and bring products to consumers. I generate a provider’s management software tohelp suppliers can manage their resources. Firstly, I thought about using microservice architecture. After research, I chose ASP.NET Boilerplate (ABP), an open source and well-documented application framework. This framework can help by offering a microservice-compatible, strict module architecture where your moduleis split into multiple layers/projects and developed independently. The system needsan API gateway as an intermediary between the client and the back-end system mi croservices. This gateway helps hide the structure of the microservices system fromthe outside and quickly tracks and manages traffic. For the user interface, I use bla zorise, a framework for building interactive client-side web UI. NET. For storage data, I decide to use MongoDB. The research provides the solution for managing suppliers in the e-commerce system.", "label": "human"}
{"ID": "00320006", "file_name": "E-commerce platform: A module for suppliers", "content": "The other parts of graduation research are organized as follows. Chapter 2 present the main functional and non-functional requirement of the project. It mentions a website for the supplier in an e-commerce system in a distributed architecture.", "label": "human"}
{"ID": "00320007", "file_name": "E-commerce platform: A module for suppliers", "content": "From the survey, I pointed out the critical business in this system and the detailedspecifications of each use case. This chapter also describes essential business pro cesses in the activity diagram.", "label": "human"}
{"ID": "00320008", "file_name": "E-commerce platform: A module for suppliers", "content": "Architecture design, detail design, application building, testing, and deployment are in chapter 4. Architecture design describes the software architecture with the supplement or improvement and the overall design project with a UML diagram.", "label": "human"}
{"ID": "00320009", "file_name": "E-commerce platform: A module for suppliers", "content": "In the detail design section, I provide a specific description of user interface de sign, layer design, and database design. The library and tools used in this project are mentioned in the application building section. In this section, the achievement and illustration of the main functions are also explicitly described. Testing is an indispensable part of this chapter. I design test cases for the essential tasks in this section and analyze testing results. Finally, the deployment section demonstrates the model and how to deploy the project in practice.", "label": "human"}
{"ID": "00320010", "file_name": "E-commerce platform: A module for suppliers", "content": "Finally, Chapter 5 is the conclusion of this project. This chapter is about the pro cess of working on this project, the difficulties of mine, and how to face and solve each difficulty, the upgrade. The experiment achievement and expensive lessons of mine are mentioned in this chapter.2.1 Status survey A small survey asking 20 people about their experience when shopping on showed that most of them had at least once bought a fake. In addition, some people have to wait half a month to receive their goods, and the shipping fee also affects their decision to order. If the shipping fee is small, they will complete the order quickly. Otherwise, they will consider the importance of the product and may not place the order.", "label": "human"}
{"ID": "00320011", "file_name": "E-commerce platform: A module for suppliers", "content": "The supplier wants to manage its product and the distributors in the market. Cur rently, on the market of e-commerce systems in Vietnam (such as Shopee, Lazada, Tiki, etc.), most of them are platforms for retailers and end consumers, so retailers will have to find their source of goods. That leads to unstable sources of goods,unknown origin, non-optimal import prices, and complicated transportation meth ods, for example, having a close source but having to import the same item fromafar. Therefore, it is necessary to have an e-commerce platform between the man ufacturer (where there is a stable, safe, and transparent source of goods) and the supplier and distributors.", "label": "human"}
{"ID": "00320012", "file_name": "E-commerce platform: A module for suppliers", "content": "Recently, similar platforms have appeared on the Vietnamese market. For exam ple, Telio is a platform that imports groceries or drugs from a distributor to a retail store. Or Alibaba is a place of direct exchange from factories or trading companiesto retailers or end users. As explained above, the value that these e-commerce plat forms bring is the ability to provide a stable source of goods, helping small and medium-sized commercial units not have a broken supply chain, and at the same time can source selection. With reasonable import prices and optimal shipping methods.", "label": "human"}
{"ID": "00320013", "file_name": "E-commerce platform: A module for suppliers", "content": "This research will make an e-commerce platform similar to the above, calledSoda. This project describes an e-commerce platform between Suppliers and Dis tributors and Customers. Customers buy goods from distributors, and the system will split orders into small orders by supplier. The closest distributors has enough goods to qualify for small order and accepts that the order will be prepared andgiven to delivery. Distributors have to buy items with a minimum quantity corresponding. Suppliers will prepare these orders and give them to deliver. This re search is a module for a supplier in the above e-commerce system. It includes the following features:•Manage resources for suppliers (including Inventory, Products, Orders, etc.).", "label": "human"}
{"ID": "00320014", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case request to be supplierThe suppliers must request to be suppliers by filling in all the required informa tion. After the request sends successfully, the System will send an email with the link to follow the recommendation.", "label": "human"}
{"ID": "00320015", "file_name": "E-commerce platform: A module for suppliers", "content": "When the admin rejects the request, System will send an email with the reason for rejection to the supplier. They can update the request with the link in the email.", "label": "human"}
{"ID": "00320016", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case request to be distributor Similar to a use case request to the supplier, the distributor who wants to join the system must create a request. And wait for the admin to approve it.", "label": "human"}
{"ID": "00320017", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case approve/reject the request Admin can approve or reject the request of the supplier. After approval, the system will send an email with account information to a supplier so that the supplier can log in to the system or if the reject system will send an email with a reason and link to update the request. Admin also has other actions with the supplier, such as blocking, editing information, and changing the password, but these use cases are not in this module. Admin can approve/reject the distributor request similar to the supplier’s request.", "label": "human"}
{"ID": "00320018", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case manage order Use case diagram of use case supplier manage order is show in figure 2.3 Figure 2.3: Use case manage order The supplier can view the distributor’s order, and they can accept or deny an order. If they take, they have to pick a stock with an amount for each item in the order. After preparing the order, they can change the order’s status to shipping.", "label": "human"}
{"ID": "00320019", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case view reports The supplier can view the report of the product and order. The supplier can export a file report in excel with the defined template in this use case.", "label": "human"}
{"ID": "00320020", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case update store name The supplier has a store name and website URL updated on the website. This information will appear in the view of the distributor, retailer, and customer.", "label": "human"}
{"ID": "00320021", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case reset password The supplier can reset their password. After resetting successfully, they can log in with the new password.", "label": "human"}
{"ID": "00320022", "file_name": "E-commerce platform: A module for suppliers", "content": "Use case forgot password When supplier forgets their password, they can use this function. After they submit the email, the system will send the link to reset the password in an email.", "label": "human"}
{"ID": "00320023", "file_name": "E-commerce platform: A module for suppliers", "content": "Business process The processing an order from beginning until delivered is describe as Figure 2.5:Figure 2.5: Activity diagram process an order As you can see, the distributor creates a valid order if the number of items is more significant than a minimum order quantity which is a product attribute.", "label": "human"}
{"ID": "00320024", "file_name": "E-commerce platform: A module for suppliers", "content": "Whenever distributors make an order, the supplier’s reserve quantity will be subs tract. The reserved amount is to guarantee enough stock inventory for other orders.", "label": "human"}
{"ID": "00320025", "file_name": "E-commerce platform: A module for suppliers", "content": "The supplier can take the items from many warehouses in enough quantity. There is a time limitation in accepting orders and preparing orders. If out of this time, the order will automatically be canceled. The distributor can cancel the order before it is delivered or if they do not receive a charge from the shipper. When an order is delivered, the stock inventory will update.2.3 Functional description 2.3.1 Description of Use case request to be supplier Brief Description : As a supplier, I want to join Soda e-commerce. I have to register to be supplier in website of supplier.", "label": "human"}
{"ID": "00320026", "file_name": "E-commerce platform: A module for suppliers", "content": "Actors :Supplier, Administrator, System Priority :Require Trigger(s) :When user select \"Đăng ký trở thành NCC\" in login page Precondition(s) :User access to login page Main flows is shown in table2.1:", "label": "human"}
{"ID": "00320027", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 1 User Submit the form 2 System Send email include the flowing link 3 Admin Accept request 4 System Send email include account information Table 2.1: Main flow of use case register to be supplier Alternative Flows is shown in table 2.2:", "label": "human"}
{"ID": "00320028", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 2a Admin Reject the request System Send email include the flowing link and reason Supplier Update the request and return to 2 Table 2.2: Alternative flow of use case register to be supplier 2.3.2 Description use case login Brief Description : As a supplier, I want to login into system.Actors :Supplier Priority :Require Precondition(s) :User already have account Main flows is described in table 2.3:", "label": "human"}
{"ID": "00320029", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 1 User Submit the login form 2 System Check the username and password 3 System Redirect into dashboard Table 2.3: Main flow of use case login Alternative Flows is described in table2.4:", "label": "human"}
{"ID": "00320030", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 1a User Submit forgot password System Redirect to forgot password page User Submit phone number or email System Check exist phone number or email System Send email with link to reset password User Submit the new password System Redirect to successfully reset password and return to 1 1c User Click on remember password System Save the token to storage and return dashboard Table 2.4: Alternative flow of use case login2.3.3 Description use case manage product a, Use case create product Brief Description : Supplier want to create their product Actors :Supplier Priority :Optional Trigger(s) :When user select \"Thêm mới sản phẩm\" in menu Precondition(s) :User login successfully into system as a supplier Main flows is in table 2.5:", "label": "human"}
{"ID": "00320031", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 1 Supplier Submit the form 2 System System check requirement field, return successful notification 3 System Redirect to list page Table 2.5: Main flow of use case create product Alternative Flows is in table 2.11:", "label": "human"}
{"ID": "00320032", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 1a User Submit to cancel System Redirect to previous page Table 2.6: Alternative flow of use case create product b, Use case delete product Brief Description : Supplier want to delete the product Actors :Supplier Priority :Optional Trigger(s) :When user click on button delete in list pagePrecondition(s) :User in list product page, has at least 1 product Main flows :", "label": "human"}
{"ID": "00320033", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 1 Supplier Submit delete product 2 System System check product in any order 3 System Notify delete successfully Table 2.7: Main flow of use case delete product Alternative Flows :", "label": "human"}
{"ID": "00320034", "file_name": "E-commerce platform: A module for suppliers", "content": "# Actor Action 2a System Product already in at least 1 order, system return error Table 2.8: Alternative flow of use case delete product c, Use case search product Brief Description : Supplier search product by name, code, warehouse, category Actors :Supplier Priority :Optional Trigger(s) :When user click into \"Danh sách sản phẩm\" in menu Precondition(s) :User login successfully into system as a supplier Main flows :# Actor Action 1 Supplier Submit filter 2 System Dislay list product with condition in filter Table 2.9: Main flow of use case search product 2.3.4 Description use case accept/deny an order Brief Description : Supplier want to accept/deny an order Actors :Supplier Priority :Optional Trigger(s) :When user in order detail page Precondition(s) :User have at least 1 order by distributor created Main flows :", "label": "human"}
{"ID": "00320035", "file_name": "E-commerce platform: A module for suppliers", "content": "Firstly the software should continuously operate correctly and responsively in any general cases. However, a slight drop in performance and response time is allowable in some exceptional cases. Implicitly stated, ideally, the response time for any tasks, with a moderate load, within the system is 1 second. But in the case of peak load, a response time of 3 seconds is permissible.", "label": "human"}
{"ID": "00320036", "file_name": "E-commerce platform: A module for suppliers", "content": "Thirdly, the system requires maintenance and development, so the architecture and source code should be good. Finally, the system requires a high-security level.3.1 Technology 3.1.1 HTML HTML, known as Hypertext Markup Language, is document-layout. It defines the syntax and placement of special embedded directions not displayed by thebrowser. Still, it tells it how to display the document’s content, including text, im ages, and other support media. HTML help to create a user interface in the browser.", "label": "human"}
{"ID": "00320037", "file_name": "E-commerce platform: A module for suppliers", "content": "JavaScriptJavaScript is an object-based language that uses prototype objects to model in heritance. Using JavaScript to create a dynamic page.", "label": "human"}
{"ID": "00320038", "file_name": "E-commerce platform: A module for suppliers", "content": "CSS describes how it should render elements on the screen, paper, speech, or othermedia. Use CSS because HTML and JavaScript are not enough to have a user friendly website. With CSS, I can style the website as I want.", "label": "human"}
{"ID": "00320039", "file_name": "E-commerce platform: A module for suppliers", "content": "BlazorBlazor lets you build interactive web UIs using C instead of JavaScript. Bla zor apps are composed of reusable web UI components implemented using C#, HTML, and CSS. Both client and server code is written in C#, allowing you toshare code and libraries. Blazor is a feature of ASP.NET, the popular web develop ment framework that extends the .NET developer platform with tools and libraries for building web apps.  Many frameworks help to create a user interface, such as reactjs, vuejs, etc. However, I chose blazorise because it is a new technology,using C#, which is also the language I write backend. In this research, I use bla zor Web Assembly. Many benefits come with using Web Assembly and, therefore, high-level programming languages in client-side Web development, such as ease of development and high performance of web applications. Web Assembly takesadvantage of current hardware capabilities to ensure the best speeds possible. An other benefit is that it provides client-side security. This is one of the weaknesses of JavaScript. Web Assembly provides better security than JavaScript by acting asboth the backend and frontend. Four major browsers currently support WebAssem bly: Chrome, Safari, Firefox, and Edge. We envision WebAssembly will gain more popularity in client-side web development in the near future.3.1.5 Abp framework ABP Framework offers an opinionated architecture to build enterprise softwaresolutions with best practices on top of the .NET and the ASP.NET Core platforms. It provides the fundamental infrastructure, production-ready startup templates, modules, themes, tooling, guides, and documentation to implement that architecture properly and automate the details and repetitive works as much as pos sible. ABP Framework can work with any UI framework such as Angular, MVCpage razor, and blazor. It can work with any database provider like entity frame work core, MongoDB, and dapper. I implement domain-driven design architecture.", "label": "human"}
{"ID": "00320040", "file_name": "E-commerce platform: A module for suppliers", "content": "There are a lot of features provided by the ABP Framework to achieve real-world scenarios easier, like Event Bus, Background Job System, Audit Logging, BLOB Storing, Data Seeding, and Data Filtering.  Abp is so suitable for micro-service,which is a technique applied in software that has an amount of user access simul taneously.", "label": "human"}
{"ID": "00320041", "file_name": "E-commerce platform: A module for suppliers", "content": "MongoDBBecause I chose abp framework, it only works with three database provider en tity frameworks core, MongoDB, and dapper. My problem is e-commerce, so I need a high database speed read data and more scalability. MongoDB is a No SQL database that stores data in JSON-like documents with dynamic schema. Therefore, it simplifies data integration and offers better scalability than traditional relational databases.", "label": "human"}
{"ID": "00320042", "file_name": "E-commerce platform: A module for suppliers", "content": "The system requires many users to want to get data at the same time with a good response time. The response time is not guaranteed if I only use the database to store. Elastic search is an open-source search engine built on top of Apache Lucene, a full-text search library. Lucene is arguably the most advanced, high-performance, fully featured search engine library today- both open source and proprietary. Elastic search provides a distributed real-time document store where every field is indexedand searchable, distributed search engine with real-time analytics, capable of scal ing hundreds of servers and petabytes of structured and unstructured data.  3.1.8 RabitMqAs mentioned before, this project uses microservice architecture. To communi cate among microservice, I use the message to send. When I have a lot of notesat the same time, how can I control it? I found that RabitMQ is the solution. Rab bitMQ is one of the most popular open source message brokers. Message brokers isan intermediary program designed to validate, transform and route messages. It isto serve the communication among services. RabitQM helps the service send a re sponse for each request quickly instead of running a procedure that takes resources of the system. Pushing messages in a queue is a solution when I want to distribute the message to many receivers and reduce work for workers. At the same time, so many suppliers click to submit to request to be suppliers. So many requests sent to the server will cause problems such as slowness, overload, congestion, etc We need RabitMq to push requests in queue in the mechanism in figure 3.1:", "label": "human"}
{"ID": "00320043", "file_name": "E-commerce platform: A module for suppliers", "content": "Redis Redis, a remote dictionary server, is an open source to save structure data and can be used as a database, cache, or message broker. It protects data in structure key-value in RAM, arranges, queries, and backups data in disk, helping backup data when the system is in trouble.", "label": "human"}
{"ID": "00320044", "file_name": "E-commerce platform: A module for suppliers", "content": "Redis can be used as cache, counter, publish/subscriber, and queues. Because of the speed of reading, data can be used as a cache, sharing data between services or temporary databases. It can be used as a counter. Redis supports thread-safe so that it can be synchronous among requests. Redis support creates a channel to exchange data between publisher and subscriber. Finally, it is used to create a queue for requests. For this research, I use Redis to create a queue and as a cache to increase read data speed.", "label": "human"}
{"ID": "00320045", "file_name": "E-commerce platform: A module for suppliers", "content": "S3 S3 stands for Amazon’s simple storage service. S3 provides infinite scalabilityand high availability at a low cost. Currently, S3 is used mostly to store multi-media documents (videos, photos, audio) shared by a community of people and rarely updated. This paper aims to demonstrate the opportunities and limitations of using S3 as a storage system for general-purpose database applications involving small objects and frequent updates. Read, write, and commit protocols are presented.", "label": "human"}
{"ID": "00320046", "file_name": "E-commerce platform: A module for suppliers", "content": "Furthermore, such a storage system’s cost, performance, and consistency properties are studied. 4.1 Architecture design 4.1.1 Software architecture selection For software architecture, I chose microservices architecture. Micro-services isa software system development method in which different single-function appli cations are coupled together. Because the system expects thousands of users to access the system simultaneously, with massive data, it is easy to be stuck, fallingdown the server at any time. Using monolithic architecture requires massive sup per storage and high configuration to guarantee a maximum response time of fewer than 3 seconds. The advantage of microservices is that each service can be scaled independently without disrupting the others. Because it is a distributed system, a microservices framework is highly scalable and can avoid the bottlenecks of a monolithic architecture.", "label": "human"}
{"ID": "00320047", "file_name": "E-commerce platform: A module for suppliers", "content": "The system has many microservices: auth service, sales service, partnership service, warehouse service, shipping service, etc., and one gateway called web Gate Way service. Each microservice is build base on domain-driven design principles and patterns. Domain-driven design principles are new architecture that includes 3 layers:", "label": "human"}
{"ID": "00320048", "file_name": "E-commerce platform: A module for suppliers", "content": "This is the heart of the applicationApplication layer: mediates between the Presentation and Domain Layers. Or chestrates business objects to perform specific application tasks. Implements use cases as the application logic.", "label": "human"}
{"ID": "00320049", "file_name": "E-commerce platform: A module for suppliers", "content": "DDD is mostly interested in the Domain and the Application layers rather than the Infrastructure and the Presentation layers. Apply architecture, the project had a little change follow abp framework. The domain layer in this research includesDomain, Domain.Shared, DbMigrator, MongoDB project. Dbmigrator layer to mi grate database and seed data if needed. MongoDB project has context to connect to database and repository interface. The repository is an intermediary layer to gettingdata in an entity. This layer reduces the dependence of the business model on stor age technology and enhances the ability to upgrade and replace technology when necessary. Domain project includes entity and implementation of repository inter-face in MongoDB project. Domain shared has constant, enum,.. that all layers can access. The application layer contains Application and Application.Contract. The http layer includes Http.Api, Http.Client, Http.Host. These layers are to provide an environment for the client to call remote HTTP services.", "label": "human"}
{"ID": "00320050", "file_name": "E-commerce platform: A module for suppliers", "content": "Overall design The UML package diagram of subsystem is shown in figure 4.1 Figure 4.1: UML package diagram of subsystem Package web has 1 package publishing web which contain the project of user interface application. Publishing web dependence with webbff package in gatewayand report package in services.", "label": "human"}
{"ID": "00320051", "file_name": "E-commerce platform: A module for suppliers", "content": "Commons package as it name, it contain everything can be reused by services .It includes 2 package are Application and Domains. Applications contains statistic class in common and Domains contain class in common.", "label": "human"}
{"ID": "00320052", "file_name": "E-commerce platform: A module for suppliers", "content": "The modules package contains two modules infrastructure and master data. Inaddition, infrastructure contains modules like elastic search modules, clock mod ules, helper modules, and mass transit. Master data contains projects for geometries and setting of system.", "label": "human"}
{"ID": "00320053", "file_name": "E-commerce platform: A module for suppliers", "content": "Services contain all microservices in the system: authentic, partnership, warehouse, sales, shipping, reviews, and report service. The responsibility of Each ser vice with a specific business. Auth service is to authenticate user and server. There is a list of servers allowed to access the system, defined by the setting. Auth service validates the user account information and generate and save token from enabling the client to access the system. Partnership service responsibility on the business of the actor’s information such as register to be the supplier and approved supplier, register to be a distributor and approve distributor, etc Warehouse management is the most important part of warehouse service. It is responsibility with the business relate to managing warehouse and stock inventory, and assurance stock inventory is always enough for all orders accepted. Shipping service in this project is quite simple with the business of user’s shipping address and change state of order to shipping. Perform order-related tasks is in sales service.", "label": "human"}
{"ID": "00320054", "file_name": "E-commerce platform: A module for suppliers", "content": "In gateway package contain webbff package which is work as a gateway for system. It dependents all micro services in services package.", "label": "human"}
{"ID": "00320055", "file_name": "E-commerce platform: A module for suppliers", "content": "figure 4.2 is sample UML package diagram of service reviews:Figure 4.2: UML package diagram of 1 micro service Application in webbff depends on application contract of micro services if it need. While The Http.Client in webbff depend on all http.client of micro service.", "label": "human"}
{"ID": "00320056", "file_name": "E-commerce platform: A module for suppliers", "content": "In each micro service application package depend on common, modules if it need to use any class in these package.In each package of micro service, there are 9 small package. These relations package is created base on domain driven design principle and pattern of abp framework. Domain layer include domain share, domain package, DbMigrator and MongoDb. Domain share contains constants, enum or other type can be safely share with all layers. This package can also be shared to 3rd-party clients. Domain package contains domain service interfaces and domain objects. Domain packagedepends on the Domain.Shared package. Dbmigrator is to migrate database to syn chronous object between objects in domains and in database. It also can be use to seed data. Mongodb contain connection string to connect with database, and implementation of domain service interface.", "label": "human"}
{"ID": "00320057", "file_name": "E-commerce platform: A module for suppliers", "content": "Application layer includes Application.Contracts and Application packages. Ap plication.Contracts contain contains application service interfaces and related datatransfer objects. Application.Contracts depends on Domains.Shared package. Application package contains application service implementations.Application pack age depends on the Domain and the Application.Contracts packages.", "label": "human"}
{"ID": "00320058", "file_name": "E-commerce platform: A module for suppliers", "content": "Http.Client and Http.Api is in Http layer. Http.API package to develop a RESTstyle HTTP API for service, depends on Application.Constracts. It contains con troller for each application service (generally by implementing their interfaces).", "label": "human"}
{"ID": "00320059", "file_name": "E-commerce platform: A module for suppliers", "content": "These controllers uses the application service interfaces to delegate the actions. It just configures routes, HTTP methods and other web related stuffs if needed. HttpApi client to provide client services for the HTTP API package. Those client ser vices implement application interfaces as clients to a remote endpoint.HTTP API Client package only depends on the Application.Contracts package.  4.1.3 Detailed package design Detailed package of use case request to be supplier is in figure 4.3 below:Figure 4.3: Detail package design use case register to be supplierI use Dependency Injection pattern for project, example in use case request to be supplier. As mention in overall design, all class in services of package Application implement services in Application.Contracts. Client in user interface application service use interfaces in Application.Contracts by using dynamic client proxy of abp framework instead of calling API thought http request.", "label": "human"}
{"ID": "00320060", "file_name": "E-commerce platform: A module for suppliers", "content": "Service SupplierRegistrationApplicationService used interface SupplierApproveRegisterResponse in command package, this interface is used in SupplierApproveReg isterRequestProxy. SupplierApproveRegisterRequestProxy extends RoutingSlipProxy,it implement build routing slip adding activities which implements IActivity in terface. All requests in routing slip is in queue and they will be send to suitable consumer to handle request.", "label": "human"}
{"ID": "00320061", "file_name": "E-commerce platform: A module for suppliers", "content": "Number of colors supported: 16,777,216 colors Screen Location of standard buttons: At the bottom right (vertically) and in the middle (horizontally) of the frame.", "label": "human"}
{"ID": "00320062", "file_name": "E-commerce platform: A module for suppliers", "content": "Consistency in expression of alphanumeric numbers: comma for separator of thousand while strings only consist of characters, digits, commas, dots, spaces, underscores, and hyphen symbol Control Size of the text: medium size (mostly 16px). Font: Averta,Regular. Color:", "label": "human"}
{"ID": "00320063", "file_name": "E-commerce platform: A module for suppliers", "content": "#333333 Input check process: Should check if it is empty or not. Next, check if the input is in the correct format or not Below are some image of user interface design:Figure 4.4: success message Figure 4.5: warning message Figure 4.6: reset password page4.2.2 Layer design a, Sequence diagram of use case register to be supplier Sequence diagram of use case register to be supplier is described in figure 4.7 below:", "label": "human"}
{"ID": "00320064", "file_name": "E-commerce platform: A module for suppliers", "content": "Sequence diagram of use case manage warehouse Suppliers will have many warehouses in different locations. Figure 4.8 below described how they can manage warehouses in system.Figure 4.8: Sequence diagram of use case manage warehouse The supplier can create a warehouse. When they submit the request, the system validates the input and notifies them if they have an error. If it is a valid form, the system will create a warehouse and inform the result of an action. Suppliersalso can view the warehouse list. The system will take all warehouses of that sup plier to show on the page. They can search warehouses by name and view detailed warehouse information. When suppliers want to delete the warehouse, they have to guarantee that the warehouse is empty. That means there are not any products in that warehouse. If not, the system will return an error.", "label": "human"}
{"ID": "00320065", "file_name": "E-commerce platform: A module for suppliers", "content": "Sequence diagram of use case update product Figure 4.9: Sequence diagram of use case update productSuppliers can update product as described in figure 4.9. When they request to update a product, the system will check if any new images or videos will upload to blob storage. After that, the system will update the product information in the database and elastic search. Finally, the system updates the stock inventory of that product. If the process has any error, the system will roll back all action and notify to user.", "label": "human"}
{"ID": "00320066", "file_name": "E-commerce platform: A module for suppliers", "content": "Database design a, Service authentication The database of authentication service I used the default of abp framework. In figure 4.10 I only show the most important table and usually be used.", "label": "human"}
{"ID": "00320067", "file_name": "E-commerce platform: A module for suppliers", "content": "Service partnership ER diagram of partnership service is figure 4.13Figure 4.13: ER diagram of partner ship serviceA supplier is created from a supplier request. Suppliers save supplier informa tion. Distributors protect distributor information. Suppliers and distributors can have a business attribute. Access table saves users’ access time in the supplier store group by date.", "label": "human"}
{"ID": "00320068", "file_name": "E-commerce platform: A module for suppliers", "content": "Libraries and Tools The libraries and tool is show in table4.1Purpose Tool URL address IDE coding Visual studio 2022  Backend framework ASP.Net core 6.0  UI library AntdBlazor v0.11.0  UI library Blazorise.Boostrap5 v1.0.4  Validate phone number libphonenumber-csharp v8.12.45  src=template Backend code Abp package v5.1.4  Generate excel file NPOI v2.5.6  Mass transit Masstransti package v7.3.1  Elastic search Nest package v7.12.1  src=template Send email Volo.Abp.Mailkit v5.1.4  Support media storage Volo.Abp.BlodStoring v5.1.4  Log Serilog.AspNetCore v4.1.0  Table 4.1: List of libraries and tools 4.3.2 Achievement The result of this study is a website subsystem of an e-commerce platform on sales and purchase channels between suppliers and distributors, helping both to have optimal solutions in trade. In addition, this website also allows the parties to manage their resources and business activities on one platform.", "label": "human"}
{"ID": "00320069", "file_name": "E-commerce platform: A module for suppliers", "content": "Number of lines of code: 322329 Number of executed line code: 85785 Number of classes : 10473 Number of interface : 182 Number of packages :92 Number of projects :64 4.3.3 Illustration of main functions a, Login page The login page is in figure 4.14Figure 4.14: Login page Sceen specification of login page is in table 4.2 and define attribute fields in table 4.3 Control Operation Function Area for input tax code Required Input the tax code Area for input password Required Input the password Button login Initial Direct to home page Button register Initial Direct to register page Button forgot password Initial Direct to forgot password page Button remember me Initial Remember token to next access Table 4.2: Screen specification of login page Item name Number of digits Type Taxcode 200 Text Password 16 Text Table 4.3: Define attribute field of login pageb, Register pageRegister page is in figure 4.15, screen specification in table4.4 and defined at tribute fields in table 4.5 below:", "label": "human"}
{"ID": "00320070", "file_name": "E-commerce platform: A module for suppliers", "content": "Testing result is in table 4.14# Functionality Test Pass 1 Create request to be supplier 4 3 2 Admin accept request of supplier 4 3 3 Admin deny request of supplier 3 3 4 Admin deny request of supplier 3 3 5 Admin deny request of supplier 3 3 6 Supplier create product 4 3 7 Supplier delete product 2 2 8 Supplier update product 2 2 9 Supplier accept a order 2 2 Table 4.14: Testing result The test case does not pass because the network connection and server are down.", "label": "human"}
{"ID": "00320071", "file_name": "E-commerce platform: A module for suppliers", "content": "My computer does not have enough performance to build all microservice at the same time. That leads server being down then response time is out of time.", "label": "human"}
{"ID": "00320072", "file_name": "E-commerce platform: A module for suppliers", "content": "In reality, for deployment, the system needs at least two domains: gateway and user interface application. A server has storage of up to 80GB. The system needs to register some services of Elastic search, mongo cloud storage, and media storage.5.1 Conclusion Choosing this topic for graduation research is a challenge for me because I havenot had any experience with thousand users, especially e-commerce systems. However, I always want to learn new things and new techniques. In the process of work ing on this research, I stuck a lot of time.", "label": "human"}
{"ID": "00320073", "file_name": "E-commerce platform: A module for suppliers", "content": "Firstly, the challenge of new techniques and the framework for front-end and back-end are new for me. They also are new techniques, especially blazor. The documents and the examples project of blazor are pretty small. I spent a lot of time reading the document and the framework’s source code to understand it. I learned a lot of techniques when using abp frameworks, such as domain-driven design patterns, dependency injection patterns, singleton patterns, etc., and applied them to this project. I might not learn these things if I had chosen the framework in graduation research one and two.", "label": "human"}
{"ID": "00320074", "file_name": "E-commerce platform: A module for suppliers", "content": "Secondly, I have no experience working with NoSQL, especially MongoDB. As you know, mongo DB stores data in JSON-like documents. It is so different from the SQL server I have learned at this university. The design database for the SQL server is different from the database in MongoDB too. I had changed the data model so many times to get the final version. The difference in a query put the work at a standstill. However, after searching and reading the documentation, I finally got the solutions.", "label": "human"}
{"ID": "00320075", "file_name": "E-commerce platform: A module for suppliers", "content": "In graduation research 2, I stored the image in google drive, then got the public URL to return to the website. But this research, I cannot use the old way because the storage of google drive of an account is limited. It is not high security with an e-commerce system. I thought I should have a storage system to store the media.", "label": "human"}
{"ID": "00320076", "file_name": "E-commerce platform: A module for suppliers", "content": "Amazon service solved my problem. I found s3, which is a service of amazon to storage media. Amazon S3 supports both server-side encryption and client-side encryption for data uploads. Amazon S3 offers flexible security features to block unauthorized users from accessing your data.", "label": "human"}
{"ID": "00320077", "file_name": "E-commerce platform: A module for suppliers", "content": "After learning distributed system course and reading the requirement of all e commerce systems, I know that this system must be in a microservice architecture.", "label": "human"}
{"ID": "00320078", "file_name": "E-commerce platform: A module for suppliers", "content": "However, this is the first time of mine worked with a micro-service. It takes me a lot of time to make the gateway work. The problem is communications among micro-services. How can I take data from another service? The gateway in thisproject also is responsible for aggregating data from micro-services to return to the client. However, when the transaction requires other micro-services works, for example, in the case of accepting a supplier’s order, it requires the sale service to change the order state and the warehouse service to update the reserve quantity in each stock. Abp framework support event bus combined with routing slip of mass transit, so that from sale service, the system can send message to warehouse to update reserve quantity in one transaction. If one event fails, a transaction will roll back. I can follow the queue of the message by using rabitmq.", "label": "human"}
{"ID": "00320079", "file_name": "E-commerce platform: A module for suppliers", "content": "When the System has many redundant data such as in table supplier request. In case requests are no longer to approved because of some reasons. What should I do to save admin work? I thought, I will reject all request if exist a setting time.", "label": "human"}
{"ID": "00320080", "file_name": "E-commerce platform: A module for suppliers", "content": "After searching, I decided to use background job.The framework provide the class HangfireBackgroundWorkerBase so that I can create my worker inherited it. Then register this service to module of partnership host. It is a first time of mine working with it. I faced with simple case so that it is pretty good.", "label": "human"}
{"ID": "00320081", "file_name": "E-commerce platform: A module for suppliers", "content": "I had no idea face with the requirement of response time for reading and search ing data. The system is for Vietnamese people. Therefore it should allow search words with no accents. In addition, the search time should be fast as possible. Only using MongoDB can not solve this problem. However, I remembered the critical word \"elastic search\" when I learned machine learning course. After reading the document, this technique will solve the problem of searching data both in response time and with no accent words. Despite that, elastic search require its library to read and write data. That leads to a problem with using the new library . NET.", "label": "human"}
{"ID": "00320082", "file_name": "E-commerce platform: A module for suppliers", "content": "Until now, the system can get, write, read, and search data in elastic search, but I felt that I had just discovered a small part of elastic search.", "label": "human"}
{"ID": "00320083", "file_name": "E-commerce platform: A module for suppliers", "content": "By passing all the difficulties when working in this research, the result is a sub system of the supplier in an e-commerce system. The software is created based onsimilar software, updated following specific businesses requirement. These sub systems help supplier manage their resource, orders, and views of the report. It has great significance in management resources.", "label": "human"}
{"ID": "00320084", "file_name": "E-commerce platform: A module for suppliers", "content": "Firstly, I applied theoretical knowledge from courses in the Hanoi university of science and technology to the actual software. I had a deeper understanding of what had been learned. Secondly, I learned a lot of new techniques and improved my reading skill, my ability to work independently, and my ability to explore and create.5.2 Future work In the future, to complete the subsystem of the supplier, firstly, the project should be integrated with a shipping system and payment system to complete the life cycle from the distributor placing an order to the supplier receiving the money for that order. Secondly, the project should extend the warehouse service into a warehouse system to track each product. The warehouse system helps reduce the situation of buying and selling counterfeit goods. Moreover, for e-commerce, subsystems for distributors, retailers, and customers should be complete in the future. C. Musciano and B. Kennedy, HTML & XHTML: The Definitive Guide: The Definitive Guide . \" O’Reilly Media, Inc.\", 2002.", "label": "human"}
{"ID": "00320085", "file_name": "E-commerce platform: A module for suppliers", "content": "N. Burkhart, W. Liao, and O. Guzide, “An overview of webassembly,” Pro ceedings of the West Virginia Academy of Science , vol. 92, no. 1, 2020.", "label": "human"}
{"ID": "00320086", "file_name": "E-commerce platform: A module for suppliers", "content": "C. Gormley and Z. Tong, Elasticsearch: the definitive guide: a distributed real-time search and analytics engine . \" O’Reilly Media, Inc.\", 2015.", "label": "human"}
{"ID": "00320087", "file_name": "E-commerce platform: A module for suppliers", "content": "M. Brantner, D. Florescu, D. Graf, D. Kossmann, and T. Kraska, “Building a database on s3,” in Proceedings of the 2008 ACM SIGMOD international conference on Management of data , 2008, pp. 251–264.", "label": "human"}
